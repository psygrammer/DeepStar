{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 frozenlake_naive.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gym\n",
    "import gym.spaces\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 16\n",
    "PERCENTILE = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드를 재활용하기 위해서 gym의 ObservationWrapper를 DiscreteOneHotWrapper 클래스에 상속시킨다.\n",
    "class DiscreteOneHotWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super(DiscreteOneHotWrapper, self).__init__(env)\n",
    "        assert isinstance(env.observation_space, gym.spaces.Discrete)\n",
    "        self.observation_space = gym.spaces.Box(0.0, 1.0, (env.observation_space.n, ), dtype=np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        res = np.copy(self.observation_space.low)\n",
    "        res[observation] = 1.0\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, obs_size, hidden_size, n_actions):\n",
    "        super(Net, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Episode = namedtuple('Episode', field_names=['reward', 'steps'])\n",
    "EpisodeStep = namedtuple('EpisodeStep', field_names=['observation', 'action'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_batches(env, net, batch_size):\n",
    "    batch = []\n",
    "    episode_reward = 0.0\n",
    "    episode_steps = []\n",
    "    obs = env.reset()\n",
    "    sm = nn.Softmax(dim=1)\n",
    "    while True:\n",
    "        obs_v = torch.FloatTensor([obs])\n",
    "        act_probs_v = sm(net(obs_v))\n",
    "        act_probs = act_probs_v.data.numpy()[0]\n",
    "        action = np.random.choice(len(act_probs), p=act_probs)\n",
    "        next_obs, reward, is_done, _ = env.step(action)\n",
    "        episode_reward += reward\n",
    "        episode_steps.append(EpisodeStep(observation=obs, action=action))\n",
    "        if is_done:\n",
    "            batch.append(Episode(reward=episode_reward, steps=episode_steps))\n",
    "            episode_reward = 0.0\n",
    "            episode_steps = []\n",
    "            next_obs = env.reset()\n",
    "            if len(batch) == batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "        obs = next_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_batch(batch, percentile):\n",
    "    rewards = list(map(lambda s: s.reward, batch))\n",
    "    reward_bound = np.percentile(rewards, percentile)\n",
    "    reward_mean = float(np.mean(rewards))\n",
    "\n",
    "    train_obs = []\n",
    "    train_act = []\n",
    "    for example in batch:\n",
    "        if example.reward < reward_bound:\n",
    "            continue\n",
    "        train_obs.extend(map(lambda step: step.observation, example.steps))\n",
    "        train_act.extend(map(lambda step: step.action, example.steps))\n",
    "\n",
    "    train_obs_v = torch.FloatTensor(train_obs)\n",
    "    train_act_v = torch.LongTensor(train_act)\n",
    "    return train_obs_v, train_act_v, reward_bound, reward_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: loss=1.390, reward_mean=0.0, reward_bound=0.0\n",
      "1: loss=1.356, reward_mean=0.0, reward_bound=0.0\n",
      "2: loss=1.348, reward_mean=0.0, reward_bound=0.0\n",
      "3: loss=1.352, reward_mean=0.0, reward_bound=0.0\n",
      "4: loss=1.277, reward_mean=0.0, reward_bound=0.0\n",
      "5: loss=1.288, reward_mean=0.1, reward_bound=0.0\n",
      "6: loss=1.242, reward_mean=0.1, reward_bound=0.0\n",
      "7: loss=1.122, reward_mean=0.0, reward_bound=0.0\n",
      "8: loss=1.195, reward_mean=0.0, reward_bound=0.0\n",
      "9: loss=1.045, reward_mean=0.0, reward_bound=0.0\n",
      "10: loss=1.045, reward_mean=0.0, reward_bound=0.0\n",
      "11: loss=1.038, reward_mean=0.0, reward_bound=0.0\n",
      "12: loss=0.958, reward_mean=0.0, reward_bound=0.0\n",
      "13: loss=0.958, reward_mean=0.0, reward_bound=0.0\n",
      "14: loss=0.949, reward_mean=0.0, reward_bound=0.0\n",
      "15: loss=0.914, reward_mean=0.0, reward_bound=0.0\n",
      "16: loss=0.973, reward_mean=0.0, reward_bound=0.0\n",
      "17: loss=0.921, reward_mean=0.0, reward_bound=0.0\n",
      "18: loss=0.890, reward_mean=0.0, reward_bound=0.0\n",
      "19: loss=0.866, reward_mean=0.0, reward_bound=0.0\n",
      "20: loss=0.865, reward_mean=0.0, reward_bound=0.0\n",
      "21: loss=0.891, reward_mean=0.0, reward_bound=0.0\n",
      "22: loss=0.893, reward_mean=0.0, reward_bound=0.0\n",
      "23: loss=0.784, reward_mean=0.0, reward_bound=0.0\n",
      "24: loss=0.862, reward_mean=0.0, reward_bound=0.0\n",
      "25: loss=0.837, reward_mean=0.0, reward_bound=0.0\n",
      "26: loss=0.785, reward_mean=0.0, reward_bound=0.0\n",
      "27: loss=0.819, reward_mean=0.0, reward_bound=0.0\n",
      "28: loss=0.759, reward_mean=0.0, reward_bound=0.0\n",
      "29: loss=0.896, reward_mean=0.1, reward_bound=0.0\n",
      "30: loss=0.781, reward_mean=0.0, reward_bound=0.0\n",
      "31: loss=0.766, reward_mean=0.0, reward_bound=0.0\n",
      "32: loss=0.834, reward_mean=0.1, reward_bound=0.0\n",
      "33: loss=0.651, reward_mean=0.0, reward_bound=0.0\n",
      "34: loss=0.889, reward_mean=0.0, reward_bound=0.0\n",
      "35: loss=0.865, reward_mean=0.1, reward_bound=0.0\n",
      "36: loss=0.716, reward_mean=0.0, reward_bound=0.0\n",
      "37: loss=0.843, reward_mean=0.0, reward_bound=0.0\n",
      "38: loss=0.880, reward_mean=0.0, reward_bound=0.0\n",
      "39: loss=0.823, reward_mean=0.0, reward_bound=0.0\n",
      "40: loss=0.782, reward_mean=0.0, reward_bound=0.0\n",
      "41: loss=1.083, reward_mean=0.1, reward_bound=0.0\n",
      "42: loss=0.861, reward_mean=0.0, reward_bound=0.0\n",
      "43: loss=0.949, reward_mean=0.0, reward_bound=0.0\n",
      "44: loss=0.872, reward_mean=0.0, reward_bound=0.0\n",
      "45: loss=0.970, reward_mean=0.0, reward_bound=0.0\n",
      "46: loss=1.076, reward_mean=0.0, reward_bound=0.0\n",
      "47: loss=1.002, reward_mean=0.0, reward_bound=0.0\n",
      "48: loss=0.978, reward_mean=0.0, reward_bound=0.0\n",
      "49: loss=1.007, reward_mean=0.0, reward_bound=0.0\n",
      "50: loss=0.976, reward_mean=0.0, reward_bound=0.0\n",
      "51: loss=1.042, reward_mean=0.0, reward_bound=0.0\n",
      "52: loss=1.052, reward_mean=0.1, reward_bound=0.0\n",
      "53: loss=0.985, reward_mean=0.0, reward_bound=0.0\n",
      "54: loss=1.084, reward_mean=0.1, reward_bound=0.0\n",
      "55: loss=1.012, reward_mean=0.0, reward_bound=0.0\n",
      "56: loss=1.029, reward_mean=0.0, reward_bound=0.0\n",
      "57: loss=1.022, reward_mean=0.0, reward_bound=0.0\n",
      "58: loss=1.060, reward_mean=0.0, reward_bound=0.0\n",
      "59: loss=1.043, reward_mean=0.0, reward_bound=0.0\n",
      "60: loss=0.936, reward_mean=0.0, reward_bound=0.0\n",
      "61: loss=0.996, reward_mean=0.0, reward_bound=0.0\n",
      "62: loss=0.946, reward_mean=0.0, reward_bound=0.0\n",
      "63: loss=0.903, reward_mean=0.1, reward_bound=0.0\n",
      "64: loss=0.941, reward_mean=0.0, reward_bound=0.0\n",
      "65: loss=0.960, reward_mean=0.0, reward_bound=0.0\n",
      "66: loss=0.919, reward_mean=0.0, reward_bound=0.0\n",
      "67: loss=0.873, reward_mean=0.0, reward_bound=0.0\n",
      "68: loss=0.827, reward_mean=0.0, reward_bound=0.0\n",
      "69: loss=0.815, reward_mean=0.0, reward_bound=0.0\n",
      "70: loss=0.860, reward_mean=0.0, reward_bound=0.0\n",
      "71: loss=0.791, reward_mean=0.0, reward_bound=0.0\n",
      "72: loss=0.805, reward_mean=0.0, reward_bound=0.0\n",
      "73: loss=0.843, reward_mean=0.0, reward_bound=0.0\n",
      "74: loss=0.886, reward_mean=0.0, reward_bound=0.0\n",
      "75: loss=0.804, reward_mean=0.0, reward_bound=0.0\n",
      "76: loss=0.852, reward_mean=0.0, reward_bound=0.0\n",
      "77: loss=0.975, reward_mean=0.0, reward_bound=0.0\n",
      "78: loss=0.874, reward_mean=0.0, reward_bound=0.0\n",
      "79: loss=0.927, reward_mean=0.0, reward_bound=0.0\n",
      "80: loss=0.928, reward_mean=0.0, reward_bound=0.0\n",
      "81: loss=1.017, reward_mean=0.0, reward_bound=0.0\n",
      "82: loss=0.950, reward_mean=0.0, reward_bound=0.0\n",
      "83: loss=1.073, reward_mean=0.1, reward_bound=0.0\n",
      "84: loss=1.015, reward_mean=0.0, reward_bound=0.0\n",
      "85: loss=1.056, reward_mean=0.0, reward_bound=0.0\n",
      "86: loss=1.122, reward_mean=0.0, reward_bound=0.0\n",
      "87: loss=1.088, reward_mean=0.0, reward_bound=0.0\n",
      "88: loss=1.052, reward_mean=0.0, reward_bound=0.0\n",
      "89: loss=1.090, reward_mean=0.0, reward_bound=0.0\n",
      "90: loss=1.094, reward_mean=0.1, reward_bound=0.0\n",
      "91: loss=1.125, reward_mean=0.0, reward_bound=0.0\n",
      "92: loss=1.015, reward_mean=0.0, reward_bound=0.0\n",
      "93: loss=1.046, reward_mean=0.0, reward_bound=0.0\n",
      "94: loss=0.995, reward_mean=0.0, reward_bound=0.0\n",
      "95: loss=0.924, reward_mean=0.0, reward_bound=0.0\n",
      "96: loss=0.953, reward_mean=0.0, reward_bound=0.0\n",
      "97: loss=0.901, reward_mean=0.0, reward_bound=0.0\n",
      "98: loss=0.708, reward_mean=0.0, reward_bound=0.0\n",
      "99: loss=0.906, reward_mean=0.0, reward_bound=0.0\n",
      "100: loss=0.954, reward_mean=0.0, reward_bound=0.0\n",
      "101: loss=0.845, reward_mean=0.1, reward_bound=0.0\n",
      "102: loss=0.750, reward_mean=0.0, reward_bound=0.0\n",
      "103: loss=0.845, reward_mean=0.0, reward_bound=0.0\n",
      "104: loss=0.809, reward_mean=0.0, reward_bound=0.0\n",
      "105: loss=0.842, reward_mean=0.0, reward_bound=0.0\n",
      "106: loss=0.795, reward_mean=0.0, reward_bound=0.0\n",
      "107: loss=0.878, reward_mean=0.0, reward_bound=0.0\n",
      "108: loss=0.901, reward_mean=0.0, reward_bound=0.0\n",
      "109: loss=0.798, reward_mean=0.0, reward_bound=0.0\n",
      "110: loss=0.766, reward_mean=0.0, reward_bound=0.0\n",
      "111: loss=0.817, reward_mean=0.0, reward_bound=0.0\n",
      "112: loss=0.757, reward_mean=0.0, reward_bound=0.0\n",
      "113: loss=0.925, reward_mean=0.0, reward_bound=0.0\n",
      "114: loss=0.919, reward_mean=0.0, reward_bound=0.0\n",
      "115: loss=0.975, reward_mean=0.0, reward_bound=0.0\n",
      "116: loss=0.883, reward_mean=0.1, reward_bound=0.0\n",
      "117: loss=0.850, reward_mean=0.0, reward_bound=0.0\n",
      "118: loss=0.996, reward_mean=0.0, reward_bound=0.0\n",
      "119: loss=0.975, reward_mean=0.0, reward_bound=0.0\n",
      "120: loss=1.011, reward_mean=0.0, reward_bound=0.0\n",
      "121: loss=0.927, reward_mean=0.0, reward_bound=0.0\n",
      "122: loss=0.917, reward_mean=0.0, reward_bound=0.0\n",
      "123: loss=0.921, reward_mean=0.0, reward_bound=0.0\n",
      "124: loss=1.023, reward_mean=0.0, reward_bound=0.0\n",
      "125: loss=0.943, reward_mean=0.0, reward_bound=0.0\n",
      "126: loss=1.005, reward_mean=0.0, reward_bound=0.0\n",
      "127: loss=0.962, reward_mean=0.0, reward_bound=0.0\n",
      "128: loss=0.993, reward_mean=0.0, reward_bound=0.0\n",
      "129: loss=1.034, reward_mean=0.0, reward_bound=0.0\n",
      "130: loss=1.003, reward_mean=0.0, reward_bound=0.0\n",
      "131: loss=0.962, reward_mean=0.0, reward_bound=0.0\n",
      "132: loss=0.959, reward_mean=0.0, reward_bound=0.0\n",
      "133: loss=0.988, reward_mean=0.0, reward_bound=0.0\n",
      "134: loss=0.938, reward_mean=0.0, reward_bound=0.0\n",
      "135: loss=0.896, reward_mean=0.0, reward_bound=0.0\n",
      "136: loss=1.032, reward_mean=0.0, reward_bound=0.0\n",
      "137: loss=1.021, reward_mean=0.0, reward_bound=0.0\n",
      "138: loss=0.924, reward_mean=0.0, reward_bound=0.0\n",
      "139: loss=0.923, reward_mean=0.0, reward_bound=0.0\n",
      "140: loss=0.971, reward_mean=0.0, reward_bound=0.0\n",
      "141: loss=0.972, reward_mean=0.0, reward_bound=0.0\n",
      "142: loss=0.952, reward_mean=0.0, reward_bound=0.0\n",
      "143: loss=1.047, reward_mean=0.0, reward_bound=0.0\n",
      "144: loss=0.902, reward_mean=0.0, reward_bound=0.0\n",
      "145: loss=1.007, reward_mean=0.0, reward_bound=0.0\n",
      "146: loss=1.024, reward_mean=0.0, reward_bound=0.0\n",
      "147: loss=0.960, reward_mean=0.0, reward_bound=0.0\n",
      "148: loss=0.885, reward_mean=0.0, reward_bound=0.0\n",
      "149: loss=0.944, reward_mean=0.0, reward_bound=0.0\n",
      "150: loss=1.136, reward_mean=0.0, reward_bound=0.0\n",
      "151: loss=1.040, reward_mean=0.0, reward_bound=0.0\n",
      "152: loss=1.079, reward_mean=0.0, reward_bound=0.0\n",
      "153: loss=1.084, reward_mean=0.1, reward_bound=0.0\n",
      "154: loss=0.980, reward_mean=0.0, reward_bound=0.0\n",
      "155: loss=1.104, reward_mean=0.0, reward_bound=0.0\n",
      "156: loss=1.043, reward_mean=0.0, reward_bound=0.0\n",
      "157: loss=1.057, reward_mean=0.0, reward_bound=0.0\n",
      "158: loss=1.010, reward_mean=0.0, reward_bound=0.0\n",
      "159: loss=1.159, reward_mean=0.0, reward_bound=0.0\n",
      "160: loss=1.057, reward_mean=0.0, reward_bound=0.0\n",
      "161: loss=1.049, reward_mean=0.0, reward_bound=0.0\n",
      "162: loss=1.040, reward_mean=0.1, reward_bound=0.0\n",
      "163: loss=1.130, reward_mean=0.0, reward_bound=0.0\n",
      "164: loss=1.133, reward_mean=0.0, reward_bound=0.0\n",
      "165: loss=1.020, reward_mean=0.0, reward_bound=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166: loss=1.026, reward_mean=0.0, reward_bound=0.0\n",
      "167: loss=1.097, reward_mean=0.0, reward_bound=0.0\n",
      "168: loss=1.168, reward_mean=0.0, reward_bound=0.0\n",
      "169: loss=1.055, reward_mean=0.0, reward_bound=0.0\n",
      "170: loss=1.095, reward_mean=0.0, reward_bound=0.0\n",
      "171: loss=1.085, reward_mean=0.1, reward_bound=0.0\n",
      "172: loss=1.087, reward_mean=0.0, reward_bound=0.0\n",
      "173: loss=1.118, reward_mean=0.0, reward_bound=0.0\n",
      "174: loss=1.095, reward_mean=0.0, reward_bound=0.0\n",
      "175: loss=1.188, reward_mean=0.0, reward_bound=0.0\n",
      "176: loss=1.130, reward_mean=0.0, reward_bound=0.0\n",
      "177: loss=1.074, reward_mean=0.0, reward_bound=0.0\n",
      "178: loss=1.244, reward_mean=0.0, reward_bound=0.0\n",
      "179: loss=1.266, reward_mean=0.0, reward_bound=0.0\n",
      "180: loss=1.161, reward_mean=0.0, reward_bound=0.0\n",
      "181: loss=1.222, reward_mean=0.0, reward_bound=0.0\n",
      "182: loss=1.193, reward_mean=0.0, reward_bound=0.0\n",
      "183: loss=1.205, reward_mean=0.0, reward_bound=0.0\n",
      "184: loss=1.276, reward_mean=0.0, reward_bound=0.0\n",
      "185: loss=1.271, reward_mean=0.0, reward_bound=0.0\n",
      "186: loss=1.227, reward_mean=0.0, reward_bound=0.0\n",
      "187: loss=1.183, reward_mean=0.0, reward_bound=0.0\n",
      "188: loss=1.293, reward_mean=0.0, reward_bound=0.0\n",
      "189: loss=1.169, reward_mean=0.0, reward_bound=0.0\n",
      "190: loss=1.248, reward_mean=0.1, reward_bound=0.0\n",
      "191: loss=1.263, reward_mean=0.0, reward_bound=0.0\n",
      "192: loss=1.203, reward_mean=0.0, reward_bound=0.0\n",
      "193: loss=1.207, reward_mean=0.0, reward_bound=0.0\n",
      "194: loss=1.244, reward_mean=0.0, reward_bound=0.0\n",
      "195: loss=1.257, reward_mean=0.0, reward_bound=0.0\n",
      "196: loss=1.239, reward_mean=0.1, reward_bound=0.0\n",
      "197: loss=1.265, reward_mean=0.1, reward_bound=0.0\n",
      "198: loss=1.133, reward_mean=0.0, reward_bound=0.0\n",
      "199: loss=1.186, reward_mean=0.0, reward_bound=0.0\n",
      "200: loss=1.173, reward_mean=0.0, reward_bound=0.0\n",
      "201: loss=1.213, reward_mean=0.0, reward_bound=0.0\n",
      "202: loss=1.228, reward_mean=0.0, reward_bound=0.0\n",
      "203: loss=1.202, reward_mean=0.1, reward_bound=0.0\n",
      "204: loss=1.104, reward_mean=0.0, reward_bound=0.0\n",
      "205: loss=1.135, reward_mean=0.0, reward_bound=0.0\n",
      "206: loss=1.252, reward_mean=0.0, reward_bound=0.0\n",
      "207: loss=1.168, reward_mean=0.0, reward_bound=0.0\n",
      "208: loss=1.124, reward_mean=0.0, reward_bound=0.0\n",
      "209: loss=1.153, reward_mean=0.0, reward_bound=0.0\n",
      "210: loss=1.096, reward_mean=0.0, reward_bound=0.0\n",
      "211: loss=1.155, reward_mean=0.0, reward_bound=0.0\n",
      "212: loss=1.123, reward_mean=0.0, reward_bound=0.0\n",
      "213: loss=1.111, reward_mean=0.0, reward_bound=0.0\n",
      "214: loss=1.122, reward_mean=0.0, reward_bound=0.0\n",
      "215: loss=1.130, reward_mean=0.0, reward_bound=0.0\n",
      "216: loss=1.076, reward_mean=0.0, reward_bound=0.0\n",
      "217: loss=1.231, reward_mean=0.0, reward_bound=0.0\n",
      "218: loss=1.078, reward_mean=0.0, reward_bound=0.0\n",
      "219: loss=0.998, reward_mean=0.0, reward_bound=0.0\n",
      "220: loss=1.145, reward_mean=0.0, reward_bound=0.0\n",
      "221: loss=1.210, reward_mean=0.0, reward_bound=0.0\n",
      "222: loss=1.084, reward_mean=0.0, reward_bound=0.0\n",
      "223: loss=0.895, reward_mean=0.0, reward_bound=0.0\n",
      "224: loss=1.097, reward_mean=0.0, reward_bound=0.0\n",
      "225: loss=1.033, reward_mean=0.0, reward_bound=0.0\n",
      "226: loss=0.926, reward_mean=0.0, reward_bound=0.0\n",
      "227: loss=0.839, reward_mean=0.1, reward_bound=0.0\n",
      "228: loss=1.004, reward_mean=0.1, reward_bound=0.0\n",
      "229: loss=0.901, reward_mean=0.0, reward_bound=0.0\n",
      "230: loss=0.854, reward_mean=0.0, reward_bound=0.0\n",
      "231: loss=0.893, reward_mean=0.1, reward_bound=0.0\n",
      "232: loss=0.976, reward_mean=0.0, reward_bound=0.0\n",
      "233: loss=0.864, reward_mean=0.1, reward_bound=0.0\n",
      "234: loss=0.951, reward_mean=0.0, reward_bound=0.0\n",
      "235: loss=0.846, reward_mean=0.0, reward_bound=0.0\n",
      "236: loss=0.839, reward_mean=0.0, reward_bound=0.0\n",
      "237: loss=0.889, reward_mean=0.0, reward_bound=0.0\n",
      "238: loss=0.758, reward_mean=0.0, reward_bound=0.0\n",
      "239: loss=0.936, reward_mean=0.0, reward_bound=0.0\n",
      "240: loss=0.788, reward_mean=0.0, reward_bound=0.0\n",
      "241: loss=0.972, reward_mean=0.0, reward_bound=0.0\n",
      "242: loss=0.676, reward_mean=0.0, reward_bound=0.0\n",
      "243: loss=0.854, reward_mean=0.0, reward_bound=0.0\n",
      "244: loss=0.767, reward_mean=0.1, reward_bound=0.0\n",
      "245: loss=1.023, reward_mean=0.1, reward_bound=0.0\n",
      "246: loss=0.966, reward_mean=0.0, reward_bound=0.0\n",
      "247: loss=0.869, reward_mean=0.0, reward_bound=0.0\n",
      "248: loss=0.968, reward_mean=0.0, reward_bound=0.0\n",
      "249: loss=0.967, reward_mean=0.0, reward_bound=0.0\n",
      "250: loss=0.853, reward_mean=0.0, reward_bound=0.0\n",
      "251: loss=1.099, reward_mean=0.0, reward_bound=0.0\n",
      "252: loss=0.977, reward_mean=0.0, reward_bound=0.0\n",
      "253: loss=0.952, reward_mean=0.0, reward_bound=0.0\n",
      "254: loss=0.959, reward_mean=0.0, reward_bound=0.0\n",
      "255: loss=0.932, reward_mean=0.0, reward_bound=0.0\n",
      "256: loss=1.046, reward_mean=0.0, reward_bound=0.0\n",
      "257: loss=0.959, reward_mean=0.0, reward_bound=0.0\n",
      "258: loss=1.050, reward_mean=0.0, reward_bound=0.0\n",
      "259: loss=1.042, reward_mean=0.0, reward_bound=0.0\n",
      "260: loss=0.921, reward_mean=0.1, reward_bound=0.0\n",
      "261: loss=1.043, reward_mean=0.0, reward_bound=0.0\n",
      "262: loss=0.900, reward_mean=0.0, reward_bound=0.0\n",
      "263: loss=0.903, reward_mean=0.0, reward_bound=0.0\n",
      "264: loss=0.917, reward_mean=0.0, reward_bound=0.0\n",
      "265: loss=0.901, reward_mean=0.0, reward_bound=0.0\n",
      "266: loss=0.820, reward_mean=0.0, reward_bound=0.0\n",
      "267: loss=0.882, reward_mean=0.0, reward_bound=0.0\n",
      "268: loss=0.831, reward_mean=0.0, reward_bound=0.0\n",
      "269: loss=0.853, reward_mean=0.0, reward_bound=0.0\n",
      "270: loss=0.874, reward_mean=0.0, reward_bound=0.0\n",
      "271: loss=0.867, reward_mean=0.0, reward_bound=0.0\n",
      "272: loss=0.906, reward_mean=0.1, reward_bound=0.0\n",
      "273: loss=0.917, reward_mean=0.0, reward_bound=0.0\n",
      "274: loss=0.943, reward_mean=0.1, reward_bound=0.0\n",
      "275: loss=0.876, reward_mean=0.0, reward_bound=0.0\n",
      "276: loss=0.981, reward_mean=0.0, reward_bound=0.0\n",
      "277: loss=1.048, reward_mean=0.0, reward_bound=0.0\n",
      "278: loss=0.970, reward_mean=0.0, reward_bound=0.0\n",
      "279: loss=1.114, reward_mean=0.0, reward_bound=0.0\n",
      "280: loss=0.965, reward_mean=0.0, reward_bound=0.0\n",
      "281: loss=0.974, reward_mean=0.0, reward_bound=0.0\n",
      "282: loss=1.042, reward_mean=0.0, reward_bound=0.0\n",
      "283: loss=1.084, reward_mean=0.0, reward_bound=0.0\n",
      "284: loss=1.062, reward_mean=0.0, reward_bound=0.0\n",
      "285: loss=1.122, reward_mean=0.0, reward_bound=0.0\n",
      "286: loss=1.165, reward_mean=0.0, reward_bound=0.0\n",
      "287: loss=1.066, reward_mean=0.0, reward_bound=0.0\n",
      "288: loss=1.172, reward_mean=0.0, reward_bound=0.0\n",
      "289: loss=1.087, reward_mean=0.0, reward_bound=0.0\n",
      "290: loss=1.171, reward_mean=0.0, reward_bound=0.0\n",
      "291: loss=1.164, reward_mean=0.0, reward_bound=0.0\n",
      "292: loss=1.131, reward_mean=0.0, reward_bound=0.0\n",
      "293: loss=1.113, reward_mean=0.0, reward_bound=0.0\n",
      "294: loss=1.157, reward_mean=0.0, reward_bound=0.0\n",
      "295: loss=1.195, reward_mean=0.0, reward_bound=0.0\n",
      "296: loss=1.146, reward_mean=0.0, reward_bound=0.0\n",
      "297: loss=1.180, reward_mean=0.0, reward_bound=0.0\n",
      "298: loss=1.139, reward_mean=0.0, reward_bound=0.0\n",
      "299: loss=1.204, reward_mean=0.0, reward_bound=0.0\n",
      "300: loss=1.082, reward_mean=0.0, reward_bound=0.0\n",
      "301: loss=1.100, reward_mean=0.0, reward_bound=0.0\n",
      "302: loss=1.198, reward_mean=0.1, reward_bound=0.0\n",
      "303: loss=1.149, reward_mean=0.0, reward_bound=0.0\n",
      "304: loss=1.149, reward_mean=0.0, reward_bound=0.0\n",
      "305: loss=1.126, reward_mean=0.0, reward_bound=0.0\n",
      "306: loss=1.075, reward_mean=0.1, reward_bound=0.0\n",
      "307: loss=1.212, reward_mean=0.0, reward_bound=0.0\n",
      "308: loss=1.061, reward_mean=0.0, reward_bound=0.0\n",
      "309: loss=1.165, reward_mean=0.0, reward_bound=0.0\n",
      "310: loss=1.110, reward_mean=0.0, reward_bound=0.0\n",
      "311: loss=1.111, reward_mean=0.0, reward_bound=0.0\n",
      "312: loss=1.037, reward_mean=0.0, reward_bound=0.0\n",
      "313: loss=1.164, reward_mean=0.0, reward_bound=0.0\n",
      "314: loss=1.111, reward_mean=0.1, reward_bound=0.0\n",
      "315: loss=1.171, reward_mean=0.0, reward_bound=0.0\n",
      "316: loss=1.069, reward_mean=0.0, reward_bound=0.0\n",
      "317: loss=0.967, reward_mean=0.1, reward_bound=0.0\n",
      "318: loss=1.068, reward_mean=0.0, reward_bound=0.0\n",
      "319: loss=1.057, reward_mean=0.1, reward_bound=0.0\n",
      "320: loss=1.110, reward_mean=0.0, reward_bound=0.0\n",
      "321: loss=1.108, reward_mean=0.0, reward_bound=0.0\n",
      "322: loss=1.111, reward_mean=0.0, reward_bound=0.0\n",
      "323: loss=1.069, reward_mean=0.0, reward_bound=0.0\n",
      "324: loss=1.084, reward_mean=0.0, reward_bound=0.0\n",
      "325: loss=1.078, reward_mean=0.0, reward_bound=0.0\n",
      "326: loss=0.999, reward_mean=0.0, reward_bound=0.0\n",
      "327: loss=1.077, reward_mean=0.0, reward_bound=0.0\n",
      "328: loss=1.028, reward_mean=0.0, reward_bound=0.0\n",
      "329: loss=1.022, reward_mean=0.0, reward_bound=0.0\n",
      "330: loss=1.090, reward_mean=0.0, reward_bound=0.0\n",
      "331: loss=1.169, reward_mean=0.0, reward_bound=0.0\n",
      "332: loss=1.121, reward_mean=0.0, reward_bound=0.0\n",
      "333: loss=0.992, reward_mean=0.0, reward_bound=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334: loss=1.003, reward_mean=0.0, reward_bound=0.0\n",
      "335: loss=0.944, reward_mean=0.0, reward_bound=0.0\n",
      "336: loss=1.101, reward_mean=0.0, reward_bound=0.0\n",
      "337: loss=0.958, reward_mean=0.0, reward_bound=0.0\n",
      "338: loss=0.981, reward_mean=0.0, reward_bound=0.0\n",
      "339: loss=1.021, reward_mean=0.1, reward_bound=0.0\n",
      "340: loss=1.079, reward_mean=0.0, reward_bound=0.0\n",
      "341: loss=1.001, reward_mean=0.0, reward_bound=0.0\n",
      "342: loss=1.051, reward_mean=0.0, reward_bound=0.0\n",
      "343: loss=0.933, reward_mean=0.0, reward_bound=0.0\n",
      "344: loss=1.001, reward_mean=0.0, reward_bound=0.0\n",
      "345: loss=1.028, reward_mean=0.0, reward_bound=0.0\n",
      "346: loss=0.962, reward_mean=0.1, reward_bound=0.0\n",
      "347: loss=0.930, reward_mean=0.0, reward_bound=0.0\n",
      "348: loss=0.949, reward_mean=0.1, reward_bound=0.0\n",
      "349: loss=1.041, reward_mean=0.0, reward_bound=0.0\n",
      "350: loss=1.049, reward_mean=0.0, reward_bound=0.0\n",
      "351: loss=1.034, reward_mean=0.0, reward_bound=0.0\n",
      "352: loss=0.946, reward_mean=0.0, reward_bound=0.0\n",
      "353: loss=0.975, reward_mean=0.0, reward_bound=0.0\n",
      "354: loss=0.955, reward_mean=0.0, reward_bound=0.0\n",
      "355: loss=1.020, reward_mean=0.0, reward_bound=0.0\n",
      "356: loss=1.051, reward_mean=0.0, reward_bound=0.0\n",
      "357: loss=1.095, reward_mean=0.0, reward_bound=0.0\n",
      "358: loss=1.036, reward_mean=0.0, reward_bound=0.0\n",
      "359: loss=0.906, reward_mean=0.0, reward_bound=0.0\n",
      "360: loss=1.113, reward_mean=0.0, reward_bound=0.0\n",
      "361: loss=1.115, reward_mean=0.1, reward_bound=0.0\n",
      "362: loss=1.087, reward_mean=0.0, reward_bound=0.0\n",
      "363: loss=1.040, reward_mean=0.0, reward_bound=0.0\n",
      "364: loss=1.110, reward_mean=0.0, reward_bound=0.0\n",
      "365: loss=1.069, reward_mean=0.0, reward_bound=0.0\n",
      "366: loss=1.059, reward_mean=0.0, reward_bound=0.0\n",
      "367: loss=1.131, reward_mean=0.0, reward_bound=0.0\n",
      "368: loss=1.018, reward_mean=0.0, reward_bound=0.0\n",
      "369: loss=1.145, reward_mean=0.0, reward_bound=0.0\n",
      "370: loss=1.069, reward_mean=0.0, reward_bound=0.0\n",
      "371: loss=1.137, reward_mean=0.0, reward_bound=0.0\n",
      "372: loss=1.114, reward_mean=0.0, reward_bound=0.0\n",
      "373: loss=1.071, reward_mean=0.0, reward_bound=0.0\n",
      "374: loss=1.121, reward_mean=0.0, reward_bound=0.0\n",
      "375: loss=1.154, reward_mean=0.0, reward_bound=0.0\n",
      "376: loss=1.200, reward_mean=0.0, reward_bound=0.0\n",
      "377: loss=1.220, reward_mean=0.0, reward_bound=0.0\n",
      "378: loss=1.102, reward_mean=0.0, reward_bound=0.0\n",
      "379: loss=1.028, reward_mean=0.0, reward_bound=0.0\n",
      "380: loss=1.171, reward_mean=0.0, reward_bound=0.0\n",
      "381: loss=1.141, reward_mean=0.1, reward_bound=0.0\n",
      "382: loss=1.180, reward_mean=0.0, reward_bound=0.0\n",
      "383: loss=1.093, reward_mean=0.0, reward_bound=0.0\n",
      "384: loss=1.103, reward_mean=0.0, reward_bound=0.0\n",
      "385: loss=1.200, reward_mean=0.0, reward_bound=0.0\n",
      "386: loss=1.217, reward_mean=0.0, reward_bound=0.0\n",
      "387: loss=1.230, reward_mean=0.0, reward_bound=0.0\n",
      "388: loss=1.105, reward_mean=0.0, reward_bound=0.0\n",
      "389: loss=1.196, reward_mean=0.0, reward_bound=0.0\n",
      "390: loss=1.137, reward_mean=0.1, reward_bound=0.0\n",
      "391: loss=1.286, reward_mean=0.0, reward_bound=0.0\n",
      "392: loss=1.172, reward_mean=0.0, reward_bound=0.0\n",
      "393: loss=1.225, reward_mean=0.0, reward_bound=0.0\n",
      "394: loss=1.159, reward_mean=0.1, reward_bound=0.0\n",
      "395: loss=1.226, reward_mean=0.0, reward_bound=0.0\n",
      "396: loss=1.252, reward_mean=0.0, reward_bound=0.0\n",
      "397: loss=1.203, reward_mean=0.0, reward_bound=0.0\n",
      "398: loss=1.184, reward_mean=0.0, reward_bound=0.0\n",
      "399: loss=1.253, reward_mean=0.0, reward_bound=0.0\n",
      "400: loss=1.222, reward_mean=0.0, reward_bound=0.0\n",
      "401: loss=1.130, reward_mean=0.0, reward_bound=0.0\n",
      "402: loss=1.156, reward_mean=0.0, reward_bound=0.0\n",
      "403: loss=1.175, reward_mean=0.0, reward_bound=0.0\n",
      "404: loss=1.151, reward_mean=0.0, reward_bound=0.0\n",
      "405: loss=1.240, reward_mean=0.1, reward_bound=0.0\n",
      "406: loss=1.163, reward_mean=0.0, reward_bound=0.0\n",
      "407: loss=1.147, reward_mean=0.1, reward_bound=0.0\n",
      "408: loss=1.199, reward_mean=0.0, reward_bound=0.0\n",
      "409: loss=1.171, reward_mean=0.0, reward_bound=0.0\n",
      "410: loss=1.296, reward_mean=0.1, reward_bound=0.0\n",
      "411: loss=1.164, reward_mean=0.0, reward_bound=0.0\n",
      "412: loss=1.221, reward_mean=0.0, reward_bound=0.0\n",
      "413: loss=1.124, reward_mean=0.1, reward_bound=0.0\n",
      "414: loss=1.086, reward_mean=0.0, reward_bound=0.0\n",
      "415: loss=1.181, reward_mean=0.0, reward_bound=0.0\n",
      "416: loss=1.176, reward_mean=0.0, reward_bound=0.0\n",
      "417: loss=1.159, reward_mean=0.0, reward_bound=0.0\n",
      "418: loss=1.201, reward_mean=0.0, reward_bound=0.0\n",
      "419: loss=1.130, reward_mean=0.0, reward_bound=0.0\n",
      "420: loss=1.226, reward_mean=0.0, reward_bound=0.0\n",
      "421: loss=1.230, reward_mean=0.0, reward_bound=0.0\n",
      "422: loss=1.078, reward_mean=0.0, reward_bound=0.0\n",
      "423: loss=1.065, reward_mean=0.0, reward_bound=0.0\n",
      "424: loss=1.210, reward_mean=0.0, reward_bound=0.0\n",
      "425: loss=1.162, reward_mean=0.0, reward_bound=0.0\n",
      "426: loss=1.193, reward_mean=0.0, reward_bound=0.0\n",
      "427: loss=1.191, reward_mean=0.1, reward_bound=0.0\n",
      "428: loss=1.182, reward_mean=0.0, reward_bound=0.0\n",
      "429: loss=1.122, reward_mean=0.0, reward_bound=0.0\n",
      "430: loss=1.207, reward_mean=0.1, reward_bound=0.0\n",
      "431: loss=1.254, reward_mean=0.0, reward_bound=0.0\n",
      "432: loss=1.213, reward_mean=0.1, reward_bound=0.0\n",
      "433: loss=1.166, reward_mean=0.0, reward_bound=0.0\n",
      "434: loss=1.203, reward_mean=0.0, reward_bound=0.0\n",
      "435: loss=1.194, reward_mean=0.0, reward_bound=0.0\n",
      "436: loss=1.074, reward_mean=0.1, reward_bound=0.0\n",
      "437: loss=1.107, reward_mean=0.0, reward_bound=0.0\n",
      "438: loss=1.197, reward_mean=0.0, reward_bound=0.0\n",
      "439: loss=1.136, reward_mean=0.0, reward_bound=0.0\n",
      "440: loss=1.177, reward_mean=0.0, reward_bound=0.0\n",
      "441: loss=1.209, reward_mean=0.0, reward_bound=0.0\n",
      "442: loss=1.138, reward_mean=0.0, reward_bound=0.0\n",
      "443: loss=1.177, reward_mean=0.0, reward_bound=0.0\n",
      "444: loss=1.150, reward_mean=0.0, reward_bound=0.0\n",
      "445: loss=1.170, reward_mean=0.0, reward_bound=0.0\n",
      "446: loss=1.128, reward_mean=0.0, reward_bound=0.0\n",
      "447: loss=1.134, reward_mean=0.0, reward_bound=0.0\n",
      "448: loss=1.091, reward_mean=0.0, reward_bound=0.0\n",
      "449: loss=1.186, reward_mean=0.1, reward_bound=0.0\n",
      "450: loss=1.157, reward_mean=0.1, reward_bound=0.0\n",
      "451: loss=1.124, reward_mean=0.0, reward_bound=0.0\n",
      "452: loss=1.132, reward_mean=0.0, reward_bound=0.0\n",
      "453: loss=1.011, reward_mean=0.0, reward_bound=0.0\n",
      "454: loss=1.135, reward_mean=0.0, reward_bound=0.0\n",
      "455: loss=1.031, reward_mean=0.1, reward_bound=0.0\n",
      "456: loss=1.137, reward_mean=0.0, reward_bound=0.0\n",
      "457: loss=1.135, reward_mean=0.0, reward_bound=0.0\n",
      "458: loss=1.127, reward_mean=0.1, reward_bound=0.0\n",
      "459: loss=1.107, reward_mean=0.0, reward_bound=0.0\n",
      "460: loss=1.084, reward_mean=0.0, reward_bound=0.0\n",
      "461: loss=1.035, reward_mean=0.0, reward_bound=0.0\n",
      "462: loss=1.037, reward_mean=0.0, reward_bound=0.0\n",
      "463: loss=1.219, reward_mean=0.0, reward_bound=0.0\n",
      "464: loss=1.111, reward_mean=0.0, reward_bound=0.0\n",
      "465: loss=1.047, reward_mean=0.0, reward_bound=0.0\n",
      "466: loss=1.021, reward_mean=0.0, reward_bound=0.0\n",
      "467: loss=1.200, reward_mean=0.0, reward_bound=0.0\n",
      "468: loss=1.102, reward_mean=0.0, reward_bound=0.0\n",
      "469: loss=1.080, reward_mean=0.0, reward_bound=0.0\n",
      "470: loss=1.090, reward_mean=0.0, reward_bound=0.0\n",
      "471: loss=1.139, reward_mean=0.0, reward_bound=0.0\n",
      "472: loss=1.092, reward_mean=0.0, reward_bound=0.0\n",
      "473: loss=0.978, reward_mean=0.0, reward_bound=0.0\n",
      "474: loss=1.096, reward_mean=0.0, reward_bound=0.0\n",
      "475: loss=1.134, reward_mean=0.0, reward_bound=0.0\n",
      "476: loss=1.111, reward_mean=0.0, reward_bound=0.0\n",
      "477: loss=1.128, reward_mean=0.0, reward_bound=0.0\n",
      "478: loss=1.141, reward_mean=0.0, reward_bound=0.0\n",
      "479: loss=0.986, reward_mean=0.0, reward_bound=0.0\n",
      "480: loss=1.088, reward_mean=0.1, reward_bound=0.0\n",
      "481: loss=1.151, reward_mean=0.1, reward_bound=0.0\n",
      "482: loss=1.158, reward_mean=0.0, reward_bound=0.0\n",
      "483: loss=1.132, reward_mean=0.1, reward_bound=0.0\n",
      "484: loss=1.073, reward_mean=0.0, reward_bound=0.0\n",
      "485: loss=1.130, reward_mean=0.0, reward_bound=0.0\n",
      "486: loss=1.096, reward_mean=0.0, reward_bound=0.0\n",
      "487: loss=1.044, reward_mean=0.0, reward_bound=0.0\n",
      "488: loss=1.059, reward_mean=0.0, reward_bound=0.0\n",
      "489: loss=1.091, reward_mean=0.0, reward_bound=0.0\n",
      "490: loss=1.042, reward_mean=0.0, reward_bound=0.0\n",
      "491: loss=1.064, reward_mean=0.0, reward_bound=0.0\n",
      "492: loss=1.053, reward_mean=0.0, reward_bound=0.0\n",
      "493: loss=1.047, reward_mean=0.0, reward_bound=0.0\n",
      "494: loss=1.120, reward_mean=0.0, reward_bound=0.0\n",
      "495: loss=1.028, reward_mean=0.0, reward_bound=0.0\n",
      "496: loss=1.138, reward_mean=0.1, reward_bound=0.0\n",
      "497: loss=1.156, reward_mean=0.0, reward_bound=0.0\n",
      "498: loss=1.132, reward_mean=0.0, reward_bound=0.0\n",
      "499: loss=1.076, reward_mean=0.0, reward_bound=0.0\n",
      "500: loss=1.092, reward_mean=0.0, reward_bound=0.0\n",
      "501: loss=0.974, reward_mean=0.0, reward_bound=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502: loss=1.115, reward_mean=0.0, reward_bound=0.0\n",
      "503: loss=1.035, reward_mean=0.0, reward_bound=0.0\n",
      "504: loss=0.970, reward_mean=0.1, reward_bound=0.0\n",
      "505: loss=0.992, reward_mean=0.0, reward_bound=0.0\n",
      "506: loss=1.087, reward_mean=0.0, reward_bound=0.0\n",
      "507: loss=1.057, reward_mean=0.0, reward_bound=0.0\n",
      "508: loss=1.158, reward_mean=0.0, reward_bound=0.0\n",
      "509: loss=1.054, reward_mean=0.0, reward_bound=0.0\n",
      "510: loss=1.117, reward_mean=0.0, reward_bound=0.0\n",
      "511: loss=1.068, reward_mean=0.0, reward_bound=0.0\n",
      "512: loss=1.065, reward_mean=0.0, reward_bound=0.0\n",
      "513: loss=0.966, reward_mean=0.0, reward_bound=0.0\n",
      "514: loss=1.134, reward_mean=0.0, reward_bound=0.0\n",
      "515: loss=0.928, reward_mean=0.0, reward_bound=0.0\n",
      "516: loss=1.022, reward_mean=0.0, reward_bound=0.0\n",
      "517: loss=1.107, reward_mean=0.0, reward_bound=0.0\n",
      "518: loss=1.050, reward_mean=0.0, reward_bound=0.0\n",
      "519: loss=1.112, reward_mean=0.0, reward_bound=0.0\n",
      "520: loss=1.012, reward_mean=0.0, reward_bound=0.0\n",
      "521: loss=1.103, reward_mean=0.0, reward_bound=0.0\n",
      "522: loss=1.066, reward_mean=0.0, reward_bound=0.0\n",
      "523: loss=1.039, reward_mean=0.0, reward_bound=0.0\n",
      "524: loss=0.940, reward_mean=0.0, reward_bound=0.0\n",
      "525: loss=1.025, reward_mean=0.0, reward_bound=0.0\n",
      "526: loss=1.012, reward_mean=0.0, reward_bound=0.0\n",
      "527: loss=0.951, reward_mean=0.0, reward_bound=0.0\n",
      "528: loss=1.062, reward_mean=0.0, reward_bound=0.0\n",
      "529: loss=0.956, reward_mean=0.0, reward_bound=0.0\n",
      "530: loss=1.208, reward_mean=0.0, reward_bound=0.0\n",
      "531: loss=1.069, reward_mean=0.1, reward_bound=0.0\n",
      "532: loss=0.949, reward_mean=0.1, reward_bound=0.0\n",
      "533: loss=0.960, reward_mean=0.0, reward_bound=0.0\n",
      "534: loss=1.043, reward_mean=0.0, reward_bound=0.0\n",
      "535: loss=1.048, reward_mean=0.1, reward_bound=0.0\n",
      "536: loss=1.156, reward_mean=0.0, reward_bound=0.0\n",
      "537: loss=0.987, reward_mean=0.0, reward_bound=0.0\n",
      "538: loss=0.956, reward_mean=0.0, reward_bound=0.0\n",
      "539: loss=1.084, reward_mean=0.0, reward_bound=0.0\n",
      "540: loss=1.068, reward_mean=0.1, reward_bound=0.0\n",
      "541: loss=1.098, reward_mean=0.1, reward_bound=0.0\n",
      "542: loss=1.032, reward_mean=0.0, reward_bound=0.0\n",
      "543: loss=0.878, reward_mean=0.0, reward_bound=0.0\n",
      "544: loss=1.035, reward_mean=0.0, reward_bound=0.0\n",
      "545: loss=1.003, reward_mean=0.0, reward_bound=0.0\n",
      "546: loss=1.069, reward_mean=0.1, reward_bound=0.0\n",
      "547: loss=0.968, reward_mean=0.0, reward_bound=0.0\n",
      "548: loss=0.917, reward_mean=0.0, reward_bound=0.0\n",
      "549: loss=1.057, reward_mean=0.0, reward_bound=0.0\n",
      "550: loss=1.033, reward_mean=0.0, reward_bound=0.0\n",
      "551: loss=0.997, reward_mean=0.0, reward_bound=0.0\n",
      "552: loss=0.914, reward_mean=0.0, reward_bound=0.0\n",
      "553: loss=0.971, reward_mean=0.1, reward_bound=0.0\n",
      "554: loss=1.030, reward_mean=0.0, reward_bound=0.0\n",
      "555: loss=1.001, reward_mean=0.0, reward_bound=0.0\n",
      "556: loss=0.988, reward_mean=0.0, reward_bound=0.0\n",
      "557: loss=1.082, reward_mean=0.0, reward_bound=0.0\n",
      "558: loss=0.959, reward_mean=0.0, reward_bound=0.0\n",
      "559: loss=0.861, reward_mean=0.0, reward_bound=0.0\n",
      "560: loss=0.889, reward_mean=0.0, reward_bound=0.0\n",
      "561: loss=0.998, reward_mean=0.0, reward_bound=0.0\n",
      "562: loss=1.010, reward_mean=0.0, reward_bound=0.0\n",
      "563: loss=0.937, reward_mean=0.0, reward_bound=0.0\n",
      "564: loss=0.968, reward_mean=0.0, reward_bound=0.0\n",
      "565: loss=0.978, reward_mean=0.1, reward_bound=0.0\n",
      "566: loss=1.089, reward_mean=0.0, reward_bound=0.0\n",
      "567: loss=0.903, reward_mean=0.0, reward_bound=0.0\n",
      "568: loss=0.942, reward_mean=0.0, reward_bound=0.0\n",
      "569: loss=0.961, reward_mean=0.0, reward_bound=0.0\n",
      "570: loss=0.901, reward_mean=0.0, reward_bound=0.0\n",
      "571: loss=0.910, reward_mean=0.0, reward_bound=0.0\n",
      "572: loss=0.892, reward_mean=0.0, reward_bound=0.0\n",
      "573: loss=1.050, reward_mean=0.0, reward_bound=0.0\n",
      "574: loss=1.029, reward_mean=0.0, reward_bound=0.0\n",
      "575: loss=0.937, reward_mean=0.0, reward_bound=0.0\n",
      "576: loss=1.019, reward_mean=0.0, reward_bound=0.0\n",
      "577: loss=0.932, reward_mean=0.0, reward_bound=0.0\n",
      "578: loss=0.955, reward_mean=0.1, reward_bound=0.0\n",
      "579: loss=0.968, reward_mean=0.0, reward_bound=0.0\n",
      "580: loss=0.958, reward_mean=0.1, reward_bound=0.0\n",
      "581: loss=0.928, reward_mean=0.0, reward_bound=0.0\n",
      "582: loss=1.010, reward_mean=0.0, reward_bound=0.0\n",
      "583: loss=0.930, reward_mean=0.0, reward_bound=0.0\n",
      "584: loss=0.925, reward_mean=0.0, reward_bound=0.0\n",
      "585: loss=1.013, reward_mean=0.1, reward_bound=0.0\n",
      "586: loss=0.961, reward_mean=0.0, reward_bound=0.0\n",
      "587: loss=1.008, reward_mean=0.0, reward_bound=0.0\n",
      "588: loss=0.997, reward_mean=0.0, reward_bound=0.0\n",
      "589: loss=0.915, reward_mean=0.1, reward_bound=0.0\n",
      "590: loss=0.894, reward_mean=0.0, reward_bound=0.0\n",
      "591: loss=0.958, reward_mean=0.1, reward_bound=0.0\n",
      "592: loss=0.895, reward_mean=0.1, reward_bound=0.0\n",
      "593: loss=1.011, reward_mean=0.0, reward_bound=0.0\n",
      "594: loss=0.922, reward_mean=0.1, reward_bound=0.0\n",
      "595: loss=0.816, reward_mean=0.0, reward_bound=0.0\n",
      "596: loss=0.899, reward_mean=0.0, reward_bound=0.0\n",
      "597: loss=0.822, reward_mean=0.0, reward_bound=0.0\n",
      "598: loss=0.908, reward_mean=0.0, reward_bound=0.0\n",
      "599: loss=0.897, reward_mean=0.0, reward_bound=0.0\n",
      "600: loss=0.891, reward_mean=0.1, reward_bound=0.0\n",
      "601: loss=0.934, reward_mean=0.1, reward_bound=0.0\n",
      "602: loss=0.874, reward_mean=0.0, reward_bound=0.0\n",
      "603: loss=0.967, reward_mean=0.1, reward_bound=0.0\n",
      "604: loss=0.877, reward_mean=0.0, reward_bound=0.0\n",
      "605: loss=0.926, reward_mean=0.0, reward_bound=0.0\n",
      "606: loss=0.886, reward_mean=0.0, reward_bound=0.0\n",
      "607: loss=0.871, reward_mean=0.1, reward_bound=0.0\n",
      "608: loss=0.959, reward_mean=0.1, reward_bound=0.0\n",
      "609: loss=0.916, reward_mean=0.0, reward_bound=0.0\n",
      "610: loss=0.921, reward_mean=0.0, reward_bound=0.0\n",
      "611: loss=0.892, reward_mean=0.0, reward_bound=0.0\n",
      "612: loss=0.831, reward_mean=0.0, reward_bound=0.0\n",
      "613: loss=0.819, reward_mean=0.0, reward_bound=0.0\n",
      "614: loss=0.808, reward_mean=0.0, reward_bound=0.0\n",
      "615: loss=0.854, reward_mean=0.0, reward_bound=0.0\n",
      "616: loss=0.879, reward_mean=0.0, reward_bound=0.0\n",
      "617: loss=0.788, reward_mean=0.1, reward_bound=0.0\n",
      "618: loss=0.844, reward_mean=0.0, reward_bound=0.0\n",
      "619: loss=0.863, reward_mean=0.1, reward_bound=0.0\n",
      "620: loss=0.788, reward_mean=0.0, reward_bound=0.0\n",
      "621: loss=0.762, reward_mean=0.1, reward_bound=0.0\n",
      "622: loss=0.904, reward_mean=0.1, reward_bound=0.0\n",
      "623: loss=0.917, reward_mean=0.0, reward_bound=0.0\n",
      "624: loss=0.815, reward_mean=0.0, reward_bound=0.0\n",
      "625: loss=0.907, reward_mean=0.1, reward_bound=0.0\n",
      "626: loss=0.757, reward_mean=0.0, reward_bound=0.0\n",
      "627: loss=0.948, reward_mean=0.0, reward_bound=0.0\n",
      "628: loss=0.921, reward_mean=0.0, reward_bound=0.0\n",
      "629: loss=0.742, reward_mean=0.0, reward_bound=0.0\n",
      "630: loss=0.803, reward_mean=0.0, reward_bound=0.0\n",
      "631: loss=0.875, reward_mean=0.0, reward_bound=0.0\n",
      "632: loss=0.922, reward_mean=0.0, reward_bound=0.0\n",
      "633: loss=0.770, reward_mean=0.0, reward_bound=0.0\n",
      "634: loss=0.842, reward_mean=0.0, reward_bound=0.0\n",
      "635: loss=0.835, reward_mean=0.0, reward_bound=0.0\n",
      "636: loss=0.743, reward_mean=0.0, reward_bound=0.0\n",
      "637: loss=0.646, reward_mean=0.0, reward_bound=0.0\n",
      "638: loss=0.693, reward_mean=0.0, reward_bound=0.0\n",
      "639: loss=0.913, reward_mean=0.0, reward_bound=0.0\n",
      "640: loss=0.764, reward_mean=0.1, reward_bound=0.0\n",
      "641: loss=0.878, reward_mean=0.1, reward_bound=0.0\n",
      "642: loss=0.831, reward_mean=0.1, reward_bound=0.0\n",
      "643: loss=0.650, reward_mean=0.0, reward_bound=0.0\n",
      "644: loss=0.771, reward_mean=0.0, reward_bound=0.0\n",
      "645: loss=0.838, reward_mean=0.0, reward_bound=0.0\n",
      "646: loss=0.779, reward_mean=0.0, reward_bound=0.0\n",
      "647: loss=0.830, reward_mean=0.0, reward_bound=0.0\n",
      "648: loss=0.799, reward_mean=0.0, reward_bound=0.0\n",
      "649: loss=0.830, reward_mean=0.0, reward_bound=0.0\n",
      "650: loss=0.869, reward_mean=0.0, reward_bound=0.0\n",
      "651: loss=0.755, reward_mean=0.0, reward_bound=0.0\n",
      "652: loss=0.763, reward_mean=0.0, reward_bound=0.0\n",
      "653: loss=0.783, reward_mean=0.0, reward_bound=0.0\n",
      "654: loss=0.636, reward_mean=0.0, reward_bound=0.0\n",
      "655: loss=0.867, reward_mean=0.0, reward_bound=0.0\n",
      "656: loss=0.895, reward_mean=0.0, reward_bound=0.0\n",
      "657: loss=0.785, reward_mean=0.0, reward_bound=0.0\n",
      "658: loss=0.898, reward_mean=0.0, reward_bound=0.0\n",
      "659: loss=0.809, reward_mean=0.0, reward_bound=0.0\n",
      "660: loss=0.711, reward_mean=0.0, reward_bound=0.0\n",
      "661: loss=0.777, reward_mean=0.0, reward_bound=0.0\n",
      "662: loss=0.753, reward_mean=0.0, reward_bound=0.0\n",
      "663: loss=0.784, reward_mean=0.0, reward_bound=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664: loss=0.776, reward_mean=0.0, reward_bound=0.0\n",
      "665: loss=0.793, reward_mean=0.0, reward_bound=0.0\n",
      "666: loss=0.833, reward_mean=0.0, reward_bound=0.0\n",
      "667: loss=0.868, reward_mean=0.0, reward_bound=0.0\n",
      "668: loss=0.729, reward_mean=0.0, reward_bound=0.0\n",
      "669: loss=0.874, reward_mean=0.0, reward_bound=0.0\n",
      "670: loss=0.854, reward_mean=0.0, reward_bound=0.0\n",
      "671: loss=0.915, reward_mean=0.0, reward_bound=0.0\n",
      "672: loss=0.968, reward_mean=0.0, reward_bound=0.0\n",
      "673: loss=0.801, reward_mean=0.0, reward_bound=0.0\n",
      "674: loss=0.881, reward_mean=0.0, reward_bound=0.0\n",
      "675: loss=0.827, reward_mean=0.0, reward_bound=0.0\n",
      "676: loss=0.844, reward_mean=0.0, reward_bound=0.0\n",
      "677: loss=0.929, reward_mean=0.0, reward_bound=0.0\n",
      "678: loss=0.777, reward_mean=0.0, reward_bound=0.0\n",
      "679: loss=0.994, reward_mean=0.0, reward_bound=0.0\n",
      "680: loss=0.891, reward_mean=0.0, reward_bound=0.0\n",
      "681: loss=0.759, reward_mean=0.0, reward_bound=0.0\n",
      "682: loss=0.816, reward_mean=0.0, reward_bound=0.0\n",
      "683: loss=0.854, reward_mean=0.0, reward_bound=0.0\n",
      "684: loss=0.747, reward_mean=0.0, reward_bound=0.0\n",
      "685: loss=0.967, reward_mean=0.0, reward_bound=0.0\n",
      "686: loss=0.881, reward_mean=0.0, reward_bound=0.0\n",
      "687: loss=1.030, reward_mean=0.0, reward_bound=0.0\n",
      "688: loss=0.764, reward_mean=0.0, reward_bound=0.0\n",
      "689: loss=0.702, reward_mean=0.0, reward_bound=0.0\n",
      "690: loss=1.022, reward_mean=0.1, reward_bound=0.0\n",
      "691: loss=0.812, reward_mean=0.0, reward_bound=0.0\n",
      "692: loss=0.944, reward_mean=0.1, reward_bound=0.0\n",
      "693: loss=0.770, reward_mean=0.0, reward_bound=0.0\n",
      "694: loss=0.833, reward_mean=0.0, reward_bound=0.0\n",
      "695: loss=0.772, reward_mean=0.0, reward_bound=0.0\n",
      "696: loss=0.910, reward_mean=0.0, reward_bound=0.0\n",
      "697: loss=0.744, reward_mean=0.0, reward_bound=0.0\n",
      "698: loss=0.828, reward_mean=0.0, reward_bound=0.0\n",
      "699: loss=0.813, reward_mean=0.0, reward_bound=0.0\n",
      "700: loss=0.947, reward_mean=0.0, reward_bound=0.0\n",
      "701: loss=0.942, reward_mean=0.0, reward_bound=0.0\n",
      "702: loss=0.924, reward_mean=0.1, reward_bound=0.0\n",
      "703: loss=1.012, reward_mean=0.0, reward_bound=0.0\n",
      "704: loss=0.965, reward_mean=0.0, reward_bound=0.0\n",
      "705: loss=0.794, reward_mean=0.0, reward_bound=0.0\n",
      "706: loss=0.863, reward_mean=0.0, reward_bound=0.0\n",
      "707: loss=0.930, reward_mean=0.0, reward_bound=0.0\n",
      "708: loss=0.950, reward_mean=0.0, reward_bound=0.0\n",
      "709: loss=0.843, reward_mean=0.0, reward_bound=0.0\n",
      "710: loss=0.848, reward_mean=0.0, reward_bound=0.0\n",
      "711: loss=0.714, reward_mean=0.0, reward_bound=0.0\n",
      "712: loss=0.928, reward_mean=0.0, reward_bound=0.0\n",
      "713: loss=0.844, reward_mean=0.0, reward_bound=0.0\n",
      "714: loss=0.927, reward_mean=0.0, reward_bound=0.0\n",
      "715: loss=0.834, reward_mean=0.0, reward_bound=0.0\n",
      "716: loss=0.813, reward_mean=0.0, reward_bound=0.0\n",
      "717: loss=0.828, reward_mean=0.0, reward_bound=0.0\n",
      "718: loss=0.987, reward_mean=0.0, reward_bound=0.0\n",
      "719: loss=0.785, reward_mean=0.0, reward_bound=0.0\n",
      "720: loss=0.842, reward_mean=0.0, reward_bound=0.0\n",
      "721: loss=0.819, reward_mean=0.0, reward_bound=0.0\n",
      "722: loss=0.750, reward_mean=0.0, reward_bound=0.0\n",
      "723: loss=0.783, reward_mean=0.0, reward_bound=0.0\n",
      "724: loss=0.861, reward_mean=0.1, reward_bound=0.0\n",
      "725: loss=0.763, reward_mean=0.0, reward_bound=0.0\n",
      "726: loss=0.866, reward_mean=0.0, reward_bound=0.0\n",
      "727: loss=0.784, reward_mean=0.0, reward_bound=0.0\n",
      "728: loss=0.778, reward_mean=0.0, reward_bound=0.0\n",
      "729: loss=0.989, reward_mean=0.0, reward_bound=0.0\n",
      "730: loss=0.877, reward_mean=0.0, reward_bound=0.0\n",
      "731: loss=0.884, reward_mean=0.0, reward_bound=0.0\n",
      "732: loss=0.788, reward_mean=0.0, reward_bound=0.0\n",
      "733: loss=0.818, reward_mean=0.0, reward_bound=0.0\n",
      "734: loss=0.832, reward_mean=0.1, reward_bound=0.0\n",
      "735: loss=0.797, reward_mean=0.0, reward_bound=0.0\n",
      "736: loss=0.852, reward_mean=0.0, reward_bound=0.0\n",
      "737: loss=0.721, reward_mean=0.0, reward_bound=0.0\n",
      "738: loss=0.798, reward_mean=0.0, reward_bound=0.0\n",
      "739: loss=0.742, reward_mean=0.1, reward_bound=0.0\n",
      "740: loss=0.761, reward_mean=0.0, reward_bound=0.0\n",
      "741: loss=0.869, reward_mean=0.0, reward_bound=0.0\n",
      "742: loss=0.818, reward_mean=0.0, reward_bound=0.0\n",
      "743: loss=0.693, reward_mean=0.0, reward_bound=0.0\n",
      "744: loss=0.813, reward_mean=0.0, reward_bound=0.0\n",
      "745: loss=0.797, reward_mean=0.0, reward_bound=0.0\n",
      "746: loss=0.661, reward_mean=0.0, reward_bound=0.0\n",
      "747: loss=0.948, reward_mean=0.0, reward_bound=0.0\n",
      "748: loss=0.885, reward_mean=0.0, reward_bound=0.0\n",
      "749: loss=0.734, reward_mean=0.0, reward_bound=0.0\n",
      "750: loss=0.853, reward_mean=0.0, reward_bound=0.0\n",
      "751: loss=0.866, reward_mean=0.0, reward_bound=0.0\n",
      "752: loss=0.795, reward_mean=0.0, reward_bound=0.0\n",
      "753: loss=0.814, reward_mean=0.0, reward_bound=0.0\n",
      "754: loss=0.860, reward_mean=0.0, reward_bound=0.0\n",
      "755: loss=0.912, reward_mean=0.0, reward_bound=0.0\n",
      "756: loss=0.871, reward_mean=0.0, reward_bound=0.0\n",
      "757: loss=0.844, reward_mean=0.0, reward_bound=0.0\n",
      "758: loss=0.697, reward_mean=0.0, reward_bound=0.0\n",
      "759: loss=0.693, reward_mean=0.0, reward_bound=0.0\n",
      "760: loss=0.749, reward_mean=0.0, reward_bound=0.0\n",
      "761: loss=0.790, reward_mean=0.1, reward_bound=0.0\n",
      "762: loss=0.880, reward_mean=0.1, reward_bound=0.0\n",
      "763: loss=0.851, reward_mean=0.0, reward_bound=0.0\n",
      "764: loss=0.760, reward_mean=0.0, reward_bound=0.0\n",
      "765: loss=0.816, reward_mean=0.0, reward_bound=0.0\n",
      "766: loss=0.833, reward_mean=0.0, reward_bound=0.0\n",
      "767: loss=0.755, reward_mean=0.0, reward_bound=0.0\n",
      "768: loss=0.713, reward_mean=0.0, reward_bound=0.0\n",
      "769: loss=0.653, reward_mean=0.0, reward_bound=0.0\n",
      "770: loss=0.727, reward_mean=0.0, reward_bound=0.0\n",
      "771: loss=0.816, reward_mean=0.0, reward_bound=0.0\n",
      "772: loss=0.701, reward_mean=0.0, reward_bound=0.0\n",
      "773: loss=0.789, reward_mean=0.0, reward_bound=0.0\n",
      "774: loss=0.704, reward_mean=0.0, reward_bound=0.0\n",
      "775: loss=0.823, reward_mean=0.0, reward_bound=0.0\n",
      "776: loss=0.703, reward_mean=0.0, reward_bound=0.0\n",
      "777: loss=0.846, reward_mean=0.0, reward_bound=0.0\n",
      "778: loss=0.840, reward_mean=0.0, reward_bound=0.0\n",
      "779: loss=0.880, reward_mean=0.0, reward_bound=0.0\n",
      "780: loss=0.762, reward_mean=0.0, reward_bound=0.0\n",
      "781: loss=0.841, reward_mean=0.0, reward_bound=0.0\n",
      "782: loss=0.775, reward_mean=0.0, reward_bound=0.0\n",
      "783: loss=0.754, reward_mean=0.0, reward_bound=0.0\n",
      "784: loss=0.899, reward_mean=0.0, reward_bound=0.0\n",
      "785: loss=0.629, reward_mean=0.0, reward_bound=0.0\n",
      "786: loss=0.735, reward_mean=0.0, reward_bound=0.0\n",
      "787: loss=0.823, reward_mean=0.0, reward_bound=0.0\n",
      "788: loss=0.767, reward_mean=0.0, reward_bound=0.0\n",
      "789: loss=0.744, reward_mean=0.0, reward_bound=0.0\n",
      "790: loss=0.747, reward_mean=0.0, reward_bound=0.0\n",
      "791: loss=0.779, reward_mean=0.0, reward_bound=0.0\n",
      "792: loss=0.916, reward_mean=0.0, reward_bound=0.0\n",
      "793: loss=0.725, reward_mean=0.0, reward_bound=0.0\n",
      "794: loss=0.738, reward_mean=0.0, reward_bound=0.0\n",
      "795: loss=0.768, reward_mean=0.0, reward_bound=0.0\n",
      "796: loss=0.669, reward_mean=0.0, reward_bound=0.0\n",
      "797: loss=0.731, reward_mean=0.0, reward_bound=0.0\n",
      "798: loss=0.754, reward_mean=0.0, reward_bound=0.0\n",
      "799: loss=0.759, reward_mean=0.0, reward_bound=0.0\n",
      "800: loss=0.805, reward_mean=0.0, reward_bound=0.0\n",
      "801: loss=0.661, reward_mean=0.0, reward_bound=0.0\n",
      "802: loss=0.662, reward_mean=0.0, reward_bound=0.0\n",
      "803: loss=0.759, reward_mean=0.0, reward_bound=0.0\n",
      "804: loss=0.627, reward_mean=0.0, reward_bound=0.0\n",
      "805: loss=0.693, reward_mean=0.0, reward_bound=0.0\n",
      "806: loss=0.793, reward_mean=0.0, reward_bound=0.0\n",
      "807: loss=0.717, reward_mean=0.1, reward_bound=0.0\n",
      "808: loss=0.851, reward_mean=0.1, reward_bound=0.0\n",
      "809: loss=0.695, reward_mean=0.1, reward_bound=0.0\n",
      "810: loss=0.675, reward_mean=0.1, reward_bound=0.0\n",
      "811: loss=0.654, reward_mean=0.0, reward_bound=0.0\n",
      "812: loss=0.712, reward_mean=0.0, reward_bound=0.0\n",
      "813: loss=0.638, reward_mean=0.0, reward_bound=0.0\n",
      "814: loss=0.706, reward_mean=0.0, reward_bound=0.0\n",
      "815: loss=0.724, reward_mean=0.0, reward_bound=0.0\n",
      "816: loss=0.798, reward_mean=0.0, reward_bound=0.0\n",
      "817: loss=0.691, reward_mean=0.0, reward_bound=0.0\n",
      "818: loss=0.720, reward_mean=0.0, reward_bound=0.0\n",
      "819: loss=0.680, reward_mean=0.0, reward_bound=0.0\n",
      "820: loss=0.613, reward_mean=0.0, reward_bound=0.0\n",
      "821: loss=0.733, reward_mean=0.1, reward_bound=0.0\n",
      "822: loss=0.722, reward_mean=0.0, reward_bound=0.0\n",
      "823: loss=0.746, reward_mean=0.1, reward_bound=0.0\n",
      "824: loss=0.563, reward_mean=0.0, reward_bound=0.0\n",
      "825: loss=0.753, reward_mean=0.1, reward_bound=0.0\n",
      "826: loss=0.856, reward_mean=0.0, reward_bound=0.0\n",
      "827: loss=0.666, reward_mean=0.0, reward_bound=0.0\n",
      "828: loss=0.636, reward_mean=0.0, reward_bound=0.0\n",
      "829: loss=0.492, reward_mean=0.0, reward_bound=0.0\n",
      "830: loss=0.709, reward_mean=0.0, reward_bound=0.0\n",
      "831: loss=0.752, reward_mean=0.0, reward_bound=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "832: loss=0.705, reward_mean=0.1, reward_bound=0.0\n",
      "833: loss=0.692, reward_mean=0.0, reward_bound=0.0\n",
      "834: loss=0.581, reward_mean=0.0, reward_bound=0.0\n",
      "835: loss=0.508, reward_mean=0.0, reward_bound=0.0\n",
      "836: loss=0.695, reward_mean=0.0, reward_bound=0.0\n",
      "837: loss=0.727, reward_mean=0.0, reward_bound=0.0\n",
      "838: loss=0.743, reward_mean=0.1, reward_bound=0.0\n",
      "839: loss=0.637, reward_mean=0.0, reward_bound=0.0\n",
      "840: loss=0.679, reward_mean=0.0, reward_bound=0.0\n",
      "841: loss=0.805, reward_mean=0.0, reward_bound=0.0\n",
      "842: loss=0.619, reward_mean=0.0, reward_bound=0.0\n",
      "843: loss=0.560, reward_mean=0.0, reward_bound=0.0\n",
      "844: loss=0.787, reward_mean=0.0, reward_bound=0.0\n",
      "845: loss=0.728, reward_mean=0.0, reward_bound=0.0\n",
      "846: loss=0.689, reward_mean=0.0, reward_bound=0.0\n",
      "847: loss=0.658, reward_mean=0.0, reward_bound=0.0\n",
      "848: loss=0.790, reward_mean=0.0, reward_bound=0.0\n",
      "849: loss=0.700, reward_mean=0.0, reward_bound=0.0\n",
      "850: loss=0.778, reward_mean=0.0, reward_bound=0.0\n",
      "851: loss=0.759, reward_mean=0.1, reward_bound=0.0\n",
      "852: loss=0.793, reward_mean=0.0, reward_bound=0.0\n",
      "853: loss=0.661, reward_mean=0.0, reward_bound=0.0\n",
      "854: loss=0.819, reward_mean=0.0, reward_bound=0.0\n",
      "855: loss=0.721, reward_mean=0.0, reward_bound=0.0\n",
      "856: loss=0.799, reward_mean=0.0, reward_bound=0.0\n",
      "857: loss=0.721, reward_mean=0.0, reward_bound=0.0\n",
      "858: loss=0.983, reward_mean=0.0, reward_bound=0.0\n",
      "859: loss=0.851, reward_mean=0.0, reward_bound=0.0\n",
      "860: loss=0.723, reward_mean=0.0, reward_bound=0.0\n",
      "861: loss=0.677, reward_mean=0.0, reward_bound=0.0\n",
      "862: loss=0.726, reward_mean=0.0, reward_bound=0.0\n",
      "863: loss=0.749, reward_mean=0.0, reward_bound=0.0\n",
      "864: loss=0.728, reward_mean=0.0, reward_bound=0.0\n",
      "865: loss=0.932, reward_mean=0.0, reward_bound=0.0\n",
      "866: loss=0.708, reward_mean=0.0, reward_bound=0.0\n",
      "867: loss=0.740, reward_mean=0.0, reward_bound=0.0\n",
      "868: loss=0.809, reward_mean=0.0, reward_bound=0.0\n",
      "869: loss=0.803, reward_mean=0.0, reward_bound=0.0\n",
      "870: loss=0.626, reward_mean=0.0, reward_bound=0.0\n",
      "871: loss=0.889, reward_mean=0.0, reward_bound=0.0\n",
      "872: loss=0.714, reward_mean=0.0, reward_bound=0.0\n",
      "873: loss=0.797, reward_mean=0.0, reward_bound=0.0\n",
      "874: loss=0.731, reward_mean=0.0, reward_bound=0.0\n",
      "875: loss=0.765, reward_mean=0.0, reward_bound=0.0\n",
      "876: loss=0.771, reward_mean=0.0, reward_bound=0.0\n",
      "877: loss=0.758, reward_mean=0.0, reward_bound=0.0\n",
      "878: loss=0.784, reward_mean=0.0, reward_bound=0.0\n",
      "879: loss=0.813, reward_mean=0.0, reward_bound=0.0\n",
      "880: loss=0.828, reward_mean=0.0, reward_bound=0.0\n",
      "881: loss=0.849, reward_mean=0.0, reward_bound=0.0\n",
      "882: loss=0.795, reward_mean=0.0, reward_bound=0.0\n",
      "883: loss=0.777, reward_mean=0.0, reward_bound=0.0\n",
      "884: loss=0.686, reward_mean=0.0, reward_bound=0.0\n",
      "885: loss=0.775, reward_mean=0.0, reward_bound=0.0\n",
      "886: loss=0.888, reward_mean=0.0, reward_bound=0.0\n",
      "887: loss=0.825, reward_mean=0.0, reward_bound=0.0\n",
      "888: loss=0.721, reward_mean=0.0, reward_bound=0.0\n",
      "889: loss=0.818, reward_mean=0.0, reward_bound=0.0\n",
      "890: loss=0.703, reward_mean=0.0, reward_bound=0.0\n",
      "891: loss=0.756, reward_mean=0.0, reward_bound=0.0\n",
      "892: loss=0.777, reward_mean=0.0, reward_bound=0.0\n",
      "893: loss=0.769, reward_mean=0.0, reward_bound=0.0\n",
      "894: loss=0.806, reward_mean=0.0, reward_bound=0.0\n",
      "895: loss=0.764, reward_mean=0.0, reward_bound=0.0\n",
      "896: loss=0.772, reward_mean=0.0, reward_bound=0.0\n",
      "897: loss=0.799, reward_mean=0.0, reward_bound=0.0\n",
      "898: loss=0.706, reward_mean=0.0, reward_bound=0.0\n",
      "899: loss=0.822, reward_mean=0.0, reward_bound=0.0\n",
      "900: loss=0.935, reward_mean=0.0, reward_bound=0.0\n",
      "901: loss=0.818, reward_mean=0.0, reward_bound=0.0\n",
      "902: loss=0.918, reward_mean=0.0, reward_bound=0.0\n",
      "903: loss=0.818, reward_mean=0.0, reward_bound=0.0\n",
      "904: loss=0.684, reward_mean=0.1, reward_bound=0.0\n",
      "905: loss=0.931, reward_mean=0.0, reward_bound=0.0\n",
      "906: loss=0.818, reward_mean=0.0, reward_bound=0.0\n",
      "907: loss=0.687, reward_mean=0.0, reward_bound=0.0\n",
      "908: loss=0.774, reward_mean=0.0, reward_bound=0.0\n",
      "909: loss=0.763, reward_mean=0.0, reward_bound=0.0\n",
      "910: loss=0.792, reward_mean=0.0, reward_bound=0.0\n",
      "911: loss=0.792, reward_mean=0.0, reward_bound=0.0\n",
      "912: loss=0.757, reward_mean=0.1, reward_bound=0.0\n",
      "913: loss=0.812, reward_mean=0.0, reward_bound=0.0\n",
      "914: loss=0.770, reward_mean=0.0, reward_bound=0.0\n",
      "915: loss=0.817, reward_mean=0.0, reward_bound=0.0\n",
      "916: loss=0.859, reward_mean=0.0, reward_bound=0.0\n",
      "917: loss=0.727, reward_mean=0.1, reward_bound=0.0\n",
      "918: loss=0.743, reward_mean=0.0, reward_bound=0.0\n",
      "919: loss=0.769, reward_mean=0.0, reward_bound=0.0\n",
      "920: loss=0.912, reward_mean=0.0, reward_bound=0.0\n",
      "921: loss=0.801, reward_mean=0.0, reward_bound=0.0\n",
      "922: loss=0.798, reward_mean=0.0, reward_bound=0.0\n",
      "923: loss=0.782, reward_mean=0.0, reward_bound=0.0\n",
      "924: loss=0.776, reward_mean=0.0, reward_bound=0.0\n",
      "925: loss=0.740, reward_mean=0.0, reward_bound=0.0\n",
      "926: loss=0.839, reward_mean=0.0, reward_bound=0.0\n",
      "927: loss=0.842, reward_mean=0.0, reward_bound=0.0\n",
      "928: loss=0.750, reward_mean=0.0, reward_bound=0.0\n",
      "929: loss=1.027, reward_mean=0.0, reward_bound=0.0\n",
      "930: loss=0.809, reward_mean=0.0, reward_bound=0.0\n",
      "931: loss=0.871, reward_mean=0.0, reward_bound=0.0\n",
      "932: loss=0.786, reward_mean=0.0, reward_bound=0.0\n",
      "933: loss=0.902, reward_mean=0.0, reward_bound=0.0\n",
      "934: loss=0.789, reward_mean=0.0, reward_bound=0.0\n",
      "935: loss=0.846, reward_mean=0.0, reward_bound=0.0\n",
      "936: loss=0.886, reward_mean=0.0, reward_bound=0.0\n",
      "937: loss=0.822, reward_mean=0.0, reward_bound=0.0\n",
      "938: loss=0.822, reward_mean=0.0, reward_bound=0.0\n",
      "939: loss=0.801, reward_mean=0.0, reward_bound=0.0\n",
      "940: loss=0.750, reward_mean=0.0, reward_bound=0.0\n",
      "941: loss=0.816, reward_mean=0.0, reward_bound=0.0\n",
      "942: loss=0.916, reward_mean=0.0, reward_bound=0.0\n",
      "943: loss=0.847, reward_mean=0.0, reward_bound=0.0\n",
      "944: loss=0.857, reward_mean=0.0, reward_bound=0.0\n",
      "945: loss=0.732, reward_mean=0.0, reward_bound=0.0\n",
      "946: loss=0.843, reward_mean=0.0, reward_bound=0.0\n",
      "947: loss=0.871, reward_mean=0.0, reward_bound=0.0\n",
      "948: loss=0.718, reward_mean=0.0, reward_bound=0.0\n",
      "949: loss=0.786, reward_mean=0.0, reward_bound=0.0\n",
      "950: loss=0.803, reward_mean=0.0, reward_bound=0.0\n",
      "951: loss=0.769, reward_mean=0.0, reward_bound=0.0\n",
      "952: loss=0.846, reward_mean=0.0, reward_bound=0.0\n",
      "953: loss=0.754, reward_mean=0.0, reward_bound=0.0\n",
      "954: loss=0.871, reward_mean=0.0, reward_bound=0.0\n",
      "955: loss=0.713, reward_mean=0.0, reward_bound=0.0\n",
      "956: loss=0.767, reward_mean=0.0, reward_bound=0.0\n",
      "957: loss=0.693, reward_mean=0.0, reward_bound=0.0\n",
      "958: loss=0.703, reward_mean=0.0, reward_bound=0.0\n",
      "959: loss=0.779, reward_mean=0.0, reward_bound=0.0\n",
      "960: loss=0.685, reward_mean=0.0, reward_bound=0.0\n",
      "961: loss=0.663, reward_mean=0.0, reward_bound=0.0\n",
      "962: loss=0.644, reward_mean=0.0, reward_bound=0.0\n",
      "963: loss=0.662, reward_mean=0.0, reward_bound=0.0\n",
      "964: loss=0.608, reward_mean=0.0, reward_bound=0.0\n",
      "965: loss=0.745, reward_mean=0.0, reward_bound=0.0\n",
      "966: loss=0.626, reward_mean=0.0, reward_bound=0.0\n",
      "967: loss=0.763, reward_mean=0.0, reward_bound=0.0\n",
      "968: loss=0.685, reward_mean=0.0, reward_bound=0.0\n",
      "969: loss=0.623, reward_mean=0.0, reward_bound=0.0\n",
      "970: loss=0.717, reward_mean=0.0, reward_bound=0.0\n",
      "971: loss=0.647, reward_mean=0.0, reward_bound=0.0\n",
      "972: loss=0.629, reward_mean=0.0, reward_bound=0.0\n",
      "973: loss=0.688, reward_mean=0.0, reward_bound=0.0\n",
      "974: loss=0.700, reward_mean=0.0, reward_bound=0.0\n",
      "975: loss=0.656, reward_mean=0.0, reward_bound=0.0\n",
      "976: loss=0.670, reward_mean=0.0, reward_bound=0.0\n",
      "977: loss=0.723, reward_mean=0.0, reward_bound=0.0\n",
      "978: loss=0.642, reward_mean=0.0, reward_bound=0.0\n",
      "979: loss=0.657, reward_mean=0.0, reward_bound=0.0\n",
      "980: loss=0.714, reward_mean=0.0, reward_bound=0.0\n",
      "981: loss=0.654, reward_mean=0.0, reward_bound=0.0\n",
      "982: loss=0.678, reward_mean=0.0, reward_bound=0.0\n",
      "983: loss=0.661, reward_mean=0.0, reward_bound=0.0\n",
      "984: loss=0.797, reward_mean=0.0, reward_bound=0.0\n",
      "985: loss=0.661, reward_mean=0.0, reward_bound=0.0\n",
      "986: loss=0.613, reward_mean=0.0, reward_bound=0.0\n",
      "987: loss=0.634, reward_mean=0.0, reward_bound=0.0\n",
      "988: loss=0.622, reward_mean=0.0, reward_bound=0.0\n",
      "989: loss=0.779, reward_mean=0.0, reward_bound=0.0\n",
      "990: loss=0.586, reward_mean=0.0, reward_bound=0.0\n",
      "991: loss=0.671, reward_mean=0.0, reward_bound=0.0\n",
      "992: loss=0.726, reward_mean=0.0, reward_bound=0.0\n",
      "993: loss=0.647, reward_mean=0.0, reward_bound=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994: loss=0.773, reward_mean=0.0, reward_bound=0.0\n",
      "995: loss=0.668, reward_mean=0.0, reward_bound=0.0\n",
      "996: loss=0.672, reward_mean=0.0, reward_bound=0.0\n",
      "997: loss=0.702, reward_mean=0.0, reward_bound=0.0\n",
      "998: loss=0.860, reward_mean=0.0, reward_bound=0.0\n",
      "999: loss=0.717, reward_mean=0.0, reward_bound=0.0\n",
      "1000: loss=0.743, reward_mean=0.0, reward_bound=0.0\n",
      "1001: loss=0.801, reward_mean=0.0, reward_bound=0.0\n",
      "1002: loss=0.766, reward_mean=0.0, reward_bound=0.0\n",
      "1003: loss=0.783, reward_mean=0.0, reward_bound=0.0\n",
      "1004: loss=0.861, reward_mean=0.0, reward_bound=0.0\n",
      "1005: loss=0.842, reward_mean=0.0, reward_bound=0.0\n",
      "1006: loss=0.756, reward_mean=0.0, reward_bound=0.0\n",
      "1007: loss=0.836, reward_mean=0.0, reward_bound=0.0\n",
      "1008: loss=0.928, reward_mean=0.0, reward_bound=0.0\n",
      "1009: loss=0.881, reward_mean=0.0, reward_bound=0.0\n",
      "1010: loss=0.856, reward_mean=0.0, reward_bound=0.0\n",
      "1011: loss=0.886, reward_mean=0.0, reward_bound=0.0\n",
      "1012: loss=0.922, reward_mean=0.0, reward_bound=0.0\n",
      "1013: loss=0.792, reward_mean=0.0, reward_bound=0.0\n",
      "1014: loss=0.957, reward_mean=0.0, reward_bound=0.0\n",
      "1015: loss=0.867, reward_mean=0.0, reward_bound=0.0\n",
      "1016: loss=0.910, reward_mean=0.0, reward_bound=0.0\n",
      "1017: loss=0.913, reward_mean=0.0, reward_bound=0.0\n",
      "1018: loss=0.837, reward_mean=0.0, reward_bound=0.0\n",
      "1019: loss=0.944, reward_mean=0.0, reward_bound=0.0\n",
      "1020: loss=0.818, reward_mean=0.0, reward_bound=0.0\n",
      "1021: loss=0.792, reward_mean=0.0, reward_bound=0.0\n",
      "1022: loss=0.861, reward_mean=0.0, reward_bound=0.0\n",
      "1023: loss=0.781, reward_mean=0.0, reward_bound=0.0\n",
      "1024: loss=0.867, reward_mean=0.0, reward_bound=0.0\n",
      "1025: loss=0.840, reward_mean=0.0, reward_bound=0.0\n",
      "1026: loss=0.923, reward_mean=0.0, reward_bound=0.0\n",
      "1027: loss=0.943, reward_mean=0.0, reward_bound=0.0\n",
      "1028: loss=0.853, reward_mean=0.0, reward_bound=0.0\n",
      "1029: loss=0.848, reward_mean=0.1, reward_bound=0.0\n",
      "1030: loss=0.936, reward_mean=0.0, reward_bound=0.0\n",
      "1031: loss=0.799, reward_mean=0.0, reward_bound=0.0\n",
      "1032: loss=0.836, reward_mean=0.0, reward_bound=0.0\n",
      "1033: loss=0.825, reward_mean=0.0, reward_bound=0.0\n",
      "1034: loss=0.882, reward_mean=0.0, reward_bound=0.0\n",
      "1035: loss=0.829, reward_mean=0.0, reward_bound=0.0\n",
      "1036: loss=0.812, reward_mean=0.0, reward_bound=0.0\n",
      "1037: loss=0.846, reward_mean=0.0, reward_bound=0.0\n",
      "1038: loss=0.885, reward_mean=0.0, reward_bound=0.0\n",
      "1039: loss=0.939, reward_mean=0.0, reward_bound=0.0\n",
      "1040: loss=0.773, reward_mean=0.0, reward_bound=0.0\n",
      "1041: loss=0.860, reward_mean=0.0, reward_bound=0.0\n",
      "1042: loss=0.901, reward_mean=0.0, reward_bound=0.0\n",
      "1043: loss=0.911, reward_mean=0.0, reward_bound=0.0\n",
      "1044: loss=0.894, reward_mean=0.0, reward_bound=0.0\n",
      "1045: loss=0.838, reward_mean=0.0, reward_bound=0.0\n",
      "1046: loss=0.824, reward_mean=0.0, reward_bound=0.0\n",
      "1047: loss=0.749, reward_mean=0.0, reward_bound=0.0\n",
      "1048: loss=0.749, reward_mean=0.0, reward_bound=0.0\n",
      "1049: loss=0.692, reward_mean=0.0, reward_bound=0.0\n",
      "1050: loss=0.831, reward_mean=0.0, reward_bound=0.0\n",
      "1051: loss=0.779, reward_mean=0.0, reward_bound=0.0\n",
      "1052: loss=0.727, reward_mean=0.0, reward_bound=0.0\n",
      "1053: loss=0.646, reward_mean=0.0, reward_bound=0.0\n",
      "1054: loss=1.023, reward_mean=0.0, reward_bound=0.0\n",
      "1055: loss=0.726, reward_mean=0.0, reward_bound=0.0\n",
      "1056: loss=0.696, reward_mean=0.0, reward_bound=0.0\n",
      "1057: loss=0.797, reward_mean=0.0, reward_bound=0.0\n",
      "1058: loss=0.740, reward_mean=0.0, reward_bound=0.0\n",
      "1059: loss=0.929, reward_mean=0.0, reward_bound=0.0\n",
      "1060: loss=0.799, reward_mean=0.0, reward_bound=0.0\n",
      "1061: loss=0.732, reward_mean=0.0, reward_bound=0.0\n",
      "1062: loss=0.737, reward_mean=0.0, reward_bound=0.0\n",
      "1063: loss=0.624, reward_mean=0.0, reward_bound=0.0\n",
      "1064: loss=0.706, reward_mean=0.0, reward_bound=0.0\n",
      "1065: loss=0.790, reward_mean=0.0, reward_bound=0.0\n",
      "1066: loss=0.674, reward_mean=0.0, reward_bound=0.0\n",
      "1067: loss=0.810, reward_mean=0.0, reward_bound=0.0\n",
      "1068: loss=0.751, reward_mean=0.0, reward_bound=0.0\n",
      "1069: loss=0.720, reward_mean=0.0, reward_bound=0.0\n",
      "1070: loss=0.726, reward_mean=0.0, reward_bound=0.0\n",
      "1071: loss=0.726, reward_mean=0.0, reward_bound=0.0\n",
      "1072: loss=0.731, reward_mean=0.0, reward_bound=0.0\n",
      "1073: loss=0.661, reward_mean=0.0, reward_bound=0.0\n",
      "1074: loss=0.728, reward_mean=0.0, reward_bound=0.0\n",
      "1075: loss=0.836, reward_mean=0.0, reward_bound=0.0\n",
      "1076: loss=0.639, reward_mean=0.0, reward_bound=0.0\n",
      "1077: loss=0.678, reward_mean=0.0, reward_bound=0.0\n",
      "1078: loss=0.686, reward_mean=0.0, reward_bound=0.0\n",
      "1079: loss=0.750, reward_mean=0.0, reward_bound=0.0\n",
      "1080: loss=0.564, reward_mean=0.0, reward_bound=0.0\n",
      "1081: loss=0.888, reward_mean=0.0, reward_bound=0.0\n",
      "1082: loss=0.857, reward_mean=0.0, reward_bound=0.0\n",
      "1083: loss=0.827, reward_mean=0.0, reward_bound=0.0\n",
      "1084: loss=0.798, reward_mean=0.0, reward_bound=0.0\n",
      "1085: loss=0.608, reward_mean=0.0, reward_bound=0.0\n",
      "1086: loss=0.834, reward_mean=0.1, reward_bound=0.0\n",
      "1087: loss=0.894, reward_mean=0.0, reward_bound=0.0\n",
      "1088: loss=0.578, reward_mean=0.0, reward_bound=0.0\n",
      "1089: loss=0.740, reward_mean=0.0, reward_bound=0.0\n",
      "1090: loss=0.807, reward_mean=0.0, reward_bound=0.0\n",
      "1091: loss=0.768, reward_mean=0.0, reward_bound=0.0\n",
      "1092: loss=0.692, reward_mean=0.0, reward_bound=0.0\n",
      "1093: loss=0.870, reward_mean=0.0, reward_bound=0.0\n",
      "1094: loss=0.710, reward_mean=0.0, reward_bound=0.0\n",
      "1095: loss=0.777, reward_mean=0.0, reward_bound=0.0\n",
      "1096: loss=0.782, reward_mean=0.0, reward_bound=0.0\n",
      "1097: loss=0.811, reward_mean=0.0, reward_bound=0.0\n",
      "1098: loss=0.844, reward_mean=0.0, reward_bound=0.0\n",
      "1099: loss=0.797, reward_mean=0.0, reward_bound=0.0\n",
      "1100: loss=0.924, reward_mean=0.0, reward_bound=0.0\n",
      "1101: loss=0.695, reward_mean=0.0, reward_bound=0.0\n",
      "1102: loss=0.906, reward_mean=0.0, reward_bound=0.0\n",
      "1103: loss=0.822, reward_mean=0.0, reward_bound=0.0\n",
      "1104: loss=0.803, reward_mean=0.0, reward_bound=0.0\n",
      "1105: loss=0.746, reward_mean=0.0, reward_bound=0.0\n",
      "1106: loss=0.862, reward_mean=0.0, reward_bound=0.0\n",
      "1107: loss=0.809, reward_mean=0.0, reward_bound=0.0\n",
      "1108: loss=0.797, reward_mean=0.0, reward_bound=0.0\n",
      "1109: loss=0.842, reward_mean=0.0, reward_bound=0.0\n",
      "1110: loss=1.022, reward_mean=0.0, reward_bound=0.0\n",
      "1111: loss=0.803, reward_mean=0.0, reward_bound=0.0\n",
      "1112: loss=0.683, reward_mean=0.0, reward_bound=0.0\n",
      "1113: loss=0.719, reward_mean=0.0, reward_bound=0.0\n",
      "1114: loss=0.744, reward_mean=0.0, reward_bound=0.0\n",
      "1115: loss=0.996, reward_mean=0.0, reward_bound=0.0\n",
      "1116: loss=0.693, reward_mean=0.0, reward_bound=0.0\n",
      "1117: loss=0.738, reward_mean=0.0, reward_bound=0.0\n",
      "1118: loss=0.798, reward_mean=0.0, reward_bound=0.0\n",
      "1119: loss=0.777, reward_mean=0.0, reward_bound=0.0\n",
      "1120: loss=0.833, reward_mean=0.0, reward_bound=0.0\n",
      "1121: loss=0.772, reward_mean=0.0, reward_bound=0.0\n",
      "1122: loss=0.732, reward_mean=0.0, reward_bound=0.0\n",
      "1123: loss=0.791, reward_mean=0.0, reward_bound=0.0\n",
      "1124: loss=0.720, reward_mean=0.0, reward_bound=0.0\n",
      "1125: loss=0.774, reward_mean=0.0, reward_bound=0.0\n",
      "1126: loss=0.810, reward_mean=0.0, reward_bound=0.0\n",
      "1127: loss=0.856, reward_mean=0.0, reward_bound=0.0\n",
      "1128: loss=1.022, reward_mean=0.0, reward_bound=0.0\n",
      "1129: loss=0.745, reward_mean=0.0, reward_bound=0.0\n",
      "1130: loss=0.725, reward_mean=0.0, reward_bound=0.0\n",
      "1131: loss=0.832, reward_mean=0.0, reward_bound=0.0\n",
      "1132: loss=0.826, reward_mean=0.0, reward_bound=0.0\n",
      "1133: loss=0.767, reward_mean=0.0, reward_bound=0.0\n",
      "1134: loss=0.791, reward_mean=0.0, reward_bound=0.0\n",
      "1135: loss=0.792, reward_mean=0.0, reward_bound=0.0\n",
      "1136: loss=0.915, reward_mean=0.0, reward_bound=0.0\n",
      "1137: loss=0.884, reward_mean=0.0, reward_bound=0.0\n",
      "1138: loss=0.863, reward_mean=0.0, reward_bound=0.0\n",
      "1139: loss=0.747, reward_mean=0.0, reward_bound=0.0\n",
      "1140: loss=0.770, reward_mean=0.0, reward_bound=0.0\n",
      "1141: loss=0.902, reward_mean=0.0, reward_bound=0.0\n",
      "1142: loss=0.861, reward_mean=0.0, reward_bound=0.0\n",
      "1143: loss=0.758, reward_mean=0.0, reward_bound=0.0\n",
      "1144: loss=0.688, reward_mean=0.0, reward_bound=0.0\n",
      "1145: loss=0.836, reward_mean=0.0, reward_bound=0.0\n",
      "1146: loss=0.651, reward_mean=0.0, reward_bound=0.0\n",
      "1147: loss=0.818, reward_mean=0.0, reward_bound=0.0\n",
      "1148: loss=0.739, reward_mean=0.0, reward_bound=0.0\n",
      "1149: loss=0.898, reward_mean=0.0, reward_bound=0.0\n",
      "1150: loss=0.836, reward_mean=0.0, reward_bound=0.0\n",
      "1151: loss=0.973, reward_mean=0.0, reward_bound=0.0\n",
      "1152: loss=0.727, reward_mean=0.0, reward_bound=0.0\n",
      "1153: loss=0.652, reward_mean=0.0, reward_bound=0.0\n",
      "1154: loss=0.670, reward_mean=0.0, reward_bound=0.0\n",
      "1155: loss=0.906, reward_mean=0.0, reward_bound=0.0\n",
      "1156: loss=0.751, reward_mean=0.0, reward_bound=0.0\n",
      "1157: loss=0.878, reward_mean=0.0, reward_bound=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1158: loss=0.862, reward_mean=0.0, reward_bound=0.0\n",
      "1159: loss=0.831, reward_mean=0.0, reward_bound=0.0\n",
      "1160: loss=0.845, reward_mean=0.0, reward_bound=0.0\n",
      "1161: loss=0.802, reward_mean=0.0, reward_bound=0.0\n",
      "1162: loss=0.867, reward_mean=0.0, reward_bound=0.0\n",
      "1163: loss=0.922, reward_mean=0.0, reward_bound=0.0\n",
      "1164: loss=0.801, reward_mean=0.0, reward_bound=0.0\n",
      "1165: loss=0.769, reward_mean=0.0, reward_bound=0.0\n",
      "1166: loss=0.774, reward_mean=0.0, reward_bound=0.0\n",
      "1167: loss=0.869, reward_mean=0.0, reward_bound=0.0\n",
      "1168: loss=0.797, reward_mean=0.0, reward_bound=0.0\n",
      "1169: loss=0.772, reward_mean=0.0, reward_bound=0.0\n",
      "1170: loss=0.752, reward_mean=0.0, reward_bound=0.0\n",
      "1171: loss=0.865, reward_mean=0.0, reward_bound=0.0\n",
      "1172: loss=0.729, reward_mean=0.0, reward_bound=0.0\n",
      "1173: loss=0.838, reward_mean=0.0, reward_bound=0.0\n",
      "1174: loss=0.842, reward_mean=0.0, reward_bound=0.0\n",
      "1175: loss=0.787, reward_mean=0.0, reward_bound=0.0\n",
      "1176: loss=0.787, reward_mean=0.0, reward_bound=0.0\n",
      "1177: loss=0.793, reward_mean=0.0, reward_bound=0.0\n",
      "1178: loss=0.857, reward_mean=0.0, reward_bound=0.0\n",
      "1179: loss=0.800, reward_mean=0.0, reward_bound=0.0\n",
      "1180: loss=0.856, reward_mean=0.0, reward_bound=0.0\n",
      "1181: loss=0.804, reward_mean=0.0, reward_bound=0.0\n",
      "1182: loss=0.806, reward_mean=0.0, reward_bound=0.0\n",
      "1183: loss=0.794, reward_mean=0.0, reward_bound=0.0\n",
      "1184: loss=0.844, reward_mean=0.0, reward_bound=0.0\n",
      "1185: loss=0.721, reward_mean=0.0, reward_bound=0.0\n",
      "1186: loss=0.876, reward_mean=0.0, reward_bound=0.0\n",
      "1187: loss=0.707, reward_mean=0.0, reward_bound=0.0\n",
      "1188: loss=0.716, reward_mean=0.0, reward_bound=0.0\n",
      "1189: loss=0.757, reward_mean=0.0, reward_bound=0.0\n",
      "1190: loss=0.860, reward_mean=0.0, reward_bound=0.0\n",
      "1191: loss=0.875, reward_mean=0.0, reward_bound=0.0\n",
      "1192: loss=0.819, reward_mean=0.0, reward_bound=0.0\n",
      "1193: loss=0.861, reward_mean=0.0, reward_bound=0.0\n",
      "1194: loss=0.759, reward_mean=0.0, reward_bound=0.0\n",
      "1195: loss=0.818, reward_mean=0.0, reward_bound=0.0\n",
      "1196: loss=0.718, reward_mean=0.0, reward_bound=0.0\n",
      "1197: loss=0.715, reward_mean=0.0, reward_bound=0.0\n",
      "1198: loss=0.809, reward_mean=0.0, reward_bound=0.0\n",
      "1199: loss=0.797, reward_mean=0.0, reward_bound=0.0\n",
      "1200: loss=0.781, reward_mean=0.0, reward_bound=0.0\n",
      "1201: loss=0.801, reward_mean=0.0, reward_bound=0.0\n",
      "1202: loss=0.776, reward_mean=0.0, reward_bound=0.0\n",
      "1203: loss=0.890, reward_mean=0.0, reward_bound=0.0\n",
      "1204: loss=0.787, reward_mean=0.0, reward_bound=0.0\n",
      "1205: loss=0.848, reward_mean=0.0, reward_bound=0.0\n",
      "1206: loss=0.693, reward_mean=0.0, reward_bound=0.0\n",
      "1207: loss=0.811, reward_mean=0.0, reward_bound=0.0\n",
      "1208: loss=0.917, reward_mean=0.0, reward_bound=0.0\n",
      "1209: loss=0.779, reward_mean=0.0, reward_bound=0.0\n",
      "1210: loss=0.741, reward_mean=0.0, reward_bound=0.0\n",
      "1211: loss=0.670, reward_mean=0.0, reward_bound=0.0\n",
      "1212: loss=0.774, reward_mean=0.0, reward_bound=0.0\n",
      "1213: loss=0.837, reward_mean=0.0, reward_bound=0.0\n",
      "1214: loss=0.761, reward_mean=0.0, reward_bound=0.0\n",
      "1215: loss=0.792, reward_mean=0.0, reward_bound=0.0\n",
      "1216: loss=0.838, reward_mean=0.0, reward_bound=0.0\n",
      "1217: loss=0.809, reward_mean=0.0, reward_bound=0.0\n",
      "1218: loss=0.794, reward_mean=0.0, reward_bound=0.0\n",
      "1219: loss=0.827, reward_mean=0.0, reward_bound=0.0\n",
      "1220: loss=0.752, reward_mean=0.0, reward_bound=0.0\n",
      "1221: loss=0.887, reward_mean=0.0, reward_bound=0.0\n",
      "1222: loss=0.786, reward_mean=0.0, reward_bound=0.0\n",
      "1223: loss=0.804, reward_mean=0.0, reward_bound=0.0\n",
      "1224: loss=0.712, reward_mean=0.0, reward_bound=0.0\n",
      "1225: loss=0.806, reward_mean=0.0, reward_bound=0.0\n",
      "1226: loss=0.812, reward_mean=0.0, reward_bound=0.0\n",
      "1227: loss=0.827, reward_mean=0.0, reward_bound=0.0\n",
      "1228: loss=0.771, reward_mean=0.0, reward_bound=0.0\n",
      "1229: loss=0.712, reward_mean=0.0, reward_bound=0.0\n",
      "1230: loss=0.865, reward_mean=0.0, reward_bound=0.0\n",
      "1231: loss=0.696, reward_mean=0.0, reward_bound=0.0\n",
      "1232: loss=0.819, reward_mean=0.0, reward_bound=0.0\n",
      "1233: loss=0.732, reward_mean=0.0, reward_bound=0.0\n",
      "1234: loss=0.724, reward_mean=0.0, reward_bound=0.0\n",
      "1235: loss=0.737, reward_mean=0.0, reward_bound=0.0\n",
      "1236: loss=0.830, reward_mean=0.0, reward_bound=0.0\n",
      "1237: loss=0.713, reward_mean=0.0, reward_bound=0.0\n",
      "1238: loss=0.774, reward_mean=0.0, reward_bound=0.0\n",
      "1239: loss=0.736, reward_mean=0.0, reward_bound=0.0\n",
      "1240: loss=0.823, reward_mean=0.0, reward_bound=0.0\n",
      "1241: loss=0.828, reward_mean=0.0, reward_bound=0.0\n",
      "1242: loss=0.594, reward_mean=0.0, reward_bound=0.0\n",
      "1243: loss=0.833, reward_mean=0.0, reward_bound=0.0\n",
      "1244: loss=0.678, reward_mean=0.0, reward_bound=0.0\n",
      "1245: loss=0.857, reward_mean=0.0, reward_bound=0.0\n",
      "1246: loss=0.697, reward_mean=0.0, reward_bound=0.0\n",
      "1247: loss=0.641, reward_mean=0.0, reward_bound=0.0\n",
      "1248: loss=0.886, reward_mean=0.0, reward_bound=0.0\n",
      "1249: loss=0.767, reward_mean=0.0, reward_bound=0.0\n",
      "1250: loss=0.746, reward_mean=0.0, reward_bound=0.0\n",
      "1251: loss=0.769, reward_mean=0.0, reward_bound=0.0\n",
      "1252: loss=0.804, reward_mean=0.0, reward_bound=0.0\n",
      "1253: loss=0.751, reward_mean=0.0, reward_bound=0.0\n",
      "1254: loss=0.796, reward_mean=0.0, reward_bound=0.0\n",
      "1255: loss=0.799, reward_mean=0.0, reward_bound=0.0\n",
      "1256: loss=0.780, reward_mean=0.0, reward_bound=0.0\n",
      "1257: loss=0.780, reward_mean=0.0, reward_bound=0.0\n",
      "1258: loss=0.723, reward_mean=0.0, reward_bound=0.0\n",
      "1259: loss=0.745, reward_mean=0.0, reward_bound=0.0\n",
      "1260: loss=0.765, reward_mean=0.0, reward_bound=0.0\n",
      "1261: loss=0.690, reward_mean=0.0, reward_bound=0.0\n",
      "1262: loss=0.796, reward_mean=0.0, reward_bound=0.0\n",
      "1263: loss=0.684, reward_mean=0.0, reward_bound=0.0\n",
      "1264: loss=0.723, reward_mean=0.0, reward_bound=0.0\n",
      "1265: loss=0.842, reward_mean=0.0, reward_bound=0.0\n",
      "1266: loss=0.735, reward_mean=0.0, reward_bound=0.0\n",
      "1267: loss=0.643, reward_mean=0.0, reward_bound=0.0\n",
      "1268: loss=0.707, reward_mean=0.0, reward_bound=0.0\n",
      "1269: loss=0.702, reward_mean=0.0, reward_bound=0.0\n",
      "1270: loss=0.715, reward_mean=0.0, reward_bound=0.0\n",
      "1271: loss=0.815, reward_mean=0.0, reward_bound=0.0\n",
      "1272: loss=0.743, reward_mean=0.0, reward_bound=0.0\n",
      "1273: loss=0.824, reward_mean=0.0, reward_bound=0.0\n",
      "1274: loss=0.710, reward_mean=0.0, reward_bound=0.0\n",
      "1275: loss=0.860, reward_mean=0.0, reward_bound=0.0\n",
      "1276: loss=0.827, reward_mean=0.1, reward_bound=0.0\n",
      "1277: loss=0.772, reward_mean=0.0, reward_bound=0.0\n",
      "1278: loss=0.716, reward_mean=0.0, reward_bound=0.0\n",
      "1279: loss=0.707, reward_mean=0.0, reward_bound=0.0\n",
      "1280: loss=0.859, reward_mean=0.0, reward_bound=0.0\n",
      "1281: loss=0.749, reward_mean=0.0, reward_bound=0.0\n",
      "1282: loss=0.832, reward_mean=0.0, reward_bound=0.0\n",
      "1283: loss=0.794, reward_mean=0.0, reward_bound=0.0\n",
      "1284: loss=0.966, reward_mean=0.0, reward_bound=0.0\n",
      "1285: loss=0.770, reward_mean=0.0, reward_bound=0.0\n",
      "1286: loss=0.892, reward_mean=0.0, reward_bound=0.0\n",
      "1287: loss=0.772, reward_mean=0.0, reward_bound=0.0\n",
      "1288: loss=0.748, reward_mean=0.0, reward_bound=0.0\n",
      "1289: loss=0.840, reward_mean=0.0, reward_bound=0.0\n",
      "1290: loss=0.876, reward_mean=0.0, reward_bound=0.0\n",
      "1291: loss=0.747, reward_mean=0.0, reward_bound=0.0\n",
      "1292: loss=0.781, reward_mean=0.0, reward_bound=0.0\n",
      "1293: loss=0.727, reward_mean=0.0, reward_bound=0.0\n",
      "1294: loss=0.746, reward_mean=0.0, reward_bound=0.0\n",
      "1295: loss=0.756, reward_mean=0.0, reward_bound=0.0\n",
      "1296: loss=0.752, reward_mean=0.0, reward_bound=0.0\n",
      "1297: loss=0.728, reward_mean=0.0, reward_bound=0.0\n",
      "1298: loss=0.680, reward_mean=0.0, reward_bound=0.0\n",
      "1299: loss=0.811, reward_mean=0.0, reward_bound=0.0\n",
      "1300: loss=0.888, reward_mean=0.0, reward_bound=0.0\n",
      "1301: loss=0.689, reward_mean=0.0, reward_bound=0.0\n",
      "1302: loss=0.762, reward_mean=0.0, reward_bound=0.0\n",
      "1303: loss=0.835, reward_mean=0.0, reward_bound=0.0\n",
      "1304: loss=0.717, reward_mean=0.0, reward_bound=0.0\n",
      "1305: loss=0.792, reward_mean=0.0, reward_bound=0.0\n",
      "1306: loss=0.742, reward_mean=0.0, reward_bound=0.0\n",
      "1307: loss=0.708, reward_mean=0.0, reward_bound=0.0\n",
      "1308: loss=0.787, reward_mean=0.0, reward_bound=0.0\n",
      "1309: loss=0.896, reward_mean=0.0, reward_bound=0.0\n",
      "1310: loss=0.744, reward_mean=0.0, reward_bound=0.0\n",
      "1311: loss=0.757, reward_mean=0.0, reward_bound=0.0\n",
      "1312: loss=0.860, reward_mean=0.0, reward_bound=0.0\n",
      "1313: loss=0.686, reward_mean=0.0, reward_bound=0.0\n",
      "1314: loss=0.797, reward_mean=0.0, reward_bound=0.0\n",
      "1315: loss=0.754, reward_mean=0.0, reward_bound=0.0\n",
      "1316: loss=0.804, reward_mean=0.0, reward_bound=0.0\n",
      "1317: loss=0.758, reward_mean=0.0, reward_bound=0.0\n",
      "1318: loss=0.803, reward_mean=0.1, reward_bound=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1319: loss=0.790, reward_mean=0.0, reward_bound=0.0\n",
      "1320: loss=0.933, reward_mean=0.0, reward_bound=0.0\n",
      "1321: loss=0.814, reward_mean=0.0, reward_bound=0.0\n",
      "1322: loss=0.674, reward_mean=0.0, reward_bound=0.0\n",
      "1323: loss=0.685, reward_mean=0.0, reward_bound=0.0\n",
      "1324: loss=0.829, reward_mean=0.0, reward_bound=0.0\n",
      "1325: loss=0.739, reward_mean=0.0, reward_bound=0.0\n",
      "1326: loss=0.777, reward_mean=0.0, reward_bound=0.0\n",
      "1327: loss=0.767, reward_mean=0.0, reward_bound=0.0\n",
      "1328: loss=0.761, reward_mean=0.0, reward_bound=0.0\n",
      "1329: loss=0.733, reward_mean=0.0, reward_bound=0.0\n",
      "1330: loss=0.611, reward_mean=0.1, reward_bound=0.0\n",
      "1331: loss=0.709, reward_mean=0.0, reward_bound=0.0\n",
      "1332: loss=0.776, reward_mean=0.0, reward_bound=0.0\n",
      "1333: loss=0.807, reward_mean=0.0, reward_bound=0.0\n",
      "1334: loss=0.749, reward_mean=0.1, reward_bound=0.0\n",
      "1335: loss=0.766, reward_mean=0.0, reward_bound=0.0\n",
      "1336: loss=0.745, reward_mean=0.0, reward_bound=0.0\n",
      "1337: loss=0.861, reward_mean=0.0, reward_bound=0.0\n",
      "1338: loss=0.739, reward_mean=0.0, reward_bound=0.0\n",
      "1339: loss=0.785, reward_mean=0.0, reward_bound=0.0\n",
      "1340: loss=0.608, reward_mean=0.0, reward_bound=0.0\n",
      "1341: loss=0.720, reward_mean=0.0, reward_bound=0.0\n",
      "1342: loss=0.726, reward_mean=0.0, reward_bound=0.0\n",
      "1343: loss=0.653, reward_mean=0.0, reward_bound=0.0\n",
      "1344: loss=0.734, reward_mean=0.0, reward_bound=0.0\n",
      "1345: loss=0.728, reward_mean=0.0, reward_bound=0.0\n",
      "1346: loss=0.772, reward_mean=0.0, reward_bound=0.0\n",
      "1347: loss=0.728, reward_mean=0.0, reward_bound=0.0\n",
      "1348: loss=0.578, reward_mean=0.0, reward_bound=0.0\n",
      "1349: loss=0.726, reward_mean=0.0, reward_bound=0.0\n",
      "1350: loss=0.656, reward_mean=0.0, reward_bound=0.0\n",
      "1351: loss=0.630, reward_mean=0.0, reward_bound=0.0\n",
      "1352: loss=0.694, reward_mean=0.0, reward_bound=0.0\n",
      "1353: loss=0.696, reward_mean=0.0, reward_bound=0.0\n",
      "1354: loss=0.639, reward_mean=0.0, reward_bound=0.0\n",
      "1355: loss=0.608, reward_mean=0.0, reward_bound=0.0\n",
      "1356: loss=0.678, reward_mean=0.0, reward_bound=0.0\n",
      "1357: loss=0.644, reward_mean=0.0, reward_bound=0.0\n",
      "1358: loss=0.650, reward_mean=0.0, reward_bound=0.0\n",
      "1359: loss=0.655, reward_mean=0.0, reward_bound=0.0\n",
      "1360: loss=0.644, reward_mean=0.0, reward_bound=0.0\n",
      "1361: loss=0.836, reward_mean=0.0, reward_bound=0.0\n",
      "1362: loss=0.636, reward_mean=0.0, reward_bound=0.0\n",
      "1363: loss=0.596, reward_mean=0.0, reward_bound=0.0\n",
      "1364: loss=0.842, reward_mean=0.0, reward_bound=0.0\n",
      "1365: loss=0.686, reward_mean=0.0, reward_bound=0.0\n",
      "1366: loss=0.518, reward_mean=0.0, reward_bound=0.0\n",
      "1367: loss=0.603, reward_mean=0.0, reward_bound=0.0\n",
      "1368: loss=0.722, reward_mean=0.0, reward_bound=0.0\n",
      "1369: loss=0.610, reward_mean=0.0, reward_bound=0.0\n",
      "1370: loss=0.703, reward_mean=0.1, reward_bound=0.0\n",
      "1371: loss=0.720, reward_mean=0.0, reward_bound=0.0\n",
      "1372: loss=0.702, reward_mean=0.0, reward_bound=0.0\n",
      "1373: loss=0.700, reward_mean=0.0, reward_bound=0.0\n",
      "1374: loss=0.607, reward_mean=0.0, reward_bound=0.0\n",
      "1375: loss=0.513, reward_mean=0.0, reward_bound=0.0\n",
      "1376: loss=0.575, reward_mean=0.1, reward_bound=0.0\n",
      "1377: loss=0.655, reward_mean=0.0, reward_bound=0.0\n",
      "1378: loss=0.566, reward_mean=0.0, reward_bound=0.0\n",
      "1379: loss=0.600, reward_mean=0.0, reward_bound=0.0\n",
      "1380: loss=0.731, reward_mean=0.1, reward_bound=0.0\n",
      "1381: loss=0.562, reward_mean=0.1, reward_bound=0.0\n",
      "1382: loss=0.565, reward_mean=0.0, reward_bound=0.0\n",
      "1383: loss=0.734, reward_mean=0.0, reward_bound=0.0\n",
      "1384: loss=0.641, reward_mean=0.1, reward_bound=0.0\n",
      "1385: loss=0.523, reward_mean=0.0, reward_bound=0.0\n",
      "1386: loss=0.580, reward_mean=0.0, reward_bound=0.0\n",
      "1387: loss=0.640, reward_mean=0.0, reward_bound=0.0\n",
      "1388: loss=0.537, reward_mean=0.0, reward_bound=0.0\n",
      "1389: loss=0.540, reward_mean=0.0, reward_bound=0.0\n",
      "1390: loss=0.595, reward_mean=0.0, reward_bound=0.0\n",
      "1391: loss=0.694, reward_mean=0.0, reward_bound=0.0\n",
      "1392: loss=0.640, reward_mean=0.0, reward_bound=0.0\n",
      "1393: loss=0.549, reward_mean=0.1, reward_bound=0.0\n",
      "1394: loss=0.585, reward_mean=0.0, reward_bound=0.0\n",
      "1395: loss=0.540, reward_mean=0.0, reward_bound=0.0\n",
      "1396: loss=0.552, reward_mean=0.1, reward_bound=0.0\n",
      "1397: loss=0.584, reward_mean=0.0, reward_bound=0.0\n",
      "1398: loss=0.643, reward_mean=0.0, reward_bound=0.0\n",
      "1399: loss=0.647, reward_mean=0.0, reward_bound=0.0\n",
      "1400: loss=0.689, reward_mean=0.0, reward_bound=0.0\n",
      "1401: loss=0.664, reward_mean=0.0, reward_bound=0.0\n",
      "1402: loss=0.633, reward_mean=0.0, reward_bound=0.0\n",
      "1403: loss=0.453, reward_mean=0.0, reward_bound=0.0\n",
      "1404: loss=0.638, reward_mean=0.0, reward_bound=0.0\n",
      "1405: loss=0.562, reward_mean=0.0, reward_bound=0.0\n",
      "1406: loss=0.520, reward_mean=0.1, reward_bound=0.0\n",
      "1407: loss=0.619, reward_mean=0.0, reward_bound=0.0\n",
      "1408: loss=0.649, reward_mean=0.1, reward_bound=0.0\n",
      "1409: loss=0.618, reward_mean=0.0, reward_bound=0.0\n",
      "1410: loss=0.638, reward_mean=0.0, reward_bound=0.0\n",
      "1411: loss=0.611, reward_mean=0.0, reward_bound=0.0\n",
      "1412: loss=0.496, reward_mean=0.1, reward_bound=0.0\n",
      "1413: loss=0.517, reward_mean=0.1, reward_bound=0.0\n",
      "1414: loss=0.558, reward_mean=0.1, reward_bound=0.0\n",
      "1415: loss=0.695, reward_mean=0.0, reward_bound=0.0\n",
      "1416: loss=0.622, reward_mean=0.0, reward_bound=0.0\n",
      "1417: loss=0.615, reward_mean=0.0, reward_bound=0.0\n",
      "1418: loss=0.452, reward_mean=0.0, reward_bound=0.0\n",
      "1419: loss=0.693, reward_mean=0.0, reward_bound=0.0\n",
      "1420: loss=0.477, reward_mean=0.0, reward_bound=0.0\n",
      "1421: loss=0.464, reward_mean=0.1, reward_bound=0.0\n",
      "1422: loss=0.734, reward_mean=0.0, reward_bound=0.0\n",
      "1423: loss=0.505, reward_mean=0.0, reward_bound=0.0\n",
      "1424: loss=0.458, reward_mean=0.0, reward_bound=0.0\n",
      "1425: loss=0.623, reward_mean=0.0, reward_bound=0.0\n",
      "1426: loss=0.548, reward_mean=0.0, reward_bound=0.0\n",
      "1427: loss=0.676, reward_mean=0.0, reward_bound=0.0\n",
      "1428: loss=0.537, reward_mean=0.1, reward_bound=0.0\n",
      "1429: loss=0.434, reward_mean=0.1, reward_bound=0.0\n",
      "1430: loss=0.604, reward_mean=0.0, reward_bound=0.0\n",
      "1431: loss=0.656, reward_mean=0.1, reward_bound=0.0\n",
      "1432: loss=0.402, reward_mean=0.0, reward_bound=0.0\n",
      "1433: loss=0.664, reward_mean=0.0, reward_bound=0.0\n",
      "1434: loss=0.515, reward_mean=0.1, reward_bound=0.0\n",
      "1435: loss=0.446, reward_mean=0.0, reward_bound=0.0\n",
      "1436: loss=0.555, reward_mean=0.1, reward_bound=0.0\n",
      "1437: loss=0.586, reward_mean=0.0, reward_bound=0.0\n",
      "1438: loss=0.677, reward_mean=0.1, reward_bound=0.0\n",
      "1439: loss=0.699, reward_mean=0.0, reward_bound=0.0\n",
      "1440: loss=0.592, reward_mean=0.0, reward_bound=0.0\n",
      "1441: loss=0.434, reward_mean=0.0, reward_bound=0.0\n",
      "1442: loss=0.569, reward_mean=0.0, reward_bound=0.0\n",
      "1443: loss=0.366, reward_mean=0.1, reward_bound=0.0\n",
      "1444: loss=0.536, reward_mean=0.0, reward_bound=0.0\n",
      "1445: loss=0.487, reward_mean=0.0, reward_bound=0.0\n",
      "1446: loss=0.745, reward_mean=0.0, reward_bound=0.0\n",
      "1447: loss=0.610, reward_mean=0.0, reward_bound=0.0\n",
      "1448: loss=0.493, reward_mean=0.0, reward_bound=0.0\n",
      "1449: loss=0.575, reward_mean=0.1, reward_bound=0.0\n",
      "1450: loss=0.654, reward_mean=0.1, reward_bound=0.0\n",
      "1451: loss=0.581, reward_mean=0.1, reward_bound=0.0\n",
      "1452: loss=0.566, reward_mean=0.1, reward_bound=0.0\n",
      "1453: loss=0.475, reward_mean=0.0, reward_bound=0.0\n",
      "1454: loss=0.557, reward_mean=0.0, reward_bound=0.0\n",
      "1455: loss=0.396, reward_mean=0.0, reward_bound=0.0\n",
      "1456: loss=0.542, reward_mean=0.0, reward_bound=0.0\n",
      "1457: loss=0.432, reward_mean=0.0, reward_bound=0.0\n",
      "1458: loss=0.670, reward_mean=0.1, reward_bound=0.0\n",
      "1459: loss=0.510, reward_mean=0.1, reward_bound=0.0\n",
      "1460: loss=0.416, reward_mean=0.0, reward_bound=0.0\n",
      "1461: loss=0.485, reward_mean=0.0, reward_bound=0.0\n",
      "1462: loss=0.461, reward_mean=0.0, reward_bound=0.0\n",
      "1463: loss=0.406, reward_mean=0.0, reward_bound=0.0\n",
      "1464: loss=0.606, reward_mean=0.0, reward_bound=0.0\n",
      "1465: loss=0.518, reward_mean=0.0, reward_bound=0.0\n",
      "1466: loss=0.446, reward_mean=0.0, reward_bound=0.0\n",
      "1467: loss=0.654, reward_mean=0.0, reward_bound=0.0\n",
      "1468: loss=0.556, reward_mean=0.0, reward_bound=0.0\n",
      "1469: loss=0.563, reward_mean=0.0, reward_bound=0.0\n",
      "1470: loss=0.418, reward_mean=0.0, reward_bound=0.0\n",
      "1471: loss=0.452, reward_mean=0.1, reward_bound=0.0\n",
      "1472: loss=0.607, reward_mean=0.0, reward_bound=0.0\n",
      "1473: loss=0.580, reward_mean=0.0, reward_bound=0.0\n",
      "1474: loss=0.459, reward_mean=0.1, reward_bound=0.0\n",
      "1475: loss=0.423, reward_mean=0.0, reward_bound=0.0\n",
      "1476: loss=0.507, reward_mean=0.1, reward_bound=0.0\n",
      "1477: loss=0.489, reward_mean=0.0, reward_bound=0.0\n",
      "1478: loss=0.758, reward_mean=0.0, reward_bound=0.0\n",
      "1479: loss=0.443, reward_mean=0.0, reward_bound=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1480: loss=0.408, reward_mean=0.0, reward_bound=0.0\n",
      "1481: loss=0.470, reward_mean=0.0, reward_bound=0.0\n",
      "1482: loss=0.505, reward_mean=0.0, reward_bound=0.0\n",
      "1483: loss=0.558, reward_mean=0.0, reward_bound=0.0\n",
      "1484: loss=0.606, reward_mean=0.0, reward_bound=0.0\n",
      "1485: loss=0.501, reward_mean=0.0, reward_bound=0.0\n",
      "1486: loss=0.742, reward_mean=0.1, reward_bound=0.0\n",
      "1487: loss=0.617, reward_mean=0.1, reward_bound=0.0\n",
      "1488: loss=0.546, reward_mean=0.0, reward_bound=0.0\n",
      "1489: loss=0.480, reward_mean=0.0, reward_bound=0.0\n",
      "1490: loss=0.415, reward_mean=0.1, reward_bound=0.0\n",
      "1491: loss=0.428, reward_mean=0.1, reward_bound=0.0\n",
      "1492: loss=0.454, reward_mean=0.0, reward_bound=0.0\n",
      "1493: loss=0.410, reward_mean=0.1, reward_bound=0.0\n",
      "1494: loss=0.494, reward_mean=0.0, reward_bound=0.0\n",
      "1495: loss=0.607, reward_mean=0.0, reward_bound=0.0\n",
      "1496: loss=0.582, reward_mean=0.0, reward_bound=0.0\n",
      "1497: loss=0.500, reward_mean=0.0, reward_bound=0.0\n",
      "1498: loss=0.517, reward_mean=0.0, reward_bound=0.0\n",
      "1499: loss=0.516, reward_mean=0.0, reward_bound=0.0\n",
      "1500: loss=0.520, reward_mean=0.1, reward_bound=0.0\n",
      "1501: loss=0.527, reward_mean=0.0, reward_bound=0.0\n",
      "1502: loss=0.445, reward_mean=0.0, reward_bound=0.0\n",
      "1503: loss=0.487, reward_mean=0.0, reward_bound=0.0\n",
      "1504: loss=0.638, reward_mean=0.0, reward_bound=0.0\n",
      "1505: loss=0.434, reward_mean=0.0, reward_bound=0.0\n",
      "1506: loss=0.485, reward_mean=0.0, reward_bound=0.0\n",
      "1507: loss=0.610, reward_mean=0.0, reward_bound=0.0\n",
      "1508: loss=0.474, reward_mean=0.0, reward_bound=0.0\n",
      "1509: loss=0.462, reward_mean=0.0, reward_bound=0.0\n",
      "1510: loss=0.501, reward_mean=0.0, reward_bound=0.0\n",
      "1511: loss=0.635, reward_mean=0.0, reward_bound=0.0\n",
      "1512: loss=0.464, reward_mean=0.1, reward_bound=0.0\n",
      "1513: loss=0.653, reward_mean=0.0, reward_bound=0.0\n",
      "1514: loss=0.550, reward_mean=0.0, reward_bound=0.0\n",
      "1515: loss=0.616, reward_mean=0.1, reward_bound=0.0\n",
      "1516: loss=0.472, reward_mean=0.0, reward_bound=0.0\n",
      "1517: loss=0.567, reward_mean=0.0, reward_bound=0.0\n",
      "1518: loss=0.448, reward_mean=0.0, reward_bound=0.0\n",
      "1519: loss=0.578, reward_mean=0.0, reward_bound=0.0\n",
      "1520: loss=0.637, reward_mean=0.0, reward_bound=0.0\n",
      "1521: loss=0.426, reward_mean=0.0, reward_bound=0.0\n",
      "1522: loss=0.506, reward_mean=0.0, reward_bound=0.0\n",
      "1523: loss=0.571, reward_mean=0.0, reward_bound=0.0\n",
      "1524: loss=0.503, reward_mean=0.0, reward_bound=0.0\n",
      "1525: loss=0.704, reward_mean=0.0, reward_bound=0.0\n",
      "1526: loss=0.583, reward_mean=0.0, reward_bound=0.0\n",
      "1527: loss=0.811, reward_mean=0.0, reward_bound=0.0\n",
      "1528: loss=0.658, reward_mean=0.0, reward_bound=0.0\n",
      "1529: loss=0.609, reward_mean=0.0, reward_bound=0.0\n",
      "1530: loss=0.592, reward_mean=0.0, reward_bound=0.0\n",
      "1531: loss=0.573, reward_mean=0.0, reward_bound=0.0\n",
      "1532: loss=0.427, reward_mean=0.1, reward_bound=0.0\n",
      "1533: loss=0.534, reward_mean=0.0, reward_bound=0.0\n",
      "1534: loss=0.571, reward_mean=0.1, reward_bound=0.0\n",
      "1535: loss=0.665, reward_mean=0.0, reward_bound=0.0\n",
      "1536: loss=0.619, reward_mean=0.0, reward_bound=0.0\n",
      "1537: loss=0.434, reward_mean=0.0, reward_bound=0.0\n",
      "1538: loss=0.589, reward_mean=0.0, reward_bound=0.0\n",
      "1539: loss=0.666, reward_mean=0.0, reward_bound=0.0\n",
      "1540: loss=0.753, reward_mean=0.0, reward_bound=0.0\n",
      "1541: loss=0.642, reward_mean=0.0, reward_bound=0.0\n",
      "1542: loss=0.489, reward_mean=0.0, reward_bound=0.0\n",
      "1543: loss=0.525, reward_mean=0.0, reward_bound=0.0\n",
      "1544: loss=0.746, reward_mean=0.0, reward_bound=0.0\n",
      "1545: loss=0.537, reward_mean=0.0, reward_bound=0.0\n",
      "1546: loss=0.547, reward_mean=0.0, reward_bound=0.0\n",
      "1547: loss=0.541, reward_mean=0.0, reward_bound=0.0\n",
      "1548: loss=0.578, reward_mean=0.0, reward_bound=0.0\n",
      "1549: loss=0.599, reward_mean=0.0, reward_bound=0.0\n",
      "1550: loss=0.433, reward_mean=0.0, reward_bound=0.0\n",
      "1551: loss=0.639, reward_mean=0.1, reward_bound=0.0\n",
      "1552: loss=0.815, reward_mean=0.0, reward_bound=0.0\n",
      "1553: loss=0.535, reward_mean=0.0, reward_bound=0.0\n",
      "1554: loss=0.533, reward_mean=0.0, reward_bound=0.0\n",
      "1555: loss=0.462, reward_mean=0.0, reward_bound=0.0\n",
      "1556: loss=0.474, reward_mean=0.1, reward_bound=0.0\n",
      "1557: loss=0.575, reward_mean=0.0, reward_bound=0.0\n",
      "1558: loss=0.524, reward_mean=0.1, reward_bound=0.0\n",
      "1559: loss=0.560, reward_mean=0.1, reward_bound=0.0\n",
      "1560: loss=0.550, reward_mean=0.1, reward_bound=0.0\n",
      "1561: loss=0.559, reward_mean=0.1, reward_bound=0.0\n",
      "1562: loss=0.561, reward_mean=0.1, reward_bound=0.0\n",
      "1563: loss=0.507, reward_mean=0.0, reward_bound=0.0\n",
      "1564: loss=0.569, reward_mean=0.0, reward_bound=0.0\n",
      "1565: loss=0.439, reward_mean=0.1, reward_bound=0.0\n",
      "1566: loss=0.524, reward_mean=0.1, reward_bound=0.0\n",
      "1567: loss=0.549, reward_mean=0.0, reward_bound=0.0\n",
      "1568: loss=0.438, reward_mean=0.0, reward_bound=0.0\n",
      "1569: loss=0.473, reward_mean=0.0, reward_bound=0.0\n",
      "1570: loss=0.548, reward_mean=0.0, reward_bound=0.0\n",
      "1571: loss=0.418, reward_mean=0.0, reward_bound=0.0\n",
      "1572: loss=0.419, reward_mean=0.1, reward_bound=0.0\n",
      "1573: loss=0.513, reward_mean=0.0, reward_bound=0.0\n",
      "1574: loss=0.370, reward_mean=0.0, reward_bound=0.0\n",
      "1575: loss=0.389, reward_mean=0.0, reward_bound=0.0\n",
      "1576: loss=0.351, reward_mean=0.1, reward_bound=0.0\n",
      "1577: loss=0.531, reward_mean=0.1, reward_bound=0.0\n",
      "1578: loss=0.505, reward_mean=0.1, reward_bound=0.0\n",
      "1579: loss=0.369, reward_mean=0.0, reward_bound=0.0\n",
      "1580: loss=0.373, reward_mean=0.1, reward_bound=0.0\n",
      "1581: loss=0.346, reward_mean=0.1, reward_bound=0.0\n",
      "1582: loss=0.465, reward_mean=0.0, reward_bound=0.0\n",
      "1583: loss=0.463, reward_mean=0.0, reward_bound=0.0\n",
      "1584: loss=0.562, reward_mean=0.0, reward_bound=0.0\n",
      "1585: loss=0.393, reward_mean=0.1, reward_bound=0.0\n",
      "1586: loss=0.452, reward_mean=0.0, reward_bound=0.0\n",
      "1587: loss=0.466, reward_mean=0.1, reward_bound=0.0\n",
      "1588: loss=0.389, reward_mean=0.0, reward_bound=0.0\n",
      "1589: loss=0.345, reward_mean=0.0, reward_bound=0.0\n",
      "1590: loss=0.346, reward_mean=0.0, reward_bound=0.0\n",
      "1591: loss=0.553, reward_mean=0.0, reward_bound=0.0\n",
      "1592: loss=0.428, reward_mean=0.1, reward_bound=0.0\n",
      "1593: loss=0.375, reward_mean=0.1, reward_bound=0.0\n",
      "1594: loss=0.457, reward_mean=0.1, reward_bound=0.0\n",
      "1595: loss=0.408, reward_mean=0.0, reward_bound=0.0\n",
      "1596: loss=0.335, reward_mean=0.0, reward_bound=0.0\n",
      "1597: loss=0.368, reward_mean=0.0, reward_bound=0.0\n",
      "1598: loss=0.398, reward_mean=0.0, reward_bound=0.0\n",
      "1599: loss=0.364, reward_mean=0.0, reward_bound=0.0\n",
      "1600: loss=0.325, reward_mean=0.0, reward_bound=0.0\n",
      "1601: loss=0.456, reward_mean=0.1, reward_bound=0.0\n",
      "1602: loss=0.523, reward_mean=0.0, reward_bound=0.0\n",
      "1603: loss=0.400, reward_mean=0.1, reward_bound=0.0\n",
      "1604: loss=0.328, reward_mean=0.1, reward_bound=0.0\n",
      "1605: loss=0.491, reward_mean=0.1, reward_bound=0.0\n",
      "1606: loss=0.347, reward_mean=0.0, reward_bound=0.0\n",
      "1607: loss=0.418, reward_mean=0.0, reward_bound=0.0\n",
      "1608: loss=0.250, reward_mean=0.0, reward_bound=0.0\n",
      "1609: loss=0.565, reward_mean=0.1, reward_bound=0.0\n",
      "1610: loss=0.491, reward_mean=0.1, reward_bound=0.0\n",
      "1611: loss=0.347, reward_mean=0.0, reward_bound=0.0\n",
      "1612: loss=0.530, reward_mean=0.0, reward_bound=0.0\n",
      "1613: loss=0.418, reward_mean=0.0, reward_bound=0.0\n",
      "1614: loss=0.364, reward_mean=0.1, reward_bound=0.0\n",
      "1615: loss=0.365, reward_mean=0.0, reward_bound=0.0\n",
      "1616: loss=0.414, reward_mean=0.0, reward_bound=0.0\n",
      "1617: loss=0.246, reward_mean=0.0, reward_bound=0.0\n",
      "1618: loss=0.291, reward_mean=0.0, reward_bound=0.0\n",
      "1619: loss=0.359, reward_mean=0.1, reward_bound=0.0\n",
      "1620: loss=0.321, reward_mean=0.0, reward_bound=0.0\n",
      "1621: loss=0.296, reward_mean=0.0, reward_bound=0.0\n",
      "1622: loss=0.286, reward_mean=0.0, reward_bound=0.0\n",
      "1623: loss=0.391, reward_mean=0.0, reward_bound=0.0\n",
      "1624: loss=0.389, reward_mean=0.0, reward_bound=0.0\n",
      "1625: loss=0.508, reward_mean=0.1, reward_bound=0.0\n",
      "1626: loss=0.409, reward_mean=0.0, reward_bound=0.0\n",
      "1627: loss=0.378, reward_mean=0.0, reward_bound=0.0\n",
      "1628: loss=0.485, reward_mean=0.1, reward_bound=0.0\n",
      "1629: loss=0.488, reward_mean=0.0, reward_bound=0.0\n",
      "1630: loss=0.448, reward_mean=0.0, reward_bound=0.0\n",
      "1631: loss=0.445, reward_mean=0.0, reward_bound=0.0\n",
      "1632: loss=0.366, reward_mean=0.1, reward_bound=0.0\n",
      "1633: loss=0.287, reward_mean=0.1, reward_bound=0.0\n",
      "1634: loss=0.405, reward_mean=0.1, reward_bound=0.0\n",
      "1635: loss=0.421, reward_mean=0.1, reward_bound=0.0\n",
      "1636: loss=0.427, reward_mean=0.0, reward_bound=0.0\n",
      "1637: loss=0.392, reward_mean=0.0, reward_bound=0.0\n",
      "1638: loss=0.464, reward_mean=0.0, reward_bound=0.0\n",
      "1639: loss=0.372, reward_mean=0.0, reward_bound=0.0\n",
      "1640: loss=0.450, reward_mean=0.1, reward_bound=0.0\n",
      "1641: loss=0.461, reward_mean=0.0, reward_bound=0.0\n",
      "1642: loss=0.402, reward_mean=0.0, reward_bound=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1643: loss=0.382, reward_mean=0.0, reward_bound=0.0\n",
      "1644: loss=0.440, reward_mean=0.0, reward_bound=0.0\n",
      "1645: loss=0.426, reward_mean=0.1, reward_bound=0.0\n",
      "1646: loss=0.439, reward_mean=0.0, reward_bound=0.0\n",
      "1647: loss=0.250, reward_mean=0.0, reward_bound=0.0\n",
      "1648: loss=0.547, reward_mean=0.1, reward_bound=0.0\n",
      "1649: loss=0.332, reward_mean=0.1, reward_bound=0.0\n",
      "1650: loss=0.488, reward_mean=0.0, reward_bound=0.0\n",
      "1651: loss=0.446, reward_mean=0.1, reward_bound=0.0\n",
      "1652: loss=0.307, reward_mean=0.1, reward_bound=0.0\n",
      "1653: loss=0.294, reward_mean=0.0, reward_bound=0.0\n",
      "1654: loss=0.634, reward_mean=0.0, reward_bound=0.0\n",
      "1655: loss=0.442, reward_mean=0.0, reward_bound=0.0\n",
      "1656: loss=0.431, reward_mean=0.0, reward_bound=0.0\n",
      "1657: loss=0.500, reward_mean=0.1, reward_bound=0.0\n",
      "1658: loss=0.384, reward_mean=0.0, reward_bound=0.0\n",
      "1659: loss=0.338, reward_mean=0.0, reward_bound=0.0\n",
      "1660: loss=0.400, reward_mean=0.1, reward_bound=0.0\n",
      "1661: loss=0.394, reward_mean=0.0, reward_bound=0.0\n",
      "1662: loss=0.471, reward_mean=0.1, reward_bound=0.0\n",
      "1663: loss=0.538, reward_mean=0.0, reward_bound=0.0\n",
      "1664: loss=0.488, reward_mean=0.0, reward_bound=0.0\n",
      "1665: loss=0.305, reward_mean=0.0, reward_bound=0.0\n",
      "1666: loss=0.434, reward_mean=0.1, reward_bound=0.0\n",
      "1667: loss=0.413, reward_mean=0.0, reward_bound=0.0\n",
      "1668: loss=0.449, reward_mean=0.0, reward_bound=0.0\n",
      "1669: loss=0.443, reward_mean=0.0, reward_bound=0.0\n",
      "1670: loss=0.235, reward_mean=0.0, reward_bound=0.0\n",
      "1671: loss=0.440, reward_mean=0.0, reward_bound=0.0\n",
      "1672: loss=0.384, reward_mean=0.0, reward_bound=0.0\n",
      "1673: loss=0.528, reward_mean=0.1, reward_bound=0.0\n",
      "1674: loss=0.413, reward_mean=0.0, reward_bound=0.0\n",
      "1675: loss=0.583, reward_mean=0.1, reward_bound=0.0\n",
      "1676: loss=0.504, reward_mean=0.0, reward_bound=0.0\n",
      "1677: loss=0.357, reward_mean=0.0, reward_bound=0.0\n",
      "1678: loss=0.387, reward_mean=0.0, reward_bound=0.0\n",
      "1679: loss=0.365, reward_mean=0.1, reward_bound=0.0\n",
      "1680: loss=0.424, reward_mean=0.0, reward_bound=0.0\n",
      "1681: loss=0.372, reward_mean=0.0, reward_bound=0.0\n",
      "1682: loss=0.653, reward_mean=0.0, reward_bound=0.0\n",
      "1683: loss=0.323, reward_mean=0.1, reward_bound=0.0\n",
      "1684: loss=0.471, reward_mean=0.0, reward_bound=0.0\n",
      "1685: loss=0.476, reward_mean=0.0, reward_bound=0.0\n",
      "1686: loss=0.312, reward_mean=0.0, reward_bound=0.0\n",
      "1687: loss=0.545, reward_mean=0.0, reward_bound=0.0\n",
      "1688: loss=0.472, reward_mean=0.0, reward_bound=0.0\n",
      "1689: loss=0.552, reward_mean=0.0, reward_bound=0.0\n",
      "1690: loss=0.473, reward_mean=0.0, reward_bound=0.0\n",
      "1691: loss=0.515, reward_mean=0.1, reward_bound=0.0\n",
      "1692: loss=0.450, reward_mean=0.0, reward_bound=0.0\n",
      "1693: loss=0.446, reward_mean=0.0, reward_bound=0.0\n",
      "1694: loss=0.603, reward_mean=0.0, reward_bound=0.0\n",
      "1695: loss=0.555, reward_mean=0.0, reward_bound=0.0\n",
      "1696: loss=0.505, reward_mean=0.1, reward_bound=0.0\n",
      "1697: loss=0.435, reward_mean=0.0, reward_bound=0.0\n",
      "1698: loss=0.459, reward_mean=0.0, reward_bound=0.0\n",
      "1699: loss=0.448, reward_mean=0.1, reward_bound=0.0\n",
      "1700: loss=0.659, reward_mean=0.0, reward_bound=0.0\n",
      "1701: loss=0.504, reward_mean=0.0, reward_bound=0.0\n",
      "1702: loss=0.414, reward_mean=0.0, reward_bound=0.0\n",
      "1703: loss=0.466, reward_mean=0.0, reward_bound=0.0\n",
      "1704: loss=0.352, reward_mean=0.0, reward_bound=0.0\n",
      "1705: loss=0.527, reward_mean=0.0, reward_bound=0.0\n",
      "1706: loss=0.503, reward_mean=0.0, reward_bound=0.0\n",
      "1707: loss=0.397, reward_mean=0.0, reward_bound=0.0\n",
      "1708: loss=0.460, reward_mean=0.0, reward_bound=0.0\n",
      "1709: loss=0.575, reward_mean=0.0, reward_bound=0.0\n",
      "1710: loss=0.526, reward_mean=0.0, reward_bound=0.0\n",
      "1711: loss=0.508, reward_mean=0.0, reward_bound=0.0\n",
      "1712: loss=0.517, reward_mean=0.0, reward_bound=0.0\n",
      "1713: loss=0.499, reward_mean=0.0, reward_bound=0.0\n",
      "1714: loss=0.421, reward_mean=0.0, reward_bound=0.0\n",
      "1715: loss=0.410, reward_mean=0.0, reward_bound=0.0\n",
      "1716: loss=0.533, reward_mean=0.0, reward_bound=0.0\n",
      "1717: loss=0.469, reward_mean=0.0, reward_bound=0.0\n",
      "1718: loss=0.455, reward_mean=0.0, reward_bound=0.0\n",
      "1719: loss=0.418, reward_mean=0.0, reward_bound=0.0\n",
      "1720: loss=0.504, reward_mean=0.0, reward_bound=0.0\n",
      "1721: loss=0.520, reward_mean=0.0, reward_bound=0.0\n",
      "1722: loss=0.423, reward_mean=0.0, reward_bound=0.0\n",
      "1723: loss=0.390, reward_mean=0.0, reward_bound=0.0\n",
      "1724: loss=0.351, reward_mean=0.0, reward_bound=0.0\n",
      "1725: loss=0.491, reward_mean=0.0, reward_bound=0.0\n",
      "1726: loss=0.601, reward_mean=0.0, reward_bound=0.0\n",
      "1727: loss=0.265, reward_mean=0.0, reward_bound=0.0\n",
      "1728: loss=0.484, reward_mean=0.0, reward_bound=0.0\n",
      "1729: loss=0.448, reward_mean=0.0, reward_bound=0.0\n",
      "1730: loss=0.319, reward_mean=0.0, reward_bound=0.0\n",
      "1731: loss=0.459, reward_mean=0.0, reward_bound=0.0\n",
      "1732: loss=0.243, reward_mean=0.0, reward_bound=0.0\n",
      "1733: loss=0.324, reward_mean=0.0, reward_bound=0.0\n",
      "1734: loss=0.306, reward_mean=0.0, reward_bound=0.0\n",
      "1735: loss=0.490, reward_mean=0.0, reward_bound=0.0\n",
      "1736: loss=0.333, reward_mean=0.0, reward_bound=0.0\n",
      "1737: loss=0.438, reward_mean=0.0, reward_bound=0.0\n",
      "1738: loss=0.322, reward_mean=0.0, reward_bound=0.0\n",
      "1739: loss=0.513, reward_mean=0.0, reward_bound=0.0\n",
      "1740: loss=0.389, reward_mean=0.0, reward_bound=0.0\n",
      "1741: loss=0.498, reward_mean=0.0, reward_bound=0.0\n",
      "1742: loss=0.407, reward_mean=0.0, reward_bound=0.0\n",
      "1743: loss=0.414, reward_mean=0.0, reward_bound=0.0\n",
      "1744: loss=0.403, reward_mean=0.0, reward_bound=0.0\n",
      "1745: loss=0.355, reward_mean=0.0, reward_bound=0.0\n",
      "1746: loss=0.335, reward_mean=0.0, reward_bound=0.0\n",
      "1747: loss=0.526, reward_mean=0.0, reward_bound=0.0\n",
      "1748: loss=0.500, reward_mean=0.0, reward_bound=0.0\n",
      "1749: loss=0.294, reward_mean=0.0, reward_bound=0.0\n",
      "1750: loss=0.412, reward_mean=0.0, reward_bound=0.0\n",
      "1751: loss=0.203, reward_mean=0.0, reward_bound=0.0\n",
      "1752: loss=0.216, reward_mean=0.0, reward_bound=0.0\n",
      "1753: loss=0.381, reward_mean=0.0, reward_bound=0.0\n",
      "1754: loss=0.447, reward_mean=0.0, reward_bound=0.0\n",
      "1755: loss=0.474, reward_mean=0.0, reward_bound=0.0\n",
      "1756: loss=0.385, reward_mean=0.0, reward_bound=0.0\n",
      "1757: loss=0.363, reward_mean=0.0, reward_bound=0.0\n",
      "1758: loss=0.259, reward_mean=0.0, reward_bound=0.0\n",
      "1759: loss=0.257, reward_mean=0.0, reward_bound=0.0\n",
      "1760: loss=0.252, reward_mean=0.0, reward_bound=0.0\n",
      "1761: loss=0.295, reward_mean=0.0, reward_bound=0.0\n",
      "1762: loss=0.315, reward_mean=0.0, reward_bound=0.0\n",
      "1763: loss=0.427, reward_mean=0.0, reward_bound=0.0\n",
      "1764: loss=0.383, reward_mean=0.0, reward_bound=0.0\n",
      "1765: loss=0.234, reward_mean=0.0, reward_bound=0.0\n",
      "1766: loss=0.293, reward_mean=0.0, reward_bound=0.0\n",
      "1767: loss=0.483, reward_mean=0.0, reward_bound=0.0\n",
      "1768: loss=0.241, reward_mean=0.0, reward_bound=0.0\n",
      "1769: loss=0.232, reward_mean=0.0, reward_bound=0.0\n",
      "1770: loss=0.273, reward_mean=0.0, reward_bound=0.0\n",
      "1771: loss=0.306, reward_mean=0.0, reward_bound=0.0\n",
      "1772: loss=0.385, reward_mean=0.0, reward_bound=0.0\n",
      "1773: loss=0.231, reward_mean=0.0, reward_bound=0.0\n",
      "1774: loss=0.405, reward_mean=0.0, reward_bound=0.0\n",
      "1775: loss=0.354, reward_mean=0.0, reward_bound=0.0\n",
      "1776: loss=0.254, reward_mean=0.1, reward_bound=0.0\n",
      "1777: loss=0.242, reward_mean=0.0, reward_bound=0.0\n",
      "1778: loss=0.315, reward_mean=0.0, reward_bound=0.0\n",
      "1779: loss=0.204, reward_mean=0.0, reward_bound=0.0\n",
      "1780: loss=0.307, reward_mean=0.0, reward_bound=0.0\n",
      "1781: loss=0.270, reward_mean=0.0, reward_bound=0.0\n",
      "1782: loss=0.266, reward_mean=0.0, reward_bound=0.0\n",
      "1783: loss=0.175, reward_mean=0.0, reward_bound=0.0\n",
      "1784: loss=0.290, reward_mean=0.0, reward_bound=0.0\n",
      "1785: loss=0.411, reward_mean=0.0, reward_bound=0.0\n",
      "1786: loss=0.411, reward_mean=0.0, reward_bound=0.0\n",
      "1787: loss=0.359, reward_mean=0.0, reward_bound=0.0\n",
      "1788: loss=0.359, reward_mean=0.0, reward_bound=0.0\n",
      "1789: loss=0.285, reward_mean=0.0, reward_bound=0.0\n",
      "1790: loss=0.206, reward_mean=0.0, reward_bound=0.0\n",
      "1791: loss=0.386, reward_mean=0.0, reward_bound=0.0\n",
      "1792: loss=0.343, reward_mean=0.0, reward_bound=0.0\n",
      "1793: loss=0.330, reward_mean=0.0, reward_bound=0.0\n",
      "1794: loss=0.224, reward_mean=0.0, reward_bound=0.0\n",
      "1795: loss=0.371, reward_mean=0.0, reward_bound=0.0\n",
      "1796: loss=0.267, reward_mean=0.0, reward_bound=0.0\n",
      "1797: loss=0.434, reward_mean=0.0, reward_bound=0.0\n",
      "1798: loss=0.123, reward_mean=0.0, reward_bound=0.0\n",
      "1799: loss=0.492, reward_mean=0.0, reward_bound=0.0\n",
      "1800: loss=0.264, reward_mean=0.0, reward_bound=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1801: loss=0.209, reward_mean=0.0, reward_bound=0.0\n",
      "1802: loss=0.373, reward_mean=0.0, reward_bound=0.0\n",
      "1803: loss=0.218, reward_mean=0.0, reward_bound=0.0\n",
      "1804: loss=0.313, reward_mean=0.0, reward_bound=0.0\n",
      "1805: loss=0.132, reward_mean=0.0, reward_bound=0.0\n",
      "1806: loss=0.336, reward_mean=0.0, reward_bound=0.0\n",
      "1807: loss=0.183, reward_mean=0.0, reward_bound=0.0\n",
      "1808: loss=0.309, reward_mean=0.0, reward_bound=0.0\n",
      "1809: loss=0.239, reward_mean=0.0, reward_bound=0.0\n",
      "1810: loss=0.220, reward_mean=0.0, reward_bound=0.0\n",
      "1811: loss=0.355, reward_mean=0.0, reward_bound=0.0\n",
      "1812: loss=0.200, reward_mean=0.0, reward_bound=0.0\n",
      "1813: loss=0.312, reward_mean=0.0, reward_bound=0.0\n",
      "1814: loss=0.322, reward_mean=0.0, reward_bound=0.0\n",
      "1815: loss=0.113, reward_mean=0.0, reward_bound=0.0\n",
      "1816: loss=0.240, reward_mean=0.0, reward_bound=0.0\n",
      "1817: loss=0.314, reward_mean=0.0, reward_bound=0.0\n",
      "1818: loss=0.296, reward_mean=0.0, reward_bound=0.0\n",
      "1819: loss=0.113, reward_mean=0.0, reward_bound=0.0\n",
      "1820: loss=0.308, reward_mean=0.0, reward_bound=0.0\n",
      "1821: loss=0.170, reward_mean=0.0, reward_bound=0.0\n",
      "1822: loss=0.179, reward_mean=0.0, reward_bound=0.0\n",
      "1823: loss=0.067, reward_mean=0.0, reward_bound=0.0\n",
      "1824: loss=0.440, reward_mean=0.0, reward_bound=0.0\n",
      "1825: loss=0.270, reward_mean=0.0, reward_bound=0.0\n",
      "1826: loss=0.247, reward_mean=0.0, reward_bound=0.0\n",
      "1827: loss=0.275, reward_mean=0.0, reward_bound=0.0\n",
      "1828: loss=0.176, reward_mean=0.0, reward_bound=0.0\n",
      "1829: loss=0.278, reward_mean=0.0, reward_bound=0.0\n",
      "1830: loss=0.172, reward_mean=0.0, reward_bound=0.0\n",
      "1831: loss=0.357, reward_mean=0.0, reward_bound=0.0\n",
      "1832: loss=0.437, reward_mean=0.0, reward_bound=0.0\n",
      "1833: loss=0.165, reward_mean=0.0, reward_bound=0.0\n",
      "1834: loss=0.303, reward_mean=0.0, reward_bound=0.0\n",
      "1835: loss=0.219, reward_mean=0.0, reward_bound=0.0\n",
      "1836: loss=0.245, reward_mean=0.0, reward_bound=0.0\n",
      "1837: loss=0.209, reward_mean=0.0, reward_bound=0.0\n",
      "1838: loss=0.457, reward_mean=0.0, reward_bound=0.0\n",
      "1839: loss=0.191, reward_mean=0.0, reward_bound=0.0\n",
      "1840: loss=0.097, reward_mean=0.0, reward_bound=0.0\n",
      "1841: loss=0.199, reward_mean=0.0, reward_bound=0.0\n",
      "1842: loss=0.206, reward_mean=0.0, reward_bound=0.0\n",
      "1843: loss=0.229, reward_mean=0.0, reward_bound=0.0\n",
      "1844: loss=0.179, reward_mean=0.0, reward_bound=0.0\n",
      "1845: loss=0.350, reward_mean=0.0, reward_bound=0.0\n",
      "1846: loss=0.252, reward_mean=0.0, reward_bound=0.0\n",
      "1847: loss=0.283, reward_mean=0.0, reward_bound=0.0\n",
      "1848: loss=0.154, reward_mean=0.0, reward_bound=0.0\n",
      "1849: loss=0.313, reward_mean=0.0, reward_bound=0.0\n",
      "1850: loss=0.140, reward_mean=0.1, reward_bound=0.0\n",
      "1851: loss=0.340, reward_mean=0.0, reward_bound=0.0\n",
      "1852: loss=0.240, reward_mean=0.0, reward_bound=0.0\n",
      "1853: loss=0.385, reward_mean=0.0, reward_bound=0.0\n",
      "1854: loss=0.263, reward_mean=0.0, reward_bound=0.0\n",
      "1855: loss=0.320, reward_mean=0.0, reward_bound=0.0\n",
      "1856: loss=0.347, reward_mean=0.0, reward_bound=0.0\n",
      "1857: loss=0.235, reward_mean=0.0, reward_bound=0.0\n",
      "1858: loss=0.322, reward_mean=0.0, reward_bound=0.0\n",
      "1859: loss=0.264, reward_mean=0.0, reward_bound=0.0\n",
      "1860: loss=0.258, reward_mean=0.0, reward_bound=0.0\n",
      "1861: loss=0.386, reward_mean=0.0, reward_bound=0.0\n",
      "1862: loss=0.211, reward_mean=0.0, reward_bound=0.0\n",
      "1863: loss=0.080, reward_mean=0.0, reward_bound=0.0\n",
      "1864: loss=0.334, reward_mean=0.0, reward_bound=0.0\n",
      "1865: loss=0.508, reward_mean=0.0, reward_bound=0.0\n",
      "1866: loss=0.328, reward_mean=0.0, reward_bound=0.0\n",
      "1867: loss=0.182, reward_mean=0.0, reward_bound=0.0\n",
      "1868: loss=0.265, reward_mean=0.0, reward_bound=0.0\n",
      "1869: loss=0.333, reward_mean=0.0, reward_bound=0.0\n",
      "1870: loss=0.288, reward_mean=0.0, reward_bound=0.0\n",
      "1871: loss=0.141, reward_mean=0.0, reward_bound=0.0\n",
      "1872: loss=0.247, reward_mean=0.0, reward_bound=0.0\n",
      "1873: loss=0.273, reward_mean=0.0, reward_bound=0.0\n",
      "1874: loss=0.199, reward_mean=0.0, reward_bound=0.0\n",
      "1875: loss=0.183, reward_mean=0.0, reward_bound=0.0\n",
      "1876: loss=0.390, reward_mean=0.0, reward_bound=0.0\n",
      "1877: loss=0.254, reward_mean=0.1, reward_bound=0.0\n",
      "1878: loss=0.301, reward_mean=0.0, reward_bound=0.0\n",
      "1879: loss=0.241, reward_mean=0.0, reward_bound=0.0\n",
      "1880: loss=0.255, reward_mean=0.0, reward_bound=0.0\n",
      "1881: loss=0.411, reward_mean=0.0, reward_bound=0.0\n",
      "1882: loss=0.302, reward_mean=0.0, reward_bound=0.0\n",
      "1883: loss=0.338, reward_mean=0.0, reward_bound=0.0\n",
      "1884: loss=0.360, reward_mean=0.0, reward_bound=0.0\n",
      "1885: loss=0.305, reward_mean=0.0, reward_bound=0.0\n",
      "1886: loss=0.333, reward_mean=0.0, reward_bound=0.0\n",
      "1887: loss=0.166, reward_mean=0.0, reward_bound=0.0\n",
      "1888: loss=0.291, reward_mean=0.0, reward_bound=0.0\n",
      "1889: loss=0.527, reward_mean=0.0, reward_bound=0.0\n",
      "1890: loss=0.326, reward_mean=0.0, reward_bound=0.0\n",
      "1891: loss=0.151, reward_mean=0.0, reward_bound=0.0\n",
      "1892: loss=0.245, reward_mean=0.0, reward_bound=0.0\n",
      "1893: loss=0.393, reward_mean=0.0, reward_bound=0.0\n",
      "1894: loss=0.331, reward_mean=0.0, reward_bound=0.0\n",
      "1895: loss=0.392, reward_mean=0.0, reward_bound=0.0\n",
      "1896: loss=0.393, reward_mean=0.0, reward_bound=0.0\n",
      "1897: loss=0.276, reward_mean=0.0, reward_bound=0.0\n",
      "1898: loss=0.396, reward_mean=0.0, reward_bound=0.0\n",
      "1899: loss=0.465, reward_mean=0.0, reward_bound=0.0\n",
      "1900: loss=0.514, reward_mean=0.0, reward_bound=0.0\n",
      "1901: loss=0.447, reward_mean=0.0, reward_bound=0.0\n",
      "1902: loss=0.388, reward_mean=0.0, reward_bound=0.0\n",
      "1903: loss=0.405, reward_mean=0.0, reward_bound=0.0\n",
      "1904: loss=0.335, reward_mean=0.0, reward_bound=0.0\n",
      "1905: loss=0.359, reward_mean=0.0, reward_bound=0.0\n",
      "1906: loss=0.365, reward_mean=0.0, reward_bound=0.0\n",
      "1907: loss=0.346, reward_mean=0.0, reward_bound=0.0\n",
      "1908: loss=0.474, reward_mean=0.0, reward_bound=0.0\n",
      "1909: loss=0.395, reward_mean=0.0, reward_bound=0.0\n",
      "1910: loss=0.389, reward_mean=0.0, reward_bound=0.0\n",
      "1911: loss=0.390, reward_mean=0.0, reward_bound=0.0\n",
      "1912: loss=0.383, reward_mean=0.0, reward_bound=0.0\n",
      "1913: loss=0.258, reward_mean=0.0, reward_bound=0.0\n",
      "1914: loss=0.401, reward_mean=0.0, reward_bound=0.0\n",
      "1915: loss=0.498, reward_mean=0.0, reward_bound=0.0\n",
      "1916: loss=0.289, reward_mean=0.0, reward_bound=0.0\n",
      "1917: loss=0.355, reward_mean=0.0, reward_bound=0.0\n",
      "1918: loss=0.318, reward_mean=0.0, reward_bound=0.0\n",
      "1919: loss=0.436, reward_mean=0.0, reward_bound=0.0\n",
      "1920: loss=0.438, reward_mean=0.0, reward_bound=0.0\n",
      "1921: loss=0.263, reward_mean=0.0, reward_bound=0.0\n",
      "1922: loss=0.309, reward_mean=0.0, reward_bound=0.0\n",
      "1923: loss=0.269, reward_mean=0.0, reward_bound=0.0\n",
      "1924: loss=0.476, reward_mean=0.0, reward_bound=0.0\n",
      "1925: loss=0.364, reward_mean=0.0, reward_bound=0.0\n",
      "1926: loss=0.411, reward_mean=0.0, reward_bound=0.0\n",
      "1927: loss=0.562, reward_mean=0.0, reward_bound=0.0\n",
      "1928: loss=0.239, reward_mean=0.0, reward_bound=0.0\n",
      "1929: loss=0.489, reward_mean=0.0, reward_bound=0.0\n",
      "1930: loss=0.316, reward_mean=0.0, reward_bound=0.0\n",
      "1931: loss=0.405, reward_mean=0.0, reward_bound=0.0\n",
      "1932: loss=0.452, reward_mean=0.0, reward_bound=0.0\n",
      "1933: loss=0.511, reward_mean=0.0, reward_bound=0.0\n",
      "1934: loss=0.352, reward_mean=0.0, reward_bound=0.0\n",
      "1935: loss=0.340, reward_mean=0.0, reward_bound=0.0\n",
      "1936: loss=0.505, reward_mean=0.0, reward_bound=0.0\n",
      "1937: loss=0.360, reward_mean=0.0, reward_bound=0.0\n",
      "1938: loss=0.430, reward_mean=0.0, reward_bound=0.0\n",
      "1939: loss=0.346, reward_mean=0.0, reward_bound=0.0\n",
      "1940: loss=0.249, reward_mean=0.0, reward_bound=0.0\n",
      "1941: loss=0.418, reward_mean=0.0, reward_bound=0.0\n",
      "1942: loss=0.533, reward_mean=0.0, reward_bound=0.0\n",
      "1943: loss=0.352, reward_mean=0.0, reward_bound=0.0\n",
      "1944: loss=0.452, reward_mean=0.0, reward_bound=0.0\n",
      "1945: loss=0.409, reward_mean=0.0, reward_bound=0.0\n",
      "1946: loss=0.376, reward_mean=0.0, reward_bound=0.0\n",
      "1947: loss=0.481, reward_mean=0.0, reward_bound=0.0\n",
      "1948: loss=0.612, reward_mean=0.0, reward_bound=0.0\n",
      "1949: loss=0.424, reward_mean=0.0, reward_bound=0.0\n",
      "1950: loss=0.407, reward_mean=0.0, reward_bound=0.0\n",
      "1951: loss=0.306, reward_mean=0.0, reward_bound=0.0\n",
      "1952: loss=0.537, reward_mean=0.0, reward_bound=0.0\n",
      "1953: loss=0.282, reward_mean=0.0, reward_bound=0.0\n",
      "1954: loss=0.329, reward_mean=0.0, reward_bound=0.0\n",
      "1955: loss=0.360, reward_mean=0.0, reward_bound=0.0\n",
      "1956: loss=0.461, reward_mean=0.0, reward_bound=0.0\n",
      "1957: loss=0.366, reward_mean=0.0, reward_bound=0.0\n",
      "1958: loss=0.492, reward_mean=0.0, reward_bound=0.0\n",
      "1959: loss=0.400, reward_mean=0.0, reward_bound=0.0\n",
      "1960: loss=0.372, reward_mean=0.0, reward_bound=0.0\n",
      "1961: loss=0.400, reward_mean=0.0, reward_bound=0.0\n",
      "1962: loss=0.446, reward_mean=0.0, reward_bound=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1963: loss=0.359, reward_mean=0.0, reward_bound=0.0\n",
      "1964: loss=0.445, reward_mean=0.0, reward_bound=0.0\n",
      "1965: loss=0.471, reward_mean=0.0, reward_bound=0.0\n",
      "1966: loss=0.514, reward_mean=0.1, reward_bound=0.0\n",
      "1967: loss=0.390, reward_mean=0.0, reward_bound=0.0\n",
      "1968: loss=0.475, reward_mean=0.0, reward_bound=0.0\n",
      "1969: loss=0.305, reward_mean=0.0, reward_bound=0.0\n",
      "1970: loss=0.244, reward_mean=0.0, reward_bound=0.0\n",
      "1971: loss=0.550, reward_mean=0.0, reward_bound=0.0\n",
      "1972: loss=0.506, reward_mean=0.0, reward_bound=0.0\n",
      "1973: loss=0.490, reward_mean=0.0, reward_bound=0.0\n",
      "1974: loss=0.335, reward_mean=0.0, reward_bound=0.0\n",
      "1975: loss=0.546, reward_mean=0.0, reward_bound=0.0\n",
      "1976: loss=0.450, reward_mean=0.0, reward_bound=0.0\n",
      "1977: loss=0.542, reward_mean=0.0, reward_bound=0.0\n",
      "1978: loss=0.483, reward_mean=0.0, reward_bound=0.0\n",
      "1979: loss=0.415, reward_mean=0.0, reward_bound=0.0\n",
      "1980: loss=0.380, reward_mean=0.0, reward_bound=0.0\n",
      "1981: loss=0.389, reward_mean=0.0, reward_bound=0.0\n",
      "1982: loss=0.336, reward_mean=0.0, reward_bound=0.0\n",
      "1983: loss=0.512, reward_mean=0.0, reward_bound=0.0\n",
      "1984: loss=0.443, reward_mean=0.0, reward_bound=0.0\n",
      "1985: loss=0.376, reward_mean=0.0, reward_bound=0.0\n",
      "1986: loss=0.417, reward_mean=0.0, reward_bound=0.0\n",
      "1987: loss=0.497, reward_mean=0.0, reward_bound=0.0\n",
      "1988: loss=0.440, reward_mean=0.0, reward_bound=0.0\n",
      "1989: loss=0.290, reward_mean=0.0, reward_bound=0.0\n",
      "1990: loss=0.434, reward_mean=0.0, reward_bound=0.0\n",
      "1991: loss=0.438, reward_mean=0.0, reward_bound=0.0\n",
      "1992: loss=0.398, reward_mean=0.0, reward_bound=0.0\n",
      "1993: loss=0.248, reward_mean=0.0, reward_bound=0.0\n",
      "1994: loss=0.426, reward_mean=0.0, reward_bound=0.0\n",
      "1995: loss=0.609, reward_mean=0.0, reward_bound=0.0\n",
      "1996: loss=0.319, reward_mean=0.0, reward_bound=0.0\n",
      "1997: loss=0.413, reward_mean=0.0, reward_bound=0.0\n",
      "1998: loss=0.313, reward_mean=0.0, reward_bound=0.0\n",
      "1999: loss=0.501, reward_mean=0.0, reward_bound=0.0\n",
      "2000: loss=0.341, reward_mean=0.0, reward_bound=0.0\n",
      "2001: loss=0.272, reward_mean=0.0, reward_bound=0.0\n",
      "2002: loss=0.445, reward_mean=0.0, reward_bound=0.0\n",
      "2003: loss=0.367, reward_mean=0.0, reward_bound=0.0\n",
      "2004: loss=0.407, reward_mean=0.0, reward_bound=0.0\n",
      "2005: loss=0.369, reward_mean=0.0, reward_bound=0.0\n",
      "2006: loss=0.468, reward_mean=0.0, reward_bound=0.0\n",
      "2007: loss=0.361, reward_mean=0.0, reward_bound=0.0\n",
      "2008: loss=0.402, reward_mean=0.0, reward_bound=0.0\n",
      "2009: loss=0.512, reward_mean=0.0, reward_bound=0.0\n",
      "2010: loss=0.470, reward_mean=0.0, reward_bound=0.0\n",
      "2011: loss=0.397, reward_mean=0.0, reward_bound=0.0\n",
      "2012: loss=0.399, reward_mean=0.0, reward_bound=0.0\n",
      "2013: loss=0.281, reward_mean=0.0, reward_bound=0.0\n",
      "2014: loss=0.287, reward_mean=0.0, reward_bound=0.0\n",
      "2015: loss=0.464, reward_mean=0.0, reward_bound=0.0\n",
      "2016: loss=0.681, reward_mean=0.0, reward_bound=0.0\n",
      "2017: loss=0.381, reward_mean=0.0, reward_bound=0.0\n",
      "2018: loss=0.465, reward_mean=0.0, reward_bound=0.0\n",
      "2019: loss=0.467, reward_mean=0.0, reward_bound=0.0\n",
      "2020: loss=0.276, reward_mean=0.0, reward_bound=0.0\n",
      "2021: loss=0.334, reward_mean=0.0, reward_bound=0.0\n",
      "2022: loss=0.441, reward_mean=0.0, reward_bound=0.0\n",
      "2023: loss=0.522, reward_mean=0.0, reward_bound=0.0\n",
      "2024: loss=0.492, reward_mean=0.0, reward_bound=0.0\n",
      "2025: loss=0.259, reward_mean=0.0, reward_bound=0.0\n",
      "2026: loss=0.301, reward_mean=0.0, reward_bound=0.0\n",
      "2027: loss=0.406, reward_mean=0.0, reward_bound=0.0\n",
      "2028: loss=0.333, reward_mean=0.0, reward_bound=0.0\n",
      "2029: loss=0.326, reward_mean=0.0, reward_bound=0.0\n",
      "2030: loss=0.258, reward_mean=0.0, reward_bound=0.0\n",
      "2031: loss=0.406, reward_mean=0.0, reward_bound=0.0\n",
      "2032: loss=0.489, reward_mean=0.0, reward_bound=0.0\n",
      "2033: loss=0.369, reward_mean=0.0, reward_bound=0.0\n",
      "2034: loss=0.306, reward_mean=0.0, reward_bound=0.0\n",
      "2035: loss=0.182, reward_mean=0.0, reward_bound=0.0\n",
      "2036: loss=0.404, reward_mean=0.0, reward_bound=0.0\n",
      "2037: loss=0.432, reward_mean=0.0, reward_bound=0.0\n",
      "2038: loss=0.249, reward_mean=0.0, reward_bound=0.0\n",
      "2039: loss=0.369, reward_mean=0.0, reward_bound=0.0\n",
      "2040: loss=0.273, reward_mean=0.0, reward_bound=0.0\n",
      "2041: loss=0.360, reward_mean=0.0, reward_bound=0.0\n",
      "2042: loss=0.269, reward_mean=0.0, reward_bound=0.0\n",
      "2043: loss=0.332, reward_mean=0.0, reward_bound=0.0\n",
      "2044: loss=0.437, reward_mean=0.0, reward_bound=0.0\n",
      "2045: loss=0.298, reward_mean=0.0, reward_bound=0.0\n",
      "2046: loss=0.347, reward_mean=0.0, reward_bound=0.0\n",
      "2047: loss=0.274, reward_mean=0.0, reward_bound=0.0\n",
      "2048: loss=0.440, reward_mean=0.0, reward_bound=0.0\n",
      "2049: loss=0.457, reward_mean=0.0, reward_bound=0.0\n",
      "2050: loss=0.144, reward_mean=0.0, reward_bound=0.0\n",
      "2051: loss=0.406, reward_mean=0.0, reward_bound=0.0\n",
      "2052: loss=0.311, reward_mean=0.0, reward_bound=0.0\n",
      "2053: loss=0.587, reward_mean=0.0, reward_bound=0.0\n",
      "2054: loss=0.421, reward_mean=0.0, reward_bound=0.0\n",
      "2055: loss=0.450, reward_mean=0.0, reward_bound=0.0\n",
      "2056: loss=0.457, reward_mean=0.0, reward_bound=0.0\n",
      "2057: loss=0.444, reward_mean=0.0, reward_bound=0.0\n",
      "2058: loss=0.422, reward_mean=0.0, reward_bound=0.0\n",
      "2059: loss=0.331, reward_mean=0.0, reward_bound=0.0\n",
      "2060: loss=0.360, reward_mean=0.0, reward_bound=0.0\n",
      "2061: loss=0.312, reward_mean=0.0, reward_bound=0.0\n",
      "2062: loss=0.432, reward_mean=0.0, reward_bound=0.0\n",
      "2063: loss=0.281, reward_mean=0.0, reward_bound=0.0\n",
      "2064: loss=0.366, reward_mean=0.0, reward_bound=0.0\n",
      "2065: loss=0.276, reward_mean=0.0, reward_bound=0.0\n",
      "2066: loss=0.425, reward_mean=0.0, reward_bound=0.0\n",
      "2067: loss=0.423, reward_mean=0.0, reward_bound=0.0\n",
      "2068: loss=0.295, reward_mean=0.0, reward_bound=0.0\n",
      "2069: loss=0.497, reward_mean=0.0, reward_bound=0.0\n",
      "2070: loss=0.483, reward_mean=0.0, reward_bound=0.0\n",
      "2071: loss=0.596, reward_mean=0.0, reward_bound=0.0\n",
      "2072: loss=0.257, reward_mean=0.0, reward_bound=0.0\n",
      "2073: loss=0.419, reward_mean=0.0, reward_bound=0.0\n",
      "2074: loss=0.376, reward_mean=0.0, reward_bound=0.0\n",
      "2075: loss=0.403, reward_mean=0.0, reward_bound=0.0\n",
      "2076: loss=0.326, reward_mean=0.0, reward_bound=0.0\n",
      "2077: loss=0.256, reward_mean=0.0, reward_bound=0.0\n",
      "2078: loss=0.432, reward_mean=0.0, reward_bound=0.0\n",
      "2079: loss=0.399, reward_mean=0.0, reward_bound=0.0\n",
      "2080: loss=0.431, reward_mean=0.0, reward_bound=0.0\n",
      "2081: loss=0.460, reward_mean=0.0, reward_bound=0.0\n",
      "2082: loss=0.538, reward_mean=0.0, reward_bound=0.0\n",
      "2083: loss=0.491, reward_mean=0.0, reward_bound=0.0\n",
      "2084: loss=0.545, reward_mean=0.0, reward_bound=0.0\n",
      "2085: loss=0.586, reward_mean=0.0, reward_bound=0.0\n",
      "2086: loss=0.477, reward_mean=0.0, reward_bound=0.0\n",
      "2087: loss=0.415, reward_mean=0.0, reward_bound=0.0\n",
      "2088: loss=0.401, reward_mean=0.0, reward_bound=0.0\n",
      "2089: loss=0.495, reward_mean=0.0, reward_bound=0.0\n",
      "2090: loss=0.450, reward_mean=0.0, reward_bound=0.0\n",
      "2091: loss=0.569, reward_mean=0.0, reward_bound=0.0\n",
      "2092: loss=0.418, reward_mean=0.0, reward_bound=0.0\n",
      "2093: loss=0.439, reward_mean=0.0, reward_bound=0.0\n",
      "2094: loss=0.435, reward_mean=0.0, reward_bound=0.0\n",
      "2095: loss=0.500, reward_mean=0.0, reward_bound=0.0\n",
      "2096: loss=0.588, reward_mean=0.0, reward_bound=0.0\n",
      "2097: loss=0.626, reward_mean=0.0, reward_bound=0.0\n",
      "2098: loss=0.556, reward_mean=0.0, reward_bound=0.0\n",
      "2099: loss=0.442, reward_mean=0.0, reward_bound=0.0\n",
      "2100: loss=0.461, reward_mean=0.0, reward_bound=0.0\n",
      "2101: loss=0.580, reward_mean=0.0, reward_bound=0.0\n",
      "2102: loss=0.472, reward_mean=0.0, reward_bound=0.0\n",
      "2103: loss=0.527, reward_mean=0.0, reward_bound=0.0\n",
      "2104: loss=0.532, reward_mean=0.0, reward_bound=0.0\n",
      "2105: loss=0.434, reward_mean=0.0, reward_bound=0.0\n",
      "2106: loss=0.456, reward_mean=0.0, reward_bound=0.0\n",
      "2107: loss=0.412, reward_mean=0.0, reward_bound=0.0\n",
      "2108: loss=0.488, reward_mean=0.0, reward_bound=0.0\n",
      "2109: loss=0.496, reward_mean=0.1, reward_bound=0.0\n",
      "2110: loss=0.418, reward_mean=0.0, reward_bound=0.0\n",
      "2111: loss=0.462, reward_mean=0.0, reward_bound=0.0\n",
      "2112: loss=0.450, reward_mean=0.0, reward_bound=0.0\n",
      "2113: loss=0.533, reward_mean=0.0, reward_bound=0.0\n",
      "2114: loss=0.574, reward_mean=0.0, reward_bound=0.0\n",
      "2115: loss=0.626, reward_mean=0.0, reward_bound=0.0\n",
      "2116: loss=0.511, reward_mean=0.0, reward_bound=0.0\n",
      "2117: loss=0.546, reward_mean=0.0, reward_bound=0.0\n",
      "2118: loss=0.528, reward_mean=0.0, reward_bound=0.0\n",
      "2119: loss=0.635, reward_mean=0.0, reward_bound=0.0\n",
      "2120: loss=0.428, reward_mean=0.0, reward_bound=0.0\n",
      "2121: loss=0.471, reward_mean=0.0, reward_bound=0.0\n",
      "2122: loss=0.450, reward_mean=0.0, reward_bound=0.0\n",
      "2123: loss=0.513, reward_mean=0.0, reward_bound=0.0\n",
      "2124: loss=0.530, reward_mean=0.0, reward_bound=0.0\n",
      "2125: loss=0.489, reward_mean=0.0, reward_bound=0.0\n",
      "2126: loss=0.466, reward_mean=0.0, reward_bound=0.0\n",
      "2127: loss=0.451, reward_mean=0.0, reward_bound=0.0\n",
      "2128: loss=0.494, reward_mean=0.0, reward_bound=0.0\n",
      "2129: loss=0.533, reward_mean=0.0, reward_bound=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2130: loss=0.624, reward_mean=0.0, reward_bound=0.0\n",
      "2131: loss=0.519, reward_mean=0.0, reward_bound=0.0\n",
      "2132: loss=0.450, reward_mean=0.0, reward_bound=0.0\n",
      "2133: loss=0.653, reward_mean=0.0, reward_bound=0.0\n",
      "2134: loss=0.550, reward_mean=0.0, reward_bound=0.0\n",
      "2135: loss=0.543, reward_mean=0.0, reward_bound=0.0\n",
      "2136: loss=0.430, reward_mean=0.0, reward_bound=0.0\n",
      "2137: loss=0.516, reward_mean=0.0, reward_bound=0.0\n",
      "2138: loss=0.583, reward_mean=0.0, reward_bound=0.0\n",
      "2139: loss=0.388, reward_mean=0.0, reward_bound=0.0\n",
      "2140: loss=0.492, reward_mean=0.0, reward_bound=0.0\n",
      "2141: loss=0.553, reward_mean=0.0, reward_bound=0.0\n",
      "2142: loss=0.721, reward_mean=0.1, reward_bound=0.0\n",
      "2143: loss=0.456, reward_mean=0.0, reward_bound=0.0\n",
      "2144: loss=0.416, reward_mean=0.0, reward_bound=0.0\n",
      "2145: loss=0.429, reward_mean=0.0, reward_bound=0.0\n",
      "2146: loss=0.636, reward_mean=0.0, reward_bound=0.0\n",
      "2147: loss=0.566, reward_mean=0.0, reward_bound=0.0\n",
      "2148: loss=0.410, reward_mean=0.0, reward_bound=0.0\n",
      "2149: loss=0.452, reward_mean=0.0, reward_bound=0.0\n",
      "2150: loss=0.490, reward_mean=0.0, reward_bound=0.0\n",
      "2151: loss=0.495, reward_mean=0.0, reward_bound=0.0\n",
      "2152: loss=0.587, reward_mean=0.0, reward_bound=0.0\n",
      "2153: loss=0.551, reward_mean=0.0, reward_bound=0.0\n",
      "2154: loss=0.541, reward_mean=0.0, reward_bound=0.0\n",
      "2155: loss=0.399, reward_mean=0.0, reward_bound=0.0\n",
      "2156: loss=0.514, reward_mean=0.0, reward_bound=0.0\n",
      "2157: loss=0.458, reward_mean=0.0, reward_bound=0.0\n",
      "2158: loss=0.416, reward_mean=0.0, reward_bound=0.0\n",
      "2159: loss=0.417, reward_mean=0.0, reward_bound=0.0\n",
      "2160: loss=0.566, reward_mean=0.0, reward_bound=0.0\n",
      "2161: loss=0.497, reward_mean=0.0, reward_bound=0.0\n",
      "2162: loss=0.522, reward_mean=0.1, reward_bound=0.0\n",
      "2163: loss=0.586, reward_mean=0.0, reward_bound=0.0\n",
      "2164: loss=0.472, reward_mean=0.0, reward_bound=0.0\n",
      "2165: loss=0.711, reward_mean=0.0, reward_bound=0.0\n",
      "2166: loss=0.663, reward_mean=0.0, reward_bound=0.0\n",
      "2167: loss=0.306, reward_mean=0.0, reward_bound=0.0\n",
      "2168: loss=0.535, reward_mean=0.0, reward_bound=0.0\n",
      "2169: loss=0.477, reward_mean=0.0, reward_bound=0.0\n",
      "2170: loss=0.491, reward_mean=0.0, reward_bound=0.0\n",
      "2171: loss=0.420, reward_mean=0.0, reward_bound=0.0\n",
      "2172: loss=0.430, reward_mean=0.0, reward_bound=0.0\n",
      "2173: loss=0.329, reward_mean=0.0, reward_bound=0.0\n",
      "2174: loss=0.517, reward_mean=0.0, reward_bound=0.0\n",
      "2175: loss=0.658, reward_mean=0.0, reward_bound=0.0\n",
      "2176: loss=0.495, reward_mean=0.0, reward_bound=0.0\n",
      "2177: loss=0.472, reward_mean=0.0, reward_bound=0.0\n",
      "2178: loss=0.444, reward_mean=0.0, reward_bound=0.0\n",
      "2179: loss=0.590, reward_mean=0.0, reward_bound=0.0\n",
      "2180: loss=0.559, reward_mean=0.0, reward_bound=0.0\n",
      "2181: loss=0.410, reward_mean=0.0, reward_bound=0.0\n",
      "2182: loss=0.568, reward_mean=0.0, reward_bound=0.0\n",
      "2183: loss=0.507, reward_mean=0.0, reward_bound=0.0\n",
      "2184: loss=0.356, reward_mean=0.0, reward_bound=0.0\n",
      "2185: loss=0.546, reward_mean=0.0, reward_bound=0.0\n",
      "2186: loss=0.412, reward_mean=0.0, reward_bound=0.0\n",
      "2187: loss=0.564, reward_mean=0.0, reward_bound=0.0\n",
      "2188: loss=0.517, reward_mean=0.0, reward_bound=0.0\n",
      "2189: loss=0.391, reward_mean=0.0, reward_bound=0.0\n",
      "2190: loss=0.494, reward_mean=0.0, reward_bound=0.0\n",
      "2191: loss=0.460, reward_mean=0.0, reward_bound=0.0\n",
      "2192: loss=0.601, reward_mean=0.0, reward_bound=0.0\n",
      "2193: loss=0.357, reward_mean=0.0, reward_bound=0.0\n",
      "2194: loss=0.424, reward_mean=0.0, reward_bound=0.0\n",
      "2195: loss=0.413, reward_mean=0.0, reward_bound=0.0\n",
      "2196: loss=0.433, reward_mean=0.0, reward_bound=0.0\n",
      "2197: loss=0.574, reward_mean=0.0, reward_bound=0.0\n",
      "2198: loss=0.489, reward_mean=0.0, reward_bound=0.0\n",
      "2199: loss=0.462, reward_mean=0.0, reward_bound=0.0\n",
      "2200: loss=0.393, reward_mean=0.0, reward_bound=0.0\n",
      "2201: loss=0.372, reward_mean=0.0, reward_bound=0.0\n",
      "2202: loss=0.559, reward_mean=0.0, reward_bound=0.0\n",
      "2203: loss=0.461, reward_mean=0.0, reward_bound=0.0\n",
      "2204: loss=0.582, reward_mean=0.0, reward_bound=0.0\n",
      "2205: loss=0.443, reward_mean=0.0, reward_bound=0.0\n",
      "2206: loss=0.487, reward_mean=0.0, reward_bound=0.0\n",
      "2207: loss=0.537, reward_mean=0.0, reward_bound=0.0\n",
      "2208: loss=0.575, reward_mean=0.0, reward_bound=0.0\n",
      "2209: loss=0.364, reward_mean=0.0, reward_bound=0.0\n",
      "2210: loss=0.297, reward_mean=0.0, reward_bound=0.0\n",
      "2211: loss=0.451, reward_mean=0.0, reward_bound=0.0\n",
      "2212: loss=0.468, reward_mean=0.0, reward_bound=0.0\n",
      "2213: loss=0.535, reward_mean=0.0, reward_bound=0.0\n",
      "2214: loss=0.590, reward_mean=0.0, reward_bound=0.0\n",
      "2215: loss=0.494, reward_mean=0.0, reward_bound=0.0\n",
      "2216: loss=0.466, reward_mean=0.0, reward_bound=0.0\n",
      "2217: loss=0.510, reward_mean=0.0, reward_bound=0.0\n",
      "2218: loss=0.441, reward_mean=0.0, reward_bound=0.0\n",
      "2219: loss=0.395, reward_mean=0.0, reward_bound=0.0\n",
      "2220: loss=0.540, reward_mean=0.0, reward_bound=0.0\n",
      "2221: loss=0.505, reward_mean=0.0, reward_bound=0.0\n",
      "2222: loss=0.490, reward_mean=0.0, reward_bound=0.0\n",
      "2223: loss=0.498, reward_mean=0.0, reward_bound=0.0\n",
      "2224: loss=0.593, reward_mean=0.0, reward_bound=0.0\n",
      "2225: loss=0.570, reward_mean=0.0, reward_bound=0.0\n",
      "2226: loss=0.461, reward_mean=0.0, reward_bound=0.0\n",
      "2227: loss=0.525, reward_mean=0.0, reward_bound=0.0\n",
      "2228: loss=0.395, reward_mean=0.0, reward_bound=0.0\n",
      "2229: loss=0.546, reward_mean=0.0, reward_bound=0.0\n",
      "2230: loss=0.588, reward_mean=0.0, reward_bound=0.0\n",
      "2231: loss=0.474, reward_mean=0.0, reward_bound=0.0\n",
      "2232: loss=0.431, reward_mean=0.0, reward_bound=0.0\n",
      "2233: loss=0.558, reward_mean=0.0, reward_bound=0.0\n",
      "2234: loss=0.510, reward_mean=0.0, reward_bound=0.0\n",
      "2235: loss=0.545, reward_mean=0.0, reward_bound=0.0\n",
      "2236: loss=0.569, reward_mean=0.0, reward_bound=0.0\n",
      "2237: loss=0.602, reward_mean=0.0, reward_bound=0.0\n",
      "2238: loss=0.479, reward_mean=0.0, reward_bound=0.0\n",
      "2239: loss=0.593, reward_mean=0.0, reward_bound=0.0\n",
      "2240: loss=0.524, reward_mean=0.0, reward_bound=0.0\n",
      "2241: loss=0.489, reward_mean=0.0, reward_bound=0.0\n",
      "2242: loss=0.608, reward_mean=0.0, reward_bound=0.0\n",
      "2243: loss=0.486, reward_mean=0.0, reward_bound=0.0\n",
      "2244: loss=0.422, reward_mean=0.0, reward_bound=0.0\n",
      "2245: loss=0.408, reward_mean=0.0, reward_bound=0.0\n",
      "2246: loss=0.633, reward_mean=0.0, reward_bound=0.0\n",
      "2247: loss=0.556, reward_mean=0.0, reward_bound=0.0\n",
      "2248: loss=0.400, reward_mean=0.0, reward_bound=0.0\n",
      "2249: loss=0.436, reward_mean=0.0, reward_bound=0.0\n",
      "2250: loss=0.668, reward_mean=0.0, reward_bound=0.0\n",
      "2251: loss=0.503, reward_mean=0.0, reward_bound=0.0\n",
      "2252: loss=0.539, reward_mean=0.0, reward_bound=0.0\n",
      "2253: loss=0.410, reward_mean=0.0, reward_bound=0.0\n",
      "2254: loss=0.456, reward_mean=0.0, reward_bound=0.0\n",
      "2255: loss=0.575, reward_mean=0.0, reward_bound=0.0\n",
      "2256: loss=0.504, reward_mean=0.0, reward_bound=0.0\n",
      "2257: loss=0.596, reward_mean=0.0, reward_bound=0.0\n",
      "2258: loss=0.534, reward_mean=0.0, reward_bound=0.0\n",
      "2259: loss=0.642, reward_mean=0.0, reward_bound=0.0\n",
      "2260: loss=0.436, reward_mean=0.0, reward_bound=0.0\n",
      "2261: loss=0.663, reward_mean=0.0, reward_bound=0.0\n",
      "2262: loss=0.486, reward_mean=0.0, reward_bound=0.0\n",
      "2263: loss=0.580, reward_mean=0.0, reward_bound=0.0\n",
      "2264: loss=0.679, reward_mean=0.0, reward_bound=0.0\n",
      "2265: loss=0.789, reward_mean=0.0, reward_bound=0.0\n",
      "2266: loss=0.459, reward_mean=0.0, reward_bound=0.0\n",
      "2267: loss=0.658, reward_mean=0.0, reward_bound=0.0\n",
      "2268: loss=0.496, reward_mean=0.0, reward_bound=0.0\n",
      "2269: loss=0.497, reward_mean=0.0, reward_bound=0.0\n",
      "2270: loss=0.472, reward_mean=0.0, reward_bound=0.0\n",
      "2271: loss=0.624, reward_mean=0.0, reward_bound=0.0\n",
      "2272: loss=0.547, reward_mean=0.0, reward_bound=0.0\n",
      "2273: loss=0.555, reward_mean=0.0, reward_bound=0.0\n",
      "2274: loss=0.542, reward_mean=0.0, reward_bound=0.0\n",
      "2275: loss=0.433, reward_mean=0.0, reward_bound=0.0\n",
      "2276: loss=0.418, reward_mean=0.0, reward_bound=0.0\n",
      "2277: loss=0.583, reward_mean=0.0, reward_bound=0.0\n",
      "2278: loss=0.657, reward_mean=0.0, reward_bound=0.0\n",
      "2279: loss=0.537, reward_mean=0.0, reward_bound=0.0\n",
      "2280: loss=0.651, reward_mean=0.0, reward_bound=0.0\n",
      "2281: loss=0.522, reward_mean=0.0, reward_bound=0.0\n",
      "2282: loss=0.556, reward_mean=0.0, reward_bound=0.0\n",
      "2283: loss=0.525, reward_mean=0.0, reward_bound=0.0\n",
      "2284: loss=0.494, reward_mean=0.0, reward_bound=0.0\n",
      "2285: loss=0.357, reward_mean=0.0, reward_bound=0.0\n",
      "2286: loss=0.520, reward_mean=0.0, reward_bound=0.0\n",
      "2287: loss=0.511, reward_mean=0.0, reward_bound=0.0\n",
      "2288: loss=0.476, reward_mean=0.0, reward_bound=0.0\n",
      "2289: loss=0.493, reward_mean=0.0, reward_bound=0.0\n",
      "2290: loss=0.591, reward_mean=0.0, reward_bound=0.0\n",
      "2291: loss=0.668, reward_mean=0.0, reward_bound=0.0\n",
      "2292: loss=0.384, reward_mean=0.0, reward_bound=0.0\n",
      "2293: loss=0.518, reward_mean=0.0, reward_bound=0.0\n",
      "2294: loss=0.290, reward_mean=0.0, reward_bound=0.0\n",
      "2295: loss=0.386, reward_mean=0.0, reward_bound=0.0\n",
      "2296: loss=0.642, reward_mean=0.0, reward_bound=0.0\n",
      "2297: loss=0.589, reward_mean=0.0, reward_bound=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2298: loss=0.690, reward_mean=0.0, reward_bound=0.0\n",
      "2299: loss=0.566, reward_mean=0.0, reward_bound=0.0\n",
      "2300: loss=0.451, reward_mean=0.0, reward_bound=0.0\n",
      "2301: loss=0.543, reward_mean=0.0, reward_bound=0.0\n",
      "2302: loss=0.418, reward_mean=0.0, reward_bound=0.0\n",
      "2303: loss=0.470, reward_mean=0.0, reward_bound=0.0\n",
      "2304: loss=0.512, reward_mean=0.0, reward_bound=0.0\n",
      "2305: loss=0.553, reward_mean=0.0, reward_bound=0.0\n",
      "2306: loss=0.516, reward_mean=0.0, reward_bound=0.0\n",
      "2307: loss=0.459, reward_mean=0.0, reward_bound=0.0\n",
      "2308: loss=0.457, reward_mean=0.0, reward_bound=0.0\n",
      "2309: loss=0.516, reward_mean=0.0, reward_bound=0.0\n",
      "2310: loss=0.591, reward_mean=0.0, reward_bound=0.0\n",
      "2311: loss=0.450, reward_mean=0.0, reward_bound=0.0\n",
      "2312: loss=0.395, reward_mean=0.0, reward_bound=0.0\n",
      "2313: loss=0.366, reward_mean=0.0, reward_bound=0.0\n",
      "2314: loss=0.496, reward_mean=0.0, reward_bound=0.0\n",
      "2315: loss=0.402, reward_mean=0.0, reward_bound=0.0\n",
      "2316: loss=0.485, reward_mean=0.0, reward_bound=0.0\n",
      "2317: loss=0.473, reward_mean=0.0, reward_bound=0.0\n",
      "2318: loss=0.377, reward_mean=0.0, reward_bound=0.0\n",
      "2319: loss=0.519, reward_mean=0.0, reward_bound=0.0\n",
      "2320: loss=0.498, reward_mean=0.0, reward_bound=0.0\n",
      "2321: loss=0.541, reward_mean=0.0, reward_bound=0.0\n",
      "2322: loss=0.307, reward_mean=0.0, reward_bound=0.0\n",
      "2323: loss=0.588, reward_mean=0.0, reward_bound=0.0\n",
      "2324: loss=0.457, reward_mean=0.0, reward_bound=0.0\n",
      "2325: loss=0.476, reward_mean=0.0, reward_bound=0.0\n",
      "2326: loss=0.432, reward_mean=0.0, reward_bound=0.0\n",
      "2327: loss=0.398, reward_mean=0.0, reward_bound=0.0\n",
      "2328: loss=0.544, reward_mean=0.0, reward_bound=0.0\n",
      "2329: loss=0.498, reward_mean=0.0, reward_bound=0.0\n",
      "2330: loss=0.428, reward_mean=0.0, reward_bound=0.0\n",
      "2331: loss=0.363, reward_mean=0.0, reward_bound=0.0\n",
      "2332: loss=0.336, reward_mean=0.0, reward_bound=0.0\n",
      "2333: loss=0.333, reward_mean=0.0, reward_bound=0.0\n",
      "2334: loss=0.412, reward_mean=0.0, reward_bound=0.0\n",
      "2335: loss=0.325, reward_mean=0.0, reward_bound=0.0\n",
      "2336: loss=0.450, reward_mean=0.0, reward_bound=0.0\n",
      "2337: loss=0.368, reward_mean=0.0, reward_bound=0.0\n",
      "2338: loss=0.256, reward_mean=0.0, reward_bound=0.0\n",
      "2339: loss=0.601, reward_mean=0.0, reward_bound=0.0\n",
      "2340: loss=0.509, reward_mean=0.0, reward_bound=0.0\n",
      "2341: loss=0.680, reward_mean=0.0, reward_bound=0.0\n",
      "2342: loss=0.515, reward_mean=0.0, reward_bound=0.0\n",
      "2343: loss=0.413, reward_mean=0.0, reward_bound=0.0\n",
      "2344: loss=0.464, reward_mean=0.0, reward_bound=0.0\n",
      "2345: loss=0.512, reward_mean=0.0, reward_bound=0.0\n",
      "2346: loss=0.411, reward_mean=0.0, reward_bound=0.0\n",
      "2347: loss=0.714, reward_mean=0.0, reward_bound=0.0\n",
      "2348: loss=0.537, reward_mean=0.0, reward_bound=0.0\n",
      "2349: loss=0.419, reward_mean=0.0, reward_bound=0.0\n",
      "2350: loss=0.457, reward_mean=0.0, reward_bound=0.0\n",
      "2351: loss=0.450, reward_mean=0.0, reward_bound=0.0\n",
      "2352: loss=0.619, reward_mean=0.0, reward_bound=0.0\n",
      "2353: loss=0.553, reward_mean=0.0, reward_bound=0.0\n",
      "2354: loss=0.461, reward_mean=0.0, reward_bound=0.0\n",
      "2355: loss=0.456, reward_mean=0.0, reward_bound=0.0\n",
      "2356: loss=0.496, reward_mean=0.0, reward_bound=0.0\n",
      "2357: loss=0.681, reward_mean=0.0, reward_bound=0.0\n",
      "2358: loss=0.499, reward_mean=0.0, reward_bound=0.0\n",
      "2359: loss=0.309, reward_mean=0.0, reward_bound=0.0\n",
      "2360: loss=0.501, reward_mean=0.0, reward_bound=0.0\n",
      "2361: loss=0.486, reward_mean=0.0, reward_bound=0.0\n",
      "2362: loss=0.420, reward_mean=0.0, reward_bound=0.0\n",
      "2363: loss=0.639, reward_mean=0.0, reward_bound=0.0\n",
      "2364: loss=0.400, reward_mean=0.0, reward_bound=0.0\n",
      "2365: loss=0.499, reward_mean=0.0, reward_bound=0.0\n",
      "2366: loss=0.358, reward_mean=0.0, reward_bound=0.0\n",
      "2367: loss=0.522, reward_mean=0.0, reward_bound=0.0\n",
      "2368: loss=0.594, reward_mean=0.0, reward_bound=0.0\n",
      "2369: loss=0.525, reward_mean=0.0, reward_bound=0.0\n",
      "2370: loss=0.427, reward_mean=0.0, reward_bound=0.0\n",
      "2371: loss=0.581, reward_mean=0.0, reward_bound=0.0\n",
      "2372: loss=0.631, reward_mean=0.0, reward_bound=0.0\n",
      "2373: loss=0.670, reward_mean=0.0, reward_bound=0.0\n",
      "2374: loss=0.350, reward_mean=0.0, reward_bound=0.0\n",
      "2375: loss=0.612, reward_mean=0.0, reward_bound=0.0\n",
      "2376: loss=0.381, reward_mean=0.0, reward_bound=0.0\n",
      "2377: loss=0.465, reward_mean=0.0, reward_bound=0.0\n",
      "2378: loss=0.553, reward_mean=0.0, reward_bound=0.0\n",
      "2379: loss=0.470, reward_mean=0.0, reward_bound=0.0\n",
      "2380: loss=0.526, reward_mean=0.0, reward_bound=0.0\n",
      "2381: loss=0.473, reward_mean=0.0, reward_bound=0.0\n",
      "2382: loss=0.439, reward_mean=0.0, reward_bound=0.0\n",
      "2383: loss=0.489, reward_mean=0.0, reward_bound=0.0\n",
      "2384: loss=0.583, reward_mean=0.0, reward_bound=0.0\n",
      "2385: loss=0.511, reward_mean=0.0, reward_bound=0.0\n",
      "2386: loss=0.495, reward_mean=0.0, reward_bound=0.0\n",
      "2387: loss=0.607, reward_mean=0.0, reward_bound=0.0\n",
      "2388: loss=0.452, reward_mean=0.0, reward_bound=0.0\n",
      "2389: loss=0.584, reward_mean=0.0, reward_bound=0.0\n",
      "2390: loss=0.529, reward_mean=0.0, reward_bound=0.0\n",
      "2391: loss=0.549, reward_mean=0.0, reward_bound=0.0\n",
      "2392: loss=0.506, reward_mean=0.0, reward_bound=0.0\n",
      "2393: loss=0.373, reward_mean=0.0, reward_bound=0.0\n",
      "2394: loss=0.529, reward_mean=0.0, reward_bound=0.0\n",
      "2395: loss=0.464, reward_mean=0.0, reward_bound=0.0\n",
      "2396: loss=0.450, reward_mean=0.0, reward_bound=0.0\n",
      "2397: loss=0.477, reward_mean=0.0, reward_bound=0.0\n",
      "2398: loss=0.451, reward_mean=0.0, reward_bound=0.0\n",
      "2399: loss=0.665, reward_mean=0.0, reward_bound=0.0\n",
      "2400: loss=0.542, reward_mean=0.0, reward_bound=0.0\n",
      "2401: loss=0.545, reward_mean=0.0, reward_bound=0.0\n",
      "2402: loss=0.631, reward_mean=0.0, reward_bound=0.0\n",
      "2403: loss=0.429, reward_mean=0.0, reward_bound=0.0\n",
      "2404: loss=0.563, reward_mean=0.0, reward_bound=0.0\n",
      "2405: loss=0.553, reward_mean=0.0, reward_bound=0.0\n",
      "2406: loss=0.552, reward_mean=0.0, reward_bound=0.0\n",
      "2407: loss=0.613, reward_mean=0.0, reward_bound=0.0\n",
      "2408: loss=0.517, reward_mean=0.0, reward_bound=0.0\n",
      "2409: loss=0.432, reward_mean=0.0, reward_bound=0.0\n",
      "2410: loss=0.460, reward_mean=0.0, reward_bound=0.0\n",
      "2411: loss=0.294, reward_mean=0.0, reward_bound=0.0\n",
      "2412: loss=0.366, reward_mean=0.0, reward_bound=0.0\n",
      "2413: loss=0.546, reward_mean=0.0, reward_bound=0.0\n",
      "2414: loss=0.466, reward_mean=0.0, reward_bound=0.0\n",
      "2415: loss=0.331, reward_mean=0.0, reward_bound=0.0\n",
      "2416: loss=0.702, reward_mean=0.0, reward_bound=0.0\n",
      "2417: loss=0.428, reward_mean=0.0, reward_bound=0.0\n",
      "2418: loss=0.563, reward_mean=0.0, reward_bound=0.0\n",
      "2419: loss=0.447, reward_mean=0.0, reward_bound=0.0\n",
      "2420: loss=0.429, reward_mean=0.0, reward_bound=0.0\n",
      "2421: loss=0.592, reward_mean=0.0, reward_bound=0.0\n",
      "2422: loss=0.472, reward_mean=0.0, reward_bound=0.0\n",
      "2423: loss=0.849, reward_mean=0.0, reward_bound=0.0\n",
      "2424: loss=0.557, reward_mean=0.0, reward_bound=0.0\n",
      "2425: loss=0.668, reward_mean=0.0, reward_bound=0.0\n",
      "2426: loss=0.486, reward_mean=0.0, reward_bound=0.0\n",
      "2427: loss=0.458, reward_mean=0.0, reward_bound=0.0\n",
      "2428: loss=0.766, reward_mean=0.0, reward_bound=0.0\n",
      "2429: loss=0.422, reward_mean=0.0, reward_bound=0.0\n",
      "2430: loss=0.662, reward_mean=0.0, reward_bound=0.0\n",
      "2431: loss=0.517, reward_mean=0.0, reward_bound=0.0\n",
      "2432: loss=0.522, reward_mean=0.0, reward_bound=0.0\n",
      "2433: loss=0.637, reward_mean=0.0, reward_bound=0.0\n",
      "2434: loss=0.506, reward_mean=0.0, reward_bound=0.0\n",
      "2435: loss=0.386, reward_mean=0.0, reward_bound=0.0\n",
      "2436: loss=0.630, reward_mean=0.0, reward_bound=0.0\n",
      "2437: loss=0.724, reward_mean=0.0, reward_bound=0.0\n",
      "2438: loss=0.514, reward_mean=0.0, reward_bound=0.0\n",
      "2439: loss=0.618, reward_mean=0.0, reward_bound=0.0\n",
      "2440: loss=0.643, reward_mean=0.0, reward_bound=0.0\n",
      "2441: loss=0.388, reward_mean=0.0, reward_bound=0.0\n",
      "2442: loss=0.415, reward_mean=0.0, reward_bound=0.0\n",
      "2443: loss=0.626, reward_mean=0.0, reward_bound=0.0\n",
      "2444: loss=0.527, reward_mean=0.0, reward_bound=0.0\n",
      "2445: loss=0.427, reward_mean=0.0, reward_bound=0.0\n",
      "2446: loss=0.467, reward_mean=0.0, reward_bound=0.0\n",
      "2447: loss=0.367, reward_mean=0.0, reward_bound=0.0\n",
      "2448: loss=0.575, reward_mean=0.0, reward_bound=0.0\n",
      "2449: loss=0.469, reward_mean=0.0, reward_bound=0.0\n",
      "2450: loss=0.621, reward_mean=0.0, reward_bound=0.0\n",
      "2451: loss=0.466, reward_mean=0.0, reward_bound=0.0\n",
      "2452: loss=0.530, reward_mean=0.0, reward_bound=0.0\n",
      "2453: loss=0.412, reward_mean=0.0, reward_bound=0.0\n",
      "2454: loss=0.595, reward_mean=0.0, reward_bound=0.0\n",
      "2455: loss=0.478, reward_mean=0.0, reward_bound=0.0\n",
      "2456: loss=0.294, reward_mean=0.0, reward_bound=0.0\n",
      "2457: loss=0.427, reward_mean=0.0, reward_bound=0.0\n",
      "2458: loss=0.552, reward_mean=0.0, reward_bound=0.0\n",
      "2459: loss=0.523, reward_mean=0.0, reward_bound=0.0\n",
      "2460: loss=0.477, reward_mean=0.0, reward_bound=0.0\n",
      "2461: loss=0.588, reward_mean=0.0, reward_bound=0.0\n",
      "2462: loss=0.608, reward_mean=0.0, reward_bound=0.0\n",
      "2463: loss=0.516, reward_mean=0.0, reward_bound=0.0\n",
      "2464: loss=0.519, reward_mean=0.0, reward_bound=0.0\n",
      "2465: loss=0.513, reward_mean=0.0, reward_bound=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2466: loss=0.482, reward_mean=0.0, reward_bound=0.0\n",
      "2467: loss=0.405, reward_mean=0.0, reward_bound=0.0\n",
      "2468: loss=0.547, reward_mean=0.0, reward_bound=0.0\n",
      "2469: loss=0.549, reward_mean=0.0, reward_bound=0.0\n",
      "2470: loss=0.382, reward_mean=0.0, reward_bound=0.0\n",
      "2471: loss=0.503, reward_mean=0.0, reward_bound=0.0\n",
      "2472: loss=0.664, reward_mean=0.0, reward_bound=0.0\n",
      "2473: loss=0.531, reward_mean=0.0, reward_bound=0.0\n",
      "2474: loss=0.597, reward_mean=0.0, reward_bound=0.0\n",
      "2475: loss=0.569, reward_mean=0.0, reward_bound=0.0\n",
      "2476: loss=0.552, reward_mean=0.0, reward_bound=0.0\n",
      "2477: loss=0.563, reward_mean=0.0, reward_bound=0.0\n",
      "2478: loss=0.546, reward_mean=0.0, reward_bound=0.0\n",
      "2479: loss=0.667, reward_mean=0.0, reward_bound=0.0\n",
      "2480: loss=0.496, reward_mean=0.0, reward_bound=0.0\n",
      "2481: loss=0.405, reward_mean=0.0, reward_bound=0.0\n",
      "2482: loss=0.437, reward_mean=0.0, reward_bound=0.0\n",
      "2483: loss=0.406, reward_mean=0.0, reward_bound=0.0\n",
      "2484: loss=0.492, reward_mean=0.0, reward_bound=0.0\n",
      "2485: loss=0.628, reward_mean=0.0, reward_bound=0.0\n",
      "2486: loss=0.451, reward_mean=0.0, reward_bound=0.0\n",
      "2487: loss=0.503, reward_mean=0.0, reward_bound=0.0\n",
      "2488: loss=0.655, reward_mean=0.0, reward_bound=0.0\n",
      "2489: loss=0.545, reward_mean=0.0, reward_bound=0.0\n",
      "2490: loss=0.452, reward_mean=0.0, reward_bound=0.0\n",
      "2491: loss=0.663, reward_mean=0.0, reward_bound=0.0\n",
      "2492: loss=0.493, reward_mean=0.0, reward_bound=0.0\n",
      "2493: loss=0.575, reward_mean=0.0, reward_bound=0.0\n",
      "2494: loss=0.488, reward_mean=0.0, reward_bound=0.0\n",
      "2495: loss=0.773, reward_mean=0.0, reward_bound=0.0\n",
      "2496: loss=0.527, reward_mean=0.0, reward_bound=0.0\n",
      "2497: loss=0.708, reward_mean=0.0, reward_bound=0.0\n",
      "2498: loss=0.529, reward_mean=0.0, reward_bound=0.0\n",
      "2499: loss=0.524, reward_mean=0.0, reward_bound=0.0\n",
      "2500: loss=0.635, reward_mean=0.0, reward_bound=0.0\n",
      "2501: loss=0.732, reward_mean=0.0, reward_bound=0.0\n",
      "2502: loss=0.475, reward_mean=0.0, reward_bound=0.0\n",
      "2503: loss=0.574, reward_mean=0.0, reward_bound=0.0\n",
      "2504: loss=0.464, reward_mean=0.0, reward_bound=0.0\n",
      "2505: loss=0.462, reward_mean=0.0, reward_bound=0.0\n",
      "2506: loss=0.734, reward_mean=0.0, reward_bound=0.0\n",
      "2507: loss=0.634, reward_mean=0.0, reward_bound=0.0\n",
      "2508: loss=0.673, reward_mean=0.0, reward_bound=0.0\n",
      "2509: loss=0.494, reward_mean=0.0, reward_bound=0.0\n",
      "2510: loss=0.732, reward_mean=0.0, reward_bound=0.0\n",
      "2511: loss=0.539, reward_mean=0.0, reward_bound=0.0\n",
      "2512: loss=0.513, reward_mean=0.0, reward_bound=0.0\n",
      "2513: loss=0.642, reward_mean=0.0, reward_bound=0.0\n",
      "2514: loss=0.671, reward_mean=0.0, reward_bound=0.0\n",
      "2515: loss=0.632, reward_mean=0.0, reward_bound=0.0\n",
      "2516: loss=0.510, reward_mean=0.0, reward_bound=0.0\n",
      "2517: loss=0.603, reward_mean=0.0, reward_bound=0.0\n",
      "2518: loss=0.758, reward_mean=0.0, reward_bound=0.0\n",
      "2519: loss=0.735, reward_mean=0.0, reward_bound=0.0\n",
      "2520: loss=0.738, reward_mean=0.0, reward_bound=0.0\n",
      "2521: loss=0.593, reward_mean=0.0, reward_bound=0.0\n",
      "2522: loss=0.602, reward_mean=0.0, reward_bound=0.0\n",
      "2523: loss=0.540, reward_mean=0.0, reward_bound=0.0\n",
      "2524: loss=0.697, reward_mean=0.0, reward_bound=0.0\n",
      "2525: loss=0.674, reward_mean=0.0, reward_bound=0.0\n",
      "2526: loss=0.549, reward_mean=0.0, reward_bound=0.0\n",
      "2527: loss=0.618, reward_mean=0.0, reward_bound=0.0\n",
      "2528: loss=0.575, reward_mean=0.0, reward_bound=0.0\n",
      "2529: loss=0.742, reward_mean=0.0, reward_bound=0.0\n",
      "2530: loss=0.622, reward_mean=0.0, reward_bound=0.0\n",
      "2531: loss=0.593, reward_mean=0.0, reward_bound=0.0\n",
      "2532: loss=0.584, reward_mean=0.0, reward_bound=0.0\n",
      "2533: loss=0.632, reward_mean=0.0, reward_bound=0.0\n",
      "2534: loss=0.612, reward_mean=0.0, reward_bound=0.0\n",
      "2535: loss=0.654, reward_mean=0.0, reward_bound=0.0\n",
      "2536: loss=0.728, reward_mean=0.0, reward_bound=0.0\n",
      "2537: loss=0.667, reward_mean=0.0, reward_bound=0.0\n",
      "2538: loss=0.507, reward_mean=0.0, reward_bound=0.0\n",
      "2539: loss=0.689, reward_mean=0.0, reward_bound=0.0\n",
      "2540: loss=0.559, reward_mean=0.0, reward_bound=0.0\n",
      "2541: loss=0.651, reward_mean=0.0, reward_bound=0.0\n",
      "2542: loss=0.757, reward_mean=0.0, reward_bound=0.0\n",
      "2543: loss=0.633, reward_mean=0.0, reward_bound=0.0\n",
      "2544: loss=0.499, reward_mean=0.0, reward_bound=0.0\n",
      "2545: loss=0.702, reward_mean=0.0, reward_bound=0.0\n",
      "2546: loss=0.698, reward_mean=0.0, reward_bound=0.0\n",
      "2547: loss=0.510, reward_mean=0.0, reward_bound=0.0\n",
      "2548: loss=0.544, reward_mean=0.0, reward_bound=0.0\n",
      "2549: loss=0.743, reward_mean=0.0, reward_bound=0.0\n",
      "2550: loss=0.569, reward_mean=0.0, reward_bound=0.0\n",
      "2551: loss=0.646, reward_mean=0.0, reward_bound=0.0\n",
      "2552: loss=0.521, reward_mean=0.0, reward_bound=0.0\n",
      "2553: loss=0.636, reward_mean=0.0, reward_bound=0.0\n",
      "2554: loss=0.786, reward_mean=0.0, reward_bound=0.0\n",
      "2555: loss=0.371, reward_mean=0.0, reward_bound=0.0\n",
      "2556: loss=0.847, reward_mean=0.0, reward_bound=0.0\n",
      "2557: loss=0.580, reward_mean=0.0, reward_bound=0.0\n",
      "2558: loss=0.581, reward_mean=0.0, reward_bound=0.0\n",
      "2559: loss=0.597, reward_mean=0.0, reward_bound=0.0\n",
      "2560: loss=0.670, reward_mean=0.0, reward_bound=0.0\n",
      "2561: loss=0.706, reward_mean=0.0, reward_bound=0.0\n",
      "2562: loss=0.562, reward_mean=0.0, reward_bound=0.0\n",
      "2563: loss=0.816, reward_mean=0.0, reward_bound=0.0\n",
      "2564: loss=0.657, reward_mean=0.0, reward_bound=0.0\n",
      "2565: loss=0.551, reward_mean=0.0, reward_bound=0.0\n",
      "2566: loss=0.583, reward_mean=0.0, reward_bound=0.0\n",
      "2567: loss=0.596, reward_mean=0.0, reward_bound=0.0\n",
      "2568: loss=0.627, reward_mean=0.0, reward_bound=0.0\n",
      "2569: loss=0.787, reward_mean=0.0, reward_bound=0.0\n",
      "2570: loss=0.672, reward_mean=0.0, reward_bound=0.0\n",
      "2571: loss=0.775, reward_mean=0.0, reward_bound=0.0\n",
      "2572: loss=0.983, reward_mean=0.0, reward_bound=0.0\n",
      "2573: loss=0.663, reward_mean=0.0, reward_bound=0.0\n",
      "2574: loss=0.738, reward_mean=0.0, reward_bound=0.0\n",
      "2575: loss=0.631, reward_mean=0.0, reward_bound=0.0\n",
      "2576: loss=0.663, reward_mean=0.0, reward_bound=0.0\n",
      "2577: loss=0.630, reward_mean=0.0, reward_bound=0.0\n",
      "2578: loss=0.647, reward_mean=0.0, reward_bound=0.0\n",
      "2579: loss=0.786, reward_mean=0.0, reward_bound=0.0\n",
      "2580: loss=0.586, reward_mean=0.0, reward_bound=0.0\n",
      "2581: loss=0.545, reward_mean=0.0, reward_bound=0.0\n",
      "2582: loss=0.651, reward_mean=0.0, reward_bound=0.0\n",
      "2583: loss=0.618, reward_mean=0.0, reward_bound=0.0\n",
      "2584: loss=0.664, reward_mean=0.0, reward_bound=0.0\n",
      "2585: loss=0.691, reward_mean=0.0, reward_bound=0.0\n",
      "2586: loss=0.679, reward_mean=0.0, reward_bound=0.0\n",
      "2587: loss=0.715, reward_mean=0.0, reward_bound=0.0\n",
      "2588: loss=0.702, reward_mean=0.0, reward_bound=0.0\n",
      "2589: loss=0.730, reward_mean=0.0, reward_bound=0.0\n",
      "2590: loss=0.820, reward_mean=0.0, reward_bound=0.0\n",
      "2591: loss=0.627, reward_mean=0.0, reward_bound=0.0\n",
      "2592: loss=0.669, reward_mean=0.0, reward_bound=0.0\n",
      "2593: loss=0.824, reward_mean=0.0, reward_bound=0.0\n",
      "2594: loss=0.818, reward_mean=0.0, reward_bound=0.0\n",
      "2595: loss=0.857, reward_mean=0.0, reward_bound=0.0\n",
      "2596: loss=0.834, reward_mean=0.0, reward_bound=0.0\n",
      "2597: loss=0.816, reward_mean=0.0, reward_bound=0.0\n",
      "2598: loss=0.686, reward_mean=0.0, reward_bound=0.0\n",
      "2599: loss=0.695, reward_mean=0.0, reward_bound=0.0\n",
      "2600: loss=0.726, reward_mean=0.0, reward_bound=0.0\n",
      "2601: loss=0.722, reward_mean=0.0, reward_bound=0.0\n",
      "2602: loss=0.648, reward_mean=0.0, reward_bound=0.0\n",
      "2603: loss=0.668, reward_mean=0.0, reward_bound=0.0\n",
      "2604: loss=0.601, reward_mean=0.0, reward_bound=0.0\n",
      "2605: loss=0.799, reward_mean=0.0, reward_bound=0.0\n",
      "2606: loss=0.707, reward_mean=0.0, reward_bound=0.0\n",
      "2607: loss=0.855, reward_mean=0.0, reward_bound=0.0\n",
      "2608: loss=0.678, reward_mean=0.0, reward_bound=0.0\n",
      "2609: loss=0.599, reward_mean=0.0, reward_bound=0.0\n",
      "2610: loss=0.790, reward_mean=0.0, reward_bound=0.0\n",
      "2611: loss=0.605, reward_mean=0.0, reward_bound=0.0\n",
      "2612: loss=0.536, reward_mean=0.0, reward_bound=0.0\n",
      "2613: loss=0.684, reward_mean=0.0, reward_bound=0.0\n",
      "2614: loss=0.614, reward_mean=0.0, reward_bound=0.0\n",
      "2615: loss=0.656, reward_mean=0.0, reward_bound=0.0\n",
      "2616: loss=0.701, reward_mean=0.0, reward_bound=0.0\n",
      "2617: loss=0.627, reward_mean=0.0, reward_bound=0.0\n",
      "2618: loss=0.736, reward_mean=0.0, reward_bound=0.0\n",
      "2619: loss=0.576, reward_mean=0.0, reward_bound=0.0\n",
      "2620: loss=0.651, reward_mean=0.0, reward_bound=0.0\n",
      "2621: loss=0.643, reward_mean=0.0, reward_bound=0.0\n",
      "2622: loss=0.717, reward_mean=0.0, reward_bound=0.0\n",
      "2623: loss=0.630, reward_mean=0.0, reward_bound=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2624: loss=0.644, reward_mean=0.0, reward_bound=0.0\n",
      "2625: loss=0.633, reward_mean=0.0, reward_bound=0.0\n",
      "2626: loss=0.547, reward_mean=0.0, reward_bound=0.0\n",
      "2627: loss=0.522, reward_mean=0.0, reward_bound=0.0\n",
      "2628: loss=0.789, reward_mean=0.0, reward_bound=0.0\n",
      "2629: loss=0.485, reward_mean=0.0, reward_bound=0.0\n",
      "2630: loss=0.634, reward_mean=0.0, reward_bound=0.0\n",
      "2631: loss=0.581, reward_mean=0.0, reward_bound=0.0\n",
      "2632: loss=0.573, reward_mean=0.0, reward_bound=0.0\n",
      "2633: loss=0.646, reward_mean=0.0, reward_bound=0.0\n",
      "2634: loss=0.641, reward_mean=0.0, reward_bound=0.0\n",
      "2635: loss=0.590, reward_mean=0.0, reward_bound=0.0\n",
      "2636: loss=0.662, reward_mean=0.0, reward_bound=0.0\n",
      "2637: loss=0.551, reward_mean=0.0, reward_bound=0.0\n",
      "2638: loss=0.592, reward_mean=0.0, reward_bound=0.0\n",
      "2639: loss=0.407, reward_mean=0.0, reward_bound=0.0\n",
      "2640: loss=0.517, reward_mean=0.0, reward_bound=0.0\n",
      "2641: loss=0.649, reward_mean=0.0, reward_bound=0.0\n",
      "2642: loss=0.659, reward_mean=0.0, reward_bound=0.0\n",
      "2643: loss=0.579, reward_mean=0.0, reward_bound=0.0\n",
      "2644: loss=0.581, reward_mean=0.0, reward_bound=0.0\n",
      "2645: loss=0.460, reward_mean=0.0, reward_bound=0.0\n",
      "2646: loss=0.624, reward_mean=0.0, reward_bound=0.0\n",
      "2647: loss=0.616, reward_mean=0.0, reward_bound=0.0\n",
      "2648: loss=0.588, reward_mean=0.0, reward_bound=0.0\n",
      "2649: loss=0.570, reward_mean=0.0, reward_bound=0.0\n",
      "2650: loss=0.515, reward_mean=0.0, reward_bound=0.0\n",
      "2651: loss=0.730, reward_mean=0.0, reward_bound=0.0\n",
      "2652: loss=0.484, reward_mean=0.0, reward_bound=0.0\n",
      "2653: loss=0.652, reward_mean=0.0, reward_bound=0.0\n",
      "2654: loss=0.566, reward_mean=0.0, reward_bound=0.0\n",
      "2655: loss=0.537, reward_mean=0.0, reward_bound=0.0\n",
      "2656: loss=0.480, reward_mean=0.0, reward_bound=0.0\n",
      "2657: loss=0.719, reward_mean=0.0, reward_bound=0.0\n",
      "2658: loss=0.475, reward_mean=0.0, reward_bound=0.0\n",
      "2659: loss=0.601, reward_mean=0.0, reward_bound=0.0\n",
      "2660: loss=0.591, reward_mean=0.0, reward_bound=0.0\n",
      "2661: loss=0.568, reward_mean=0.0, reward_bound=0.0\n",
      "2662: loss=0.613, reward_mean=0.0, reward_bound=0.0\n",
      "2663: loss=0.564, reward_mean=0.0, reward_bound=0.0\n",
      "2664: loss=0.438, reward_mean=0.0, reward_bound=0.0\n",
      "2665: loss=0.717, reward_mean=0.0, reward_bound=0.0\n",
      "2666: loss=0.537, reward_mean=0.0, reward_bound=0.0\n",
      "2667: loss=0.513, reward_mean=0.0, reward_bound=0.0\n",
      "2668: loss=0.468, reward_mean=0.0, reward_bound=0.0\n",
      "2669: loss=0.655, reward_mean=0.0, reward_bound=0.0\n",
      "2670: loss=0.568, reward_mean=0.0, reward_bound=0.0\n",
      "2671: loss=0.624, reward_mean=0.0, reward_bound=0.0\n",
      "2672: loss=0.597, reward_mean=0.0, reward_bound=0.0\n",
      "2673: loss=0.597, reward_mean=0.0, reward_bound=0.0\n",
      "2674: loss=0.525, reward_mean=0.0, reward_bound=0.0\n",
      "2675: loss=0.589, reward_mean=0.0, reward_bound=0.0\n",
      "2676: loss=0.526, reward_mean=0.0, reward_bound=0.0\n",
      "2677: loss=0.628, reward_mean=0.0, reward_bound=0.0\n",
      "2678: loss=0.467, reward_mean=0.0, reward_bound=0.0\n",
      "2679: loss=0.764, reward_mean=0.0, reward_bound=0.0\n",
      "2680: loss=0.677, reward_mean=0.0, reward_bound=0.0\n",
      "2681: loss=0.529, reward_mean=0.0, reward_bound=0.0\n",
      "2682: loss=0.655, reward_mean=0.0, reward_bound=0.0\n",
      "2683: loss=0.438, reward_mean=0.0, reward_bound=0.0\n",
      "2684: loss=0.621, reward_mean=0.0, reward_bound=0.0\n",
      "2685: loss=0.569, reward_mean=0.0, reward_bound=0.0\n",
      "2686: loss=0.526, reward_mean=0.0, reward_bound=0.0\n",
      "2687: loss=0.651, reward_mean=0.0, reward_bound=0.0\n",
      "2688: loss=0.533, reward_mean=0.0, reward_bound=0.0\n",
      "2689: loss=0.420, reward_mean=0.0, reward_bound=0.0\n",
      "2690: loss=0.608, reward_mean=0.0, reward_bound=0.0\n",
      "2691: loss=0.653, reward_mean=0.0, reward_bound=0.0\n",
      "2692: loss=0.639, reward_mean=0.0, reward_bound=0.0\n",
      "2693: loss=0.436, reward_mean=0.0, reward_bound=0.0\n",
      "2694: loss=0.426, reward_mean=0.0, reward_bound=0.0\n",
      "2695: loss=0.765, reward_mean=0.0, reward_bound=0.0\n",
      "2696: loss=0.530, reward_mean=0.0, reward_bound=0.0\n",
      "2697: loss=0.524, reward_mean=0.0, reward_bound=0.0\n",
      "2698: loss=0.585, reward_mean=0.0, reward_bound=0.0\n",
      "2699: loss=0.639, reward_mean=0.0, reward_bound=0.0\n",
      "2700: loss=0.472, reward_mean=0.0, reward_bound=0.0\n",
      "2701: loss=0.603, reward_mean=0.0, reward_bound=0.0\n",
      "2702: loss=0.745, reward_mean=0.0, reward_bound=0.0\n",
      "2703: loss=0.728, reward_mean=0.0, reward_bound=0.0\n",
      "2704: loss=0.445, reward_mean=0.0, reward_bound=0.0\n",
      "2705: loss=0.465, reward_mean=0.0, reward_bound=0.0\n",
      "2706: loss=0.738, reward_mean=0.0, reward_bound=0.0\n",
      "2707: loss=0.676, reward_mean=0.0, reward_bound=0.0\n",
      "2708: loss=0.670, reward_mean=0.0, reward_bound=0.0\n",
      "2709: loss=0.630, reward_mean=0.0, reward_bound=0.0\n",
      "2710: loss=0.655, reward_mean=0.0, reward_bound=0.0\n",
      "2711: loss=0.512, reward_mean=0.0, reward_bound=0.0\n",
      "2712: loss=0.585, reward_mean=0.0, reward_bound=0.0\n",
      "2713: loss=0.542, reward_mean=0.0, reward_bound=0.0\n",
      "2714: loss=0.694, reward_mean=0.0, reward_bound=0.0\n",
      "2715: loss=0.670, reward_mean=0.0, reward_bound=0.0\n",
      "2716: loss=0.565, reward_mean=0.0, reward_bound=0.0\n",
      "2717: loss=0.422, reward_mean=0.0, reward_bound=0.0\n",
      "2718: loss=0.570, reward_mean=0.0, reward_bound=0.0\n",
      "2719: loss=0.476, reward_mean=0.0, reward_bound=0.0\n",
      "2720: loss=0.504, reward_mean=0.0, reward_bound=0.0\n",
      "2721: loss=0.670, reward_mean=0.0, reward_bound=0.0\n",
      "2722: loss=0.550, reward_mean=0.0, reward_bound=0.0\n",
      "2723: loss=0.503, reward_mean=0.0, reward_bound=0.0\n",
      "2724: loss=0.628, reward_mean=0.0, reward_bound=0.0\n",
      "2725: loss=0.671, reward_mean=0.0, reward_bound=0.0\n",
      "2726: loss=0.697, reward_mean=0.0, reward_bound=0.0\n",
      "2727: loss=0.431, reward_mean=0.0, reward_bound=0.0\n",
      "2728: loss=0.509, reward_mean=0.0, reward_bound=0.0\n",
      "2729: loss=0.446, reward_mean=0.0, reward_bound=0.0\n",
      "2730: loss=0.421, reward_mean=0.0, reward_bound=0.0\n",
      "2731: loss=0.544, reward_mean=0.0, reward_bound=0.0\n",
      "2732: loss=0.624, reward_mean=0.0, reward_bound=0.0\n",
      "2733: loss=0.551, reward_mean=0.0, reward_bound=0.0\n",
      "2734: loss=0.565, reward_mean=0.0, reward_bound=0.0\n",
      "2735: loss=0.488, reward_mean=0.0, reward_bound=0.0\n",
      "2736: loss=0.435, reward_mean=0.0, reward_bound=0.0\n",
      "2737: loss=0.443, reward_mean=0.0, reward_bound=0.0\n",
      "2738: loss=0.647, reward_mean=0.0, reward_bound=0.0\n",
      "2739: loss=0.487, reward_mean=0.0, reward_bound=0.0\n",
      "2740: loss=0.454, reward_mean=0.0, reward_bound=0.0\n",
      "2741: loss=0.543, reward_mean=0.0, reward_bound=0.0\n",
      "2742: loss=0.372, reward_mean=0.0, reward_bound=0.0\n",
      "2743: loss=0.307, reward_mean=0.0, reward_bound=0.0\n",
      "2744: loss=0.436, reward_mean=0.0, reward_bound=0.0\n",
      "2745: loss=0.250, reward_mean=0.0, reward_bound=0.0\n",
      "2746: loss=0.461, reward_mean=0.0, reward_bound=0.0\n",
      "2747: loss=0.389, reward_mean=0.0, reward_bound=0.0\n",
      "2748: loss=0.355, reward_mean=0.0, reward_bound=0.0\n",
      "2749: loss=0.614, reward_mean=0.0, reward_bound=0.0\n",
      "2750: loss=0.525, reward_mean=0.0, reward_bound=0.0\n",
      "2751: loss=0.444, reward_mean=0.0, reward_bound=0.0\n",
      "2752: loss=0.424, reward_mean=0.0, reward_bound=0.0\n",
      "2753: loss=0.679, reward_mean=0.0, reward_bound=0.0\n",
      "2754: loss=0.222, reward_mean=0.0, reward_bound=0.0\n",
      "2755: loss=0.367, reward_mean=0.0, reward_bound=0.0\n",
      "2756: loss=0.360, reward_mean=0.0, reward_bound=0.0\n",
      "2757: loss=0.516, reward_mean=0.0, reward_bound=0.0\n",
      "2758: loss=0.408, reward_mean=0.0, reward_bound=0.0\n",
      "2759: loss=0.416, reward_mean=0.0, reward_bound=0.0\n",
      "2760: loss=0.367, reward_mean=0.0, reward_bound=0.0\n",
      "2761: loss=0.503, reward_mean=0.0, reward_bound=0.0\n",
      "2762: loss=0.312, reward_mean=0.0, reward_bound=0.0\n",
      "2763: loss=0.475, reward_mean=0.0, reward_bound=0.0\n",
      "2764: loss=0.439, reward_mean=0.0, reward_bound=0.0\n",
      "2765: loss=0.286, reward_mean=0.0, reward_bound=0.0\n",
      "2766: loss=0.301, reward_mean=0.0, reward_bound=0.0\n",
      "2767: loss=0.489, reward_mean=0.0, reward_bound=0.0\n",
      "2768: loss=0.199, reward_mean=0.0, reward_bound=0.0\n",
      "2769: loss=0.448, reward_mean=0.0, reward_bound=0.0\n",
      "2770: loss=0.406, reward_mean=0.0, reward_bound=0.0\n",
      "2771: loss=0.546, reward_mean=0.0, reward_bound=0.0\n",
      "2772: loss=0.592, reward_mean=0.0, reward_bound=0.0\n",
      "2773: loss=0.381, reward_mean=0.0, reward_bound=0.0\n",
      "2774: loss=0.571, reward_mean=0.0, reward_bound=0.0\n",
      "2775: loss=0.487, reward_mean=0.0, reward_bound=0.0\n",
      "2776: loss=0.517, reward_mean=0.0, reward_bound=0.0\n",
      "2777: loss=0.512, reward_mean=0.0, reward_bound=0.0\n",
      "2778: loss=0.525, reward_mean=0.0, reward_bound=0.0\n",
      "2779: loss=0.446, reward_mean=0.0, reward_bound=0.0\n",
      "2780: loss=0.651, reward_mean=0.0, reward_bound=0.0\n",
      "2781: loss=0.416, reward_mean=0.0, reward_bound=0.0\n",
      "2782: loss=0.515, reward_mean=0.0, reward_bound=0.0\n",
      "2783: loss=0.513, reward_mean=0.0, reward_bound=0.0\n",
      "2784: loss=0.444, reward_mean=0.0, reward_bound=0.0\n",
      "2785: loss=0.623, reward_mean=0.0, reward_bound=0.0\n",
      "2786: loss=0.587, reward_mean=0.0, reward_bound=0.0\n",
      "2787: loss=0.569, reward_mean=0.0, reward_bound=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2788: loss=0.595, reward_mean=0.0, reward_bound=0.0\n",
      "2789: loss=0.637, reward_mean=0.0, reward_bound=0.0\n",
      "2790: loss=0.639, reward_mean=0.0, reward_bound=0.0\n",
      "2791: loss=0.734, reward_mean=0.0, reward_bound=0.0\n",
      "2792: loss=0.619, reward_mean=0.0, reward_bound=0.0\n",
      "2793: loss=0.840, reward_mean=0.0, reward_bound=0.0\n",
      "2794: loss=0.628, reward_mean=0.0, reward_bound=0.0\n",
      "2795: loss=0.719, reward_mean=0.0, reward_bound=0.0\n",
      "2796: loss=0.630, reward_mean=0.0, reward_bound=0.0\n",
      "2797: loss=0.770, reward_mean=0.0, reward_bound=0.0\n",
      "2798: loss=0.671, reward_mean=0.0, reward_bound=0.0\n",
      "2799: loss=0.574, reward_mean=0.0, reward_bound=0.0\n",
      "2800: loss=0.889, reward_mean=0.0, reward_bound=0.0\n",
      "2801: loss=0.596, reward_mean=0.0, reward_bound=0.0\n",
      "2802: loss=0.763, reward_mean=0.0, reward_bound=0.0\n",
      "2803: loss=0.698, reward_mean=0.0, reward_bound=0.0\n",
      "2804: loss=0.636, reward_mean=0.0, reward_bound=0.0\n",
      "2805: loss=0.733, reward_mean=0.0, reward_bound=0.0\n",
      "2806: loss=0.759, reward_mean=0.0, reward_bound=0.0\n",
      "2807: loss=0.653, reward_mean=0.0, reward_bound=0.0\n",
      "2808: loss=0.737, reward_mean=0.0, reward_bound=0.0\n",
      "2809: loss=0.706, reward_mean=0.0, reward_bound=0.0\n",
      "2810: loss=0.576, reward_mean=0.0, reward_bound=0.0\n",
      "2811: loss=0.691, reward_mean=0.0, reward_bound=0.0\n",
      "2812: loss=0.595, reward_mean=0.0, reward_bound=0.0\n",
      "2813: loss=0.681, reward_mean=0.0, reward_bound=0.0\n",
      "2814: loss=0.704, reward_mean=0.0, reward_bound=0.0\n",
      "2815: loss=0.729, reward_mean=0.0, reward_bound=0.0\n",
      "2816: loss=0.757, reward_mean=0.0, reward_bound=0.0\n",
      "2817: loss=0.706, reward_mean=0.0, reward_bound=0.0\n",
      "2818: loss=0.722, reward_mean=0.0, reward_bound=0.0\n",
      "2819: loss=0.593, reward_mean=0.0, reward_bound=0.0\n",
      "2820: loss=0.653, reward_mean=0.0, reward_bound=0.0\n",
      "2821: loss=0.761, reward_mean=0.0, reward_bound=0.0\n",
      "2822: loss=0.705, reward_mean=0.0, reward_bound=0.0\n",
      "2823: loss=0.575, reward_mean=0.0, reward_bound=0.0\n",
      "2824: loss=0.749, reward_mean=0.0, reward_bound=0.0\n",
      "2825: loss=0.658, reward_mean=0.0, reward_bound=0.0\n",
      "2826: loss=0.544, reward_mean=0.0, reward_bound=0.0\n",
      "2827: loss=0.741, reward_mean=0.0, reward_bound=0.0\n",
      "2828: loss=0.746, reward_mean=0.0, reward_bound=0.0\n",
      "2829: loss=0.600, reward_mean=0.0, reward_bound=0.0\n",
      "2830: loss=0.716, reward_mean=0.0, reward_bound=0.0\n",
      "2831: loss=0.601, reward_mean=0.0, reward_bound=0.0\n",
      "2832: loss=0.631, reward_mean=0.0, reward_bound=0.0\n",
      "2833: loss=0.638, reward_mean=0.0, reward_bound=0.0\n",
      "2834: loss=0.726, reward_mean=0.0, reward_bound=0.0\n",
      "2835: loss=0.653, reward_mean=0.0, reward_bound=0.0\n",
      "2836: loss=0.580, reward_mean=0.0, reward_bound=0.0\n",
      "2837: loss=0.765, reward_mean=0.0, reward_bound=0.0\n",
      "2838: loss=0.618, reward_mean=0.0, reward_bound=0.0\n",
      "2839: loss=0.605, reward_mean=0.0, reward_bound=0.0\n",
      "2840: loss=0.768, reward_mean=0.0, reward_bound=0.0\n",
      "2841: loss=0.711, reward_mean=0.0, reward_bound=0.0\n",
      "2842: loss=0.744, reward_mean=0.0, reward_bound=0.0\n",
      "2843: loss=0.780, reward_mean=0.0, reward_bound=0.0\n",
      "2844: loss=0.582, reward_mean=0.0, reward_bound=0.0\n",
      "2845: loss=0.710, reward_mean=0.0, reward_bound=0.0\n",
      "2846: loss=0.528, reward_mean=0.0, reward_bound=0.0\n",
      "2847: loss=0.631, reward_mean=0.0, reward_bound=0.0\n",
      "2848: loss=0.598, reward_mean=0.0, reward_bound=0.0\n",
      "2849: loss=0.718, reward_mean=0.0, reward_bound=0.0\n",
      "2850: loss=0.705, reward_mean=0.0, reward_bound=0.0\n",
      "2851: loss=0.501, reward_mean=0.0, reward_bound=0.0\n",
      "2852: loss=0.693, reward_mean=0.0, reward_bound=0.0\n",
      "2853: loss=0.753, reward_mean=0.0, reward_bound=0.0\n",
      "2854: loss=0.605, reward_mean=0.0, reward_bound=0.0\n",
      "2855: loss=0.645, reward_mean=0.0, reward_bound=0.0\n",
      "2856: loss=0.702, reward_mean=0.0, reward_bound=0.0\n",
      "2857: loss=0.719, reward_mean=0.0, reward_bound=0.0\n",
      "2858: loss=0.776, reward_mean=0.0, reward_bound=0.0\n",
      "2859: loss=0.634, reward_mean=0.0, reward_bound=0.0\n",
      "2860: loss=0.585, reward_mean=0.0, reward_bound=0.0\n",
      "2861: loss=0.552, reward_mean=0.0, reward_bound=0.0\n",
      "2862: loss=0.817, reward_mean=0.0, reward_bound=0.0\n",
      "2863: loss=0.674, reward_mean=0.0, reward_bound=0.0\n",
      "2864: loss=0.641, reward_mean=0.0, reward_bound=0.0\n",
      "2865: loss=0.559, reward_mean=0.0, reward_bound=0.0\n",
      "2866: loss=0.641, reward_mean=0.0, reward_bound=0.0\n",
      "2867: loss=0.690, reward_mean=0.0, reward_bound=0.0\n",
      "2868: loss=0.446, reward_mean=0.0, reward_bound=0.0\n",
      "2869: loss=0.769, reward_mean=0.0, reward_bound=0.0\n",
      "2870: loss=0.529, reward_mean=0.0, reward_bound=0.0\n",
      "2871: loss=0.773, reward_mean=0.0, reward_bound=0.0\n",
      "2872: loss=0.618, reward_mean=0.0, reward_bound=0.0\n",
      "2873: loss=0.785, reward_mean=0.0, reward_bound=0.0\n",
      "2874: loss=0.561, reward_mean=0.0, reward_bound=0.0\n",
      "2875: loss=0.645, reward_mean=0.0, reward_bound=0.0\n",
      "2876: loss=0.552, reward_mean=0.0, reward_bound=0.0\n",
      "2877: loss=0.719, reward_mean=0.0, reward_bound=0.0\n",
      "2878: loss=0.581, reward_mean=0.0, reward_bound=0.0\n",
      "2879: loss=0.543, reward_mean=0.0, reward_bound=0.0\n",
      "2880: loss=0.695, reward_mean=0.0, reward_bound=0.0\n",
      "2881: loss=0.676, reward_mean=0.0, reward_bound=0.0\n",
      "2882: loss=0.515, reward_mean=0.0, reward_bound=0.0\n",
      "2883: loss=0.642, reward_mean=0.0, reward_bound=0.0\n",
      "2884: loss=0.734, reward_mean=0.0, reward_bound=0.0\n",
      "2885: loss=0.472, reward_mean=0.0, reward_bound=0.0\n",
      "2886: loss=0.500, reward_mean=0.0, reward_bound=0.0\n",
      "2887: loss=0.557, reward_mean=0.0, reward_bound=0.0\n",
      "2888: loss=0.734, reward_mean=0.0, reward_bound=0.0\n",
      "2889: loss=0.494, reward_mean=0.0, reward_bound=0.0\n",
      "2890: loss=0.771, reward_mean=0.0, reward_bound=0.0\n",
      "2891: loss=0.439, reward_mean=0.0, reward_bound=0.0\n",
      "2892: loss=0.482, reward_mean=0.0, reward_bound=0.0\n",
      "2893: loss=0.519, reward_mean=0.0, reward_bound=0.0\n",
      "2894: loss=0.692, reward_mean=0.0, reward_bound=0.0\n",
      "2895: loss=0.538, reward_mean=0.0, reward_bound=0.0\n",
      "2896: loss=0.650, reward_mean=0.0, reward_bound=0.0\n",
      "2897: loss=0.729, reward_mean=0.0, reward_bound=0.0\n",
      "2898: loss=0.615, reward_mean=0.0, reward_bound=0.0\n",
      "2899: loss=0.596, reward_mean=0.0, reward_bound=0.0\n",
      "2900: loss=0.517, reward_mean=0.0, reward_bound=0.0\n",
      "2901: loss=0.639, reward_mean=0.0, reward_bound=0.0\n",
      "2902: loss=0.646, reward_mean=0.0, reward_bound=0.0\n",
      "2903: loss=0.639, reward_mean=0.0, reward_bound=0.0\n",
      "2904: loss=0.548, reward_mean=0.0, reward_bound=0.0\n",
      "2905: loss=0.530, reward_mean=0.0, reward_bound=0.0\n",
      "2906: loss=0.569, reward_mean=0.0, reward_bound=0.0\n",
      "2907: loss=0.482, reward_mean=0.0, reward_bound=0.0\n",
      "2908: loss=0.540, reward_mean=0.0, reward_bound=0.0\n",
      "2909: loss=0.492, reward_mean=0.0, reward_bound=0.0\n",
      "2910: loss=0.553, reward_mean=0.0, reward_bound=0.0\n",
      "2911: loss=0.558, reward_mean=0.0, reward_bound=0.0\n",
      "2912: loss=0.745, reward_mean=0.0, reward_bound=0.0\n",
      "2913: loss=0.706, reward_mean=0.0, reward_bound=0.0\n",
      "2914: loss=0.479, reward_mean=0.0, reward_bound=0.0\n",
      "2915: loss=0.592, reward_mean=0.0, reward_bound=0.0\n",
      "2916: loss=0.469, reward_mean=0.0, reward_bound=0.0\n",
      "2917: loss=0.662, reward_mean=0.0, reward_bound=0.0\n",
      "2918: loss=0.505, reward_mean=0.0, reward_bound=0.0\n",
      "2919: loss=0.655, reward_mean=0.0, reward_bound=0.0\n",
      "2920: loss=0.512, reward_mean=0.0, reward_bound=0.0\n",
      "2921: loss=0.642, reward_mean=0.0, reward_bound=0.0\n",
      "2922: loss=0.536, reward_mean=0.0, reward_bound=0.0\n",
      "2923: loss=0.555, reward_mean=0.0, reward_bound=0.0\n",
      "2924: loss=0.710, reward_mean=0.0, reward_bound=0.0\n",
      "2925: loss=0.602, reward_mean=0.0, reward_bound=0.0\n",
      "2926: loss=0.535, reward_mean=0.0, reward_bound=0.0\n",
      "2927: loss=0.622, reward_mean=0.0, reward_bound=0.0\n",
      "2928: loss=0.618, reward_mean=0.0, reward_bound=0.0\n",
      "2929: loss=0.665, reward_mean=0.0, reward_bound=0.0\n",
      "2930: loss=0.591, reward_mean=0.0, reward_bound=0.0\n",
      "2931: loss=0.573, reward_mean=0.0, reward_bound=0.0\n",
      "2932: loss=0.656, reward_mean=0.0, reward_bound=0.0\n",
      "2933: loss=0.581, reward_mean=0.0, reward_bound=0.0\n",
      "2934: loss=0.598, reward_mean=0.0, reward_bound=0.0\n",
      "2935: loss=0.602, reward_mean=0.0, reward_bound=0.0\n",
      "2936: loss=0.565, reward_mean=0.0, reward_bound=0.0\n",
      "2937: loss=0.661, reward_mean=0.0, reward_bound=0.0\n",
      "2938: loss=0.513, reward_mean=0.0, reward_bound=0.0\n",
      "2939: loss=0.442, reward_mean=0.0, reward_bound=0.0\n",
      "2940: loss=0.559, reward_mean=0.0, reward_bound=0.0\n",
      "2941: loss=0.517, reward_mean=0.0, reward_bound=0.0\n",
      "2942: loss=0.321, reward_mean=0.0, reward_bound=0.0\n",
      "2943: loss=0.573, reward_mean=0.0, reward_bound=0.0\n",
      "2944: loss=0.583, reward_mean=0.0, reward_bound=0.0\n",
      "2945: loss=0.683, reward_mean=0.0, reward_bound=0.0\n",
      "2946: loss=0.556, reward_mean=0.0, reward_bound=0.0\n",
      "2947: loss=0.479, reward_mean=0.0, reward_bound=0.0\n",
      "2948: loss=0.410, reward_mean=0.0, reward_bound=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2949: loss=0.536, reward_mean=0.0, reward_bound=0.0\n",
      "2950: loss=0.511, reward_mean=0.0, reward_bound=0.0\n",
      "2951: loss=0.448, reward_mean=0.0, reward_bound=0.0\n",
      "2952: loss=0.552, reward_mean=0.0, reward_bound=0.0\n",
      "2953: loss=0.412, reward_mean=0.0, reward_bound=0.0\n",
      "2954: loss=0.653, reward_mean=0.0, reward_bound=0.0\n",
      "2955: loss=0.554, reward_mean=0.0, reward_bound=0.0\n",
      "2956: loss=0.497, reward_mean=0.0, reward_bound=0.0\n",
      "2957: loss=0.463, reward_mean=0.0, reward_bound=0.0\n",
      "2958: loss=0.681, reward_mean=0.0, reward_bound=0.0\n",
      "2959: loss=0.726, reward_mean=0.0, reward_bound=0.0\n",
      "2960: loss=0.520, reward_mean=0.0, reward_bound=0.0\n",
      "2961: loss=0.492, reward_mean=0.0, reward_bound=0.0\n",
      "2962: loss=0.520, reward_mean=0.0, reward_bound=0.0\n",
      "2963: loss=0.599, reward_mean=0.0, reward_bound=0.0\n",
      "2964: loss=0.484, reward_mean=0.0, reward_bound=0.0\n",
      "2965: loss=0.601, reward_mean=0.0, reward_bound=0.0\n",
      "2966: loss=0.433, reward_mean=0.0, reward_bound=0.0\n",
      "2967: loss=0.563, reward_mean=0.0, reward_bound=0.0\n",
      "2968: loss=0.506, reward_mean=0.0, reward_bound=0.0\n",
      "2969: loss=0.610, reward_mean=0.0, reward_bound=0.0\n",
      "2970: loss=0.529, reward_mean=0.0, reward_bound=0.0\n",
      "2971: loss=0.556, reward_mean=0.0, reward_bound=0.0\n",
      "2972: loss=0.537, reward_mean=0.0, reward_bound=0.0\n",
      "2973: loss=0.529, reward_mean=0.0, reward_bound=0.0\n",
      "2974: loss=0.779, reward_mean=0.0, reward_bound=0.0\n",
      "2975: loss=0.549, reward_mean=0.0, reward_bound=0.0\n",
      "2976: loss=0.603, reward_mean=0.0, reward_bound=0.0\n",
      "2977: loss=0.463, reward_mean=0.0, reward_bound=0.0\n",
      "2978: loss=0.513, reward_mean=0.0, reward_bound=0.0\n",
      "2979: loss=0.536, reward_mean=0.0, reward_bound=0.0\n",
      "2980: loss=0.636, reward_mean=0.0, reward_bound=0.0\n",
      "2981: loss=0.454, reward_mean=0.0, reward_bound=0.0\n",
      "2982: loss=0.574, reward_mean=0.0, reward_bound=0.0\n",
      "2983: loss=0.742, reward_mean=0.0, reward_bound=0.0\n",
      "2984: loss=0.583, reward_mean=0.0, reward_bound=0.0\n",
      "2985: loss=0.528, reward_mean=0.0, reward_bound=0.0\n",
      "2986: loss=0.508, reward_mean=0.0, reward_bound=0.0\n",
      "2987: loss=0.701, reward_mean=0.0, reward_bound=0.0\n",
      "2988: loss=0.530, reward_mean=0.0, reward_bound=0.0\n",
      "2989: loss=0.717, reward_mean=0.0, reward_bound=0.0\n",
      "2990: loss=0.534, reward_mean=0.0, reward_bound=0.0\n",
      "2991: loss=0.505, reward_mean=0.0, reward_bound=0.0\n",
      "2992: loss=0.463, reward_mean=0.0, reward_bound=0.0\n",
      "2993: loss=0.536, reward_mean=0.0, reward_bound=0.0\n",
      "2994: loss=0.507, reward_mean=0.0, reward_bound=0.0\n",
      "2995: loss=0.579, reward_mean=0.0, reward_bound=0.0\n",
      "2996: loss=0.465, reward_mean=0.0, reward_bound=0.0\n",
      "2997: loss=0.523, reward_mean=0.0, reward_bound=0.0\n",
      "2998: loss=0.700, reward_mean=0.0, reward_bound=0.0\n",
      "2999: loss=0.474, reward_mean=0.0, reward_bound=0.0\n",
      "3000: loss=0.394, reward_mean=0.0, reward_bound=0.0\n",
      "3001: loss=0.589, reward_mean=0.0, reward_bound=0.0\n"
     ]
    }
   ],
   "source": [
    "env = DiscreteOneHotWrapper(gym.make(\"FrozenLake-v0\"))\n",
    "# env = gym.wrappers.Monitor(env, directory=\"mon\", force=True)\n",
    "obs_size = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "net = Net(obs_size, HIDDEN_SIZE, n_actions)\n",
    "objective = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=net.parameters(), lr=0.01)\n",
    "writer = SummaryWriter(comment=\"-frozenlake-naive\")\n",
    "\n",
    "for iter_no, batch in enumerate(iterate_batches(env, net, BATCH_SIZE)):\n",
    "    obs_v, acts_v, reward_b, reward_m = filter_batch(batch, PERCENTILE)\n",
    "    optimizer.zero_grad()\n",
    "    action_scores_v = net(obs_v)\n",
    "    loss_v = objective(action_scores_v, acts_v)\n",
    "    loss_v.backward()\n",
    "    optimizer.step()\n",
    "    print(\"%d: loss=%.3f, reward_mean=%.1f, reward_bound=%.1f\" % (iter_no, loss_v.item(), reward_m, reward_b))\n",
    "    writer.add_scalar(\"loss\", loss_v.item(), iter_no)\n",
    "    writer.add_scalar(\"reward_bound\", reward_b, iter_no)\n",
    "    writer.add_scalar(\"reward_mean\", reward_m, iter_no)\n",
    "    if reward_m > 0.8:\n",
    "        print(\"Solved!\")\n",
    "        break\n",
    "    if iter_no > 3000: ########################################################\n",
    "        print(\"Wrapper does not improve the score!!!\") ########################\n",
    "        break\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/LackofConvergence.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cartpole과 비교했을 때 FrozenLake는 환경, 에피소드, 보상이 다르다.\n",
    "<img src=\"./images/RewardCartPole.png\" />\n",
    "보상 1.0을 받기 위해서는 목표지점에 도착해야만 가능할 뿐만 아니라, 이런 보상이 각 에피소드가 얼만큼 유익했는지(예: 목표지점까지 신속하거나 효율적으로 이동했는지)알려주질 않는다는 점이 차이가 난다. 오로지 성공 (1) 또는 실패(0)만 있을 뿐이다.  \n",
    "엘리트 에피소드를 퍼센티지로 선택하는 방식은 Frozen Lake 문제에서는 완전히 잘못되었고, 훈련시키는데 나쁜 예만을 가져다 준다.\n",
    "<img src=\"./images/RewardFrozenLake.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 frozenlake_tweaked.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 16\n",
    "# PERCENTILE = 70\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "PERCENTILE = 30\n",
    "GAMMA = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "교차 엔트로피로 Lake 문제를 해결하기 위해서는 코드 상으로 몇가지 수정이 필요하다.  \n",
    "Cartpole에서는 배치크기를 16으로 하는 것으로 충분하였지만, Lake에서는 최소 100이상의 배치가 필요하다.  \n",
    "오래걸리는 에피소드보다 적은시간이 소요되는 에피소드에 보상이 상대적으로 높아야 한다. 이는 할인(discount)개념을 써서 구현한다.  \n",
    "FrozenLake는 Cartpole보다 성공적인 에피소드의 숫자가 적으므로 바로 바로 에피소드를 환경으로부터 샘플링하고 버릴 수 없고, 몇번의 반복동안 성공적인 에피소드를 가지고 있어야 한다.  \n",
    "학습율을 줄여서 더 많은 훈련샘플들을 평균할 시간을 준다.  \n",
    "성공적인 에피소드들이 50%이상 쌓이기 위해서는 적어도 5000번의 반복이 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_batch(batch, percentile):\n",
    "#     rewards = list(map(lambda s: s.reward, batch))\n",
    "#     reward_bound = np.percentile(rewards, percentile)\n",
    "#     reward_mean = float(np.mean(rewards))\n",
    "    disc_rewards = list(map(lambda s: s.reward * (GAMMA ** len(s.steps)), batch))\n",
    "    ## discounted reward를 계산해준다.\n",
    "    \n",
    "    reward_bound = np.percentile(disc_rewards, percentile)\n",
    "\n",
    "    train_obs = []\n",
    "    train_act = []\n",
    "    \n",
    "    elite_batch = [] ## 엘리트 에피소드를 가지고 있다가 다음 학습 iteration으로 넘겨주는 리스트\n",
    "    \n",
    "#     for example in batch:\n",
    "#         if example.reward < reward_bound:\n",
    "#             continue\n",
    "#         train_obs.extend(map(lambda step: step.observation, example.steps))\n",
    "#         train_act.extend(map(lambda step: step.action, example.steps))\n",
    "    \n",
    "    for example, discounted_reward in zip(batch, disc_rewards):\n",
    "        if discounted_reward > reward_bound:\n",
    "            train_obs.extend(map(lambda step: step.observation, example.steps))\n",
    "            train_act.extend(map(lambda step: step.action, example.steps))\n",
    "            elite_batch.append(example)\n",
    "    \n",
    "#     train_obs_v = torch.FloatTensor(train_obs)\n",
    "#     train_act_v = torch.LongTensor(train_act)\n",
    "#     return train_obs_v, train_act_v, reward_bound, reward_mean\n",
    "\n",
    "\n",
    "    return elite_batch, train_obs, train_act, reward_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: loss=1.364, reward_mean=0.010, reward_bound=0.000, batch=1\n",
      "1: loss=1.374, reward_mean=0.050, reward_bound=0.000, batch=6\n",
      "2: loss=1.373, reward_mean=0.010, reward_bound=0.000, batch=7\n",
      "3: loss=1.371, reward_mean=0.000, reward_bound=0.000, batch=7\n",
      "4: loss=1.366, reward_mean=0.020, reward_bound=0.000, batch=9\n",
      "5: loss=1.364, reward_mean=0.000, reward_bound=0.000, batch=9\n",
      "6: loss=1.372, reward_mean=0.030, reward_bound=0.000, batch=12\n",
      "7: loss=1.376, reward_mean=0.050, reward_bound=0.000, batch=17\n",
      "8: loss=1.376, reward_mean=0.010, reward_bound=0.000, batch=18\n",
      "9: loss=1.377, reward_mean=0.020, reward_bound=0.000, batch=20\n",
      "10: loss=1.378, reward_mean=0.020, reward_bound=0.000, batch=22\n",
      "11: loss=1.381, reward_mean=0.010, reward_bound=0.000, batch=23\n",
      "12: loss=1.378, reward_mean=0.030, reward_bound=0.000, batch=26\n",
      "13: loss=1.376, reward_mean=0.010, reward_bound=0.000, batch=27\n",
      "14: loss=1.373, reward_mean=0.010, reward_bound=0.000, batch=28\n",
      "15: loss=1.372, reward_mean=0.000, reward_bound=0.000, batch=28\n",
      "16: loss=1.371, reward_mean=0.000, reward_bound=0.000, batch=28\n",
      "17: loss=1.371, reward_mean=0.010, reward_bound=0.000, batch=29\n",
      "18: loss=1.370, reward_mean=0.020, reward_bound=0.000, batch=31\n",
      "19: loss=1.368, reward_mean=0.050, reward_bound=0.000, batch=36\n",
      "20: loss=1.368, reward_mean=0.020, reward_bound=0.000, batch=38\n",
      "21: loss=1.368, reward_mean=0.010, reward_bound=0.000, batch=39\n",
      "22: loss=1.369, reward_mean=0.020, reward_bound=0.000, batch=41\n",
      "23: loss=1.368, reward_mean=0.010, reward_bound=0.000, batch=42\n",
      "24: loss=1.365, reward_mean=0.020, reward_bound=0.000, batch=44\n",
      "25: loss=1.365, reward_mean=0.000, reward_bound=0.000, batch=44\n",
      "26: loss=1.364, reward_mean=0.000, reward_bound=0.000, batch=44\n",
      "27: loss=1.363, reward_mean=0.010, reward_bound=0.000, batch=45\n",
      "28: loss=1.363, reward_mean=0.020, reward_bound=0.000, batch=47\n",
      "29: loss=1.365, reward_mean=0.020, reward_bound=0.000, batch=49\n",
      "30: loss=1.364, reward_mean=0.020, reward_bound=0.000, batch=51\n",
      "31: loss=1.362, reward_mean=0.040, reward_bound=0.000, batch=55\n",
      "32: loss=1.359, reward_mean=0.020, reward_bound=0.000, batch=57\n",
      "33: loss=1.358, reward_mean=0.010, reward_bound=0.000, batch=58\n",
      "34: loss=1.357, reward_mean=0.010, reward_bound=0.000, batch=59\n",
      "35: loss=1.354, reward_mean=0.030, reward_bound=0.000, batch=62\n",
      "36: loss=1.353, reward_mean=0.000, reward_bound=0.000, batch=62\n",
      "37: loss=1.352, reward_mean=0.020, reward_bound=0.000, batch=64\n",
      "38: loss=1.350, reward_mean=0.030, reward_bound=0.000, batch=67\n",
      "39: loss=1.348, reward_mean=0.030, reward_bound=0.000, batch=70\n",
      "40: loss=1.348, reward_mean=0.030, reward_bound=0.000, batch=73\n",
      "41: loss=1.347, reward_mean=0.010, reward_bound=0.000, batch=74\n",
      "42: loss=1.345, reward_mean=0.040, reward_bound=0.000, batch=78\n",
      "43: loss=1.345, reward_mean=0.010, reward_bound=0.000, batch=79\n",
      "44: loss=1.345, reward_mean=0.000, reward_bound=0.000, batch=79\n",
      "45: loss=1.344, reward_mean=0.010, reward_bound=0.000, batch=80\n",
      "46: loss=1.342, reward_mean=0.020, reward_bound=0.000, batch=82\n",
      "47: loss=1.342, reward_mean=0.020, reward_bound=0.000, batch=84\n",
      "48: loss=1.344, reward_mean=0.010, reward_bound=0.000, batch=85\n",
      "49: loss=1.343, reward_mean=0.010, reward_bound=0.000, batch=86\n",
      "50: loss=1.344, reward_mean=0.020, reward_bound=0.000, batch=88\n",
      "51: loss=1.342, reward_mean=0.040, reward_bound=0.000, batch=92\n",
      "52: loss=1.342, reward_mean=0.010, reward_bound=0.000, batch=93\n",
      "53: loss=1.341, reward_mean=0.030, reward_bound=0.000, batch=96\n",
      "54: loss=1.339, reward_mean=0.020, reward_bound=0.000, batch=98\n",
      "55: loss=1.338, reward_mean=0.020, reward_bound=0.000, batch=100\n",
      "56: loss=1.337, reward_mean=0.030, reward_bound=0.000, batch=103\n",
      "57: loss=1.337, reward_mean=0.010, reward_bound=0.000, batch=104\n",
      "58: loss=1.337, reward_mean=0.030, reward_bound=0.000, batch=107\n",
      "59: loss=1.337, reward_mean=0.010, reward_bound=0.000, batch=108\n",
      "60: loss=1.336, reward_mean=0.040, reward_bound=0.000, batch=112\n",
      "61: loss=1.336, reward_mean=0.010, reward_bound=0.000, batch=113\n",
      "62: loss=1.335, reward_mean=0.020, reward_bound=0.000, batch=115\n",
      "63: loss=1.332, reward_mean=0.030, reward_bound=0.000, batch=118\n",
      "64: loss=1.332, reward_mean=0.010, reward_bound=0.000, batch=119\n",
      "65: loss=1.332, reward_mean=0.020, reward_bound=0.000, batch=121\n",
      "66: loss=1.331, reward_mean=0.010, reward_bound=0.000, batch=122\n",
      "67: loss=1.331, reward_mean=0.040, reward_bound=0.000, batch=126\n",
      "68: loss=1.330, reward_mean=0.010, reward_bound=0.000, batch=127\n",
      "69: loss=1.329, reward_mean=0.040, reward_bound=0.000, batch=131\n",
      "70: loss=1.327, reward_mean=0.030, reward_bound=0.000, batch=134\n",
      "71: loss=1.327, reward_mean=0.010, reward_bound=0.000, batch=135\n",
      "72: loss=1.326, reward_mean=0.030, reward_bound=0.000, batch=138\n",
      "73: loss=1.325, reward_mean=0.030, reward_bound=0.000, batch=141\n",
      "74: loss=1.324, reward_mean=0.030, reward_bound=0.000, batch=144\n",
      "75: loss=1.323, reward_mean=0.020, reward_bound=0.000, batch=146\n",
      "76: loss=1.323, reward_mean=0.000, reward_bound=0.000, batch=146\n",
      "77: loss=1.323, reward_mean=0.020, reward_bound=0.000, batch=148\n",
      "78: loss=1.323, reward_mean=0.010, reward_bound=0.000, batch=149\n",
      "79: loss=1.321, reward_mean=0.010, reward_bound=0.000, batch=150\n",
      "80: loss=1.319, reward_mean=0.020, reward_bound=0.000, batch=152\n",
      "81: loss=1.318, reward_mean=0.000, reward_bound=0.000, batch=152\n",
      "82: loss=1.318, reward_mean=0.040, reward_bound=0.000, batch=156\n",
      "83: loss=1.317, reward_mean=0.020, reward_bound=0.000, batch=158\n",
      "84: loss=1.316, reward_mean=0.040, reward_bound=0.000, batch=162\n",
      "85: loss=1.316, reward_mean=0.010, reward_bound=0.000, batch=163\n",
      "86: loss=1.315, reward_mean=0.040, reward_bound=0.000, batch=167\n",
      "87: loss=1.313, reward_mean=0.040, reward_bound=0.000, batch=171\n",
      "88: loss=1.314, reward_mean=0.010, reward_bound=0.000, batch=172\n",
      "89: loss=1.312, reward_mean=0.020, reward_bound=0.000, batch=174\n",
      "90: loss=1.311, reward_mean=0.020, reward_bound=0.000, batch=176\n",
      "91: loss=1.309, reward_mean=0.040, reward_bound=0.000, batch=180\n",
      "92: loss=1.309, reward_mean=0.020, reward_bound=0.000, batch=182\n",
      "93: loss=1.308, reward_mean=0.020, reward_bound=0.000, batch=184\n",
      "94: loss=1.308, reward_mean=0.020, reward_bound=0.000, batch=186\n",
      "95: loss=1.307, reward_mean=0.040, reward_bound=0.000, batch=190\n",
      "96: loss=1.306, reward_mean=0.040, reward_bound=0.000, batch=194\n",
      "97: loss=1.307, reward_mean=0.030, reward_bound=0.000, batch=197\n",
      "98: loss=1.306, reward_mean=0.030, reward_bound=0.000, batch=200\n",
      "99: loss=1.305, reward_mean=0.010, reward_bound=0.000, batch=201\n",
      "100: loss=1.303, reward_mean=0.040, reward_bound=0.000, batch=205\n",
      "101: loss=1.301, reward_mean=0.080, reward_bound=0.006, batch=213\n",
      "102: loss=1.300, reward_mean=0.020, reward_bound=0.000, batch=215\n",
      "103: loss=1.299, reward_mean=0.020, reward_bound=0.000, batch=217\n",
      "104: loss=1.298, reward_mean=0.020, reward_bound=0.000, batch=219\n",
      "105: loss=1.298, reward_mean=0.040, reward_bound=0.012, batch=223\n",
      "106: loss=1.294, reward_mean=0.050, reward_bound=0.041, batch=226\n",
      "107: loss=1.295, reward_mean=0.030, reward_bound=0.042, batch=226\n",
      "108: loss=1.294, reward_mean=0.050, reward_bound=0.061, batch=228\n",
      "109: loss=1.291, reward_mean=0.040, reward_bound=0.072, batch=228\n",
      "110: loss=1.289, reward_mean=0.020, reward_bound=0.089, batch=228\n",
      "111: loss=1.288, reward_mean=0.070, reward_bound=0.100, batch=229\n",
      "112: loss=1.288, reward_mean=0.020, reward_bound=0.109, batch=229\n",
      "113: loss=1.284, reward_mean=0.020, reward_bound=0.122, batch=226\n",
      "114: loss=1.279, reward_mean=0.030, reward_bound=0.135, batch=221\n",
      "115: loss=1.278, reward_mean=0.050, reward_bound=0.150, batch=218\n",
      "116: loss=1.277, reward_mean=0.010, reward_bound=0.000, batch=219\n",
      "117: loss=1.276, reward_mean=0.060, reward_bound=0.133, batch=223\n",
      "118: loss=1.274, reward_mean=0.050, reward_bound=0.160, batch=226\n",
      "119: loss=1.267, reward_mean=0.030, reward_bound=0.167, batch=218\n",
      "120: loss=1.266, reward_mean=0.030, reward_bound=0.000, batch=221\n",
      "121: loss=1.265, reward_mean=0.040, reward_bound=0.185, batch=214\n",
      "122: loss=1.264, reward_mean=0.030, reward_bound=0.000, batch=217\n",
      "123: loss=1.263, reward_mean=0.050, reward_bound=0.088, batch=222\n",
      "124: loss=1.262, reward_mean=0.040, reward_bound=0.095, batch=225\n",
      "125: loss=1.261, reward_mean=0.040, reward_bound=0.124, batch=227\n",
      "126: loss=1.260, reward_mean=0.040, reward_bound=0.135, batch=228\n",
      "127: loss=1.260, reward_mean=0.050, reward_bound=0.169, batch=229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128: loss=1.262, reward_mean=0.040, reward_bound=0.185, batch=229\n",
      "129: loss=1.262, reward_mean=0.010, reward_bound=0.082, batch=230\n",
      "130: loss=1.261, reward_mean=0.010, reward_bound=0.144, batch=231\n",
      "131: loss=1.255, reward_mean=0.060, reward_bound=0.206, batch=221\n",
      "132: loss=1.255, reward_mean=0.020, reward_bound=0.000, batch=223\n",
      "133: loss=1.255, reward_mean=0.040, reward_bound=0.098, batch=226\n",
      "134: loss=1.255, reward_mean=0.050, reward_bound=0.143, batch=228\n",
      "135: loss=1.251, reward_mean=0.050, reward_bound=0.206, batch=228\n",
      "136: loss=1.249, reward_mean=0.030, reward_bound=0.229, batch=206\n",
      "137: loss=1.249, reward_mean=0.020, reward_bound=0.000, batch=208\n",
      "138: loss=1.248, reward_mean=0.010, reward_bound=0.000, batch=209\n",
      "139: loss=1.246, reward_mean=0.010, reward_bound=0.000, batch=210\n",
      "140: loss=1.244, reward_mean=0.070, reward_bound=0.008, batch=217\n",
      "141: loss=1.244, reward_mean=0.060, reward_bound=0.030, batch=222\n",
      "142: loss=1.243, reward_mean=0.020, reward_bound=0.000, batch=224\n",
      "143: loss=1.242, reward_mean=0.010, reward_bound=0.000, batch=225\n",
      "144: loss=1.241, reward_mean=0.070, reward_bound=0.149, batch=227\n",
      "145: loss=1.242, reward_mean=0.080, reward_bound=0.206, batch=228\n",
      "146: loss=1.244, reward_mean=0.040, reward_bound=0.229, batch=228\n",
      "147: loss=1.245, reward_mean=0.050, reward_bound=0.254, batch=200\n",
      "148: loss=1.247, reward_mean=0.060, reward_bound=0.000, batch=206\n",
      "149: loss=1.245, reward_mean=0.060, reward_bound=0.000, batch=212\n",
      "150: loss=1.247, reward_mean=0.030, reward_bound=0.000, batch=215\n",
      "151: loss=1.243, reward_mean=0.050, reward_bound=0.008, batch=220\n",
      "152: loss=1.245, reward_mean=0.060, reward_bound=0.078, batch=224\n",
      "153: loss=1.243, reward_mean=0.020, reward_bound=0.000, batch=226\n",
      "154: loss=1.239, reward_mean=0.040, reward_bound=0.122, batch=227\n",
      "155: loss=1.238, reward_mean=0.020, reward_bound=0.120, batch=229\n",
      "156: loss=1.236, reward_mean=0.040, reward_bound=0.167, batch=229\n",
      "157: loss=1.234, reward_mean=0.050, reward_bound=0.194, batch=230\n",
      "158: loss=1.235, reward_mean=0.070, reward_bound=0.247, batch=231\n",
      "159: loss=1.235, reward_mean=0.040, reward_bound=0.254, batch=230\n",
      "160: loss=1.235, reward_mean=0.050, reward_bound=0.282, batch=206\n",
      "161: loss=1.233, reward_mean=0.050, reward_bound=0.000, batch=211\n",
      "162: loss=1.232, reward_mean=0.020, reward_bound=0.000, batch=213\n",
      "163: loss=1.233, reward_mean=0.030, reward_bound=0.000, batch=216\n",
      "164: loss=1.227, reward_mean=0.060, reward_bound=0.054, batch=221\n",
      "165: loss=1.227, reward_mean=0.040, reward_bound=0.065, batch=224\n",
      "166: loss=1.226, reward_mean=0.040, reward_bound=0.072, batch=227\n",
      "167: loss=1.225, reward_mean=0.070, reward_bound=0.185, batch=226\n",
      "168: loss=1.227, reward_mean=0.060, reward_bound=0.241, batch=228\n",
      "169: loss=1.227, reward_mean=0.070, reward_bound=0.282, batch=228\n",
      "170: loss=1.227, reward_mean=0.030, reward_bound=0.208, batch=229\n",
      "171: loss=1.216, reward_mean=0.070, reward_bound=0.314, batch=192\n",
      "172: loss=1.220, reward_mean=0.070, reward_bound=0.000, batch=199\n",
      "173: loss=1.215, reward_mean=0.070, reward_bound=0.000, batch=206\n",
      "174: loss=1.213, reward_mean=0.020, reward_bound=0.000, batch=208\n",
      "175: loss=1.209, reward_mean=0.050, reward_bound=0.000, batch=213\n",
      "176: loss=1.209, reward_mean=0.040, reward_bound=0.000, batch=217\n",
      "177: loss=1.209, reward_mean=0.060, reward_bound=0.036, batch=222\n",
      "178: loss=1.208, reward_mean=0.020, reward_bound=0.000, batch=224\n",
      "179: loss=1.204, reward_mean=0.060, reward_bound=0.108, batch=227\n",
      "180: loss=1.199, reward_mean=0.070, reward_bound=0.135, batch=228\n",
      "181: loss=1.199, reward_mean=0.020, reward_bound=0.150, batch=228\n",
      "182: loss=1.197, reward_mean=0.030, reward_bound=0.167, batch=226\n",
      "183: loss=1.201, reward_mean=0.050, reward_bound=0.196, batch=228\n",
      "184: loss=1.205, reward_mean=0.060, reward_bound=0.208, batch=229\n",
      "185: loss=1.206, reward_mean=0.030, reward_bound=0.229, batch=225\n",
      "186: loss=1.206, reward_mean=0.030, reward_bound=0.210, batch=227\n",
      "187: loss=1.206, reward_mean=0.040, reward_bound=0.213, batch=229\n",
      "188: loss=1.206, reward_mean=0.050, reward_bound=0.239, batch=230\n",
      "189: loss=1.206, reward_mean=0.040, reward_bound=0.254, batch=226\n",
      "190: loss=1.206, reward_mean=0.040, reward_bound=0.210, batch=228\n",
      "191: loss=1.206, reward_mean=0.090, reward_bound=0.282, batch=221\n",
      "192: loss=1.206, reward_mean=0.040, reward_bound=0.109, batch=224\n",
      "193: loss=1.207, reward_mean=0.060, reward_bound=0.204, batch=227\n",
      "194: loss=1.205, reward_mean=0.020, reward_bound=0.010, batch=229\n",
      "195: loss=1.206, reward_mean=0.070, reward_bound=0.295, batch=230\n",
      "196: loss=1.205, reward_mean=0.080, reward_bound=0.314, batch=224\n",
      "197: loss=1.206, reward_mean=0.030, reward_bound=0.185, batch=227\n",
      "198: loss=1.204, reward_mean=0.090, reward_bound=0.229, batch=228\n",
      "199: loss=1.205, reward_mean=0.080, reward_bound=0.349, batch=178\n",
      "200: loss=1.200, reward_mean=0.050, reward_bound=0.000, batch=183\n",
      "201: loss=1.199, reward_mean=0.040, reward_bound=0.000, batch=187\n",
      "202: loss=1.193, reward_mean=0.050, reward_bound=0.000, batch=192\n",
      "203: loss=1.192, reward_mean=0.040, reward_bound=0.000, batch=196\n",
      "204: loss=1.190, reward_mean=0.020, reward_bound=0.000, batch=198\n",
      "205: loss=1.189, reward_mean=0.050, reward_bound=0.000, batch=203\n",
      "206: loss=1.188, reward_mean=0.030, reward_bound=0.000, batch=206\n",
      "207: loss=1.187, reward_mean=0.050, reward_bound=0.000, batch=211\n",
      "208: loss=1.184, reward_mean=0.050, reward_bound=0.000, batch=216\n",
      "209: loss=1.182, reward_mean=0.040, reward_bound=0.000, batch=220\n",
      "210: loss=1.183, reward_mean=0.070, reward_bound=0.051, batch=224\n",
      "211: loss=1.178, reward_mean=0.080, reward_bound=0.108, batch=227\n",
      "212: loss=1.180, reward_mean=0.070, reward_bound=0.122, batch=228\n",
      "213: loss=1.180, reward_mean=0.040, reward_bound=0.135, batch=225\n",
      "214: loss=1.179, reward_mean=0.060, reward_bound=0.167, batch=226\n",
      "215: loss=1.175, reward_mean=0.050, reward_bound=0.185, batch=226\n",
      "216: loss=1.176, reward_mean=0.010, reward_bound=0.000, batch=227\n",
      "217: loss=1.176, reward_mean=0.020, reward_bound=0.079, batch=229\n",
      "218: loss=1.177, reward_mean=0.080, reward_bound=0.206, batch=229\n",
      "219: loss=1.176, reward_mean=0.030, reward_bound=0.203, batch=230\n",
      "220: loss=1.183, reward_mean=0.070, reward_bound=0.229, batch=230\n",
      "221: loss=1.184, reward_mean=0.080, reward_bound=0.254, batch=225\n",
      "222: loss=1.185, reward_mean=0.040, reward_bound=0.194, batch=227\n",
      "223: loss=1.185, reward_mean=0.030, reward_bound=0.182, batch=229\n",
      "224: loss=1.181, reward_mean=0.060, reward_bound=0.282, batch=226\n",
      "225: loss=1.184, reward_mean=0.060, reward_bound=0.314, batch=219\n",
      "226: loss=1.184, reward_mean=0.050, reward_bound=0.089, batch=223\n",
      "227: loss=1.184, reward_mean=0.140, reward_bound=0.349, batch=220\n",
      "228: loss=1.185, reward_mean=0.050, reward_bound=0.180, batch=224\n",
      "229: loss=1.183, reward_mean=0.050, reward_bound=0.159, batch=227\n",
      "230: loss=1.182, reward_mean=0.110, reward_bound=0.380, batch=229\n",
      "231: loss=1.150, reward_mean=0.050, reward_bound=0.387, batch=158\n",
      "232: loss=1.149, reward_mean=0.040, reward_bound=0.000, batch=162\n",
      "233: loss=1.142, reward_mean=0.090, reward_bound=0.000, batch=171\n",
      "234: loss=1.142, reward_mean=0.050, reward_bound=0.000, batch=176\n",
      "235: loss=1.148, reward_mean=0.100, reward_bound=0.000, batch=186\n",
      "236: loss=1.150, reward_mean=0.030, reward_bound=0.000, batch=189\n",
      "237: loss=1.149, reward_mean=0.060, reward_bound=0.000, batch=195\n",
      "238: loss=1.146, reward_mean=0.110, reward_bound=0.005, batch=206\n",
      "239: loss=1.148, reward_mean=0.070, reward_bound=0.000, batch=213\n",
      "240: loss=1.145, reward_mean=0.040, reward_bound=0.000, batch=217\n",
      "241: loss=1.147, reward_mean=0.020, reward_bound=0.000, batch=219\n",
      "242: loss=1.140, reward_mean=0.050, reward_bound=0.038, batch=223\n",
      "243: loss=1.134, reward_mean=0.110, reward_bound=0.098, batch=225\n",
      "244: loss=1.131, reward_mean=0.050, reward_bound=0.109, batch=230\n",
      "245: loss=1.130, reward_mean=0.080, reward_bound=0.131, batch=231\n",
      "246: loss=1.129, reward_mean=0.060, reward_bound=0.150, batch=230\n",
      "247: loss=1.129, reward_mean=0.070, reward_bound=0.180, batch=231\n",
      "248: loss=1.126, reward_mean=0.140, reward_bound=0.206, batch=226\n",
      "249: loss=1.126, reward_mean=0.060, reward_bound=0.207, batch=228\n",
      "250: loss=1.123, reward_mean=0.040, reward_bound=0.229, batch=225\n",
      "251: loss=1.124, reward_mean=0.040, reward_bound=0.138, batch=227\n",
      "252: loss=1.125, reward_mean=0.050, reward_bound=0.202, batch=229\n",
      "253: loss=1.130, reward_mean=0.100, reward_bound=0.254, batch=229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254: loss=1.125, reward_mean=0.050, reward_bound=0.282, batch=220\n",
      "255: loss=1.125, reward_mean=0.050, reward_bound=0.153, batch=224\n",
      "256: loss=1.125, reward_mean=0.060, reward_bound=0.280, batch=227\n",
      "257: loss=1.123, reward_mean=0.050, reward_bound=0.237, batch=229\n",
      "258: loss=1.123, reward_mean=0.050, reward_bound=0.254, batch=229\n",
      "259: loss=1.121, reward_mean=0.050, reward_bound=0.282, batch=229\n",
      "260: loss=1.121, reward_mean=0.060, reward_bound=0.314, batch=221\n",
      "261: loss=1.120, reward_mean=0.060, reward_bound=0.229, batch=224\n",
      "262: loss=1.124, reward_mean=0.060, reward_bound=0.349, batch=214\n",
      "263: loss=1.127, reward_mean=0.050, reward_bound=0.000, batch=219\n",
      "264: loss=1.129, reward_mean=0.030, reward_bound=0.000, batch=222\n",
      "265: loss=1.132, reward_mean=0.030, reward_bound=0.007, batch=225\n",
      "266: loss=1.131, reward_mean=0.050, reward_bound=0.091, batch=227\n",
      "267: loss=1.126, reward_mean=0.040, reward_bound=0.135, batch=228\n",
      "268: loss=1.123, reward_mean=0.070, reward_bound=0.231, batch=229\n",
      "269: loss=1.126, reward_mean=0.130, reward_bound=0.387, batch=207\n",
      "270: loss=1.118, reward_mean=0.070, reward_bound=0.000, batch=214\n",
      "271: loss=1.114, reward_mean=0.020, reward_bound=0.000, batch=216\n",
      "272: loss=1.112, reward_mean=0.060, reward_bound=0.025, batch=220\n",
      "273: loss=1.113, reward_mean=0.060, reward_bound=0.080, batch=222\n",
      "274: loss=1.115, reward_mean=0.030, reward_bound=0.030, batch=225\n",
      "275: loss=1.107, reward_mean=0.050, reward_bound=0.170, batch=227\n",
      "276: loss=1.107, reward_mean=0.040, reward_bound=0.142, batch=229\n",
      "277: loss=1.109, reward_mean=0.100, reward_bound=0.239, batch=230\n",
      "278: loss=1.114, reward_mean=0.070, reward_bound=0.254, batch=230\n",
      "279: loss=1.111, reward_mean=0.060, reward_bound=0.304, batch=231\n",
      "280: loss=1.114, reward_mean=0.100, reward_bound=0.349, batch=230\n",
      "281: loss=1.116, reward_mean=0.080, reward_bound=0.387, batch=224\n",
      "282: loss=1.116, reward_mean=0.040, reward_bound=0.268, batch=227\n",
      "283: loss=1.118, reward_mean=0.050, reward_bound=0.282, batch=228\n",
      "284: loss=1.114, reward_mean=0.060, reward_bound=0.387, batch=227\n",
      "285: loss=1.112, reward_mean=0.080, reward_bound=0.245, batch=229\n",
      "286: loss=1.111, reward_mean=0.100, reward_bound=0.430, batch=132\n",
      "287: loss=1.112, reward_mean=0.040, reward_bound=0.000, batch=136\n",
      "288: loss=1.100, reward_mean=0.110, reward_bound=0.000, batch=147\n",
      "289: loss=1.101, reward_mean=0.030, reward_bound=0.000, batch=150\n",
      "290: loss=1.099, reward_mean=0.040, reward_bound=0.000, batch=154\n",
      "291: loss=1.100, reward_mean=0.070, reward_bound=0.000, batch=161\n",
      "292: loss=1.101, reward_mean=0.060, reward_bound=0.000, batch=167\n",
      "293: loss=1.099, reward_mean=0.100, reward_bound=0.000, batch=177\n",
      "294: loss=1.103, reward_mean=0.040, reward_bound=0.000, batch=181\n",
      "295: loss=1.104, reward_mean=0.090, reward_bound=0.000, batch=190\n",
      "296: loss=1.102, reward_mean=0.070, reward_bound=0.000, batch=197\n",
      "297: loss=1.099, reward_mean=0.040, reward_bound=0.000, batch=201\n",
      "298: loss=1.101, reward_mean=0.060, reward_bound=0.000, batch=207\n",
      "299: loss=1.102, reward_mean=0.070, reward_bound=0.000, batch=214\n",
      "300: loss=1.100, reward_mean=0.070, reward_bound=0.021, batch=220\n",
      "301: loss=1.101, reward_mean=0.030, reward_bound=0.000, batch=223\n",
      "302: loss=1.110, reward_mean=0.100, reward_bound=0.066, batch=226\n",
      "303: loss=1.108, reward_mean=0.010, reward_bound=0.000, batch=227\n",
      "304: loss=1.109, reward_mean=0.080, reward_bound=0.107, batch=229\n",
      "305: loss=1.106, reward_mean=0.080, reward_bound=0.141, batch=230\n",
      "306: loss=1.102, reward_mean=0.070, reward_bound=0.162, batch=231\n",
      "307: loss=1.105, reward_mean=0.080, reward_bound=0.185, batch=223\n",
      "308: loss=1.105, reward_mean=0.070, reward_bound=0.144, batch=226\n",
      "309: loss=1.102, reward_mean=0.060, reward_bound=0.206, batch=222\n",
      "310: loss=1.099, reward_mean=0.030, reward_bound=0.014, batch=225\n",
      "311: loss=1.099, reward_mean=0.030, reward_bound=0.052, batch=227\n",
      "312: loss=1.098, reward_mean=0.030, reward_bound=0.122, batch=229\n",
      "313: loss=1.093, reward_mean=0.060, reward_bound=0.215, batch=230\n",
      "314: loss=1.097, reward_mean=0.090, reward_bound=0.229, batch=223\n",
      "315: loss=1.096, reward_mean=0.030, reward_bound=0.153, batch=226\n",
      "316: loss=1.103, reward_mean=0.040, reward_bound=0.254, batch=216\n",
      "317: loss=1.116, reward_mean=0.070, reward_bound=0.282, batch=214\n",
      "318: loss=1.112, reward_mean=0.080, reward_bound=0.247, batch=220\n",
      "319: loss=1.106, reward_mean=0.060, reward_bound=0.118, batch=224\n",
      "320: loss=1.105, reward_mean=0.020, reward_bound=0.000, batch=226\n",
      "321: loss=1.104, reward_mean=0.090, reward_bound=0.229, batch=227\n",
      "322: loss=1.103, reward_mean=0.050, reward_bound=0.198, batch=229\n",
      "323: loss=1.103, reward_mean=0.040, reward_bound=0.225, batch=230\n",
      "324: loss=1.104, reward_mean=0.130, reward_bound=0.274, batch=231\n",
      "325: loss=1.108, reward_mean=0.080, reward_bound=0.282, batch=229\n",
      "326: loss=1.102, reward_mean=0.070, reward_bound=0.314, batch=220\n",
      "327: loss=1.097, reward_mean=0.030, reward_bound=0.000, batch=223\n",
      "328: loss=1.099, reward_mean=0.070, reward_bound=0.322, batch=226\n",
      "329: loss=1.103, reward_mean=0.150, reward_bound=0.349, batch=212\n",
      "330: loss=1.101, reward_mean=0.040, reward_bound=0.000, batch=216\n",
      "331: loss=1.097, reward_mean=0.090, reward_bound=0.124, batch=221\n",
      "332: loss=1.100, reward_mean=0.070, reward_bound=0.185, batch=224\n",
      "333: loss=1.098, reward_mean=0.070, reward_bound=0.226, batch=227\n",
      "334: loss=1.094, reward_mean=0.130, reward_bound=0.277, batch=229\n",
      "335: loss=1.092, reward_mean=0.060, reward_bound=0.295, batch=230\n",
      "336: loss=1.092, reward_mean=0.040, reward_bound=0.288, batch=231\n",
      "337: loss=1.099, reward_mean=0.110, reward_bound=0.349, batch=228\n",
      "338: loss=1.095, reward_mean=0.100, reward_bound=0.387, batch=194\n",
      "339: loss=1.090, reward_mean=0.060, reward_bound=0.000, batch=200\n",
      "340: loss=1.084, reward_mean=0.080, reward_bound=0.000, batch=208\n",
      "341: loss=1.088, reward_mean=0.090, reward_bound=0.034, batch=215\n",
      "342: loss=1.095, reward_mean=0.060, reward_bound=0.068, batch=220\n",
      "343: loss=1.087, reward_mean=0.050, reward_bound=0.093, batch=224\n",
      "344: loss=1.086, reward_mean=0.040, reward_bound=0.131, batch=227\n",
      "345: loss=1.085, reward_mean=0.100, reward_bound=0.167, batch=228\n",
      "346: loss=1.086, reward_mean=0.050, reward_bound=0.185, batch=226\n",
      "347: loss=1.091, reward_mean=0.070, reward_bound=0.206, batch=227\n",
      "348: loss=1.087, reward_mean=0.070, reward_bound=0.229, batch=228\n",
      "349: loss=1.092, reward_mean=0.070, reward_bound=0.254, batch=225\n",
      "350: loss=1.093, reward_mean=0.060, reward_bound=0.282, batch=222\n",
      "351: loss=1.093, reward_mean=0.090, reward_bound=0.314, batch=222\n",
      "352: loss=1.097, reward_mean=0.090, reward_bound=0.349, batch=220\n",
      "353: loss=1.098, reward_mean=0.030, reward_bound=0.000, batch=223\n",
      "354: loss=1.100, reward_mean=0.060, reward_bound=0.271, batch=226\n",
      "355: loss=1.100, reward_mean=0.130, reward_bound=0.331, batch=228\n",
      "356: loss=1.101, reward_mean=0.130, reward_bound=0.349, batch=228\n",
      "357: loss=1.100, reward_mean=0.080, reward_bound=0.387, batch=216\n",
      "358: loss=1.100, reward_mean=0.060, reward_bound=0.061, batch=221\n",
      "359: loss=1.103, reward_mean=0.050, reward_bound=0.038, batch=224\n",
      "360: loss=1.102, reward_mean=0.060, reward_bound=0.204, batch=227\n",
      "361: loss=1.103, reward_mean=0.120, reward_bound=0.254, batch=228\n",
      "362: loss=1.102, reward_mean=0.030, reward_bound=0.282, batch=228\n",
      "363: loss=1.099, reward_mean=0.070, reward_bound=0.317, batch=229\n",
      "364: loss=1.098, reward_mean=0.070, reward_bound=0.349, batch=227\n",
      "365: loss=1.098, reward_mean=0.090, reward_bound=0.314, batch=228\n",
      "366: loss=1.099, reward_mean=0.050, reward_bound=0.387, batch=228\n",
      "367: loss=1.100, reward_mean=0.080, reward_bound=0.430, batch=192\n",
      "368: loss=1.102, reward_mean=0.070, reward_bound=0.000, batch=199\n",
      "369: loss=1.101, reward_mean=0.110, reward_bound=0.087, batch=209\n",
      "370: loss=1.101, reward_mean=0.070, reward_bound=0.014, batch=216\n",
      "371: loss=1.100, reward_mean=0.060, reward_bound=0.038, batch=221\n",
      "372: loss=1.098, reward_mean=0.050, reward_bound=0.042, batch=224\n",
      "373: loss=1.099, reward_mean=0.090, reward_bound=0.135, batch=225\n",
      "374: loss=1.096, reward_mean=0.070, reward_bound=0.185, batch=226\n",
      "375: loss=1.097, reward_mean=0.050, reward_bound=0.186, batch=228\n",
      "376: loss=1.098, reward_mean=0.070, reward_bound=0.229, batch=223\n",
      "377: loss=1.097, reward_mean=0.120, reward_bound=0.254, batch=225\n",
      "378: loss=1.097, reward_mean=0.090, reward_bound=0.282, batch=225\n",
      "379: loss=1.095, reward_mean=0.050, reward_bound=0.246, batch=227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380: loss=1.093, reward_mean=0.070, reward_bound=0.308, batch=229\n",
      "381: loss=1.104, reward_mean=0.060, reward_bound=0.314, batch=225\n",
      "382: loss=1.103, reward_mean=0.090, reward_bound=0.314, batch=226\n",
      "383: loss=1.105, reward_mean=0.040, reward_bound=0.229, batch=228\n",
      "384: loss=1.102, reward_mean=0.040, reward_bound=0.349, batch=222\n",
      "385: loss=1.101, reward_mean=0.060, reward_bound=0.238, batch=225\n",
      "386: loss=1.102, reward_mean=0.040, reward_bound=0.289, batch=227\n",
      "387: loss=1.099, reward_mean=0.050, reward_bound=0.284, batch=229\n",
      "388: loss=1.100, reward_mean=0.050, reward_bound=0.328, batch=230\n",
      "389: loss=1.099, reward_mean=0.060, reward_bound=0.376, batch=231\n",
      "390: loss=1.097, reward_mean=0.060, reward_bound=0.387, batch=222\n",
      "391: loss=1.098, reward_mean=0.080, reward_bound=0.324, batch=225\n",
      "392: loss=1.097, reward_mean=0.070, reward_bound=0.387, batch=225\n",
      "393: loss=1.096, reward_mean=0.050, reward_bound=0.289, batch=227\n",
      "394: loss=1.094, reward_mean=0.060, reward_bound=0.342, batch=229\n",
      "395: loss=1.093, reward_mean=0.100, reward_bound=0.387, batch=229\n",
      "396: loss=1.092, reward_mean=0.030, reward_bound=0.360, batch=230\n",
      "397: loss=1.093, reward_mean=0.040, reward_bound=0.222, batch=231\n",
      "398: loss=1.097, reward_mean=0.090, reward_bound=0.430, batch=213\n",
      "399: loss=1.096, reward_mean=0.060, reward_bound=0.124, batch=219\n",
      "400: loss=1.095, reward_mean=0.070, reward_bound=0.215, batch=223\n",
      "401: loss=1.093, reward_mean=0.070, reward_bound=0.211, batch=226\n",
      "402: loss=1.093, reward_mean=0.070, reward_bound=0.254, batch=226\n",
      "403: loss=1.093, reward_mean=0.050, reward_bound=0.282, batch=226\n",
      "404: loss=1.092, reward_mean=0.070, reward_bound=0.314, batch=226\n",
      "405: loss=1.093, reward_mean=0.100, reward_bound=0.277, batch=228\n",
      "406: loss=1.095, reward_mean=0.100, reward_bound=0.349, batch=228\n",
      "407: loss=1.096, reward_mean=0.120, reward_bound=0.430, batch=227\n",
      "408: loss=1.096, reward_mean=0.100, reward_bound=0.387, batch=227\n",
      "409: loss=1.093, reward_mean=0.100, reward_bound=0.422, batch=229\n",
      "410: loss=1.094, reward_mean=0.090, reward_bound=0.405, batch=230\n",
      "411: loss=1.093, reward_mean=0.040, reward_bound=0.378, batch=231\n",
      "412: loss=1.093, reward_mean=0.020, reward_bound=0.229, batch=231\n",
      "413: loss=1.095, reward_mean=0.100, reward_bound=0.430, batch=229\n",
      "414: loss=1.095, reward_mean=0.030, reward_bound=0.424, batch=230\n",
      "415: loss=1.093, reward_mean=0.040, reward_bound=0.356, batch=231\n",
      "416: loss=1.093, reward_mean=0.060, reward_bound=0.314, batch=231\n",
      "417: loss=1.095, reward_mean=0.150, reward_bound=0.430, batch=231\n",
      "418: loss=1.095, reward_mean=0.080, reward_bound=0.430, batch=231\n",
      "419: loss=1.092, reward_mean=0.070, reward_bound=0.478, batch=100\n",
      "420: loss=1.096, reward_mean=0.080, reward_bound=0.000, batch=108\n",
      "421: loss=1.087, reward_mean=0.080, reward_bound=0.000, batch=116\n",
      "422: loss=1.089, reward_mean=0.070, reward_bound=0.000, batch=123\n",
      "423: loss=1.085, reward_mean=0.080, reward_bound=0.000, batch=131\n",
      "424: loss=1.091, reward_mean=0.120, reward_bound=0.000, batch=143\n",
      "425: loss=1.088, reward_mean=0.060, reward_bound=0.000, batch=149\n",
      "426: loss=1.081, reward_mean=0.070, reward_bound=0.000, batch=156\n",
      "427: loss=1.082, reward_mean=0.040, reward_bound=0.000, batch=160\n",
      "428: loss=1.080, reward_mean=0.110, reward_bound=0.000, batch=171\n",
      "429: loss=1.077, reward_mean=0.070, reward_bound=0.000, batch=178\n",
      "430: loss=1.071, reward_mean=0.040, reward_bound=0.000, batch=182\n",
      "431: loss=1.074, reward_mean=0.050, reward_bound=0.000, batch=187\n",
      "432: loss=1.071, reward_mean=0.060, reward_bound=0.000, batch=193\n",
      "433: loss=1.073, reward_mean=0.100, reward_bound=0.000, batch=203\n",
      "434: loss=1.074, reward_mean=0.060, reward_bound=0.000, batch=209\n",
      "435: loss=1.073, reward_mean=0.040, reward_bound=0.000, batch=213\n",
      "436: loss=1.074, reward_mean=0.060, reward_bound=0.025, batch=219\n",
      "437: loss=1.072, reward_mean=0.040, reward_bound=0.002, batch=223\n",
      "438: loss=1.076, reward_mean=0.080, reward_bound=0.072, batch=222\n",
      "439: loss=1.074, reward_mean=0.020, reward_bound=0.000, batch=224\n",
      "440: loss=1.079, reward_mean=0.060, reward_bound=0.097, batch=227\n",
      "441: loss=1.085, reward_mean=0.110, reward_bound=0.135, batch=225\n",
      "442: loss=1.084, reward_mean=0.090, reward_bound=0.167, batch=223\n",
      "443: loss=1.085, reward_mean=0.100, reward_bound=0.198, batch=226\n",
      "444: loss=1.083, reward_mean=0.060, reward_bound=0.186, batch=228\n",
      "445: loss=1.079, reward_mean=0.100, reward_bound=0.208, batch=229\n",
      "446: loss=1.083, reward_mean=0.040, reward_bound=0.229, batch=223\n",
      "447: loss=1.081, reward_mean=0.090, reward_bound=0.254, batch=215\n",
      "448: loss=1.079, reward_mean=0.070, reward_bound=0.240, batch=220\n",
      "449: loss=1.078, reward_mean=0.060, reward_bound=0.174, batch=224\n",
      "450: loss=1.079, reward_mean=0.050, reward_bound=0.277, batch=227\n",
      "451: loss=1.086, reward_mean=0.060, reward_bound=0.282, batch=209\n",
      "452: loss=1.079, reward_mean=0.070, reward_bound=0.023, batch=216\n",
      "453: loss=1.081, reward_mean=0.030, reward_bound=0.000, batch=219\n",
      "454: loss=1.075, reward_mean=0.030, reward_bound=0.000, batch=222\n",
      "455: loss=1.081, reward_mean=0.110, reward_bound=0.236, batch=225\n",
      "456: loss=1.080, reward_mean=0.060, reward_bound=0.282, batch=226\n",
      "457: loss=1.084, reward_mean=0.080, reward_bound=0.314, batch=210\n",
      "458: loss=1.080, reward_mean=0.030, reward_bound=0.000, batch=213\n",
      "459: loss=1.081, reward_mean=0.110, reward_bound=0.171, batch=219\n",
      "460: loss=1.081, reward_mean=0.060, reward_bound=0.164, batch=223\n",
      "461: loss=1.080, reward_mean=0.090, reward_bound=0.235, batch=226\n",
      "462: loss=1.078, reward_mean=0.120, reward_bound=0.298, batch=228\n",
      "463: loss=1.076, reward_mean=0.060, reward_bound=0.349, batch=208\n",
      "464: loss=1.075, reward_mean=0.110, reward_bound=0.257, batch=215\n",
      "465: loss=1.073, reward_mean=0.060, reward_bound=0.032, batch=220\n",
      "466: loss=1.071, reward_mean=0.090, reward_bound=0.259, batch=224\n",
      "467: loss=1.072, reward_mean=0.070, reward_bound=0.282, batch=225\n",
      "468: loss=1.071, reward_mean=0.060, reward_bound=0.289, batch=227\n",
      "469: loss=1.071, reward_mean=0.110, reward_bound=0.314, batch=226\n",
      "470: loss=1.072, reward_mean=0.070, reward_bound=0.301, batch=228\n",
      "471: loss=1.072, reward_mean=0.100, reward_bound=0.349, batch=223\n",
      "472: loss=1.072, reward_mean=0.100, reward_bound=0.345, batch=226\n",
      "473: loss=1.072, reward_mean=0.070, reward_bound=0.351, batch=228\n",
      "474: loss=1.071, reward_mean=0.090, reward_bound=0.387, batch=197\n",
      "475: loss=1.071, reward_mean=0.020, reward_bound=0.000, batch=199\n",
      "476: loss=1.066, reward_mean=0.080, reward_bound=0.000, batch=207\n",
      "477: loss=1.063, reward_mean=0.060, reward_bound=0.000, batch=213\n",
      "478: loss=1.065, reward_mean=0.080, reward_bound=0.091, batch=219\n",
      "479: loss=1.066, reward_mean=0.060, reward_bound=0.103, batch=223\n",
      "480: loss=1.070, reward_mean=0.090, reward_bound=0.178, batch=226\n",
      "481: loss=1.067, reward_mean=0.030, reward_bound=0.107, batch=228\n",
      "482: loss=1.065, reward_mean=0.090, reward_bound=0.206, batch=227\n",
      "483: loss=1.065, reward_mean=0.030, reward_bound=0.213, batch=229\n",
      "484: loss=1.066, reward_mean=0.070, reward_bound=0.254, batch=225\n",
      "485: loss=1.070, reward_mean=0.050, reward_bound=0.289, batch=227\n",
      "486: loss=1.069, reward_mean=0.040, reward_bound=0.308, batch=229\n",
      "487: loss=1.072, reward_mean=0.100, reward_bound=0.314, batch=228\n",
      "488: loss=1.072, reward_mean=0.050, reward_bound=0.282, batch=228\n",
      "489: loss=1.073, reward_mean=0.050, reward_bound=0.349, batch=225\n",
      "490: loss=1.071, reward_mean=0.070, reward_bound=0.329, batch=227\n",
      "491: loss=1.071, reward_mean=0.060, reward_bound=0.330, batch=229\n",
      "492: loss=1.070, reward_mean=0.050, reward_bound=0.349, batch=229\n",
      "493: loss=1.068, reward_mean=0.060, reward_bound=0.387, batch=216\n",
      "494: loss=1.067, reward_mean=0.050, reward_bound=0.055, batch=221\n",
      "495: loss=1.065, reward_mean=0.070, reward_bound=0.282, batch=221\n",
      "496: loss=1.066, reward_mean=0.120, reward_bound=0.387, batch=222\n",
      "497: loss=1.067, reward_mean=0.060, reward_bound=0.360, batch=225\n",
      "498: loss=1.067, reward_mean=0.050, reward_bound=0.266, batch=227\n",
      "499: loss=1.065, reward_mean=0.100, reward_bound=0.342, batch=229\n",
      "500: loss=1.067, reward_mean=0.070, reward_bound=0.349, batch=228\n",
      "501: loss=1.065, reward_mean=0.060, reward_bound=0.387, batch=228\n",
      "502: loss=1.064, reward_mean=0.070, reward_bound=0.392, batch=229\n",
      "503: loss=1.064, reward_mean=0.050, reward_bound=0.328, batch=230\n",
      "504: loss=1.065, reward_mean=0.080, reward_bound=0.406, batch=231\n",
      "505: loss=1.074, reward_mean=0.110, reward_bound=0.430, batch=170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506: loss=1.067, reward_mean=0.110, reward_bound=0.000, batch=181\n",
      "507: loss=1.058, reward_mean=0.170, reward_bound=0.052, batch=195\n",
      "508: loss=1.052, reward_mean=0.110, reward_bound=0.007, batch=206\n",
      "509: loss=1.056, reward_mean=0.130, reward_bound=0.098, batch=213\n",
      "510: loss=1.055, reward_mean=0.070, reward_bound=0.091, batch=219\n",
      "511: loss=1.055, reward_mean=0.050, reward_bound=0.120, batch=223\n",
      "512: loss=1.055, reward_mean=0.130, reward_bound=0.167, batch=225\n",
      "513: loss=1.059, reward_mean=0.110, reward_bound=0.206, batch=225\n",
      "514: loss=1.055, reward_mean=0.090, reward_bound=0.234, batch=227\n",
      "515: loss=1.056, reward_mean=0.050, reward_bound=0.205, batch=229\n",
      "516: loss=1.059, reward_mean=0.120, reward_bound=0.282, batch=225\n",
      "517: loss=1.061, reward_mean=0.100, reward_bound=0.314, batch=219\n",
      "518: loss=1.059, reward_mean=0.060, reward_bound=0.328, batch=223\n",
      "519: loss=1.063, reward_mean=0.060, reward_bound=0.349, batch=218\n",
      "520: loss=1.061, reward_mean=0.070, reward_bound=0.234, batch=222\n",
      "521: loss=1.058, reward_mean=0.030, reward_bound=0.045, batch=225\n",
      "522: loss=1.063, reward_mean=0.030, reward_bound=0.094, batch=227\n",
      "523: loss=1.063, reward_mean=0.070, reward_bound=0.202, batch=229\n",
      "524: loss=1.063, reward_mean=0.040, reward_bound=0.125, batch=230\n",
      "525: loss=1.057, reward_mean=0.060, reward_bound=0.274, batch=231\n",
      "526: loss=1.056, reward_mean=0.080, reward_bound=0.282, batch=231\n",
      "527: loss=1.056, reward_mean=0.040, reward_bound=0.314, batch=230\n",
      "528: loss=1.057, reward_mean=0.100, reward_bound=0.376, batch=231\n",
      "529: loss=1.057, reward_mean=0.040, reward_bound=0.349, batch=231\n",
      "530: loss=1.053, reward_mean=0.090, reward_bound=0.387, batch=218\n",
      "531: loss=1.051, reward_mean=0.060, reward_bound=0.150, batch=221\n",
      "532: loss=1.050, reward_mean=0.050, reward_bound=0.282, batch=224\n",
      "533: loss=1.052, reward_mean=0.070, reward_bound=0.349, batch=225\n",
      "534: loss=1.059, reward_mean=0.050, reward_bound=0.430, batch=202\n",
      "535: loss=1.058, reward_mean=0.100, reward_bound=0.126, batch=211\n",
      "536: loss=1.055, reward_mean=0.060, reward_bound=0.000, batch=217\n",
      "537: loss=1.054, reward_mean=0.080, reward_bound=0.122, batch=221\n",
      "538: loss=1.055, reward_mean=0.110, reward_bound=0.229, batch=223\n",
      "539: loss=1.053, reward_mean=0.050, reward_bound=0.125, batch=226\n",
      "540: loss=1.053, reward_mean=0.040, reward_bound=0.220, batch=228\n",
      "541: loss=1.052, reward_mean=0.130, reward_bound=0.257, batch=229\n",
      "542: loss=1.055, reward_mean=0.040, reward_bound=0.282, batch=227\n",
      "543: loss=1.053, reward_mean=0.080, reward_bound=0.314, batch=228\n",
      "544: loss=1.053, reward_mean=0.060, reward_bound=0.349, batch=226\n",
      "545: loss=1.052, reward_mean=0.070, reward_bound=0.301, batch=228\n",
      "546: loss=1.052, reward_mean=0.100, reward_bound=0.289, batch=229\n",
      "547: loss=1.051, reward_mean=0.090, reward_bound=0.364, batch=230\n",
      "548: loss=1.054, reward_mean=0.090, reward_bound=0.387, batch=224\n",
      "549: loss=1.051, reward_mean=0.080, reward_bound=0.369, batch=227\n",
      "550: loss=1.050, reward_mean=0.070, reward_bound=0.302, batch=229\n",
      "551: loss=1.050, reward_mean=0.030, reward_bound=0.133, batch=230\n",
      "552: loss=1.049, reward_mean=0.080, reward_bound=0.365, batch=231\n",
      "553: loss=1.050, reward_mean=0.090, reward_bound=0.387, batch=229\n",
      "554: loss=1.049, reward_mean=0.080, reward_bound=0.343, batch=230\n",
      "555: loss=1.051, reward_mean=0.070, reward_bound=0.430, batch=219\n",
      "556: loss=1.047, reward_mean=0.060, reward_bound=0.182, batch=223\n",
      "557: loss=1.047, reward_mean=0.050, reward_bound=0.244, batch=226\n",
      "558: loss=1.048, reward_mean=0.080, reward_bound=0.298, batch=228\n",
      "559: loss=1.048, reward_mean=0.040, reward_bound=0.314, batch=228\n",
      "560: loss=1.049, reward_mean=0.070, reward_bound=0.349, batch=227\n",
      "561: loss=1.050, reward_mean=0.070, reward_bound=0.387, batch=226\n",
      "562: loss=1.051, reward_mean=0.070, reward_bound=0.356, batch=228\n",
      "563: loss=1.050, reward_mean=0.090, reward_bound=0.430, batch=226\n",
      "564: loss=1.050, reward_mean=0.040, reward_bound=0.298, batch=228\n",
      "565: loss=1.051, reward_mean=0.060, reward_bound=0.237, batch=229\n",
      "566: loss=1.050, reward_mean=0.080, reward_bound=0.314, batch=229\n",
      "567: loss=1.050, reward_mean=0.060, reward_bound=0.328, batch=230\n",
      "568: loss=1.050, reward_mean=0.040, reward_bound=0.253, batch=231\n",
      "569: loss=1.051, reward_mean=0.080, reward_bound=0.314, batch=231\n",
      "570: loss=1.054, reward_mean=0.060, reward_bound=0.349, batch=230\n",
      "571: loss=1.050, reward_mean=0.100, reward_bound=0.387, batch=230\n",
      "572: loss=1.049, reward_mean=0.040, reward_bound=0.430, batch=228\n",
      "573: loss=1.048, reward_mean=0.080, reward_bound=0.435, batch=229\n",
      "574: loss=1.047, reward_mean=0.040, reward_bound=0.342, batch=230\n",
      "575: loss=1.047, reward_mean=0.040, reward_bound=0.387, batch=230\n",
      "576: loss=1.045, reward_mean=0.030, reward_bound=0.304, batch=231\n",
      "577: loss=1.049, reward_mean=0.040, reward_bound=0.430, batch=231\n",
      "578: loss=1.049, reward_mean=0.110, reward_bound=0.387, batch=231\n",
      "579: loss=1.049, reward_mean=0.070, reward_bound=0.478, batch=157\n",
      "580: loss=1.051, reward_mean=0.050, reward_bound=0.000, batch=162\n",
      "581: loss=1.040, reward_mean=0.070, reward_bound=0.000, batch=169\n",
      "582: loss=1.041, reward_mean=0.060, reward_bound=0.000, batch=175\n",
      "583: loss=1.036, reward_mean=0.080, reward_bound=0.000, batch=183\n",
      "584: loss=1.031, reward_mean=0.080, reward_bound=0.000, batch=191\n",
      "585: loss=1.030, reward_mean=0.020, reward_bound=0.000, batch=193\n",
      "586: loss=1.033, reward_mean=0.080, reward_bound=0.000, batch=201\n",
      "587: loss=1.033, reward_mean=0.100, reward_bound=0.089, batch=210\n",
      "588: loss=1.031, reward_mean=0.070, reward_bound=0.069, batch=217\n",
      "589: loss=1.032, reward_mean=0.060, reward_bound=0.084, batch=222\n",
      "590: loss=1.032, reward_mean=0.050, reward_bound=0.077, batch=225\n",
      "591: loss=1.031, reward_mean=0.020, reward_bound=0.018, batch=227\n",
      "592: loss=1.030, reward_mean=0.010, reward_bound=0.000, batch=228\n",
      "593: loss=1.030, reward_mean=0.010, reward_bound=0.009, batch=229\n",
      "594: loss=1.040, reward_mean=0.080, reward_bound=0.135, batch=228\n",
      "595: loss=1.034, reward_mean=0.060, reward_bound=0.169, batch=229\n",
      "596: loss=1.039, reward_mean=0.060, reward_bound=0.194, batch=230\n",
      "597: loss=1.039, reward_mean=0.040, reward_bound=0.206, batch=233\n",
      "598: loss=1.033, reward_mean=0.050, reward_bound=0.206, batch=232\n",
      "599: loss=1.036, reward_mean=0.080, reward_bound=0.229, batch=229\n",
      "600: loss=1.030, reward_mean=0.080, reward_bound=0.254, batch=223\n",
      "601: loss=1.031, reward_mean=0.050, reward_bound=0.236, batch=226\n",
      "602: loss=1.035, reward_mean=0.050, reward_bound=0.282, batch=220\n",
      "603: loss=1.035, reward_mean=0.060, reward_bound=0.266, batch=224\n",
      "604: loss=1.031, reward_mean=0.040, reward_bound=0.127, batch=227\n",
      "605: loss=1.033, reward_mean=0.110, reward_bound=0.277, batch=229\n",
      "606: loss=1.031, reward_mean=0.100, reward_bound=0.314, batch=218\n",
      "607: loss=1.029, reward_mean=0.060, reward_bound=0.195, batch=222\n",
      "608: loss=1.025, reward_mean=0.070, reward_bound=0.213, batch=225\n",
      "609: loss=1.029, reward_mean=0.070, reward_bound=0.296, batch=227\n",
      "610: loss=1.030, reward_mean=0.070, reward_bound=0.330, batch=229\n",
      "611: loss=1.035, reward_mean=0.070, reward_bound=0.349, batch=217\n",
      "612: loss=1.040, reward_mean=0.090, reward_bound=0.224, batch=222\n",
      "613: loss=1.033, reward_mean=0.050, reward_bound=0.245, batch=225\n",
      "614: loss=1.033, reward_mean=0.050, reward_bound=0.289, batch=227\n",
      "615: loss=1.034, reward_mean=0.070, reward_bound=0.314, batch=226\n",
      "616: loss=1.039, reward_mean=0.090, reward_bound=0.387, batch=207\n",
      "617: loss=1.040, reward_mean=0.050, reward_bound=0.000, batch=212\n",
      "618: loss=1.035, reward_mean=0.100, reward_bound=0.122, batch=218\n",
      "619: loss=1.031, reward_mean=0.060, reward_bound=0.156, batch=222\n",
      "620: loss=1.033, reward_mean=0.070, reward_bound=0.122, batch=225\n",
      "621: loss=1.032, reward_mean=0.050, reward_bound=0.161, batch=227\n",
      "622: loss=1.033, reward_mean=0.080, reward_bound=0.314, batch=228\n",
      "623: loss=1.033, reward_mean=0.050, reward_bound=0.231, batch=229\n",
      "624: loss=1.036, reward_mean=0.120, reward_bound=0.364, batch=230\n",
      "625: loss=1.039, reward_mean=0.060, reward_bound=0.387, batch=223\n",
      "626: loss=1.038, reward_mean=0.050, reward_bound=0.345, batch=226\n",
      "627: loss=1.038, reward_mean=0.040, reward_bound=0.387, batch=225\n",
      "628: loss=1.037, reward_mean=0.100, reward_bound=0.365, batch=227\n",
      "629: loss=1.034, reward_mean=0.080, reward_bound=0.430, batch=206\n",
      "630: loss=1.037, reward_mean=0.060, reward_bound=0.000, batch=212\n",
      "631: loss=1.037, reward_mean=0.100, reward_bound=0.263, batch=218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632: loss=1.034, reward_mean=0.080, reward_bound=0.282, batch=220\n",
      "633: loss=1.033, reward_mean=0.070, reward_bound=0.254, batch=223\n",
      "634: loss=1.033, reward_mean=0.100, reward_bound=0.335, batch=226\n",
      "635: loss=1.034, reward_mean=0.050, reward_bound=0.331, batch=228\n",
      "636: loss=1.034, reward_mean=0.040, reward_bound=0.282, batch=228\n",
      "637: loss=1.038, reward_mean=0.080, reward_bound=0.353, batch=229\n",
      "638: loss=1.037, reward_mean=0.070, reward_bound=0.343, batch=230\n",
      "639: loss=1.036, reward_mean=0.060, reward_bound=0.387, batch=225\n",
      "640: loss=1.032, reward_mean=0.070, reward_bound=0.289, batch=227\n",
      "641: loss=1.034, reward_mean=0.080, reward_bound=0.342, batch=229\n",
      "642: loss=1.035, reward_mean=0.040, reward_bound=0.250, batch=230\n",
      "643: loss=1.033, reward_mean=0.040, reward_bound=0.329, batch=231\n",
      "644: loss=1.035, reward_mean=0.020, reward_bound=0.349, batch=230\n",
      "645: loss=1.035, reward_mean=0.050, reward_bound=0.356, batch=231\n",
      "646: loss=1.035, reward_mean=0.070, reward_bound=0.387, batch=231\n",
      "647: loss=1.031, reward_mean=0.060, reward_bound=0.430, batch=223\n",
      "648: loss=1.032, reward_mean=0.050, reward_bound=0.154, batch=226\n",
      "649: loss=1.028, reward_mean=0.050, reward_bound=0.282, batch=226\n",
      "650: loss=1.029, reward_mean=0.110, reward_bound=0.368, batch=228\n",
      "651: loss=1.028, reward_mean=0.080, reward_bound=0.387, batch=228\n",
      "652: loss=1.028, reward_mean=0.060, reward_bound=0.435, batch=229\n",
      "653: loss=1.029, reward_mean=0.040, reward_bound=0.380, batch=230\n",
      "654: loss=1.028, reward_mean=0.060, reward_bound=0.439, batch=231\n",
      "655: loss=1.039, reward_mean=0.050, reward_bound=0.478, batch=187\n",
      "656: loss=1.037, reward_mean=0.060, reward_bound=0.000, batch=193\n",
      "657: loss=1.031, reward_mean=0.120, reward_bound=0.053, batch=205\n",
      "658: loss=1.028, reward_mean=0.070, reward_bound=0.000, batch=212\n",
      "659: loss=1.027, reward_mean=0.070, reward_bound=0.067, batch=218\n",
      "660: loss=1.020, reward_mean=0.070, reward_bound=0.111, batch=222\n",
      "661: loss=1.023, reward_mean=0.050, reward_bound=0.155, batch=225\n",
      "662: loss=1.019, reward_mean=0.100, reward_bound=0.210, batch=227\n",
      "663: loss=1.020, reward_mean=0.100, reward_bound=0.249, batch=229\n",
      "664: loss=1.024, reward_mean=0.060, reward_bound=0.254, batch=226\n",
      "665: loss=1.024, reward_mean=0.090, reward_bound=0.282, batch=224\n",
      "666: loss=1.021, reward_mean=0.110, reward_bound=0.311, batch=227\n",
      "667: loss=1.021, reward_mean=0.070, reward_bound=0.314, batch=225\n",
      "668: loss=1.022, reward_mean=0.040, reward_bound=0.321, batch=227\n",
      "669: loss=1.025, reward_mean=0.090, reward_bound=0.349, batch=221\n",
      "670: loss=1.025, reward_mean=0.070, reward_bound=0.349, batch=223\n",
      "671: loss=1.025, reward_mean=0.050, reward_bound=0.151, batch=226\n",
      "672: loss=1.022, reward_mean=0.050, reward_bound=0.254, batch=227\n",
      "673: loss=1.023, reward_mean=0.030, reward_bound=0.246, batch=229\n",
      "674: loss=1.022, reward_mean=0.050, reward_bound=0.364, batch=230\n",
      "675: loss=1.031, reward_mean=0.090, reward_bound=0.387, batch=217\n",
      "676: loss=1.030, reward_mean=0.080, reward_bound=0.173, batch=222\n",
      "677: loss=1.029, reward_mean=0.070, reward_bound=0.220, batch=225\n",
      "678: loss=1.028, reward_mean=0.030, reward_bound=0.171, batch=227\n",
      "679: loss=1.030, reward_mean=0.070, reward_bound=0.254, batch=228\n",
      "680: loss=1.031, reward_mean=0.070, reward_bound=0.282, batch=228\n",
      "681: loss=1.029, reward_mean=0.040, reward_bound=0.353, batch=229\n",
      "682: loss=1.031, reward_mean=0.100, reward_bound=0.387, batch=228\n",
      "683: loss=1.030, reward_mean=0.040, reward_bound=0.392, batch=229\n",
      "684: loss=1.029, reward_mean=0.030, reward_bound=0.381, batch=230\n",
      "685: loss=1.028, reward_mean=0.070, reward_bound=0.376, batch=231\n",
      "686: loss=1.029, reward_mean=0.070, reward_bound=0.387, batch=231\n",
      "687: loss=1.034, reward_mean=0.110, reward_bound=0.430, batch=216\n",
      "688: loss=1.033, reward_mean=0.090, reward_bound=0.298, batch=221\n",
      "689: loss=1.035, reward_mean=0.080, reward_bound=0.314, batch=224\n",
      "690: loss=1.034, reward_mean=0.050, reward_bound=0.204, batch=227\n",
      "691: loss=1.035, reward_mean=0.110, reward_bound=0.314, batch=228\n",
      "692: loss=1.036, reward_mean=0.050, reward_bound=0.317, batch=229\n",
      "693: loss=1.033, reward_mean=0.100, reward_bound=0.349, batch=229\n",
      "694: loss=1.033, reward_mean=0.040, reward_bound=0.292, batch=230\n",
      "695: loss=1.032, reward_mean=0.040, reward_bound=0.174, batch=231\n",
      "696: loss=1.033, reward_mean=0.050, reward_bound=0.349, batch=231\n",
      "697: loss=1.031, reward_mean=0.080, reward_bound=0.387, batch=229\n",
      "698: loss=1.031, reward_mean=0.060, reward_bound=0.360, batch=230\n",
      "699: loss=1.030, reward_mean=0.080, reward_bound=0.430, batch=226\n",
      "700: loss=1.032, reward_mean=0.090, reward_bound=0.368, batch=228\n",
      "701: loss=1.032, reward_mean=0.040, reward_bound=0.353, batch=229\n",
      "702: loss=1.032, reward_mean=0.050, reward_bound=0.364, batch=230\n",
      "703: loss=1.029, reward_mean=0.090, reward_bound=0.387, batch=229\n",
      "704: loss=1.029, reward_mean=0.070, reward_bound=0.405, batch=230\n",
      "705: loss=1.028, reward_mean=0.050, reward_bound=0.304, batch=231\n",
      "706: loss=1.030, reward_mean=0.060, reward_bound=0.349, batch=231\n",
      "707: loss=1.030, reward_mean=0.040, reward_bound=0.282, batch=231\n",
      "708: loss=1.030, reward_mean=0.060, reward_bound=0.430, batch=230\n",
      "709: loss=1.032, reward_mean=0.090, reward_bound=0.478, batch=204\n",
      "710: loss=1.040, reward_mean=0.080, reward_bound=0.000, batch=212\n",
      "711: loss=1.036, reward_mean=0.040, reward_bound=0.000, batch=216\n",
      "712: loss=1.030, reward_mean=0.070, reward_bound=0.170, batch=221\n",
      "713: loss=1.030, reward_mean=0.060, reward_bound=0.229, batch=222\n",
      "714: loss=1.026, reward_mean=0.100, reward_bound=0.314, batch=223\n",
      "715: loss=1.025, reward_mean=0.070, reward_bound=0.335, batch=226\n",
      "716: loss=1.025, reward_mean=0.040, reward_bound=0.284, batch=228\n",
      "717: loss=1.025, reward_mean=0.040, reward_bound=0.192, batch=229\n",
      "718: loss=1.028, reward_mean=0.050, reward_bound=0.328, batch=230\n",
      "719: loss=1.030, reward_mean=0.050, reward_bound=0.349, batch=228\n",
      "720: loss=1.032, reward_mean=0.130, reward_bound=0.387, batch=223\n",
      "721: loss=1.032, reward_mean=0.050, reward_bound=0.244, batch=226\n",
      "722: loss=1.032, reward_mean=0.090, reward_bound=0.390, batch=228\n",
      "723: loss=1.030, reward_mean=0.060, reward_bound=0.430, batch=223\n",
      "724: loss=1.029, reward_mean=0.080, reward_bound=0.252, batch=226\n",
      "725: loss=1.028, reward_mean=0.020, reward_bound=0.014, batch=228\n",
      "726: loss=1.028, reward_mean=0.070, reward_bound=0.286, batch=229\n",
      "727: loss=1.026, reward_mean=0.050, reward_bound=0.343, batch=230\n",
      "728: loss=1.025, reward_mean=0.060, reward_bound=0.418, batch=231\n",
      "729: loss=1.028, reward_mean=0.060, reward_bound=0.430, batch=227\n",
      "730: loss=1.029, reward_mean=0.050, reward_bound=0.430, batch=228\n",
      "731: loss=1.028, reward_mean=0.080, reward_bound=0.317, batch=229\n",
      "732: loss=1.026, reward_mean=0.070, reward_bound=0.381, batch=230\n",
      "733: loss=1.027, reward_mean=0.040, reward_bound=0.365, batch=231\n",
      "734: loss=1.026, reward_mean=0.070, reward_bound=0.387, batch=230\n",
      "735: loss=1.026, reward_mean=0.040, reward_bound=0.346, batch=231\n",
      "736: loss=1.027, reward_mean=0.050, reward_bound=0.430, batch=231\n",
      "737: loss=1.027, reward_mean=0.050, reward_bound=0.387, batch=231\n",
      "738: loss=1.027, reward_mean=0.040, reward_bound=0.430, batch=231\n",
      "739: loss=1.027, reward_mean=0.070, reward_bound=0.430, batch=231\n",
      "740: loss=1.027, reward_mean=0.050, reward_bound=0.314, batch=231\n",
      "741: loss=1.027, reward_mean=0.100, reward_bound=0.430, batch=231\n",
      "742: loss=1.024, reward_mean=0.060, reward_bound=0.478, batch=215\n",
      "743: loss=1.022, reward_mean=0.090, reward_bound=0.289, batch=220\n",
      "744: loss=1.018, reward_mean=0.030, reward_bound=0.000, batch=223\n",
      "745: loss=1.024, reward_mean=0.100, reward_bound=0.220, batch=226\n",
      "746: loss=1.023, reward_mean=0.040, reward_bound=0.196, batch=228\n",
      "747: loss=1.025, reward_mean=0.030, reward_bound=0.206, batch=228\n",
      "748: loss=1.020, reward_mean=0.050, reward_bound=0.254, batch=225\n",
      "749: loss=1.024, reward_mean=0.090, reward_bound=0.314, batch=226\n",
      "750: loss=1.025, reward_mean=0.120, reward_bound=0.349, batch=225\n",
      "751: loss=1.027, reward_mean=0.080, reward_bound=0.329, batch=227\n",
      "752: loss=1.024, reward_mean=0.070, reward_bound=0.387, batch=223\n",
      "753: loss=1.026, reward_mean=0.050, reward_bound=0.178, batch=226\n",
      "754: loss=1.021, reward_mean=0.080, reward_bound=0.207, batch=228\n",
      "755: loss=1.020, reward_mean=0.060, reward_bound=0.234, batch=229\n",
      "756: loss=1.025, reward_mean=0.110, reward_bound=0.387, batch=227\n",
      "757: loss=1.024, reward_mean=0.060, reward_bound=0.430, batch=223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758: loss=1.023, reward_mean=0.060, reward_bound=0.192, batch=226\n",
      "759: loss=1.023, reward_mean=0.090, reward_bound=0.254, batch=227\n",
      "760: loss=1.024, reward_mean=0.060, reward_bound=0.342, batch=229\n",
      "761: loss=1.023, reward_mean=0.060, reward_bound=0.349, batch=228\n",
      "762: loss=1.021, reward_mean=0.040, reward_bound=0.286, batch=229\n",
      "763: loss=1.023, reward_mean=0.070, reward_bound=0.328, batch=230\n",
      "764: loss=1.020, reward_mean=0.120, reward_bound=0.376, batch=231\n",
      "765: loss=1.021, reward_mean=0.030, reward_bound=0.387, batch=230\n",
      "766: loss=1.021, reward_mean=0.050, reward_bound=0.418, batch=231\n",
      "767: loss=1.021, reward_mean=0.100, reward_bound=0.349, batch=231\n",
      "768: loss=1.022, reward_mean=0.090, reward_bound=0.430, batch=229\n",
      "769: loss=1.021, reward_mean=0.020, reward_bound=0.324, batch=230\n",
      "770: loss=1.022, reward_mean=0.090, reward_bound=0.387, batch=230\n",
      "771: loss=1.022, reward_mean=0.040, reward_bound=0.420, batch=231\n",
      "772: loss=1.019, reward_mean=0.110, reward_bound=0.478, batch=224\n",
      "773: loss=1.020, reward_mean=0.070, reward_bound=0.422, batch=227\n",
      "774: loss=1.020, reward_mean=0.100, reward_bound=0.430, batch=227\n",
      "775: loss=1.019, reward_mean=0.010, reward_bound=0.000, batch=228\n",
      "776: loss=1.018, reward_mean=0.060, reward_bound=0.349, batch=228\n",
      "777: loss=1.020, reward_mean=0.080, reward_bound=0.321, batch=229\n",
      "778: loss=1.020, reward_mean=0.050, reward_bound=0.387, batch=228\n",
      "779: loss=1.019, reward_mean=0.040, reward_bound=0.286, batch=229\n",
      "780: loss=1.021, reward_mean=0.060, reward_bound=0.405, batch=230\n",
      "781: loss=1.021, reward_mean=0.040, reward_bound=0.386, batch=231\n",
      "782: loss=1.021, reward_mean=0.030, reward_bound=0.387, batch=231\n",
      "783: loss=1.022, reward_mean=0.040, reward_bound=0.430, batch=231\n",
      "784: loss=1.021, reward_mean=0.020, reward_bound=0.314, batch=231\n",
      "785: loss=1.021, reward_mean=0.030, reward_bound=0.387, batch=231\n",
      "786: loss=1.021, reward_mean=0.020, reward_bound=0.478, batch=228\n",
      "787: loss=1.021, reward_mean=0.040, reward_bound=0.353, batch=229\n",
      "788: loss=1.021, reward_mean=0.060, reward_bound=0.349, batch=229\n",
      "789: loss=1.021, reward_mean=0.070, reward_bound=0.445, batch=230\n",
      "790: loss=1.021, reward_mean=0.070, reward_bound=0.478, batch=230\n",
      "791: loss=1.022, reward_mean=0.080, reward_bound=0.347, batch=231\n",
      "792: loss=1.021, reward_mean=0.080, reward_bound=0.430, batch=231\n",
      "793: loss=1.021, reward_mean=0.070, reward_bound=0.387, batch=231\n",
      "794: loss=1.022, reward_mean=0.070, reward_bound=0.478, batch=231\n",
      "795: loss=1.022, reward_mean=0.070, reward_bound=0.349, batch=231\n",
      "797: loss=1.029, reward_mean=0.050, reward_bound=0.000, batch=5\n",
      "798: loss=0.998, reward_mean=0.060, reward_bound=0.000, batch=11\n",
      "799: loss=1.009, reward_mean=0.060, reward_bound=0.000, batch=17\n",
      "800: loss=0.991, reward_mean=0.080, reward_bound=0.000, batch=25\n",
      "801: loss=0.971, reward_mean=0.060, reward_bound=0.000, batch=31\n",
      "802: loss=0.970, reward_mean=0.020, reward_bound=0.000, batch=33\n",
      "803: loss=0.972, reward_mean=0.060, reward_bound=0.000, batch=39\n",
      "804: loss=0.987, reward_mean=0.090, reward_bound=0.000, batch=48\n",
      "805: loss=0.980, reward_mean=0.060, reward_bound=0.000, batch=54\n",
      "806: loss=0.980, reward_mean=0.040, reward_bound=0.000, batch=58\n",
      "807: loss=0.975, reward_mean=0.060, reward_bound=0.000, batch=64\n",
      "808: loss=0.970, reward_mean=0.140, reward_bound=0.000, batch=78\n",
      "809: loss=0.969, reward_mean=0.100, reward_bound=0.000, batch=88\n",
      "810: loss=0.968, reward_mean=0.070, reward_bound=0.000, batch=95\n",
      "811: loss=0.959, reward_mean=0.130, reward_bound=0.000, batch=108\n",
      "812: loss=0.958, reward_mean=0.140, reward_bound=0.000, batch=122\n",
      "813: loss=0.954, reward_mean=0.090, reward_bound=0.000, batch=131\n",
      "814: loss=0.956, reward_mean=0.080, reward_bound=0.000, batch=139\n",
      "815: loss=0.956, reward_mean=0.070, reward_bound=0.000, batch=146\n",
      "816: loss=0.956, reward_mean=0.070, reward_bound=0.000, batch=153\n",
      "817: loss=0.956, reward_mean=0.130, reward_bound=0.000, batch=166\n",
      "818: loss=0.952, reward_mean=0.090, reward_bound=0.000, batch=175\n",
      "819: loss=0.947, reward_mean=0.160, reward_bound=0.000, batch=191\n",
      "820: loss=0.947, reward_mean=0.090, reward_bound=0.000, batch=200\n",
      "821: loss=0.947, reward_mean=0.120, reward_bound=0.012, batch=210\n",
      "822: loss=0.945, reward_mean=0.100, reward_bound=0.022, batch=217\n",
      "823: loss=0.953, reward_mean=0.100, reward_bound=0.042, batch=219\n",
      "824: loss=0.947, reward_mean=0.070, reward_bound=0.052, batch=221\n",
      "825: loss=0.948, reward_mean=0.110, reward_bound=0.065, batch=224\n",
      "826: loss=0.948, reward_mean=0.100, reward_bound=0.080, batch=225\n",
      "827: loss=0.942, reward_mean=0.150, reward_bound=0.109, batch=231\n",
      "828: loss=0.938, reward_mean=0.110, reward_bound=0.122, batch=225\n",
      "829: loss=0.938, reward_mean=0.110, reward_bound=0.135, batch=225\n",
      "830: loss=0.940, reward_mean=0.140, reward_bound=0.150, batch=225\n",
      "831: loss=0.937, reward_mean=0.110, reward_bound=0.167, batch=215\n",
      "832: loss=0.929, reward_mean=0.090, reward_bound=0.185, batch=208\n",
      "833: loss=0.931, reward_mean=0.120, reward_bound=0.156, batch=215\n",
      "834: loss=0.930, reward_mean=0.160, reward_bound=0.189, batch=220\n",
      "835: loss=0.931, reward_mean=0.110, reward_bound=0.206, batch=225\n",
      "836: loss=0.934, reward_mean=0.130, reward_bound=0.206, batch=211\n",
      "837: loss=0.932, reward_mean=0.070, reward_bound=0.080, batch=217\n",
      "838: loss=0.929, reward_mean=0.170, reward_bound=0.185, batch=220\n",
      "839: loss=0.924, reward_mean=0.180, reward_bound=0.229, batch=208\n",
      "840: loss=0.923, reward_mean=0.120, reward_bound=0.208, batch=215\n",
      "841: loss=0.921, reward_mean=0.130, reward_bound=0.206, batch=218\n",
      "842: loss=0.921, reward_mean=0.090, reward_bound=0.229, batch=219\n",
      "843: loss=0.922, reward_mean=0.100, reward_bound=0.239, batch=223\n",
      "844: loss=0.929, reward_mean=0.120, reward_bound=0.254, batch=212\n",
      "845: loss=0.927, reward_mean=0.100, reward_bound=0.078, batch=218\n",
      "846: loss=0.924, reward_mean=0.210, reward_bound=0.229, batch=220\n",
      "847: loss=0.932, reward_mean=0.130, reward_bound=0.282, batch=180\n",
      "848: loss=0.924, reward_mean=0.100, reward_bound=0.000, batch=190\n",
      "849: loss=0.919, reward_mean=0.090, reward_bound=0.000, batch=199\n",
      "850: loss=0.919, reward_mean=0.190, reward_bound=0.194, batch=209\n",
      "851: loss=0.913, reward_mean=0.150, reward_bound=0.182, batch=216\n",
      "852: loss=0.908, reward_mean=0.150, reward_bound=0.206, batch=220\n",
      "853: loss=0.906, reward_mean=0.110, reward_bound=0.222, batch=224\n",
      "854: loss=0.905, reward_mean=0.030, reward_bound=0.028, batch=227\n",
      "855: loss=0.904, reward_mean=0.100, reward_bound=0.224, batch=229\n",
      "856: loss=0.913, reward_mean=0.100, reward_bound=0.229, batch=229\n",
      "857: loss=0.912, reward_mean=0.070, reward_bound=0.225, batch=230\n",
      "858: loss=0.917, reward_mean=0.090, reward_bound=0.254, batch=229\n",
      "859: loss=0.918, reward_mean=0.100, reward_bound=0.282, batch=219\n",
      "860: loss=0.920, reward_mean=0.070, reward_bound=0.254, batch=222\n",
      "861: loss=0.921, reward_mean=0.090, reward_bound=0.213, batch=225\n",
      "862: loss=0.921, reward_mean=0.060, reward_bound=0.229, batch=226\n",
      "863: loss=0.931, reward_mean=0.160, reward_bound=0.314, batch=188\n",
      "864: loss=0.927, reward_mean=0.110, reward_bound=0.000, batch=199\n",
      "865: loss=0.925, reward_mean=0.140, reward_bound=0.092, batch=209\n",
      "866: loss=0.925, reward_mean=0.080, reward_bound=0.097, batch=216\n",
      "867: loss=0.921, reward_mean=0.110, reward_bound=0.115, batch=221\n",
      "868: loss=0.920, reward_mean=0.140, reward_bound=0.167, batch=223\n",
      "869: loss=0.918, reward_mean=0.120, reward_bound=0.185, batch=225\n",
      "870: loss=0.913, reward_mean=0.050, reward_bound=0.210, batch=227\n",
      "871: loss=0.916, reward_mean=0.110, reward_bound=0.282, batch=224\n",
      "872: loss=0.914, reward_mean=0.040, reward_bound=0.123, batch=227\n",
      "873: loss=0.916, reward_mean=0.060, reward_bound=0.220, batch=229\n",
      "874: loss=0.914, reward_mean=0.130, reward_bound=0.254, batch=229\n",
      "875: loss=0.917, reward_mean=0.100, reward_bound=0.314, batch=220\n",
      "876: loss=0.918, reward_mean=0.060, reward_bound=0.081, batch=224\n",
      "877: loss=0.918, reward_mean=0.110, reward_bound=0.254, batch=226\n",
      "878: loss=0.916, reward_mean=0.080, reward_bound=0.298, batch=228\n",
      "879: loss=0.933, reward_mean=0.140, reward_bound=0.349, batch=178\n",
      "880: loss=0.930, reward_mean=0.030, reward_bound=0.000, batch=181\n",
      "881: loss=0.943, reward_mean=0.170, reward_bound=0.089, batch=196\n",
      "882: loss=0.937, reward_mean=0.160, reward_bound=0.109, batch=206\n",
      "883: loss=0.936, reward_mean=0.090, reward_bound=0.065, batch=214\n",
      "884: loss=0.934, reward_mean=0.130, reward_bound=0.134, batch=220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "885: loss=0.927, reward_mean=0.130, reward_bound=0.180, batch=224\n",
      "886: loss=0.933, reward_mean=0.110, reward_bound=0.206, batch=221\n",
      "887: loss=0.940, reward_mean=0.170, reward_bound=0.254, batch=218\n",
      "888: loss=0.938, reward_mean=0.090, reward_bound=0.113, batch=222\n",
      "889: loss=0.933, reward_mean=0.120, reward_bound=0.263, batch=225\n",
      "890: loss=0.933, reward_mean=0.110, reward_bound=0.282, batch=222\n",
      "891: loss=0.931, reward_mean=0.090, reward_bound=0.272, batch=225\n",
      "892: loss=0.930, reward_mean=0.110, reward_bound=0.266, batch=227\n",
      "893: loss=0.930, reward_mean=0.090, reward_bound=0.314, batch=218\n",
      "894: loss=0.928, reward_mean=0.090, reward_bound=0.231, batch=222\n",
      "895: loss=0.929, reward_mean=0.070, reward_bound=0.263, batch=225\n",
      "896: loss=0.927, reward_mean=0.040, reward_bound=0.154, batch=227\n",
      "897: loss=0.930, reward_mean=0.070, reward_bound=0.308, batch=229\n",
      "898: loss=0.929, reward_mean=0.090, reward_bound=0.314, batch=229\n",
      "899: loss=0.930, reward_mean=0.140, reward_bound=0.349, batch=223\n",
      "900: loss=0.927, reward_mean=0.060, reward_bound=0.252, batch=226\n",
      "901: loss=0.931, reward_mean=0.100, reward_bound=0.314, batch=227\n",
      "902: loss=0.927, reward_mean=0.130, reward_bound=0.349, batch=228\n",
      "903: loss=0.936, reward_mean=0.110, reward_bound=0.387, batch=148\n",
      "904: loss=0.917, reward_mean=0.130, reward_bound=0.000, batch=161\n",
      "905: loss=0.914, reward_mean=0.120, reward_bound=0.000, batch=173\n",
      "906: loss=0.915, reward_mean=0.140, reward_bound=0.000, batch=187\n",
      "907: loss=0.914, reward_mean=0.100, reward_bound=0.000, batch=197\n",
      "908: loss=0.915, reward_mean=0.120, reward_bound=0.012, batch=208\n",
      "909: loss=0.915, reward_mean=0.180, reward_bound=0.109, batch=214\n",
      "910: loss=0.913, reward_mean=0.090, reward_bound=0.109, batch=219\n",
      "911: loss=0.914, reward_mean=0.060, reward_bound=0.122, batch=222\n",
      "912: loss=0.914, reward_mean=0.100, reward_bound=0.135, batch=224\n",
      "913: loss=0.919, reward_mean=0.090, reward_bound=0.150, batch=226\n",
      "914: loss=0.925, reward_mean=0.140, reward_bound=0.185, batch=222\n",
      "915: loss=0.922, reward_mean=0.110, reward_bound=0.206, batch=230\n",
      "916: loss=0.923, reward_mean=0.130, reward_bound=0.206, batch=238\n",
      "917: loss=0.923, reward_mean=0.100, reward_bound=0.206, batch=234\n",
      "918: loss=0.930, reward_mean=0.110, reward_bound=0.229, batch=226\n",
      "919: loss=0.932, reward_mean=0.160, reward_bound=0.254, batch=227\n",
      "920: loss=0.926, reward_mean=0.100, reward_bound=0.282, batch=215\n",
      "921: loss=0.923, reward_mean=0.140, reward_bound=0.282, batch=218\n",
      "922: loss=0.928, reward_mean=0.150, reward_bound=0.314, batch=206\n",
      "923: loss=0.918, reward_mean=0.100, reward_bound=0.081, batch=214\n",
      "924: loss=0.911, reward_mean=0.090, reward_bound=0.161, batch=220\n",
      "925: loss=0.915, reward_mean=0.090, reward_bound=0.167, batch=223\n",
      "926: loss=0.920, reward_mean=0.080, reward_bound=0.206, batch=224\n",
      "927: loss=0.926, reward_mean=0.140, reward_bound=0.229, batch=226\n",
      "928: loss=0.926, reward_mean=0.090, reward_bound=0.230, batch=228\n",
      "929: loss=0.922, reward_mean=0.120, reward_bound=0.286, batch=229\n",
      "930: loss=0.922, reward_mean=0.090, reward_bound=0.314, batch=225\n",
      "931: loss=0.929, reward_mean=0.150, reward_bound=0.349, batch=211\n",
      "932: loss=0.927, reward_mean=0.100, reward_bound=0.150, batch=217\n",
      "933: loss=0.924, reward_mean=0.160, reward_bound=0.224, batch=222\n",
      "934: loss=0.925, reward_mean=0.130, reward_bound=0.282, batch=224\n",
      "935: loss=0.926, reward_mean=0.120, reward_bound=0.308, batch=227\n",
      "936: loss=0.934, reward_mean=0.110, reward_bound=0.314, batch=228\n",
      "937: loss=0.937, reward_mean=0.070, reward_bound=0.349, batch=227\n",
      "938: loss=0.938, reward_mean=0.100, reward_bound=0.387, batch=201\n",
      "939: loss=0.937, reward_mean=0.120, reward_bound=0.065, batch=210\n",
      "940: loss=0.937, reward_mean=0.130, reward_bound=0.167, batch=216\n",
      "941: loss=0.933, reward_mean=0.100, reward_bound=0.176, batch=221\n",
      "942: loss=0.930, reward_mean=0.070, reward_bound=0.185, batch=223\n",
      "943: loss=0.924, reward_mean=0.090, reward_bound=0.229, batch=225\n",
      "944: loss=0.927, reward_mean=0.120, reward_bound=0.254, batch=225\n",
      "945: loss=0.924, reward_mean=0.090, reward_bound=0.221, batch=227\n",
      "946: loss=0.926, reward_mean=0.070, reward_bound=0.249, batch=229\n",
      "947: loss=0.929, reward_mean=0.140, reward_bound=0.295, batch=230\n",
      "948: loss=0.932, reward_mean=0.130, reward_bound=0.314, batch=224\n",
      "949: loss=0.929, reward_mean=0.140, reward_bound=0.349, batch=225\n",
      "950: loss=0.929, reward_mean=0.080, reward_bound=0.303, batch=227\n",
      "951: loss=0.930, reward_mean=0.080, reward_bound=0.361, batch=229\n",
      "952: loss=0.934, reward_mean=0.090, reward_bound=0.387, batch=221\n",
      "953: loss=0.935, reward_mean=0.060, reward_bound=0.254, batch=224\n",
      "954: loss=0.934, reward_mean=0.100, reward_bound=0.345, batch=227\n",
      "955: loss=0.935, reward_mean=0.090, reward_bound=0.387, batch=228\n",
      "956: loss=0.930, reward_mean=0.090, reward_bound=0.430, batch=129\n",
      "957: loss=0.903, reward_mean=0.140, reward_bound=0.000, batch=143\n",
      "958: loss=0.901, reward_mean=0.150, reward_bound=0.000, batch=158\n",
      "959: loss=0.894, reward_mean=0.070, reward_bound=0.000, batch=165\n",
      "960: loss=0.888, reward_mean=0.060, reward_bound=0.000, batch=171\n",
      "961: loss=0.880, reward_mean=0.090, reward_bound=0.000, batch=180\n",
      "962: loss=0.878, reward_mean=0.060, reward_bound=0.000, batch=186\n",
      "963: loss=0.875, reward_mean=0.120, reward_bound=0.000, batch=198\n",
      "964: loss=0.873, reward_mean=0.080, reward_bound=0.000, batch=206\n",
      "965: loss=0.870, reward_mean=0.120, reward_bound=0.041, batch=214\n",
      "966: loss=0.866, reward_mean=0.100, reward_bound=0.071, batch=220\n",
      "967: loss=0.860, reward_mean=0.080, reward_bound=0.086, batch=224\n",
      "968: loss=0.858, reward_mean=0.120, reward_bound=0.120, batch=227\n",
      "969: loss=0.865, reward_mean=0.150, reward_bound=0.135, batch=224\n",
      "970: loss=0.871, reward_mean=0.110, reward_bound=0.150, batch=224\n",
      "971: loss=0.878, reward_mean=0.150, reward_bound=0.167, batch=223\n",
      "972: loss=0.878, reward_mean=0.100, reward_bound=0.185, batch=220\n",
      "973: loss=0.873, reward_mean=0.060, reward_bound=0.081, batch=224\n",
      "974: loss=0.879, reward_mean=0.110, reward_bound=0.202, batch=227\n",
      "975: loss=0.881, reward_mean=0.130, reward_bound=0.206, batch=216\n",
      "976: loss=0.877, reward_mean=0.070, reward_bound=0.077, batch=221\n",
      "977: loss=0.882, reward_mean=0.120, reward_bound=0.206, batch=222\n",
      "978: loss=0.886, reward_mean=0.100, reward_bound=0.229, batch=222\n",
      "979: loss=0.893, reward_mean=0.070, reward_bound=0.254, batch=216\n",
      "980: loss=0.895, reward_mean=0.120, reward_bound=0.282, batch=207\n",
      "981: loss=0.889, reward_mean=0.150, reward_bound=0.282, batch=213\n",
      "982: loss=0.890, reward_mean=0.100, reward_bound=0.211, batch=219\n",
      "983: loss=0.884, reward_mean=0.140, reward_bound=0.239, batch=223\n",
      "984: loss=0.885, reward_mean=0.060, reward_bound=0.254, batch=222\n",
      "985: loss=0.888, reward_mean=0.170, reward_bound=0.314, batch=209\n",
      "986: loss=0.884, reward_mean=0.170, reward_bound=0.292, batch=216\n",
      "987: loss=0.889, reward_mean=0.100, reward_bound=0.139, batch=221\n",
      "988: loss=0.886, reward_mean=0.120, reward_bound=0.314, batch=223\n",
      "989: loss=0.884, reward_mean=0.150, reward_bound=0.261, batch=226\n",
      "990: loss=0.883, reward_mean=0.120, reward_bound=0.298, batch=228\n",
      "991: loss=0.887, reward_mean=0.120, reward_bound=0.317, batch=229\n",
      "992: loss=0.896, reward_mean=0.100, reward_bound=0.349, batch=203\n",
      "993: loss=0.891, reward_mean=0.080, reward_bound=0.000, batch=211\n",
      "994: loss=0.886, reward_mean=0.100, reward_bound=0.150, batch=217\n",
      "995: loss=0.885, reward_mean=0.050, reward_bound=0.006, batch=222\n",
      "996: loss=0.887, reward_mean=0.050, reward_bound=0.081, batch=225\n",
      "997: loss=0.891, reward_mean=0.110, reward_bound=0.206, batch=224\n",
      "998: loss=0.886, reward_mean=0.090, reward_bound=0.229, batch=226\n",
      "999: loss=0.882, reward_mean=0.090, reward_bound=0.254, batch=226\n",
      "1000: loss=0.884, reward_mean=0.120, reward_bound=0.282, batch=226\n",
      "1001: loss=0.885, reward_mean=0.140, reward_bound=0.314, batch=224\n",
      "1002: loss=0.890, reward_mean=0.130, reward_bound=0.349, batch=221\n",
      "1003: loss=0.890, reward_mean=0.060, reward_bound=0.206, batch=224\n",
      "1004: loss=0.890, reward_mean=0.090, reward_bound=0.280, batch=227\n",
      "1005: loss=0.888, reward_mean=0.110, reward_bound=0.349, batch=227\n",
      "1006: loss=0.887, reward_mean=0.050, reward_bound=0.380, batch=229\n",
      "1007: loss=0.909, reward_mean=0.210, reward_bound=0.387, batch=196\n",
      "1008: loss=0.913, reward_mean=0.220, reward_bound=0.186, batch=207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1009: loss=0.910, reward_mean=0.120, reward_bound=0.167, batch=214\n",
      "1010: loss=0.908, reward_mean=0.080, reward_bound=0.195, batch=220\n",
      "1011: loss=0.908, reward_mean=0.090, reward_bound=0.175, batch=224\n",
      "1012: loss=0.906, reward_mean=0.140, reward_bound=0.229, batch=222\n",
      "1013: loss=0.906, reward_mean=0.180, reward_bound=0.282, batch=222\n",
      "1014: loss=0.907, reward_mean=0.070, reward_bound=0.236, batch=225\n",
      "1015: loss=0.905, reward_mean=0.060, reward_bound=0.254, batch=226\n",
      "1016: loss=0.907, reward_mean=0.140, reward_bound=0.314, batch=223\n",
      "1017: loss=0.911, reward_mean=0.120, reward_bound=0.349, batch=220\n",
      "1018: loss=0.913, reward_mean=0.150, reward_bound=0.365, batch=224\n",
      "1019: loss=0.912, reward_mean=0.150, reward_bound=0.349, batch=226\n",
      "1020: loss=0.913, reward_mean=0.150, reward_bound=0.387, batch=223\n",
      "1021: loss=0.915, reward_mean=0.080, reward_bound=0.384, batch=226\n",
      "1022: loss=0.916, reward_mean=0.110, reward_bound=0.349, batch=227\n",
      "1023: loss=0.915, reward_mean=0.090, reward_bound=0.387, batch=228\n",
      "1024: loss=0.917, reward_mean=0.090, reward_bound=0.317, batch=229\n",
      "1025: loss=0.914, reward_mean=0.110, reward_bound=0.387, batch=229\n",
      "1026: loss=0.918, reward_mean=0.160, reward_bound=0.430, batch=193\n",
      "1027: loss=0.918, reward_mean=0.100, reward_bound=0.000, batch=203\n",
      "1028: loss=0.912, reward_mean=0.120, reward_bound=0.065, batch=211\n",
      "1029: loss=0.909, reward_mean=0.140, reward_bound=0.135, batch=217\n",
      "1030: loss=0.901, reward_mean=0.100, reward_bound=0.163, batch=222\n",
      "1031: loss=0.893, reward_mean=0.030, reward_bound=0.001, batch=225\n",
      "1032: loss=0.908, reward_mean=0.140, reward_bound=0.229, batch=225\n",
      "1033: loss=0.908, reward_mean=0.110, reward_bound=0.254, batch=223\n",
      "1034: loss=0.909, reward_mean=0.070, reward_bound=0.229, batch=226\n",
      "1035: loss=0.912, reward_mean=0.140, reward_bound=0.282, batch=223\n",
      "1036: loss=0.909, reward_mean=0.070, reward_bound=0.150, batch=225\n",
      "1037: loss=0.909, reward_mean=0.120, reward_bound=0.266, batch=227\n",
      "1038: loss=0.908, reward_mean=0.120, reward_bound=0.314, batch=226\n",
      "1039: loss=0.913, reward_mean=0.090, reward_bound=0.349, batch=219\n",
      "1040: loss=0.914, reward_mean=0.080, reward_bound=0.119, batch=223\n",
      "1041: loss=0.913, reward_mean=0.100, reward_bound=0.229, batch=225\n",
      "1042: loss=0.915, reward_mean=0.130, reward_bound=0.289, batch=227\n",
      "1043: loss=0.914, reward_mean=0.060, reward_bound=0.288, batch=229\n",
      "1044: loss=0.912, reward_mean=0.050, reward_bound=0.328, batch=230\n",
      "1045: loss=0.908, reward_mean=0.110, reward_bound=0.349, batch=229\n",
      "1046: loss=0.904, reward_mean=0.090, reward_bound=0.387, batch=217\n",
      "1047: loss=0.903, reward_mean=0.110, reward_bound=0.302, batch=222\n",
      "1048: loss=0.903, reward_mean=0.110, reward_bound=0.314, batch=224\n",
      "1049: loss=0.904, reward_mean=0.120, reward_bound=0.202, batch=227\n",
      "1050: loss=0.901, reward_mean=0.090, reward_bound=0.302, batch=229\n",
      "1051: loss=0.901, reward_mean=0.170, reward_bound=0.349, batch=229\n",
      "1052: loss=0.912, reward_mean=0.170, reward_bound=0.430, batch=213\n",
      "1053: loss=0.913, reward_mean=0.050, reward_bound=0.000, batch=218\n",
      "1054: loss=0.908, reward_mean=0.100, reward_bound=0.154, batch=222\n",
      "1055: loss=0.906, reward_mean=0.110, reward_bound=0.206, batch=226\n",
      "1056: loss=0.915, reward_mean=0.130, reward_bound=0.268, batch=228\n",
      "1057: loss=0.915, reward_mean=0.150, reward_bound=0.314, batch=228\n",
      "1058: loss=0.907, reward_mean=0.130, reward_bound=0.349, batch=224\n",
      "1059: loss=0.911, reward_mean=0.100, reward_bound=0.311, batch=227\n",
      "1060: loss=0.909, reward_mean=0.110, reward_bound=0.314, batch=228\n",
      "1061: loss=0.904, reward_mean=0.120, reward_bound=0.387, batch=226\n",
      "1062: loss=0.904, reward_mean=0.140, reward_bound=0.368, batch=228\n",
      "1063: loss=0.907, reward_mean=0.140, reward_bound=0.430, batch=222\n",
      "1064: loss=0.909, reward_mean=0.110, reward_bound=0.283, batch=225\n",
      "1065: loss=0.911, reward_mean=0.080, reward_bound=0.321, batch=227\n",
      "1066: loss=0.912, reward_mean=0.090, reward_bound=0.342, batch=229\n",
      "1067: loss=0.903, reward_mean=0.110, reward_bound=0.364, batch=230\n",
      "1068: loss=0.908, reward_mean=0.130, reward_bound=0.387, batch=228\n",
      "1069: loss=0.909, reward_mean=0.080, reward_bound=0.430, batch=226\n",
      "1070: loss=0.908, reward_mean=0.090, reward_bound=0.387, batch=227\n",
      "1071: loss=0.907, reward_mean=0.050, reward_bound=0.288, batch=229\n",
      "1072: loss=0.907, reward_mean=0.120, reward_bound=0.364, batch=230\n",
      "1073: loss=0.909, reward_mean=0.090, reward_bound=0.418, batch=231\n",
      "1074: loss=0.908, reward_mean=0.100, reward_bound=0.430, batch=228\n",
      "1075: loss=0.908, reward_mean=0.090, reward_bound=0.268, batch=229\n",
      "1076: loss=0.907, reward_mean=0.100, reward_bound=0.387, batch=229\n",
      "1077: loss=0.907, reward_mean=0.100, reward_bound=0.430, batch=229\n",
      "1078: loss=0.907, reward_mean=0.100, reward_bound=0.387, batch=229\n",
      "1079: loss=0.905, reward_mean=0.100, reward_bound=0.381, batch=230\n",
      "1080: loss=0.908, reward_mean=0.100, reward_bound=0.464, batch=231\n",
      "1081: loss=0.866, reward_mean=0.080, reward_bound=0.478, batch=93\n",
      "1082: loss=0.848, reward_mean=0.080, reward_bound=0.000, batch=101\n",
      "1083: loss=0.859, reward_mean=0.110, reward_bound=0.000, batch=112\n",
      "1084: loss=0.853, reward_mean=0.050, reward_bound=0.000, batch=117\n",
      "1085: loss=0.856, reward_mean=0.100, reward_bound=0.000, batch=127\n",
      "1086: loss=0.863, reward_mean=0.120, reward_bound=0.000, batch=139\n",
      "1087: loss=0.868, reward_mean=0.090, reward_bound=0.000, batch=148\n",
      "1088: loss=0.866, reward_mean=0.140, reward_bound=0.000, batch=162\n",
      "1089: loss=0.858, reward_mean=0.160, reward_bound=0.000, batch=178\n",
      "1090: loss=0.844, reward_mean=0.120, reward_bound=0.000, batch=190\n",
      "1091: loss=0.845, reward_mean=0.090, reward_bound=0.000, batch=199\n",
      "1092: loss=0.842, reward_mean=0.080, reward_bound=0.000, batch=207\n",
      "1093: loss=0.845, reward_mean=0.140, reward_bound=0.022, batch=215\n",
      "1094: loss=0.855, reward_mean=0.130, reward_bound=0.038, batch=217\n",
      "1095: loss=0.843, reward_mean=0.130, reward_bound=0.058, batch=224\n",
      "1096: loss=0.840, reward_mean=0.080, reward_bound=0.058, batch=226\n",
      "1097: loss=0.840, reward_mean=0.160, reward_bound=0.084, batch=228\n",
      "1098: loss=0.841, reward_mean=0.090, reward_bound=0.098, batch=227\n",
      "1099: loss=0.837, reward_mean=0.160, reward_bound=0.122, batch=228\n",
      "1100: loss=0.832, reward_mean=0.070, reward_bound=0.135, batch=220\n",
      "1101: loss=0.833, reward_mean=0.110, reward_bound=0.150, batch=215\n",
      "1102: loss=0.834, reward_mean=0.110, reward_bound=0.167, batch=215\n",
      "1103: loss=0.828, reward_mean=0.090, reward_bound=0.185, batch=210\n",
      "1104: loss=0.822, reward_mean=0.090, reward_bound=0.030, batch=217\n",
      "1105: loss=0.822, reward_mean=0.110, reward_bound=0.135, batch=221\n",
      "1106: loss=0.824, reward_mean=0.100, reward_bound=0.185, batch=224\n",
      "1107: loss=0.820, reward_mean=0.110, reward_bound=0.206, batch=216\n",
      "1108: loss=0.819, reward_mean=0.080, reward_bound=0.058, batch=221\n",
      "1109: loss=0.819, reward_mean=0.150, reward_bound=0.150, batch=222\n",
      "1110: loss=0.821, reward_mean=0.090, reward_bound=0.172, batch=225\n",
      "1111: loss=0.828, reward_mean=0.110, reward_bound=0.229, batch=214\n",
      "1112: loss=0.822, reward_mean=0.090, reward_bound=0.200, batch=220\n",
      "1113: loss=0.819, reward_mean=0.160, reward_bound=0.247, batch=224\n",
      "1114: loss=0.815, reward_mean=0.120, reward_bound=0.254, batch=213\n",
      "1115: loss=0.813, reward_mean=0.120, reward_bound=0.261, batch=219\n",
      "1116: loss=0.810, reward_mean=0.110, reward_bound=0.213, batch=223\n",
      "1117: loss=0.809, reward_mean=0.150, reward_bound=0.271, batch=226\n",
      "1118: loss=0.809, reward_mean=0.150, reward_bound=0.282, batch=213\n",
      "1119: loss=0.806, reward_mean=0.120, reward_bound=0.178, batch=219\n",
      "1120: loss=0.803, reward_mean=0.110, reward_bound=0.229, batch=222\n",
      "1121: loss=0.803, reward_mean=0.100, reward_bound=0.254, batch=224\n",
      "1122: loss=0.807, reward_mean=0.130, reward_bound=0.282, batch=226\n",
      "1123: loss=0.823, reward_mean=0.160, reward_bound=0.314, batch=198\n",
      "1124: loss=0.818, reward_mean=0.120, reward_bound=0.038, batch=208\n",
      "1125: loss=0.822, reward_mean=0.110, reward_bound=0.122, batch=214\n",
      "1126: loss=0.814, reward_mean=0.130, reward_bound=0.183, batch=220\n",
      "1127: loss=0.815, reward_mean=0.090, reward_bound=0.206, batch=225\n",
      "1128: loss=0.811, reward_mean=0.120, reward_bound=0.229, batch=222\n",
      "1129: loss=0.815, reward_mean=0.130, reward_bound=0.254, batch=224\n",
      "1130: loss=0.815, reward_mean=0.110, reward_bound=0.275, batch=227\n",
      "1131: loss=0.815, reward_mean=0.080, reward_bound=0.254, batch=227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132: loss=0.813, reward_mean=0.100, reward_bound=0.207, batch=229\n",
      "1133: loss=0.820, reward_mean=0.110, reward_bound=0.282, batch=226\n",
      "1134: loss=0.815, reward_mean=0.210, reward_bound=0.314, batch=226\n",
      "1135: loss=0.815, reward_mean=0.130, reward_bound=0.331, batch=228\n",
      "1136: loss=0.814, reward_mean=0.100, reward_bound=0.289, batch=229\n",
      "1137: loss=0.814, reward_mean=0.140, reward_bound=0.309, batch=230\n",
      "1138: loss=0.833, reward_mean=0.180, reward_bound=0.349, batch=196\n",
      "1139: loss=0.830, reward_mean=0.150, reward_bound=0.150, batch=206\n",
      "1140: loss=0.829, reward_mean=0.150, reward_bound=0.158, batch=214\n",
      "1141: loss=0.822, reward_mean=0.130, reward_bound=0.146, batch=220\n",
      "1142: loss=0.827, reward_mean=0.150, reward_bound=0.234, batch=224\n",
      "1143: loss=0.823, reward_mean=0.130, reward_bound=0.254, batch=225\n",
      "1144: loss=0.827, reward_mean=0.140, reward_bound=0.314, batch=221\n",
      "1145: loss=0.832, reward_mean=0.080, reward_bound=0.349, batch=209\n",
      "1146: loss=0.831, reward_mean=0.180, reward_bound=0.265, batch=216\n",
      "1147: loss=0.830, reward_mean=0.110, reward_bound=0.170, batch=221\n",
      "1148: loss=0.836, reward_mean=0.170, reward_bound=0.282, batch=223\n",
      "1149: loss=0.834, reward_mean=0.080, reward_bound=0.261, batch=226\n",
      "1150: loss=0.832, reward_mean=0.180, reward_bound=0.314, batch=227\n",
      "1151: loss=0.831, reward_mean=0.130, reward_bound=0.349, batch=224\n",
      "1152: loss=0.830, reward_mean=0.110, reward_bound=0.254, batch=226\n",
      "1153: loss=0.830, reward_mean=0.110, reward_bound=0.351, batch=228\n",
      "1154: loss=0.832, reward_mean=0.090, reward_bound=0.353, batch=229\n",
      "1155: loss=0.830, reward_mean=0.150, reward_bound=0.364, batch=230\n",
      "1156: loss=0.829, reward_mean=0.110, reward_bound=0.376, batch=231\n",
      "1157: loss=0.849, reward_mean=0.130, reward_bound=0.387, batch=189\n",
      "1158: loss=0.846, reward_mean=0.100, reward_bound=0.000, batch=199\n",
      "1159: loss=0.835, reward_mean=0.130, reward_bound=0.079, batch=209\n",
      "1160: loss=0.832, reward_mean=0.080, reward_bound=0.041, batch=216\n",
      "1161: loss=0.830, reward_mean=0.090, reward_bound=0.066, batch=221\n",
      "1162: loss=0.841, reward_mean=0.140, reward_bound=0.150, batch=222\n",
      "1163: loss=0.842, reward_mean=0.200, reward_bound=0.254, batch=222\n",
      "1164: loss=0.843, reward_mean=0.150, reward_bound=0.314, batch=220\n",
      "1165: loss=0.841, reward_mean=0.130, reward_bound=0.222, batch=224\n",
      "1166: loss=0.837, reward_mean=0.120, reward_bound=0.229, batch=226\n",
      "1167: loss=0.836, reward_mean=0.100, reward_bound=0.314, batch=227\n",
      "1168: loss=0.838, reward_mean=0.100, reward_bound=0.349, batch=226\n",
      "1169: loss=0.835, reward_mean=0.070, reward_bound=0.160, batch=228\n",
      "1170: loss=0.839, reward_mean=0.180, reward_bound=0.353, batch=229\n",
      "1171: loss=0.841, reward_mean=0.140, reward_bound=0.387, batch=219\n",
      "1172: loss=0.840, reward_mean=0.110, reward_bound=0.328, batch=223\n",
      "1173: loss=0.835, reward_mean=0.150, reward_bound=0.349, batch=225\n",
      "1174: loss=0.837, reward_mean=0.110, reward_bound=0.387, batch=224\n",
      "1175: loss=0.833, reward_mean=0.120, reward_bound=0.422, batch=227\n",
      "1176: loss=0.834, reward_mean=0.090, reward_bound=0.422, batch=229\n",
      "1177: loss=0.834, reward_mean=0.160, reward_bound=0.343, batch=230\n",
      "1178: loss=0.831, reward_mean=0.170, reward_bound=0.418, batch=231\n",
      "1179: loss=0.840, reward_mean=0.130, reward_bound=0.430, batch=163\n",
      "1180: loss=0.838, reward_mean=0.140, reward_bound=0.000, batch=177\n",
      "1181: loss=0.832, reward_mean=0.070, reward_bound=0.000, batch=184\n",
      "1182: loss=0.826, reward_mean=0.080, reward_bound=0.000, batch=192\n",
      "1183: loss=0.815, reward_mean=0.130, reward_bound=0.009, batch=204\n",
      "1184: loss=0.820, reward_mean=0.160, reward_bound=0.051, batch=213\n",
      "1185: loss=0.819, reward_mean=0.110, reward_bound=0.069, batch=219\n",
      "1186: loss=0.831, reward_mean=0.150, reward_bound=0.127, batch=223\n",
      "1187: loss=0.830, reward_mean=0.100, reward_bound=0.135, batch=220\n",
      "1188: loss=0.827, reward_mean=0.100, reward_bound=0.180, batch=224\n",
      "1189: loss=0.827, reward_mean=0.130, reward_bound=0.185, batch=226\n",
      "1190: loss=0.830, reward_mean=0.150, reward_bound=0.229, batch=221\n",
      "1191: loss=0.834, reward_mean=0.080, reward_bound=0.254, batch=218\n",
      "1192: loss=0.829, reward_mean=0.160, reward_bound=0.257, batch=222\n",
      "1193: loss=0.834, reward_mean=0.140, reward_bound=0.282, batch=216\n",
      "1194: loss=0.833, reward_mean=0.130, reward_bound=0.229, batch=220\n",
      "1195: loss=0.832, reward_mean=0.160, reward_bound=0.274, batch=224\n",
      "1196: loss=0.829, reward_mean=0.160, reward_bound=0.311, batch=227\n",
      "1197: loss=0.832, reward_mean=0.130, reward_bound=0.314, batch=214\n",
      "1198: loss=0.831, reward_mean=0.130, reward_bound=0.349, batch=207\n",
      "1199: loss=0.828, reward_mean=0.180, reward_bound=0.220, batch=215\n",
      "1200: loss=0.825, reward_mean=0.130, reward_bound=0.234, batch=220\n",
      "1201: loss=0.821, reward_mean=0.110, reward_bound=0.114, batch=224\n",
      "1202: loss=0.833, reward_mean=0.140, reward_bound=0.254, batch=225\n",
      "1203: loss=0.837, reward_mean=0.080, reward_bound=0.205, batch=227\n",
      "1204: loss=0.835, reward_mean=0.170, reward_bound=0.282, batch=226\n",
      "1205: loss=0.833, reward_mean=0.130, reward_bound=0.349, batch=227\n",
      "1206: loss=0.832, reward_mean=0.120, reward_bound=0.387, batch=208\n",
      "1207: loss=0.823, reward_mean=0.180, reward_bound=0.257, batch=215\n",
      "1208: loss=0.833, reward_mean=0.170, reward_bound=0.282, batch=219\n",
      "1209: loss=0.831, reward_mean=0.130, reward_bound=0.314, batch=221\n",
      "1210: loss=0.832, reward_mean=0.150, reward_bound=0.349, batch=221\n",
      "1211: loss=0.828, reward_mean=0.140, reward_bound=0.349, batch=224\n",
      "1212: loss=0.825, reward_mean=0.090, reward_bound=0.280, batch=227\n",
      "1213: loss=0.827, reward_mean=0.170, reward_bound=0.380, batch=229\n",
      "1214: loss=0.829, reward_mean=0.140, reward_bound=0.387, batch=223\n",
      "1215: loss=0.830, reward_mean=0.170, reward_bound=0.372, batch=226\n",
      "1216: loss=0.827, reward_mean=0.140, reward_bound=0.368, batch=228\n",
      "1217: loss=0.827, reward_mean=0.150, reward_bound=0.353, batch=229\n",
      "1218: loss=0.828, reward_mean=0.090, reward_bound=0.387, batch=227\n",
      "1219: loss=0.826, reward_mean=0.130, reward_bound=0.297, batch=229\n",
      "1220: loss=0.827, reward_mean=0.150, reward_bound=0.387, batch=228\n",
      "1221: loss=0.839, reward_mean=0.110, reward_bound=0.430, batch=197\n",
      "1222: loss=0.832, reward_mean=0.150, reward_bound=0.087, batch=208\n",
      "1223: loss=0.844, reward_mean=0.180, reward_bound=0.124, batch=215\n",
      "1224: loss=0.841, reward_mean=0.200, reward_bound=0.229, batch=218\n",
      "1225: loss=0.832, reward_mean=0.120, reward_bound=0.282, batch=219\n",
      "1226: loss=0.836, reward_mean=0.120, reward_bound=0.314, batch=216\n",
      "1227: loss=0.835, reward_mean=0.170, reward_bound=0.349, batch=219\n",
      "1228: loss=0.840, reward_mean=0.110, reward_bound=0.192, batch=223\n",
      "1229: loss=0.839, reward_mean=0.140, reward_bound=0.271, batch=226\n",
      "1230: loss=0.838, reward_mean=0.040, reward_bound=0.241, batch=228\n",
      "1231: loss=0.839, reward_mean=0.160, reward_bound=0.314, batch=227\n",
      "1232: loss=0.841, reward_mean=0.090, reward_bound=0.387, batch=219\n",
      "1233: loss=0.843, reward_mean=0.160, reward_bound=0.295, batch=223\n",
      "1234: loss=0.838, reward_mean=0.110, reward_bound=0.335, batch=226\n",
      "1235: loss=0.836, reward_mean=0.140, reward_bound=0.268, batch=228\n",
      "1236: loss=0.838, reward_mean=0.130, reward_bound=0.289, batch=229\n",
      "1237: loss=0.840, reward_mean=0.110, reward_bound=0.364, batch=230\n",
      "1238: loss=0.840, reward_mean=0.130, reward_bound=0.430, batch=217\n",
      "1239: loss=0.837, reward_mean=0.140, reward_bound=0.308, batch=222\n",
      "1240: loss=0.838, reward_mean=0.110, reward_bound=0.314, batch=224\n",
      "1241: loss=0.834, reward_mean=0.110, reward_bound=0.229, batch=225\n",
      "1242: loss=0.839, reward_mean=0.150, reward_bound=0.356, batch=227\n",
      "1243: loss=0.841, reward_mean=0.100, reward_bound=0.387, batch=227\n",
      "1244: loss=0.841, reward_mean=0.070, reward_bound=0.422, batch=229\n",
      "1245: loss=0.840, reward_mean=0.210, reward_bound=0.430, batch=226\n",
      "1246: loss=0.839, reward_mean=0.100, reward_bound=0.298, batch=228\n",
      "1247: loss=0.840, reward_mean=0.120, reward_bound=0.353, batch=229\n",
      "1248: loss=0.843, reward_mean=0.100, reward_bound=0.405, batch=230\n",
      "1249: loss=0.843, reward_mean=0.100, reward_bound=0.418, batch=231\n",
      "1250: loss=0.844, reward_mean=0.110, reward_bound=0.430, batch=231\n",
      "1251: loss=0.847, reward_mean=0.120, reward_bound=0.478, batch=157\n",
      "1252: loss=0.868, reward_mean=0.170, reward_bound=0.000, batch=174\n",
      "1253: loss=0.861, reward_mean=0.070, reward_bound=0.000, batch=181\n",
      "1254: loss=0.847, reward_mean=0.100, reward_bound=0.000, batch=191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1255: loss=0.832, reward_mean=0.090, reward_bound=0.000, batch=200\n",
      "1256: loss=0.844, reward_mean=0.140, reward_bound=0.022, batch=210\n",
      "1257: loss=0.848, reward_mean=0.140, reward_bound=0.065, batch=216\n",
      "1258: loss=0.847, reward_mean=0.110, reward_bound=0.109, batch=220\n",
      "1259: loss=0.848, reward_mean=0.090, reward_bound=0.135, batch=222\n",
      "1260: loss=0.856, reward_mean=0.120, reward_bound=0.150, batch=221\n",
      "1261: loss=0.856, reward_mean=0.090, reward_bound=0.167, batch=223\n",
      "1262: loss=0.855, reward_mean=0.080, reward_bound=0.185, batch=220\n",
      "1263: loss=0.854, reward_mean=0.140, reward_bound=0.206, batch=226\n",
      "1264: loss=0.854, reward_mean=0.150, reward_bound=0.206, batch=224\n",
      "1265: loss=0.864, reward_mean=0.100, reward_bound=0.229, batch=221\n",
      "1266: loss=0.859, reward_mean=0.140, reward_bound=0.254, batch=218\n",
      "1267: loss=0.861, reward_mean=0.100, reward_bound=0.178, batch=222\n",
      "1268: loss=0.860, reward_mean=0.130, reward_bound=0.282, batch=219\n",
      "1269: loss=0.858, reward_mean=0.160, reward_bound=0.282, batch=222\n",
      "1270: loss=0.848, reward_mean=0.150, reward_bound=0.314, batch=215\n",
      "1271: loss=0.843, reward_mean=0.140, reward_bound=0.167, batch=219\n",
      "1272: loss=0.837, reward_mean=0.050, reward_bound=0.009, batch=223\n",
      "1273: loss=0.839, reward_mean=0.130, reward_bound=0.206, batch=225\n",
      "1274: loss=0.846, reward_mean=0.140, reward_bound=0.282, batch=224\n",
      "1275: loss=0.846, reward_mean=0.160, reward_bound=0.314, batch=226\n",
      "1276: loss=0.847, reward_mean=0.150, reward_bound=0.349, batch=209\n",
      "1277: loss=0.845, reward_mean=0.130, reward_bound=0.309, batch=216\n",
      "1278: loss=0.850, reward_mean=0.100, reward_bound=0.268, batch=221\n",
      "1279: loss=0.848, reward_mean=0.130, reward_bound=0.314, batch=224\n",
      "1280: loss=0.843, reward_mean=0.130, reward_bound=0.349, batch=223\n",
      "1281: loss=0.844, reward_mean=0.080, reward_bound=0.155, batch=226\n",
      "1282: loss=0.847, reward_mean=0.160, reward_bound=0.349, batch=227\n",
      "1283: loss=0.849, reward_mean=0.070, reward_bound=0.335, batch=229\n",
      "1284: loss=0.850, reward_mean=0.160, reward_bound=0.387, batch=207\n",
      "1285: loss=0.852, reward_mean=0.140, reward_bound=0.198, batch=215\n",
      "1286: loss=0.855, reward_mean=0.130, reward_bound=0.210, batch=220\n",
      "1287: loss=0.858, reward_mean=0.110, reward_bound=0.266, batch=224\n",
      "1288: loss=0.857, reward_mean=0.090, reward_bound=0.183, batch=227\n",
      "1289: loss=0.865, reward_mean=0.120, reward_bound=0.308, batch=229\n",
      "1290: loss=0.861, reward_mean=0.100, reward_bound=0.314, batch=226\n",
      "1291: loss=0.861, reward_mean=0.110, reward_bound=0.349, batch=226\n",
      "1292: loss=0.851, reward_mean=0.140, reward_bound=0.387, batch=224\n",
      "1293: loss=0.847, reward_mean=0.070, reward_bound=0.311, batch=227\n",
      "1294: loss=0.849, reward_mean=0.130, reward_bound=0.422, batch=229\n",
      "1295: loss=0.873, reward_mean=0.120, reward_bound=0.430, batch=199\n",
      "1296: loss=0.867, reward_mean=0.130, reward_bound=0.114, batch=209\n",
      "1297: loss=0.868, reward_mean=0.160, reward_bound=0.215, batch=216\n",
      "1298: loss=0.871, reward_mean=0.120, reward_bound=0.229, batch=219\n",
      "1299: loss=0.868, reward_mean=0.080, reward_bound=0.203, batch=223\n",
      "1300: loss=0.869, reward_mean=0.100, reward_bound=0.244, batch=226\n",
      "1301: loss=0.864, reward_mean=0.120, reward_bound=0.268, batch=228\n",
      "1302: loss=0.866, reward_mean=0.030, reward_bound=0.282, batch=224\n",
      "1303: loss=0.865, reward_mean=0.080, reward_bound=0.182, batch=227\n",
      "1304: loss=0.864, reward_mean=0.150, reward_bound=0.308, batch=229\n",
      "1305: loss=0.868, reward_mean=0.070, reward_bound=0.314, batch=223\n",
      "1306: loss=0.868, reward_mean=0.060, reward_bound=0.160, batch=226\n",
      "1307: loss=0.870, reward_mean=0.140, reward_bound=0.331, batch=228\n",
      "1308: loss=0.871, reward_mean=0.150, reward_bound=0.317, batch=229\n",
      "1309: loss=0.871, reward_mean=0.110, reward_bound=0.349, batch=224\n",
      "1310: loss=0.866, reward_mean=0.160, reward_bound=0.384, batch=227\n",
      "1311: loss=0.865, reward_mean=0.110, reward_bound=0.342, batch=229\n",
      "1312: loss=0.866, reward_mean=0.120, reward_bound=0.364, batch=230\n",
      "1313: loss=0.875, reward_mean=0.170, reward_bound=0.387, batch=223\n",
      "1314: loss=0.874, reward_mean=0.130, reward_bound=0.322, batch=226\n",
      "1315: loss=0.877, reward_mean=0.080, reward_bound=0.349, batch=227\n",
      "1316: loss=0.877, reward_mean=0.100, reward_bound=0.380, batch=229\n",
      "1317: loss=0.877, reward_mean=0.110, reward_bound=0.307, batch=230\n",
      "1318: loss=0.874, reward_mean=0.110, reward_bound=0.430, batch=220\n",
      "1319: loss=0.872, reward_mean=0.130, reward_bound=0.338, batch=224\n",
      "1320: loss=0.874, reward_mean=0.150, reward_bound=0.384, batch=227\n",
      "1321: loss=0.875, reward_mean=0.110, reward_bound=0.387, batch=228\n",
      "1322: loss=0.871, reward_mean=0.110, reward_bound=0.430, batch=225\n",
      "1323: loss=0.870, reward_mean=0.140, reward_bound=0.365, batch=227\n",
      "1324: loss=0.871, reward_mean=0.080, reward_bound=0.229, batch=228\n",
      "1325: loss=0.872, reward_mean=0.130, reward_bound=0.435, batch=229\n",
      "1326: loss=0.871, reward_mean=0.060, reward_bound=0.309, batch=230\n",
      "1327: loss=0.870, reward_mean=0.050, reward_bound=0.320, batch=231\n",
      "1328: loss=0.850, reward_mean=0.130, reward_bound=0.478, batch=181\n",
      "1329: loss=0.846, reward_mean=0.140, reward_bound=0.000, batch=195\n",
      "1330: loss=0.829, reward_mean=0.100, reward_bound=0.000, batch=205\n",
      "1331: loss=0.834, reward_mean=0.090, reward_bound=0.017, batch=213\n",
      "1332: loss=0.837, reward_mean=0.120, reward_bound=0.079, batch=219\n",
      "1333: loss=0.839, reward_mean=0.140, reward_bound=0.167, batch=220\n",
      "1334: loss=0.836, reward_mean=0.040, reward_bound=0.085, batch=224\n",
      "1335: loss=0.832, reward_mean=0.140, reward_bound=0.206, batch=225\n",
      "1336: loss=0.837, reward_mean=0.150, reward_bound=0.254, batch=222\n",
      "1337: loss=0.841, reward_mean=0.110, reward_bound=0.282, batch=220\n",
      "1338: loss=0.840, reward_mean=0.100, reward_bound=0.162, batch=224\n",
      "1339: loss=0.837, reward_mean=0.050, reward_bound=0.165, batch=227\n",
      "1340: loss=0.843, reward_mean=0.170, reward_bound=0.314, batch=225\n",
      "1341: loss=0.841, reward_mean=0.110, reward_bound=0.289, batch=227\n",
      "1342: loss=0.846, reward_mean=0.130, reward_bound=0.349, batch=217\n",
      "1343: loss=0.847, reward_mean=0.200, reward_bound=0.267, batch=222\n",
      "1344: loss=0.846, reward_mean=0.120, reward_bound=0.314, batch=222\n",
      "1345: loss=0.844, reward_mean=0.080, reward_bound=0.292, batch=225\n",
      "1346: loss=0.844, reward_mean=0.090, reward_bound=0.321, batch=227\n",
      "1347: loss=0.844, reward_mean=0.120, reward_bound=0.349, batch=227\n",
      "1348: loss=0.844, reward_mean=0.100, reward_bound=0.380, batch=229\n",
      "1349: loss=0.844, reward_mean=0.110, reward_bound=0.387, batch=211\n",
      "1350: loss=0.841, reward_mean=0.110, reward_bound=0.150, batch=217\n",
      "1351: loss=0.843, reward_mean=0.150, reward_bound=0.185, batch=221\n",
      "1352: loss=0.842, reward_mean=0.130, reward_bound=0.229, batch=223\n",
      "1353: loss=0.841, reward_mean=0.080, reward_bound=0.206, batch=224\n",
      "1354: loss=0.843, reward_mean=0.080, reward_bound=0.165, batch=227\n",
      "1355: loss=0.849, reward_mean=0.080, reward_bound=0.254, batch=226\n",
      "1356: loss=0.852, reward_mean=0.100, reward_bound=0.314, batch=226\n",
      "1357: loss=0.851, reward_mean=0.140, reward_bound=0.314, batch=227\n",
      "1358: loss=0.847, reward_mean=0.120, reward_bound=0.335, batch=229\n",
      "1359: loss=0.844, reward_mean=0.080, reward_bound=0.349, batch=229\n",
      "1360: loss=0.841, reward_mean=0.090, reward_bound=0.387, batch=223\n",
      "1361: loss=0.840, reward_mean=0.080, reward_bound=0.261, batch=226\n",
      "1362: loss=0.840, reward_mean=0.070, reward_bound=0.254, batch=226\n",
      "1363: loss=0.838, reward_mean=0.120, reward_bound=0.351, batch=228\n",
      "1364: loss=0.837, reward_mean=0.090, reward_bound=0.293, batch=229\n",
      "1365: loss=0.835, reward_mean=0.070, reward_bound=0.364, batch=230\n",
      "1366: loss=0.835, reward_mean=0.080, reward_bound=0.340, batch=231\n",
      "1367: loss=0.837, reward_mean=0.070, reward_bound=0.387, batch=226\n",
      "1368: loss=0.840, reward_mean=0.110, reward_bound=0.409, batch=228\n",
      "1369: loss=0.841, reward_mean=0.090, reward_bound=0.357, batch=229\n",
      "1370: loss=0.841, reward_mean=0.070, reward_bound=0.309, batch=230\n",
      "1371: loss=0.847, reward_mean=0.090, reward_bound=0.430, batch=212\n",
      "1372: loss=0.844, reward_mean=0.140, reward_bound=0.249, batch=218\n",
      "1373: loss=0.845, reward_mean=0.120, reward_bound=0.349, batch=221\n",
      "1374: loss=0.843, reward_mean=0.090, reward_bound=0.349, batch=222\n",
      "1375: loss=0.839, reward_mean=0.120, reward_bound=0.360, batch=225\n",
      "1376: loss=0.839, reward_mean=0.110, reward_bound=0.254, batch=226\n",
      "1377: loss=0.839, reward_mean=0.130, reward_bound=0.349, batch=226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1378: loss=0.838, reward_mean=0.090, reward_bound=0.351, batch=228\n",
      "1379: loss=0.844, reward_mean=0.130, reward_bound=0.387, batch=221\n",
      "1380: loss=0.843, reward_mean=0.120, reward_bound=0.314, batch=224\n",
      "1381: loss=0.839, reward_mean=0.050, reward_bound=0.180, batch=227\n",
      "1382: loss=0.836, reward_mean=0.060, reward_bound=0.182, batch=229\n",
      "1383: loss=0.841, reward_mean=0.080, reward_bound=0.295, batch=230\n",
      "1384: loss=0.844, reward_mean=0.080, reward_bound=0.338, batch=231\n",
      "1385: loss=0.840, reward_mean=0.110, reward_bound=0.349, batch=229\n",
      "1386: loss=0.842, reward_mean=0.080, reward_bound=0.430, batch=222\n",
      "1387: loss=0.843, reward_mean=0.080, reward_bound=0.276, batch=225\n",
      "1388: loss=0.840, reward_mean=0.100, reward_bound=0.387, batch=225\n",
      "1389: loss=0.838, reward_mean=0.120, reward_bound=0.356, batch=227\n",
      "1390: loss=0.839, reward_mean=0.100, reward_bound=0.387, batch=228\n",
      "1391: loss=0.840, reward_mean=0.100, reward_bound=0.392, batch=229\n",
      "1392: loss=0.840, reward_mean=0.080, reward_bound=0.387, batch=229\n",
      "1393: loss=0.840, reward_mean=0.140, reward_bound=0.430, batch=229\n",
      "1394: loss=0.838, reward_mean=0.100, reward_bound=0.424, batch=230\n",
      "1395: loss=0.838, reward_mean=0.080, reward_bound=0.418, batch=231\n",
      "1396: loss=0.837, reward_mean=0.120, reward_bound=0.430, batch=231\n",
      "1397: loss=0.843, reward_mean=0.150, reward_bound=0.478, batch=201\n",
      "1398: loss=0.851, reward_mean=0.110, reward_bound=0.058, batch=210\n",
      "1399: loss=0.849, reward_mean=0.160, reward_bound=0.240, batch=217\n",
      "1400: loss=0.854, reward_mean=0.170, reward_bound=0.277, batch=222\n",
      "1401: loss=0.850, reward_mean=0.070, reward_bound=0.117, batch=225\n",
      "1402: loss=0.846, reward_mean=0.110, reward_bound=0.282, batch=221\n",
      "1403: loss=0.843, reward_mean=0.070, reward_bound=0.185, batch=224\n",
      "1404: loss=0.841, reward_mean=0.110, reward_bound=0.308, batch=227\n",
      "1405: loss=0.841, reward_mean=0.100, reward_bound=0.314, batch=227\n",
      "1406: loss=0.841, reward_mean=0.100, reward_bound=0.342, batch=229\n",
      "1407: loss=0.840, reward_mean=0.140, reward_bound=0.349, batch=225\n",
      "1408: loss=0.838, reward_mean=0.090, reward_bound=0.387, batch=218\n",
      "1409: loss=0.838, reward_mean=0.090, reward_bound=0.286, batch=222\n",
      "1410: loss=0.839, reward_mean=0.090, reward_bound=0.229, batch=224\n",
      "1411: loss=0.836, reward_mean=0.090, reward_bound=0.252, batch=227\n",
      "1412: loss=0.837, reward_mean=0.130, reward_bound=0.308, batch=229\n",
      "1413: loss=0.837, reward_mean=0.110, reward_bound=0.349, batch=228\n",
      "1414: loss=0.834, reward_mean=0.100, reward_bound=0.387, batch=226\n",
      "1415: loss=0.832, reward_mean=0.090, reward_bound=0.234, batch=228\n",
      "1416: loss=0.833, reward_mean=0.160, reward_bound=0.357, batch=229\n",
      "1417: loss=0.832, reward_mean=0.120, reward_bound=0.364, batch=230\n",
      "1418: loss=0.842, reward_mean=0.120, reward_bound=0.430, batch=219\n",
      "1419: loss=0.848, reward_mean=0.140, reward_bound=0.203, batch=223\n",
      "1420: loss=0.845, reward_mean=0.070, reward_bound=0.261, batch=226\n",
      "1421: loss=0.844, reward_mean=0.100, reward_bound=0.282, batch=226\n",
      "1422: loss=0.839, reward_mean=0.170, reward_bound=0.368, batch=228\n",
      "1423: loss=0.838, reward_mean=0.130, reward_bound=0.353, batch=229\n",
      "1424: loss=0.837, reward_mean=0.110, reward_bound=0.295, batch=230\n",
      "1425: loss=0.838, reward_mean=0.110, reward_bound=0.365, batch=231\n",
      "1426: loss=0.838, reward_mean=0.080, reward_bound=0.387, batch=228\n",
      "1427: loss=0.838, reward_mean=0.090, reward_bound=0.430, batch=225\n",
      "1428: loss=0.838, reward_mean=0.100, reward_bound=0.282, batch=226\n",
      "1429: loss=0.836, reward_mean=0.140, reward_bound=0.454, batch=228\n",
      "1430: loss=0.836, reward_mean=0.080, reward_bound=0.282, batch=228\n",
      "1431: loss=0.836, reward_mean=0.080, reward_bound=0.478, batch=230\n",
      "1432: loss=0.835, reward_mean=0.110, reward_bound=0.439, batch=231\n",
      "1433: loss=0.835, reward_mean=0.130, reward_bound=0.387, batch=231\n",
      "1434: loss=0.838, reward_mean=0.160, reward_bound=0.478, batch=213\n",
      "1435: loss=0.830, reward_mean=0.150, reward_bound=0.261, batch=219\n",
      "1436: loss=0.828, reward_mean=0.100, reward_bound=0.155, batch=223\n",
      "1437: loss=0.821, reward_mean=0.160, reward_bound=0.261, batch=226\n",
      "1438: loss=0.818, reward_mean=0.140, reward_bound=0.282, batch=227\n",
      "1439: loss=0.823, reward_mean=0.110, reward_bound=0.314, batch=227\n",
      "1440: loss=0.823, reward_mean=0.170, reward_bound=0.349, batch=228\n",
      "1441: loss=0.821, reward_mean=0.110, reward_bound=0.293, batch=229\n",
      "1442: loss=0.830, reward_mean=0.100, reward_bound=0.387, batch=226\n",
      "1443: loss=0.830, reward_mean=0.090, reward_bound=0.409, batch=228\n",
      "1444: loss=0.829, reward_mean=0.070, reward_bound=0.392, batch=229\n",
      "1445: loss=0.829, reward_mean=0.060, reward_bound=0.296, batch=230\n",
      "1446: loss=0.827, reward_mean=0.110, reward_bound=0.406, batch=231\n",
      "1447: loss=0.834, reward_mean=0.150, reward_bound=0.430, batch=221\n",
      "1448: loss=0.836, reward_mean=0.090, reward_bound=0.282, batch=223\n",
      "1449: loss=0.830, reward_mean=0.110, reward_bound=0.413, batch=226\n",
      "1450: loss=0.827, reward_mean=0.100, reward_bound=0.331, batch=228\n",
      "1451: loss=0.829, reward_mean=0.150, reward_bound=0.392, batch=229\n",
      "1452: loss=0.832, reward_mean=0.110, reward_bound=0.430, batch=229\n",
      "1453: loss=0.831, reward_mean=0.140, reward_bound=0.424, batch=230\n",
      "1454: loss=0.833, reward_mean=0.190, reward_bound=0.464, batch=231\n",
      "1455: loss=0.840, reward_mean=0.100, reward_bound=0.478, batch=219\n",
      "1456: loss=0.842, reward_mean=0.130, reward_bound=0.265, batch=223\n",
      "1457: loss=0.840, reward_mean=0.100, reward_bound=0.282, batch=225\n",
      "1458: loss=0.837, reward_mean=0.110, reward_bound=0.314, batch=224\n",
      "1459: loss=0.840, reward_mean=0.130, reward_bound=0.280, batch=227\n",
      "1460: loss=0.840, reward_mean=0.090, reward_bound=0.282, batch=228\n",
      "1461: loss=0.841, reward_mean=0.150, reward_bound=0.387, batch=226\n",
      "1462: loss=0.844, reward_mean=0.120, reward_bound=0.390, batch=228\n",
      "1463: loss=0.842, reward_mean=0.150, reward_bound=0.430, batch=226\n",
      "1464: loss=0.840, reward_mean=0.150, reward_bound=0.387, batch=227\n",
      "1465: loss=0.835, reward_mean=0.120, reward_bound=0.478, batch=224\n",
      "1466: loss=0.832, reward_mean=0.110, reward_bound=0.349, batch=226\n",
      "1467: loss=0.828, reward_mean=0.090, reward_bound=0.271, batch=228\n",
      "1468: loss=0.835, reward_mean=0.120, reward_bound=0.387, batch=228\n",
      "1469: loss=0.833, reward_mean=0.140, reward_bound=0.430, batch=228\n",
      "1470: loss=0.833, reward_mean=0.100, reward_bound=0.435, batch=229\n",
      "1471: loss=0.833, reward_mean=0.160, reward_bound=0.478, batch=231\n",
      "1472: loss=0.835, reward_mean=0.140, reward_bound=0.478, batch=227\n",
      "1473: loss=0.838, reward_mean=0.110, reward_bound=0.361, batch=229\n",
      "1474: loss=0.838, reward_mean=0.110, reward_bound=0.349, batch=229\n",
      "1475: loss=0.836, reward_mean=0.060, reward_bound=0.309, batch=230\n",
      "1476: loss=0.835, reward_mean=0.110, reward_bound=0.387, batch=229\n",
      "1477: loss=0.836, reward_mean=0.160, reward_bound=0.450, batch=230\n",
      "1478: loss=0.839, reward_mean=0.130, reward_bound=0.418, batch=231\n",
      "1479: loss=0.838, reward_mean=0.130, reward_bound=0.430, batch=231\n",
      "1480: loss=0.836, reward_mean=0.100, reward_bound=0.478, batch=230\n",
      "1481: loss=0.836, reward_mean=0.180, reward_bound=0.515, batch=231\n",
      "1482: loss=0.836, reward_mean=0.060, reward_bound=0.387, batch=231\n",
      "1483: loss=0.836, reward_mean=0.180, reward_bound=0.314, batch=231\n",
      "1484: loss=0.836, reward_mean=0.160, reward_bound=0.478, batch=231\n",
      "1486: loss=0.762, reward_mean=0.140, reward_bound=0.000, batch=14\n",
      "1487: loss=0.755, reward_mean=0.110, reward_bound=0.000, batch=25\n",
      "1488: loss=0.768, reward_mean=0.130, reward_bound=0.000, batch=38\n",
      "1489: loss=0.766, reward_mean=0.100, reward_bound=0.000, batch=48\n",
      "1490: loss=0.744, reward_mean=0.140, reward_bound=0.000, batch=62\n",
      "1491: loss=0.735, reward_mean=0.170, reward_bound=0.000, batch=79\n",
      "1492: loss=0.748, reward_mean=0.150, reward_bound=0.000, batch=94\n",
      "1493: loss=0.738, reward_mean=0.190, reward_bound=0.000, batch=113\n",
      "1494: loss=0.729, reward_mean=0.140, reward_bound=0.000, batch=127\n",
      "1495: loss=0.729, reward_mean=0.110, reward_bound=0.000, batch=138\n",
      "1496: loss=0.727, reward_mean=0.190, reward_bound=0.000, batch=157\n",
      "1497: loss=0.721, reward_mean=0.170, reward_bound=0.000, batch=174\n",
      "1498: loss=0.718, reward_mean=0.130, reward_bound=0.000, batch=187\n",
      "1499: loss=0.709, reward_mean=0.170, reward_bound=0.005, batch=201\n",
      "1500: loss=0.710, reward_mean=0.150, reward_bound=0.012, batch=209\n",
      "1501: loss=0.704, reward_mean=0.170, reward_bound=0.028, batch=215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1502: loss=0.712, reward_mean=0.110, reward_bound=0.038, batch=216\n",
      "1503: loss=0.711, reward_mean=0.140, reward_bound=0.052, batch=217\n",
      "1504: loss=0.701, reward_mean=0.260, reward_bound=0.080, batch=220\n",
      "1505: loss=0.702, reward_mean=0.260, reward_bound=0.109, batch=219\n",
      "1506: loss=0.703, reward_mean=0.150, reward_bound=0.122, batch=222\n",
      "1507: loss=0.697, reward_mean=0.140, reward_bound=0.135, batch=214\n",
      "1508: loss=0.707, reward_mean=0.170, reward_bound=0.150, batch=208\n",
      "1509: loss=0.712, reward_mean=0.260, reward_bound=0.167, batch=212\n",
      "1510: loss=0.702, reward_mean=0.160, reward_bound=0.185, batch=208\n",
      "1511: loss=0.702, reward_mean=0.130, reward_bound=0.171, batch=215\n",
      "1512: loss=0.691, reward_mean=0.250, reward_bound=0.206, batch=201\n",
      "1513: loss=0.684, reward_mean=0.180, reward_bound=0.122, batch=210\n",
      "1514: loss=0.681, reward_mean=0.200, reward_bound=0.167, batch=216\n",
      "1515: loss=0.682, reward_mean=0.230, reward_bound=0.229, batch=196\n",
      "1516: loss=0.679, reward_mean=0.200, reward_bound=0.158, batch=207\n",
      "1517: loss=0.681, reward_mean=0.160, reward_bound=0.158, batch=215\n",
      "1518: loss=0.689, reward_mean=0.160, reward_bound=0.170, batch=220\n",
      "1519: loss=0.683, reward_mean=0.200, reward_bound=0.222, batch=224\n",
      "1520: loss=0.680, reward_mean=0.220, reward_bound=0.229, batch=226\n",
      "1521: loss=0.678, reward_mean=0.180, reward_bound=0.254, batch=207\n",
      "1522: loss=0.682, reward_mean=0.220, reward_bound=0.220, batch=215\n",
      "1523: loss=0.681, reward_mean=0.140, reward_bound=0.254, batch=218\n",
      "1524: loss=0.680, reward_mean=0.130, reward_bound=0.257, batch=222\n",
      "1525: loss=0.691, reward_mean=0.200, reward_bound=0.282, batch=191\n",
      "1526: loss=0.683, reward_mean=0.150, reward_bound=0.109, batch=203\n",
      "1527: loss=0.683, reward_mean=0.250, reward_bound=0.229, batch=211\n",
      "1528: loss=0.685, reward_mean=0.210, reward_bound=0.254, batch=215\n",
      "1529: loss=0.688, reward_mean=0.190, reward_bound=0.282, batch=214\n",
      "1530: loss=0.688, reward_mean=0.170, reward_bound=0.280, batch=220\n",
      "1531: loss=0.697, reward_mean=0.140, reward_bound=0.304, batch=224\n",
      "1532: loss=0.699, reward_mean=0.140, reward_bound=0.311, batch=227\n",
      "1533: loss=0.702, reward_mean=0.140, reward_bound=0.314, batch=184\n",
      "1534: loss=0.696, reward_mean=0.080, reward_bound=0.000, batch=192\n",
      "1535: loss=0.689, reward_mean=0.190, reward_bound=0.092, batch=204\n",
      "1536: loss=0.690, reward_mean=0.250, reward_bound=0.150, batch=210\n",
      "1537: loss=0.689, reward_mean=0.220, reward_bound=0.185, batch=212\n",
      "1538: loss=0.685, reward_mean=0.210, reward_bound=0.206, batch=220\n",
      "1539: loss=0.683, reward_mean=0.150, reward_bound=0.206, batch=227\n",
      "1540: loss=0.686, reward_mean=0.130, reward_bound=0.206, batch=223\n",
      "1541: loss=0.694, reward_mean=0.160, reward_bound=0.229, batch=221\n",
      "1542: loss=0.691, reward_mean=0.210, reward_bound=0.254, batch=221\n",
      "1543: loss=0.689, reward_mean=0.250, reward_bound=0.282, batch=220\n",
      "1544: loss=0.689, reward_mean=0.190, reward_bound=0.296, batch=224\n",
      "1545: loss=0.680, reward_mean=0.180, reward_bound=0.314, batch=217\n",
      "1546: loss=0.679, reward_mean=0.220, reward_bound=0.330, batch=222\n",
      "1547: loss=0.678, reward_mean=0.190, reward_bound=0.314, batch=224\n",
      "1548: loss=0.678, reward_mean=0.190, reward_bound=0.252, batch=227\n",
      "1549: loss=0.679, reward_mean=0.240, reward_bound=0.314, batch=228\n",
      "1550: loss=0.681, reward_mean=0.210, reward_bound=0.349, batch=178\n",
      "1551: loss=0.681, reward_mean=0.090, reward_bound=0.000, batch=187\n",
      "1552: loss=0.668, reward_mean=0.210, reward_bound=0.034, batch=201\n",
      "1553: loss=0.665, reward_mean=0.120, reward_bound=0.047, batch=210\n",
      "1554: loss=0.663, reward_mean=0.210, reward_bound=0.106, batch=217\n",
      "1555: loss=0.665, reward_mean=0.220, reward_bound=0.150, batch=220\n",
      "1556: loss=0.664, reward_mean=0.150, reward_bound=0.185, batch=220\n",
      "1557: loss=0.659, reward_mean=0.210, reward_bound=0.206, batch=228\n",
      "1558: loss=0.659, reward_mean=0.180, reward_bound=0.208, batch=229\n",
      "1559: loss=0.659, reward_mean=0.230, reward_bound=0.265, batch=230\n",
      "1560: loss=0.674, reward_mean=0.190, reward_bound=0.282, batch=214\n",
      "1561: loss=0.673, reward_mean=0.270, reward_bound=0.314, batch=212\n",
      "1562: loss=0.674, reward_mean=0.160, reward_bound=0.140, batch=218\n",
      "1563: loss=0.672, reward_mean=0.150, reward_bound=0.154, batch=222\n",
      "1564: loss=0.674, reward_mean=0.140, reward_bound=0.213, batch=225\n",
      "1565: loss=0.674, reward_mean=0.190, reward_bound=0.314, batch=226\n",
      "1566: loss=0.672, reward_mean=0.110, reward_bound=0.298, batch=228\n",
      "1567: loss=0.674, reward_mean=0.160, reward_bound=0.349, batch=215\n",
      "1568: loss=0.669, reward_mean=0.180, reward_bound=0.289, batch=220\n",
      "1569: loss=0.669, reward_mean=0.190, reward_bound=0.216, batch=224\n",
      "1570: loss=0.664, reward_mean=0.190, reward_bound=0.254, batch=226\n",
      "1571: loss=0.668, reward_mean=0.180, reward_bound=0.349, batch=225\n",
      "1572: loss=0.681, reward_mean=0.180, reward_bound=0.387, batch=154\n",
      "1573: loss=0.665, reward_mean=0.180, reward_bound=0.000, batch=172\n",
      "1574: loss=0.666, reward_mean=0.140, reward_bound=0.000, batch=186\n",
      "1575: loss=0.661, reward_mean=0.210, reward_bound=0.047, batch=199\n",
      "1576: loss=0.650, reward_mean=0.140, reward_bound=0.067, batch=209\n",
      "1577: loss=0.670, reward_mean=0.240, reward_bound=0.109, batch=211\n",
      "1578: loss=0.663, reward_mean=0.160, reward_bound=0.122, batch=217\n",
      "1579: loss=0.669, reward_mean=0.230, reward_bound=0.150, batch=220\n",
      "1580: loss=0.662, reward_mean=0.130, reward_bound=0.167, batch=220\n",
      "1581: loss=0.663, reward_mean=0.190, reward_bound=0.185, batch=222\n",
      "1582: loss=0.661, reward_mean=0.190, reward_bound=0.213, batch=225\n",
      "1583: loss=0.655, reward_mean=0.170, reward_bound=0.229, batch=224\n",
      "1584: loss=0.651, reward_mean=0.230, reward_bound=0.254, batch=226\n",
      "1585: loss=0.653, reward_mean=0.180, reward_bound=0.282, batch=216\n",
      "1586: loss=0.656, reward_mean=0.160, reward_bound=0.284, batch=221\n",
      "1587: loss=0.654, reward_mean=0.230, reward_bound=0.314, batch=214\n",
      "1588: loss=0.646, reward_mean=0.130, reward_bound=0.183, batch=220\n",
      "1589: loss=0.648, reward_mean=0.220, reward_bound=0.240, batch=224\n",
      "1590: loss=0.644, reward_mean=0.190, reward_bound=0.345, batch=227\n",
      "1591: loss=0.652, reward_mean=0.230, reward_bound=0.349, batch=208\n",
      "1592: loss=0.641, reward_mean=0.150, reward_bound=0.187, batch=215\n",
      "1593: loss=0.650, reward_mean=0.210, reward_bound=0.206, batch=218\n",
      "1594: loss=0.653, reward_mean=0.140, reward_bound=0.190, batch=222\n",
      "1595: loss=0.655, reward_mean=0.220, reward_bound=0.254, batch=221\n",
      "1596: loss=0.655, reward_mean=0.150, reward_bound=0.282, batch=223\n",
      "1597: loss=0.650, reward_mean=0.200, reward_bound=0.314, batch=225\n",
      "1598: loss=0.648, reward_mean=0.220, reward_bound=0.349, batch=221\n",
      "1599: loss=0.649, reward_mean=0.240, reward_bound=0.254, batch=224\n",
      "1600: loss=0.646, reward_mean=0.220, reward_bound=0.380, batch=227\n",
      "1601: loss=0.646, reward_mean=0.190, reward_bound=0.335, batch=229\n",
      "1602: loss=0.652, reward_mean=0.170, reward_bound=0.364, batch=230\n",
      "1603: loss=0.671, reward_mean=0.240, reward_bound=0.387, batch=212\n",
      "1604: loss=0.662, reward_mean=0.170, reward_bound=0.206, batch=218\n",
      "1605: loss=0.666, reward_mean=0.220, reward_bound=0.282, batch=221\n",
      "1606: loss=0.667, reward_mean=0.180, reward_bound=0.314, batch=222\n",
      "1607: loss=0.665, reward_mean=0.240, reward_bound=0.302, batch=225\n",
      "1608: loss=0.662, reward_mean=0.190, reward_bound=0.349, batch=225\n",
      "1609: loss=0.662, reward_mean=0.190, reward_bound=0.387, batch=225\n",
      "1610: loss=0.661, reward_mean=0.190, reward_bound=0.260, batch=227\n",
      "1611: loss=0.672, reward_mean=0.290, reward_bound=0.430, batch=133\n",
      "1612: loss=0.645, reward_mean=0.130, reward_bound=0.000, batch=146\n",
      "1613: loss=0.632, reward_mean=0.220, reward_bound=0.000, batch=168\n",
      "1614: loss=0.639, reward_mean=0.250, reward_bound=0.021, batch=187\n",
      "1615: loss=0.636, reward_mean=0.180, reward_bound=0.027, batch=201\n",
      "1616: loss=0.626, reward_mean=0.100, reward_bound=0.000, batch=210\n",
      "1617: loss=0.637, reward_mean=0.200, reward_bound=0.063, batch=217\n",
      "1618: loss=0.658, reward_mean=0.260, reward_bound=0.098, batch=219\n",
      "1619: loss=0.647, reward_mean=0.210, reward_bound=0.135, batch=220\n",
      "1620: loss=0.646, reward_mean=0.170, reward_bound=0.150, batch=222\n",
      "1621: loss=0.640, reward_mean=0.190, reward_bound=0.167, batch=220\n",
      "1622: loss=0.647, reward_mean=0.210, reward_bound=0.185, batch=215\n",
      "1623: loss=0.640, reward_mean=0.200, reward_bound=0.206, batch=212\n",
      "1624: loss=0.642, reward_mean=0.180, reward_bound=0.213, batch=218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1625: loss=0.643, reward_mean=0.240, reward_bound=0.229, batch=218\n",
      "1626: loss=0.654, reward_mean=0.230, reward_bound=0.254, batch=212\n",
      "1627: loss=0.648, reward_mean=0.220, reward_bound=0.198, batch=218\n",
      "1628: loss=0.649, reward_mean=0.300, reward_bound=0.282, batch=221\n",
      "1629: loss=0.661, reward_mean=0.250, reward_bound=0.314, batch=209\n",
      "1630: loss=0.670, reward_mean=0.310, reward_bound=0.349, batch=200\n",
      "1631: loss=0.657, reward_mean=0.240, reward_bound=0.162, batch=210\n",
      "1632: loss=0.652, reward_mean=0.210, reward_bound=0.167, batch=216\n",
      "1633: loss=0.653, reward_mean=0.230, reward_bound=0.217, batch=221\n",
      "1634: loss=0.664, reward_mean=0.220, reward_bound=0.254, batch=222\n",
      "1635: loss=0.662, reward_mean=0.230, reward_bound=0.282, batch=223\n",
      "1636: loss=0.667, reward_mean=0.190, reward_bound=0.314, batch=221\n",
      "1637: loss=0.664, reward_mean=0.300, reward_bound=0.349, batch=220\n",
      "1638: loss=0.668, reward_mean=0.200, reward_bound=0.274, batch=224\n",
      "1639: loss=0.668, reward_mean=0.300, reward_bound=0.345, batch=227\n",
      "1640: loss=0.665, reward_mean=0.220, reward_bound=0.349, batch=228\n",
      "1641: loss=0.668, reward_mean=0.260, reward_bound=0.387, batch=201\n",
      "1642: loss=0.663, reward_mean=0.170, reward_bound=0.206, batch=210\n",
      "1643: loss=0.659, reward_mean=0.200, reward_bound=0.229, batch=215\n",
      "1644: loss=0.658, reward_mean=0.170, reward_bound=0.254, batch=218\n",
      "1645: loss=0.654, reward_mean=0.220, reward_bound=0.286, batch=222\n",
      "1646: loss=0.662, reward_mean=0.250, reward_bound=0.314, batch=221\n",
      "1647: loss=0.659, reward_mean=0.180, reward_bound=0.229, batch=224\n",
      "1648: loss=0.659, reward_mean=0.210, reward_bound=0.349, batch=222\n",
      "1649: loss=0.657, reward_mean=0.250, reward_bound=0.387, batch=220\n",
      "1650: loss=0.654, reward_mean=0.220, reward_bound=0.222, batch=224\n",
      "1651: loss=0.652, reward_mean=0.200, reward_bound=0.314, batch=226\n",
      "1652: loss=0.651, reward_mean=0.240, reward_bound=0.301, batch=228\n",
      "1653: loss=0.654, reward_mean=0.230, reward_bound=0.387, batch=226\n",
      "1654: loss=0.653, reward_mean=0.160, reward_bound=0.387, batch=227\n",
      "1655: loss=0.663, reward_mean=0.190, reward_bound=0.430, batch=189\n",
      "1656: loss=0.657, reward_mean=0.240, reward_bound=0.079, batch=202\n",
      "1657: loss=0.640, reward_mean=0.190, reward_bound=0.122, batch=210\n",
      "1658: loss=0.630, reward_mean=0.220, reward_bound=0.146, batch=217\n",
      "1659: loss=0.629, reward_mean=0.110, reward_bound=0.163, batch=222\n",
      "1660: loss=0.627, reward_mean=0.250, reward_bound=0.206, batch=230\n",
      "1661: loss=0.630, reward_mean=0.150, reward_bound=0.206, batch=235\n",
      "1662: loss=0.651, reward_mean=0.280, reward_bound=0.229, batch=228\n",
      "1663: loss=0.659, reward_mean=0.180, reward_bound=0.254, batch=225\n",
      "1664: loss=0.663, reward_mean=0.200, reward_bound=0.282, batch=217\n",
      "1665: loss=0.667, reward_mean=0.160, reward_bound=0.182, batch=222\n",
      "1666: loss=0.671, reward_mean=0.210, reward_bound=0.292, batch=225\n",
      "1667: loss=0.666, reward_mean=0.180, reward_bound=0.314, batch=221\n",
      "1668: loss=0.665, reward_mean=0.220, reward_bound=0.282, batch=224\n",
      "1669: loss=0.658, reward_mean=0.240, reward_bound=0.349, batch=217\n",
      "1670: loss=0.656, reward_mean=0.230, reward_bound=0.349, batch=221\n",
      "1671: loss=0.662, reward_mean=0.220, reward_bound=0.282, batch=224\n",
      "1672: loss=0.655, reward_mean=0.230, reward_bound=0.349, batch=225\n",
      "1673: loss=0.655, reward_mean=0.220, reward_bound=0.321, batch=227\n",
      "1674: loss=0.656, reward_mean=0.180, reward_bound=0.349, batch=228\n",
      "1675: loss=0.656, reward_mean=0.230, reward_bound=0.387, batch=217\n",
      "1676: loss=0.656, reward_mean=0.250, reward_bound=0.380, batch=222\n",
      "1677: loss=0.657, reward_mean=0.180, reward_bound=0.360, batch=225\n",
      "1678: loss=0.656, reward_mean=0.110, reward_bound=0.387, batch=226\n",
      "1679: loss=0.662, reward_mean=0.210, reward_bound=0.430, batch=208\n",
      "1680: loss=0.665, reward_mean=0.260, reward_bound=0.282, batch=214\n",
      "1681: loss=0.665, reward_mean=0.190, reward_bound=0.249, batch=220\n",
      "1682: loss=0.657, reward_mean=0.220, reward_bound=0.304, batch=224\n",
      "1683: loss=0.658, reward_mean=0.260, reward_bound=0.314, batch=225\n",
      "1684: loss=0.662, reward_mean=0.180, reward_bound=0.349, batch=225\n",
      "1685: loss=0.660, reward_mean=0.230, reward_bound=0.356, batch=227\n",
      "1686: loss=0.660, reward_mean=0.170, reward_bound=0.302, batch=229\n",
      "1687: loss=0.662, reward_mean=0.210, reward_bound=0.314, batch=229\n",
      "1688: loss=0.664, reward_mean=0.230, reward_bound=0.387, batch=226\n",
      "1689: loss=0.663, reward_mean=0.190, reward_bound=0.356, batch=228\n",
      "1690: loss=0.662, reward_mean=0.270, reward_bound=0.392, batch=229\n",
      "1691: loss=0.662, reward_mean=0.280, reward_bound=0.430, batch=220\n",
      "1692: loss=0.657, reward_mean=0.220, reward_bound=0.266, batch=224\n",
      "1693: loss=0.660, reward_mean=0.170, reward_bound=0.345, batch=227\n",
      "1694: loss=0.658, reward_mean=0.190, reward_bound=0.292, batch=229\n",
      "1695: loss=0.659, reward_mean=0.220, reward_bound=0.387, batch=226\n",
      "1696: loss=0.658, reward_mean=0.170, reward_bound=0.409, batch=228\n",
      "1697: loss=0.663, reward_mean=0.180, reward_bound=0.430, batch=225\n",
      "1698: loss=0.665, reward_mean=0.190, reward_bound=0.406, batch=227\n",
      "1699: loss=0.664, reward_mean=0.220, reward_bound=0.380, batch=229\n",
      "1700: loss=0.664, reward_mean=0.230, reward_bound=0.430, batch=228\n",
      "1701: loss=0.665, reward_mean=0.210, reward_bound=0.435, batch=229\n",
      "1702: loss=0.665, reward_mean=0.200, reward_bound=0.314, batch=229\n",
      "1703: loss=0.663, reward_mean=0.190, reward_bound=0.342, batch=230\n",
      "1704: loss=0.662, reward_mean=0.180, reward_bound=0.464, batch=231\n",
      "1705: loss=0.679, reward_mean=0.190, reward_bound=0.478, batch=104\n",
      "1706: loss=0.647, reward_mean=0.230, reward_bound=0.000, batch=127\n",
      "1707: loss=0.620, reward_mean=0.190, reward_bound=0.000, batch=146\n",
      "1708: loss=0.627, reward_mean=0.290, reward_bound=0.001, batch=171\n",
      "1709: loss=0.624, reward_mean=0.280, reward_bound=0.013, batch=189\n",
      "1710: loss=0.629, reward_mean=0.240, reward_bound=0.034, batch=202\n",
      "1711: loss=0.632, reward_mean=0.260, reward_bound=0.058, batch=210\n",
      "1712: loss=0.628, reward_mean=0.160, reward_bound=0.072, batch=216\n",
      "1713: loss=0.614, reward_mean=0.180, reward_bound=0.104, batch=221\n",
      "1714: loss=0.621, reward_mean=0.180, reward_bound=0.109, batch=224\n",
      "1715: loss=0.635, reward_mean=0.250, reward_bound=0.135, batch=216\n",
      "1716: loss=0.640, reward_mean=0.290, reward_bound=0.167, batch=203\n",
      "1717: loss=0.635, reward_mean=0.200, reward_bound=0.185, batch=206\n",
      "1718: loss=0.629, reward_mean=0.240, reward_bound=0.143, batch=214\n",
      "1719: loss=0.629, reward_mean=0.150, reward_bound=0.206, batch=205\n",
      "1720: loss=0.639, reward_mean=0.180, reward_bound=0.229, batch=198\n",
      "1721: loss=0.638, reward_mean=0.200, reward_bound=0.208, batch=208\n",
      "1722: loss=0.637, reward_mean=0.220, reward_bound=0.206, batch=214\n",
      "1723: loss=0.630, reward_mean=0.200, reward_bound=0.252, batch=220\n",
      "1724: loss=0.640, reward_mean=0.150, reward_bound=0.254, batch=201\n",
      "1725: loss=0.637, reward_mean=0.220, reward_bound=0.229, batch=207\n",
      "1726: loss=0.636, reward_mean=0.220, reward_bound=0.182, batch=215\n",
      "1727: loss=0.643, reward_mean=0.270, reward_bound=0.229, batch=219\n",
      "1728: loss=0.655, reward_mean=0.230, reward_bound=0.282, batch=203\n",
      "1729: loss=0.650, reward_mean=0.190, reward_bound=0.185, batch=211\n",
      "1730: loss=0.659, reward_mean=0.270, reward_bound=0.282, batch=216\n",
      "1731: loss=0.659, reward_mean=0.210, reward_bound=0.298, batch=221\n",
      "1732: loss=0.671, reward_mean=0.190, reward_bound=0.314, batch=202\n",
      "1733: loss=0.678, reward_mean=0.190, reward_bound=0.150, batch=211\n",
      "1734: loss=0.671, reward_mean=0.300, reward_bound=0.314, batch=214\n",
      "1735: loss=0.672, reward_mean=0.300, reward_bound=0.314, batch=219\n",
      "1736: loss=0.673, reward_mean=0.180, reward_bound=0.237, batch=223\n",
      "1737: loss=0.684, reward_mean=0.200, reward_bound=0.349, batch=207\n",
      "1738: loss=0.685, reward_mean=0.180, reward_bound=0.245, batch=215\n",
      "1739: loss=0.677, reward_mean=0.200, reward_bound=0.254, batch=219\n",
      "1740: loss=0.678, reward_mean=0.290, reward_bound=0.282, batch=219\n",
      "1741: loss=0.683, reward_mean=0.210, reward_bound=0.349, batch=218\n",
      "1742: loss=0.684, reward_mean=0.280, reward_bound=0.314, batch=221\n",
      "1743: loss=0.682, reward_mean=0.170, reward_bound=0.314, batch=222\n",
      "1744: loss=0.683, reward_mean=0.200, reward_bound=0.292, batch=225\n",
      "1745: loss=0.680, reward_mean=0.200, reward_bound=0.356, batch=227\n",
      "1746: loss=0.680, reward_mean=0.230, reward_bound=0.349, batch=228\n",
      "1747: loss=0.677, reward_mean=0.160, reward_bound=0.387, batch=194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1748: loss=0.667, reward_mean=0.200, reward_bound=0.204, batch=206\n",
      "1749: loss=0.663, reward_mean=0.180, reward_bound=0.196, batch=214\n",
      "1750: loss=0.664, reward_mean=0.270, reward_bound=0.206, batch=216\n",
      "1751: loss=0.668, reward_mean=0.230, reward_bound=0.254, batch=219\n",
      "1752: loss=0.665, reward_mean=0.170, reward_bound=0.282, batch=216\n",
      "1753: loss=0.667, reward_mean=0.210, reward_bound=0.314, batch=217\n",
      "1754: loss=0.669, reward_mean=0.220, reward_bound=0.229, batch=221\n",
      "1755: loss=0.669, reward_mean=0.160, reward_bound=0.314, batch=224\n",
      "1756: loss=0.671, reward_mean=0.160, reward_bound=0.252, batch=227\n",
      "1757: loss=0.669, reward_mean=0.180, reward_bound=0.308, batch=229\n",
      "1758: loss=0.671, reward_mean=0.240, reward_bound=0.349, batch=222\n",
      "1759: loss=0.671, reward_mean=0.210, reward_bound=0.282, batch=224\n",
      "1760: loss=0.670, reward_mean=0.150, reward_bound=0.342, batch=227\n",
      "1761: loss=0.672, reward_mean=0.240, reward_bound=0.349, batch=228\n",
      "1762: loss=0.671, reward_mean=0.110, reward_bound=0.353, batch=229\n",
      "1763: loss=0.666, reward_mean=0.180, reward_bound=0.387, batch=222\n",
      "1764: loss=0.664, reward_mean=0.210, reward_bound=0.302, batch=225\n",
      "1765: loss=0.662, reward_mean=0.210, reward_bound=0.356, batch=227\n",
      "1766: loss=0.660, reward_mean=0.170, reward_bound=0.380, batch=229\n",
      "1767: loss=0.658, reward_mean=0.190, reward_bound=0.343, batch=230\n",
      "1768: loss=0.657, reward_mean=0.170, reward_bound=0.365, batch=231\n",
      "1769: loss=0.657, reward_mean=0.220, reward_bound=0.387, batch=231\n",
      "1770: loss=0.657, reward_mean=0.190, reward_bound=0.430, batch=171\n",
      "1771: loss=0.634, reward_mean=0.220, reward_bound=0.018, batch=189\n",
      "1772: loss=0.635, reward_mean=0.180, reward_bound=0.034, batch=202\n",
      "1773: loss=0.643, reward_mean=0.230, reward_bound=0.092, batch=211\n",
      "1774: loss=0.642, reward_mean=0.190, reward_bound=0.150, batch=214\n",
      "1775: loss=0.642, reward_mean=0.250, reward_bound=0.185, batch=219\n",
      "1776: loss=0.637, reward_mean=0.200, reward_bound=0.206, batch=216\n",
      "1777: loss=0.637, reward_mean=0.210, reward_bound=0.217, batch=221\n",
      "1778: loss=0.640, reward_mean=0.210, reward_bound=0.229, batch=217\n",
      "1779: loss=0.643, reward_mean=0.200, reward_bound=0.254, batch=218\n",
      "1780: loss=0.646, reward_mean=0.260, reward_bound=0.282, batch=210\n",
      "1781: loss=0.652, reward_mean=0.220, reward_bound=0.222, batch=217\n",
      "1782: loss=0.652, reward_mean=0.190, reward_bound=0.249, batch=222\n",
      "1783: loss=0.657, reward_mean=0.200, reward_bound=0.254, batch=224\n",
      "1784: loss=0.646, reward_mean=0.280, reward_bound=0.282, batch=225\n",
      "1785: loss=0.645, reward_mean=0.210, reward_bound=0.314, batch=216\n",
      "1786: loss=0.652, reward_mean=0.230, reward_bound=0.220, batch=221\n",
      "1787: loss=0.650, reward_mean=0.290, reward_bound=0.349, batch=206\n",
      "1788: loss=0.639, reward_mean=0.160, reward_bound=0.130, batch=214\n",
      "1789: loss=0.647, reward_mean=0.230, reward_bound=0.185, batch=218\n",
      "1790: loss=0.646, reward_mean=0.210, reward_bound=0.282, batch=220\n",
      "1791: loss=0.651, reward_mean=0.270, reward_bound=0.349, batch=220\n",
      "1792: loss=0.650, reward_mean=0.280, reward_bound=0.376, batch=224\n",
      "1793: loss=0.650, reward_mean=0.270, reward_bound=0.349, batch=225\n",
      "1794: loss=0.649, reward_mean=0.210, reward_bound=0.321, batch=227\n",
      "1795: loss=0.647, reward_mean=0.200, reward_bound=0.342, batch=229\n",
      "1796: loss=0.645, reward_mean=0.260, reward_bound=0.364, batch=230\n",
      "1797: loss=0.641, reward_mean=0.280, reward_bound=0.387, batch=212\n",
      "1798: loss=0.638, reward_mean=0.280, reward_bound=0.229, batch=217\n",
      "1799: loss=0.639, reward_mean=0.170, reward_bound=0.216, batch=222\n",
      "1800: loss=0.638, reward_mean=0.250, reward_bound=0.263, batch=225\n",
      "1801: loss=0.636, reward_mean=0.210, reward_bound=0.289, batch=227\n",
      "1802: loss=0.636, reward_mean=0.210, reward_bound=0.314, batch=228\n",
      "1803: loss=0.635, reward_mean=0.240, reward_bound=0.349, batch=224\n",
      "1804: loss=0.637, reward_mean=0.280, reward_bound=0.252, batch=227\n",
      "1805: loss=0.632, reward_mean=0.250, reward_bound=0.282, batch=227\n",
      "1806: loss=0.630, reward_mean=0.240, reward_bound=0.314, batch=228\n",
      "1807: loss=0.629, reward_mean=0.160, reward_bound=0.317, batch=229\n",
      "1808: loss=0.633, reward_mean=0.240, reward_bound=0.364, batch=230\n",
      "1809: loss=0.637, reward_mean=0.210, reward_bound=0.387, batch=225\n",
      "1810: loss=0.639, reward_mean=0.250, reward_bound=0.396, batch=227\n",
      "1811: loss=0.641, reward_mean=0.200, reward_bound=0.314, batch=228\n",
      "1812: loss=0.640, reward_mean=0.230, reward_bound=0.392, batch=229\n",
      "1813: loss=0.643, reward_mean=0.240, reward_bound=0.430, batch=208\n",
      "1814: loss=0.632, reward_mean=0.220, reward_bound=0.206, batch=214\n",
      "1815: loss=0.635, reward_mean=0.220, reward_bound=0.185, batch=219\n",
      "1816: loss=0.633, reward_mean=0.200, reward_bound=0.185, batch=222\n",
      "1817: loss=0.633, reward_mean=0.200, reward_bound=0.229, batch=224\n",
      "1818: loss=0.634, reward_mean=0.240, reward_bound=0.280, batch=227\n",
      "1819: loss=0.637, reward_mean=0.180, reward_bound=0.277, batch=229\n",
      "1820: loss=0.632, reward_mean=0.260, reward_bound=0.282, batch=227\n",
      "1821: loss=0.629, reward_mean=0.240, reward_bound=0.314, batch=227\n",
      "1822: loss=0.629, reward_mean=0.230, reward_bound=0.314, batch=228\n",
      "1823: loss=0.637, reward_mean=0.140, reward_bound=0.353, batch=229\n",
      "1824: loss=0.632, reward_mean=0.220, reward_bound=0.387, batch=222\n",
      "1825: loss=0.634, reward_mean=0.180, reward_bound=0.283, batch=225\n",
      "1826: loss=0.633, reward_mean=0.220, reward_bound=0.321, batch=227\n",
      "1827: loss=0.629, reward_mean=0.250, reward_bound=0.422, batch=229\n",
      "1828: loss=0.628, reward_mean=0.180, reward_bound=0.405, batch=230\n",
      "1829: loss=0.628, reward_mean=0.240, reward_bound=0.418, batch=231\n",
      "1830: loss=0.638, reward_mean=0.280, reward_bound=0.430, batch=222\n",
      "1831: loss=0.638, reward_mean=0.200, reward_bound=0.292, batch=225\n",
      "1832: loss=0.639, reward_mean=0.250, reward_bound=0.349, batch=226\n",
      "1833: loss=0.639, reward_mean=0.180, reward_bound=0.387, batch=227\n",
      "1834: loss=0.642, reward_mean=0.210, reward_bound=0.373, batch=229\n",
      "1835: loss=0.636, reward_mean=0.290, reward_bound=0.387, batch=229\n",
      "1836: loss=0.635, reward_mean=0.310, reward_bound=0.405, batch=230\n",
      "1837: loss=0.634, reward_mean=0.230, reward_bound=0.430, batch=225\n",
      "1838: loss=0.632, reward_mean=0.250, reward_bound=0.254, batch=226\n",
      "1839: loss=0.634, reward_mean=0.210, reward_bound=0.430, batch=225\n",
      "1840: loss=0.637, reward_mean=0.250, reward_bound=0.321, batch=227\n",
      "1841: loss=0.633, reward_mean=0.280, reward_bound=0.460, batch=229\n",
      "1842: loss=0.632, reward_mean=0.200, reward_bound=0.450, batch=230\n",
      "1843: loss=0.632, reward_mean=0.190, reward_bound=0.387, batch=230\n",
      "1844: loss=0.632, reward_mean=0.210, reward_bound=0.430, batch=230\n",
      "1845: loss=0.630, reward_mean=0.180, reward_bound=0.464, batch=231\n",
      "1846: loss=0.644, reward_mean=0.250, reward_bound=0.478, batch=158\n",
      "1847: loss=0.613, reward_mean=0.200, reward_bound=0.000, batch=178\n",
      "1848: loss=0.615, reward_mean=0.260, reward_bound=0.038, batch=193\n",
      "1849: loss=0.628, reward_mean=0.270, reward_bound=0.072, batch=203\n",
      "1850: loss=0.626, reward_mean=0.210, reward_bound=0.095, batch=212\n",
      "1851: loss=0.612, reward_mean=0.310, reward_bound=0.135, batch=217\n",
      "1852: loss=0.614, reward_mean=0.170, reward_bound=0.167, batch=221\n",
      "1853: loss=0.617, reward_mean=0.170, reward_bound=0.185, batch=222\n",
      "1854: loss=0.617, reward_mean=0.220, reward_bound=0.229, batch=221\n",
      "1855: loss=0.613, reward_mean=0.210, reward_bound=0.254, batch=217\n",
      "1856: loss=0.614, reward_mean=0.280, reward_bound=0.229, batch=221\n",
      "1857: loss=0.612, reward_mean=0.160, reward_bound=0.185, batch=224\n",
      "1858: loss=0.622, reward_mean=0.190, reward_bound=0.282, batch=211\n",
      "1859: loss=0.627, reward_mean=0.290, reward_bound=0.314, batch=202\n",
      "1860: loss=0.629, reward_mean=0.290, reward_bound=0.282, batch=210\n",
      "1861: loss=0.622, reward_mean=0.240, reward_bound=0.254, batch=215\n",
      "1862: loss=0.617, reward_mean=0.240, reward_bound=0.210, batch=220\n",
      "1863: loss=0.619, reward_mean=0.190, reward_bound=0.210, batch=224\n",
      "1864: loss=0.623, reward_mean=0.220, reward_bound=0.282, batch=224\n",
      "1865: loss=0.617, reward_mean=0.160, reward_bound=0.200, batch=227\n",
      "1866: loss=0.630, reward_mean=0.270, reward_bound=0.314, batch=226\n",
      "1867: loss=0.628, reward_mean=0.240, reward_bound=0.316, batch=228\n",
      "1868: loss=0.632, reward_mean=0.170, reward_bound=0.349, batch=201\n",
      "1869: loss=0.632, reward_mean=0.220, reward_bound=0.206, batch=210\n",
      "1870: loss=0.626, reward_mean=0.200, reward_bound=0.229, batch=215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1871: loss=0.625, reward_mean=0.190, reward_bound=0.229, batch=219\n",
      "1872: loss=0.635, reward_mean=0.240, reward_bound=0.265, batch=223\n",
      "1873: loss=0.633, reward_mean=0.210, reward_bound=0.282, batch=224\n",
      "1874: loss=0.628, reward_mean=0.160, reward_bound=0.311, batch=227\n",
      "1875: loss=0.633, reward_mean=0.200, reward_bound=0.314, batch=226\n",
      "1876: loss=0.624, reward_mean=0.280, reward_bound=0.349, batch=219\n",
      "1877: loss=0.624, reward_mean=0.230, reward_bound=0.309, batch=223\n",
      "1878: loss=0.620, reward_mean=0.190, reward_bound=0.290, batch=226\n",
      "1879: loss=0.620, reward_mean=0.180, reward_bound=0.331, batch=228\n",
      "1880: loss=0.624, reward_mean=0.210, reward_bound=0.387, batch=206\n",
      "1881: loss=0.620, reward_mean=0.190, reward_bound=0.176, batch=214\n",
      "1882: loss=0.624, reward_mean=0.240, reward_bound=0.280, batch=220\n",
      "1883: loss=0.625, reward_mean=0.170, reward_bound=0.206, batch=225\n",
      "1884: loss=0.630, reward_mean=0.220, reward_bound=0.234, batch=227\n",
      "1885: loss=0.624, reward_mean=0.160, reward_bound=0.254, batch=228\n",
      "1886: loss=0.619, reward_mean=0.260, reward_bound=0.282, batch=226\n",
      "1887: loss=0.631, reward_mean=0.240, reward_bound=0.349, batch=225\n",
      "1888: loss=0.630, reward_mean=0.200, reward_bound=0.321, batch=227\n",
      "1889: loss=0.628, reward_mean=0.210, reward_bound=0.380, batch=229\n",
      "1890: loss=0.624, reward_mean=0.200, reward_bound=0.387, batch=225\n",
      "1891: loss=0.621, reward_mean=0.210, reward_bound=0.356, batch=227\n",
      "1892: loss=0.624, reward_mean=0.260, reward_bound=0.422, batch=229\n",
      "1893: loss=0.630, reward_mean=0.200, reward_bound=0.430, batch=198\n",
      "1894: loss=0.625, reward_mean=0.170, reward_bound=0.112, batch=208\n",
      "1895: loss=0.616, reward_mean=0.210, reward_bound=0.167, batch=214\n",
      "1896: loss=0.614, reward_mean=0.240, reward_bound=0.229, batch=219\n",
      "1897: loss=0.619, reward_mean=0.190, reward_bound=0.254, batch=218\n",
      "1898: loss=0.619, reward_mean=0.230, reward_bound=0.257, batch=222\n",
      "1899: loss=0.628, reward_mean=0.270, reward_bound=0.324, batch=225\n",
      "1900: loss=0.629, reward_mean=0.190, reward_bound=0.349, batch=223\n",
      "1901: loss=0.628, reward_mean=0.170, reward_bound=0.349, batch=224\n",
      "1902: loss=0.628, reward_mean=0.220, reward_bound=0.339, batch=227\n",
      "1903: loss=0.628, reward_mean=0.260, reward_bound=0.387, batch=216\n",
      "1904: loss=0.634, reward_mean=0.220, reward_bound=0.254, batch=220\n",
      "1905: loss=0.632, reward_mean=0.240, reward_bound=0.282, batch=223\n",
      "1906: loss=0.628, reward_mean=0.170, reward_bound=0.235, batch=226\n",
      "1907: loss=0.622, reward_mean=0.220, reward_bound=0.314, batch=225\n",
      "1908: loss=0.622, reward_mean=0.180, reward_bound=0.349, batch=223\n",
      "1909: loss=0.620, reward_mean=0.200, reward_bound=0.349, batch=225\n",
      "1910: loss=0.623, reward_mean=0.250, reward_bound=0.387, batch=226\n",
      "1911: loss=0.626, reward_mean=0.170, reward_bound=0.387, batch=227\n",
      "1912: loss=0.623, reward_mean=0.180, reward_bound=0.373, batch=229\n",
      "1913: loss=0.626, reward_mean=0.250, reward_bound=0.430, batch=221\n",
      "1914: loss=0.625, reward_mean=0.280, reward_bound=0.387, batch=223\n",
      "1915: loss=0.624, reward_mean=0.250, reward_bound=0.387, batch=225\n",
      "1916: loss=0.622, reward_mean=0.230, reward_bound=0.396, batch=227\n",
      "1917: loss=0.625, reward_mean=0.250, reward_bound=0.430, batch=225\n",
      "1918: loss=0.623, reward_mean=0.200, reward_bound=0.406, batch=227\n",
      "1919: loss=0.621, reward_mean=0.210, reward_bound=0.460, batch=229\n",
      "1920: loss=0.620, reward_mean=0.240, reward_bound=0.401, batch=230\n",
      "1921: loss=0.623, reward_mean=0.210, reward_bound=0.478, batch=185\n",
      "1922: loss=0.601, reward_mean=0.270, reward_bound=0.098, batch=197\n",
      "1923: loss=0.593, reward_mean=0.230, reward_bound=0.135, batch=207\n",
      "1924: loss=0.594, reward_mean=0.280, reward_bound=0.163, batch=215\n",
      "1925: loss=0.609, reward_mean=0.300, reward_bound=0.189, batch=220\n",
      "1926: loss=0.603, reward_mean=0.150, reward_bound=0.206, batch=226\n",
      "1927: loss=0.612, reward_mean=0.170, reward_bound=0.217, batch=228\n",
      "1928: loss=0.607, reward_mean=0.370, reward_bound=0.254, batch=226\n",
      "1929: loss=0.616, reward_mean=0.220, reward_bound=0.282, batch=219\n",
      "1930: loss=0.618, reward_mean=0.230, reward_bound=0.314, batch=220\n",
      "1931: loss=0.617, reward_mean=0.210, reward_bound=0.304, batch=224\n",
      "1932: loss=0.617, reward_mean=0.200, reward_bound=0.206, batch=226\n",
      "1933: loss=0.620, reward_mean=0.210, reward_bound=0.314, batch=226\n",
      "1934: loss=0.616, reward_mean=0.230, reward_bound=0.349, batch=217\n",
      "1935: loss=0.615, reward_mean=0.190, reward_bound=0.229, batch=220\n",
      "1936: loss=0.610, reward_mean=0.260, reward_bound=0.376, batch=224\n",
      "1937: loss=0.615, reward_mean=0.210, reward_bound=0.280, batch=227\n",
      "1938: loss=0.607, reward_mean=0.240, reward_bound=0.308, batch=229\n",
      "1939: loss=0.609, reward_mean=0.180, reward_bound=0.314, batch=229\n",
      "1940: loss=0.609, reward_mean=0.220, reward_bound=0.349, batch=228\n",
      "1941: loss=0.608, reward_mean=0.240, reward_bound=0.387, batch=221\n",
      "1942: loss=0.608, reward_mean=0.250, reward_bound=0.387, batch=223\n",
      "1943: loss=0.608, reward_mean=0.240, reward_bound=0.349, batch=225\n",
      "1944: loss=0.608, reward_mean=0.240, reward_bound=0.387, batch=224\n",
      "1945: loss=0.606, reward_mean=0.260, reward_bound=0.426, batch=227\n",
      "1946: loss=0.618, reward_mean=0.180, reward_bound=0.430, batch=198\n",
      "1947: loss=0.617, reward_mean=0.230, reward_bound=0.314, batch=207\n",
      "1948: loss=0.613, reward_mean=0.180, reward_bound=0.206, batch=214\n",
      "1949: loss=0.619, reward_mean=0.200, reward_bound=0.280, batch=220\n",
      "1950: loss=0.621, reward_mean=0.190, reward_bound=0.282, batch=222\n",
      "1951: loss=0.621, reward_mean=0.210, reward_bound=0.263, batch=225\n",
      "1952: loss=0.618, reward_mean=0.190, reward_bound=0.314, batch=225\n",
      "1953: loss=0.619, reward_mean=0.180, reward_bound=0.234, batch=227\n",
      "1954: loss=0.632, reward_mean=0.320, reward_bound=0.349, batch=219\n",
      "1955: loss=0.630, reward_mean=0.260, reward_bound=0.349, batch=222\n",
      "1956: loss=0.624, reward_mean=0.210, reward_bound=0.387, batch=218\n",
      "1957: loss=0.623, reward_mean=0.180, reward_bound=0.387, batch=220\n",
      "1958: loss=0.620, reward_mean=0.200, reward_bound=0.304, batch=224\n",
      "1959: loss=0.622, reward_mean=0.190, reward_bound=0.349, batch=226\n",
      "1960: loss=0.622, reward_mean=0.190, reward_bound=0.387, batch=226\n",
      "1961: loss=0.619, reward_mean=0.200, reward_bound=0.368, batch=228\n",
      "1962: loss=0.619, reward_mean=0.190, reward_bound=0.349, batch=228\n",
      "1963: loss=0.619, reward_mean=0.240, reward_bound=0.387, batch=228\n",
      "1964: loss=0.619, reward_mean=0.170, reward_bound=0.314, batch=228\n",
      "1965: loss=0.619, reward_mean=0.200, reward_bound=0.392, batch=229\n",
      "1966: loss=0.617, reward_mean=0.230, reward_bound=0.328, batch=230\n",
      "1967: loss=0.620, reward_mean=0.310, reward_bound=0.387, batch=230\n",
      "1968: loss=0.618, reward_mean=0.230, reward_bound=0.329, batch=231\n",
      "1969: loss=0.620, reward_mean=0.270, reward_bound=0.387, batch=230\n",
      "1970: loss=0.619, reward_mean=0.240, reward_bound=0.430, batch=224\n",
      "1971: loss=0.619, reward_mean=0.230, reward_bound=0.384, batch=227\n",
      "1972: loss=0.623, reward_mean=0.290, reward_bound=0.430, batch=227\n",
      "1973: loss=0.623, reward_mean=0.200, reward_bound=0.387, batch=228\n",
      "1974: loss=0.624, reward_mean=0.250, reward_bound=0.478, batch=231\n",
      "1975: loss=0.624, reward_mean=0.230, reward_bound=0.430, batch=231\n",
      "1976: loss=0.621, reward_mean=0.240, reward_bound=0.478, batch=210\n",
      "1977: loss=0.615, reward_mean=0.270, reward_bound=0.338, batch=217\n",
      "1978: loss=0.614, reward_mean=0.170, reward_bound=0.277, batch=222\n",
      "1979: loss=0.617, reward_mean=0.270, reward_bound=0.349, batch=224\n",
      "1980: loss=0.616, reward_mean=0.230, reward_bound=0.308, batch=227\n",
      "1981: loss=0.616, reward_mean=0.260, reward_bound=0.380, batch=229\n",
      "1982: loss=0.619, reward_mean=0.270, reward_bound=0.387, batch=226\n",
      "1983: loss=0.617, reward_mean=0.190, reward_bound=0.349, batch=227\n",
      "1984: loss=0.616, reward_mean=0.200, reward_bound=0.407, batch=229\n",
      "1985: loss=0.615, reward_mean=0.230, reward_bound=0.381, batch=230\n",
      "1986: loss=0.627, reward_mean=0.200, reward_bound=0.430, batch=222\n",
      "1987: loss=0.627, reward_mean=0.220, reward_bound=0.400, batch=225\n",
      "1988: loss=0.628, reward_mean=0.170, reward_bound=0.430, batch=223\n",
      "1989: loss=0.629, reward_mean=0.250, reward_bound=0.244, batch=226\n",
      "1990: loss=0.626, reward_mean=0.230, reward_bound=0.284, batch=228\n",
      "1991: loss=0.624, reward_mean=0.220, reward_bound=0.317, batch=229\n",
      "1992: loss=0.623, reward_mean=0.230, reward_bound=0.328, batch=230\n",
      "1993: loss=0.624, reward_mean=0.240, reward_bound=0.387, batch=227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994: loss=0.622, reward_mean=0.220, reward_bound=0.422, batch=229\n",
      "1995: loss=0.622, reward_mean=0.220, reward_bound=0.430, batch=228\n",
      "1996: loss=0.620, reward_mean=0.200, reward_bound=0.478, batch=230\n",
      "1997: loss=0.620, reward_mean=0.280, reward_bound=0.418, batch=231\n",
      "1998: loss=0.619, reward_mean=0.220, reward_bound=0.430, batch=231\n",
      "1999: loss=0.616, reward_mean=0.170, reward_bound=0.478, batch=221\n",
      "2000: loss=0.613, reward_mean=0.330, reward_bound=0.387, batch=224\n",
      "2001: loss=0.616, reward_mean=0.200, reward_bound=0.430, batch=223\n",
      "2002: loss=0.616, reward_mean=0.260, reward_bound=0.335, batch=226\n",
      "2003: loss=0.618, reward_mean=0.260, reward_bound=0.349, batch=227\n",
      "2004: loss=0.619, reward_mean=0.260, reward_bound=0.380, batch=229\n",
      "2005: loss=0.619, reward_mean=0.240, reward_bound=0.405, batch=230\n",
      "2006: loss=0.617, reward_mean=0.220, reward_bound=0.418, batch=231\n",
      "2007: loss=0.617, reward_mean=0.220, reward_bound=0.430, batch=229\n",
      "2008: loss=0.616, reward_mean=0.220, reward_bound=0.450, batch=230\n",
      "2009: loss=0.616, reward_mean=0.240, reward_bound=0.451, batch=231\n",
      "2010: loss=0.616, reward_mean=0.210, reward_bound=0.430, batch=231\n",
      "2011: loss=0.614, reward_mean=0.250, reward_bound=0.478, batch=226\n",
      "2012: loss=0.614, reward_mean=0.150, reward_bound=0.390, batch=228\n",
      "2013: loss=0.613, reward_mean=0.170, reward_bound=0.297, batch=229\n",
      "2014: loss=0.613, reward_mean=0.210, reward_bound=0.430, batch=227\n",
      "2015: loss=0.609, reward_mean=0.170, reward_bound=0.373, batch=229\n",
      "2016: loss=0.615, reward_mean=0.240, reward_bound=0.387, batch=229\n",
      "2017: loss=0.613, reward_mean=0.240, reward_bound=0.405, batch=230\n",
      "2018: loss=0.611, reward_mean=0.240, reward_bound=0.430, batch=229\n",
      "2019: loss=0.610, reward_mean=0.250, reward_bound=0.424, batch=230\n",
      "2020: loss=0.610, reward_mean=0.260, reward_bound=0.429, batch=231\n",
      "2021: loss=0.611, reward_mean=0.180, reward_bound=0.478, batch=229\n",
      "2022: loss=0.611, reward_mean=0.290, reward_bound=0.387, batch=229\n",
      "2023: loss=0.611, reward_mean=0.260, reward_bound=0.349, batch=229\n",
      "2024: loss=0.611, reward_mean=0.190, reward_bound=0.430, batch=229\n",
      "2025: loss=0.610, reward_mean=0.230, reward_bound=0.450, batch=230\n",
      "2026: loss=0.610, reward_mean=0.180, reward_bound=0.365, batch=231\n",
      "2027: loss=0.610, reward_mean=0.200, reward_bound=0.387, batch=231\n",
      "2028: loss=0.610, reward_mean=0.210, reward_bound=0.430, batch=231\n",
      "2029: loss=0.610, reward_mean=0.220, reward_bound=0.387, batch=231\n",
      "2030: loss=0.611, reward_mean=0.260, reward_bound=0.478, batch=230\n",
      "2031: loss=0.609, reward_mean=0.230, reward_bound=0.418, batch=231\n",
      "2032: loss=0.612, reward_mean=0.260, reward_bound=0.430, batch=231\n",
      "2034: loss=0.541, reward_mean=0.240, reward_bound=0.000, batch=24\n",
      "2035: loss=0.524, reward_mean=0.230, reward_bound=0.000, batch=47\n",
      "2036: loss=0.534, reward_mean=0.230, reward_bound=0.000, batch=70\n",
      "2037: loss=0.527, reward_mean=0.280, reward_bound=0.000, batch=98\n",
      "2038: loss=0.539, reward_mean=0.210, reward_bound=0.000, batch=119\n",
      "2039: loss=0.539, reward_mean=0.170, reward_bound=0.000, batch=136\n",
      "2040: loss=0.534, reward_mean=0.230, reward_bound=0.000, batch=159\n",
      "2041: loss=0.525, reward_mean=0.280, reward_bound=0.004, batch=181\n",
      "2042: loss=0.527, reward_mean=0.280, reward_bound=0.016, batch=196\n",
      "2043: loss=0.527, reward_mean=0.240, reward_bound=0.028, batch=207\n",
      "2044: loss=0.536, reward_mean=0.290, reward_bound=0.047, batch=207\n",
      "2045: loss=0.531, reward_mean=0.260, reward_bound=0.065, batch=210\n",
      "2046: loss=0.528, reward_mean=0.240, reward_bound=0.080, batch=210\n",
      "2047: loss=0.527, reward_mean=0.230, reward_bound=0.089, batch=213\n",
      "2048: loss=0.533, reward_mean=0.350, reward_bound=0.109, batch=207\n",
      "2049: loss=0.540, reward_mean=0.220, reward_bound=0.122, batch=198\n",
      "2050: loss=0.529, reward_mean=0.220, reward_bound=0.135, batch=199\n",
      "2051: loss=0.527, reward_mean=0.290, reward_bound=0.150, batch=195\n",
      "2052: loss=0.526, reward_mean=0.240, reward_bound=0.101, batch=206\n",
      "2053: loss=0.520, reward_mean=0.180, reward_bound=0.109, batch=211\n",
      "2054: loss=0.524, reward_mean=0.220, reward_bound=0.122, batch=216\n",
      "2055: loss=0.527, reward_mean=0.260, reward_bound=0.150, batch=220\n",
      "2056: loss=0.529, reward_mean=0.260, reward_bound=0.167, batch=207\n",
      "2057: loss=0.537, reward_mean=0.280, reward_bound=0.185, batch=193\n",
      "2058: loss=0.531, reward_mean=0.260, reward_bound=0.135, batch=204\n",
      "2059: loss=0.530, reward_mean=0.300, reward_bound=0.204, batch=213\n",
      "2060: loss=0.536, reward_mean=0.360, reward_bound=0.206, batch=194\n",
      "2061: loss=0.531, reward_mean=0.220, reward_bound=0.107, batch=206\n",
      "2062: loss=0.525, reward_mean=0.220, reward_bound=0.099, batch=214\n",
      "2063: loss=0.525, reward_mean=0.250, reward_bound=0.185, batch=217\n",
      "2064: loss=0.524, reward_mean=0.280, reward_bound=0.229, batch=196\n",
      "2065: loss=0.521, reward_mean=0.360, reward_bound=0.254, batch=177\n",
      "2066: loss=0.519, reward_mean=0.240, reward_bound=0.059, batch=194\n",
      "2067: loss=0.509, reward_mean=0.300, reward_bound=0.122, batch=204\n",
      "2068: loss=0.512, reward_mean=0.250, reward_bound=0.167, batch=209\n",
      "2069: loss=0.513, reward_mean=0.310, reward_bound=0.215, batch=216\n",
      "2070: loss=0.511, reward_mean=0.260, reward_bound=0.229, batch=215\n",
      "2071: loss=0.514, reward_mean=0.280, reward_bound=0.254, batch=219\n",
      "2072: loss=0.534, reward_mean=0.280, reward_bound=0.282, batch=186\n",
      "2073: loss=0.529, reward_mean=0.280, reward_bound=0.122, batch=199\n",
      "2074: loss=0.523, reward_mean=0.360, reward_bound=0.135, batch=208\n",
      "2075: loss=0.524, reward_mean=0.220, reward_bound=0.150, batch=214\n",
      "2076: loss=0.523, reward_mean=0.190, reward_bound=0.167, batch=219\n",
      "2077: loss=0.527, reward_mean=0.300, reward_bound=0.206, batch=220\n",
      "2078: loss=0.528, reward_mean=0.310, reward_bound=0.229, batch=223\n",
      "2079: loss=0.527, reward_mean=0.230, reward_bound=0.271, batch=226\n",
      "2080: loss=0.528, reward_mean=0.200, reward_bound=0.254, batch=227\n",
      "2081: loss=0.530, reward_mean=0.260, reward_bound=0.282, batch=228\n",
      "2082: loss=0.529, reward_mean=0.300, reward_bound=0.314, batch=184\n",
      "2083: loss=0.523, reward_mean=0.270, reward_bound=0.165, batch=199\n",
      "2084: loss=0.525, reward_mean=0.300, reward_bound=0.206, batch=208\n",
      "2085: loss=0.523, reward_mean=0.240, reward_bound=0.154, batch=215\n",
      "2086: loss=0.528, reward_mean=0.240, reward_bound=0.229, batch=217\n",
      "2087: loss=0.526, reward_mean=0.280, reward_bound=0.254, batch=218\n",
      "2088: loss=0.525, reward_mean=0.310, reward_bound=0.282, batch=220\n",
      "2089: loss=0.526, reward_mean=0.190, reward_bound=0.304, batch=224\n",
      "2090: loss=0.525, reward_mean=0.280, reward_bound=0.314, batch=222\n",
      "2091: loss=0.513, reward_mean=0.270, reward_bound=0.349, batch=167\n",
      "2092: loss=0.489, reward_mean=0.200, reward_bound=0.003, batch=187\n",
      "2093: loss=0.496, reward_mean=0.300, reward_bound=0.072, batch=200\n",
      "2094: loss=0.502, reward_mean=0.230, reward_bound=0.089, batch=209\n",
      "2095: loss=0.506, reward_mean=0.340, reward_bound=0.122, batch=213\n",
      "2096: loss=0.501, reward_mean=0.400, reward_bound=0.160, batch=219\n",
      "2097: loss=0.502, reward_mean=0.200, reward_bound=0.167, batch=217\n",
      "2098: loss=0.505, reward_mean=0.290, reward_bound=0.185, batch=220\n",
      "2099: loss=0.510, reward_mean=0.290, reward_bound=0.206, batch=230\n",
      "2100: loss=0.513, reward_mean=0.200, reward_bound=0.206, batch=237\n",
      "2101: loss=0.519, reward_mean=0.210, reward_bound=0.229, batch=227\n",
      "2102: loss=0.525, reward_mean=0.220, reward_bound=0.254, batch=221\n",
      "2103: loss=0.523, reward_mean=0.220, reward_bound=0.282, batch=215\n",
      "2104: loss=0.527, reward_mean=0.310, reward_bound=0.234, batch=220\n",
      "2105: loss=0.522, reward_mean=0.230, reward_bound=0.282, batch=223\n",
      "2106: loss=0.517, reward_mean=0.290, reward_bound=0.314, batch=210\n",
      "2107: loss=0.514, reward_mean=0.210, reward_bound=0.222, batch=217\n",
      "2108: loss=0.522, reward_mean=0.240, reward_bound=0.277, batch=222\n",
      "2109: loss=0.514, reward_mean=0.300, reward_bound=0.282, batch=224\n",
      "2110: loss=0.513, reward_mean=0.320, reward_bound=0.314, batch=225\n",
      "2111: loss=0.512, reward_mean=0.240, reward_bound=0.266, batch=227\n",
      "2112: loss=0.513, reward_mean=0.210, reward_bound=0.342, batch=229\n",
      "2113: loss=0.513, reward_mean=0.330, reward_bound=0.349, batch=211\n",
      "2114: loss=0.516, reward_mean=0.290, reward_bound=0.314, batch=217\n",
      "2115: loss=0.512, reward_mean=0.260, reward_bound=0.380, batch=222\n",
      "2116: loss=0.551, reward_mean=0.250, reward_bound=0.387, batch=144\n",
      "2117: loss=0.521, reward_mean=0.300, reward_bound=0.014, batch=171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2118: loss=0.507, reward_mean=0.360, reward_bound=0.080, batch=186\n",
      "2119: loss=0.500, reward_mean=0.300, reward_bound=0.109, batch=196\n",
      "2120: loss=0.498, reward_mean=0.210, reward_bound=0.104, batch=207\n",
      "2121: loss=0.496, reward_mean=0.340, reward_bound=0.135, batch=211\n",
      "2122: loss=0.492, reward_mean=0.280, reward_bound=0.150, batch=214\n",
      "2123: loss=0.510, reward_mean=0.330, reward_bound=0.185, batch=217\n",
      "2124: loss=0.520, reward_mean=0.270, reward_bound=0.206, batch=210\n",
      "2125: loss=0.518, reward_mean=0.150, reward_bound=0.115, batch=217\n",
      "2126: loss=0.522, reward_mean=0.270, reward_bound=0.229, batch=215\n",
      "2127: loss=0.526, reward_mean=0.200, reward_bound=0.254, batch=209\n",
      "2128: loss=0.517, reward_mean=0.290, reward_bound=0.215, batch=216\n",
      "2129: loss=0.519, reward_mean=0.260, reward_bound=0.229, batch=220\n",
      "2130: loss=0.516, reward_mean=0.280, reward_bound=0.274, batch=224\n",
      "2131: loss=0.520, reward_mean=0.340, reward_bound=0.282, batch=217\n",
      "2132: loss=0.524, reward_mean=0.310, reward_bound=0.314, batch=211\n",
      "2133: loss=0.522, reward_mean=0.270, reward_bound=0.206, batch=216\n",
      "2134: loss=0.521, reward_mean=0.210, reward_bound=0.282, batch=220\n",
      "2135: loss=0.524, reward_mean=0.180, reward_bound=0.304, batch=224\n",
      "2136: loss=0.524, reward_mean=0.200, reward_bound=0.282, batch=226\n",
      "2137: loss=0.522, reward_mean=0.240, reward_bound=0.298, batch=228\n",
      "2138: loss=0.524, reward_mean=0.310, reward_bound=0.314, batch=228\n",
      "2139: loss=0.537, reward_mean=0.270, reward_bound=0.349, batch=202\n",
      "2140: loss=0.527, reward_mean=0.300, reward_bound=0.155, batch=211\n",
      "2141: loss=0.525, reward_mean=0.280, reward_bound=0.185, batch=215\n",
      "2142: loss=0.524, reward_mean=0.280, reward_bound=0.234, batch=220\n",
      "2143: loss=0.526, reward_mean=0.270, reward_bound=0.254, batch=219\n",
      "2144: loss=0.524, reward_mean=0.370, reward_bound=0.282, batch=222\n",
      "2145: loss=0.524, reward_mean=0.370, reward_bound=0.324, batch=225\n",
      "2146: loss=0.526, reward_mean=0.280, reward_bound=0.234, batch=227\n",
      "2147: loss=0.530, reward_mean=0.260, reward_bound=0.349, batch=222\n",
      "2148: loss=0.535, reward_mean=0.300, reward_bound=0.360, batch=225\n",
      "2149: loss=0.537, reward_mean=0.370, reward_bound=0.387, batch=205\n",
      "2150: loss=0.534, reward_mean=0.270, reward_bound=0.229, batch=211\n",
      "2151: loss=0.530, reward_mean=0.260, reward_bound=0.254, batch=216\n",
      "2152: loss=0.526, reward_mean=0.300, reward_bound=0.314, batch=220\n",
      "2153: loss=0.531, reward_mean=0.300, reward_bound=0.349, batch=221\n",
      "2154: loss=0.534, reward_mean=0.380, reward_bound=0.387, batch=222\n",
      "2155: loss=0.532, reward_mean=0.310, reward_bound=0.360, batch=225\n",
      "2156: loss=0.533, reward_mean=0.260, reward_bound=0.387, batch=224\n",
      "2157: loss=0.530, reward_mean=0.280, reward_bound=0.384, batch=227\n",
      "2158: loss=0.532, reward_mean=0.290, reward_bound=0.422, batch=229\n",
      "2159: loss=0.531, reward_mean=0.200, reward_bound=0.405, batch=230\n",
      "2160: loss=0.531, reward_mean=0.220, reward_bound=0.418, batch=231\n",
      "2161: loss=0.496, reward_mean=0.280, reward_bound=0.430, batch=120\n",
      "2162: loss=0.464, reward_mean=0.320, reward_bound=0.000, batch=152\n",
      "2163: loss=0.463, reward_mean=0.150, reward_bound=0.000, batch=167\n",
      "2164: loss=0.452, reward_mean=0.190, reward_bound=0.000, batch=186\n",
      "2165: loss=0.452, reward_mean=0.270, reward_bound=0.034, batch=199\n",
      "2166: loss=0.447, reward_mean=0.320, reward_bound=0.075, batch=209\n",
      "2167: loss=0.455, reward_mean=0.260, reward_bound=0.109, batch=214\n",
      "2168: loss=0.460, reward_mean=0.180, reward_bound=0.135, batch=217\n",
      "2169: loss=0.462, reward_mean=0.310, reward_bound=0.167, batch=215\n",
      "2170: loss=0.475, reward_mean=0.270, reward_bound=0.185, batch=217\n",
      "2171: loss=0.475, reward_mean=0.250, reward_bound=0.206, batch=216\n",
      "2172: loss=0.483, reward_mean=0.390, reward_bound=0.229, batch=219\n",
      "2173: loss=0.484, reward_mean=0.240, reward_bound=0.254, batch=208\n",
      "2174: loss=0.487, reward_mean=0.250, reward_bound=0.254, batch=214\n",
      "2175: loss=0.495, reward_mean=0.420, reward_bound=0.282, batch=205\n",
      "2176: loss=0.492, reward_mean=0.320, reward_bound=0.189, batch=213\n",
      "2177: loss=0.485, reward_mean=0.340, reward_bound=0.229, batch=218\n",
      "2178: loss=0.490, reward_mean=0.250, reward_bound=0.254, batch=221\n",
      "2179: loss=0.490, reward_mean=0.250, reward_bound=0.314, batch=208\n",
      "2180: loss=0.491, reward_mean=0.190, reward_bound=0.138, batch=215\n",
      "2181: loss=0.491, reward_mean=0.350, reward_bound=0.254, batch=217\n",
      "2182: loss=0.492, reward_mean=0.340, reward_bound=0.249, batch=222\n",
      "2183: loss=0.489, reward_mean=0.250, reward_bound=0.282, batch=222\n",
      "2184: loss=0.485, reward_mean=0.270, reward_bound=0.283, batch=225\n",
      "2185: loss=0.492, reward_mean=0.250, reward_bound=0.349, batch=196\n",
      "2186: loss=0.493, reward_mean=0.260, reward_bound=0.167, batch=206\n",
      "2187: loss=0.494, reward_mean=0.270, reward_bound=0.207, batch=214\n",
      "2188: loss=0.494, reward_mean=0.320, reward_bound=0.229, batch=219\n",
      "2189: loss=0.495, reward_mean=0.290, reward_bound=0.254, batch=222\n",
      "2190: loss=0.492, reward_mean=0.340, reward_bound=0.292, batch=225\n",
      "2191: loss=0.483, reward_mean=0.300, reward_bound=0.314, batch=226\n",
      "2192: loss=0.482, reward_mean=0.230, reward_bound=0.314, batch=227\n",
      "2193: loss=0.486, reward_mean=0.350, reward_bound=0.349, batch=223\n",
      "2194: loss=0.483, reward_mean=0.300, reward_bound=0.372, batch=226\n",
      "2195: loss=0.482, reward_mean=0.280, reward_bound=0.387, batch=191\n",
      "2196: loss=0.474, reward_mean=0.210, reward_bound=0.122, batch=203\n",
      "2197: loss=0.479, reward_mean=0.280, reward_bound=0.185, batch=210\n",
      "2198: loss=0.484, reward_mean=0.290, reward_bound=0.206, batch=220\n",
      "2199: loss=0.481, reward_mean=0.340, reward_bound=0.229, batch=223\n",
      "2200: loss=0.483, reward_mean=0.230, reward_bound=0.254, batch=222\n",
      "2201: loss=0.479, reward_mean=0.220, reward_bound=0.292, batch=225\n",
      "2202: loss=0.484, reward_mean=0.300, reward_bound=0.314, batch=218\n",
      "2203: loss=0.487, reward_mean=0.210, reward_bound=0.317, batch=222\n",
      "2204: loss=0.487, reward_mean=0.250, reward_bound=0.292, batch=225\n",
      "2205: loss=0.487, reward_mean=0.180, reward_bound=0.234, batch=227\n",
      "2206: loss=0.490, reward_mean=0.270, reward_bound=0.308, batch=229\n",
      "2207: loss=0.495, reward_mean=0.230, reward_bound=0.349, batch=219\n",
      "2208: loss=0.492, reward_mean=0.240, reward_bound=0.265, batch=223\n",
      "2209: loss=0.495, reward_mean=0.320, reward_bound=0.301, batch=226\n",
      "2210: loss=0.495, reward_mean=0.340, reward_bound=0.331, batch=228\n",
      "2211: loss=0.495, reward_mean=0.200, reward_bound=0.349, batch=227\n",
      "2212: loss=0.498, reward_mean=0.250, reward_bound=0.387, batch=215\n",
      "2213: loss=0.496, reward_mean=0.230, reward_bound=0.246, batch=220\n",
      "2214: loss=0.495, reward_mean=0.260, reward_bound=0.304, batch=224\n",
      "2215: loss=0.496, reward_mean=0.310, reward_bound=0.314, batch=222\n",
      "2216: loss=0.495, reward_mean=0.290, reward_bound=0.349, batch=224\n",
      "2217: loss=0.497, reward_mean=0.310, reward_bound=0.387, batch=224\n",
      "2218: loss=0.489, reward_mean=0.220, reward_bound=0.430, batch=177\n",
      "2219: loss=0.491, reward_mean=0.280, reward_bound=0.147, batch=194\n",
      "2220: loss=0.490, reward_mean=0.240, reward_bound=0.106, batch=206\n",
      "2221: loss=0.481, reward_mean=0.250, reward_bound=0.143, batch=214\n",
      "2222: loss=0.481, reward_mean=0.270, reward_bound=0.185, batch=215\n",
      "2223: loss=0.484, reward_mean=0.240, reward_bound=0.206, batch=218\n",
      "2224: loss=0.482, reward_mean=0.280, reward_bound=0.254, batch=221\n",
      "2225: loss=0.484, reward_mean=0.320, reward_bound=0.282, batch=214\n",
      "2226: loss=0.482, reward_mean=0.290, reward_bound=0.282, batch=219\n",
      "2227: loss=0.488, reward_mean=0.310, reward_bound=0.314, batch=222\n",
      "2228: loss=0.489, reward_mean=0.230, reward_bound=0.349, batch=212\n",
      "2229: loss=0.485, reward_mean=0.300, reward_bound=0.349, batch=217\n",
      "2230: loss=0.483, reward_mean=0.260, reward_bound=0.342, batch=222\n",
      "2231: loss=0.482, reward_mean=0.330, reward_bound=0.349, batch=221\n",
      "2232: loss=0.482, reward_mean=0.390, reward_bound=0.282, batch=223\n",
      "2233: loss=0.481, reward_mean=0.270, reward_bound=0.387, batch=210\n",
      "2234: loss=0.476, reward_mean=0.320, reward_bound=0.338, batch=217\n",
      "2235: loss=0.476, reward_mean=0.350, reward_bound=0.254, batch=221\n",
      "2236: loss=0.472, reward_mean=0.350, reward_bound=0.314, batch=224\n",
      "2237: loss=0.471, reward_mean=0.240, reward_bound=0.308, batch=227\n",
      "2238: loss=0.473, reward_mean=0.260, reward_bound=0.349, batch=228\n",
      "2239: loss=0.473, reward_mean=0.270, reward_bound=0.387, batch=223\n",
      "2240: loss=0.477, reward_mean=0.270, reward_bound=0.197, batch=226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2241: loss=0.476, reward_mean=0.310, reward_bound=0.268, batch=228\n",
      "2242: loss=0.471, reward_mean=0.230, reward_bound=0.286, batch=229\n",
      "2243: loss=0.472, reward_mean=0.290, reward_bound=0.314, batch=229\n",
      "2244: loss=0.479, reward_mean=0.280, reward_bound=0.430, batch=204\n",
      "2245: loss=0.470, reward_mean=0.340, reward_bound=0.226, batch=213\n",
      "2246: loss=0.470, reward_mean=0.300, reward_bound=0.198, batch=219\n",
      "2247: loss=0.471, reward_mean=0.270, reward_bound=0.229, batch=222\n",
      "2248: loss=0.474, reward_mean=0.270, reward_bound=0.254, batch=224\n",
      "2249: loss=0.473, reward_mean=0.280, reward_bound=0.311, batch=227\n",
      "2250: loss=0.471, reward_mean=0.320, reward_bound=0.314, batch=223\n",
      "2251: loss=0.468, reward_mean=0.270, reward_bound=0.290, batch=226\n",
      "2252: loss=0.467, reward_mean=0.310, reward_bound=0.331, batch=228\n",
      "2253: loss=0.470, reward_mean=0.260, reward_bound=0.349, batch=228\n",
      "2254: loss=0.471, reward_mean=0.210, reward_bound=0.387, batch=222\n",
      "2255: loss=0.470, reward_mean=0.260, reward_bound=0.272, batch=225\n",
      "2256: loss=0.472, reward_mean=0.300, reward_bound=0.396, batch=227\n",
      "2257: loss=0.472, reward_mean=0.350, reward_bound=0.430, batch=222\n",
      "2258: loss=0.472, reward_mean=0.300, reward_bound=0.387, batch=223\n",
      "2259: loss=0.477, reward_mean=0.260, reward_bound=0.372, batch=226\n",
      "2260: loss=0.476, reward_mean=0.210, reward_bound=0.409, batch=228\n",
      "2261: loss=0.474, reward_mean=0.240, reward_bound=0.317, batch=229\n",
      "2262: loss=0.475, reward_mean=0.220, reward_bound=0.328, batch=230\n",
      "2263: loss=0.473, reward_mean=0.300, reward_bound=0.430, batch=226\n",
      "2264: loss=0.471, reward_mean=0.340, reward_bound=0.387, batch=227\n",
      "2265: loss=0.470, reward_mean=0.260, reward_bound=0.422, batch=229\n",
      "2266: loss=0.470, reward_mean=0.310, reward_bound=0.405, batch=230\n",
      "2267: loss=0.470, reward_mean=0.280, reward_bound=0.418, batch=231\n",
      "2268: loss=0.470, reward_mean=0.250, reward_bound=0.430, batch=229\n",
      "2269: loss=0.470, reward_mean=0.220, reward_bound=0.343, batch=230\n",
      "2270: loss=0.470, reward_mean=0.270, reward_bound=0.387, batch=229\n",
      "2271: loss=0.473, reward_mean=0.220, reward_bound=0.478, batch=233\n",
      "2272: loss=0.467, reward_mean=0.380, reward_bound=0.478, batch=106\n",
      "2273: loss=0.410, reward_mean=0.300, reward_bound=0.000, batch=136\n",
      "2274: loss=0.405, reward_mean=0.290, reward_bound=0.000, batch=165\n",
      "2275: loss=0.419, reward_mean=0.280, reward_bound=0.011, batch=184\n",
      "2276: loss=0.421, reward_mean=0.360, reward_bound=0.042, batch=197\n",
      "2277: loss=0.417, reward_mean=0.280, reward_bound=0.058, batch=213\n",
      "2278: loss=0.421, reward_mean=0.290, reward_bound=0.069, batch=219\n",
      "2279: loss=0.421, reward_mean=0.350, reward_bound=0.098, batch=222\n",
      "2280: loss=0.439, reward_mean=0.350, reward_bound=0.135, batch=216\n",
      "2281: loss=0.442, reward_mean=0.230, reward_bound=0.150, batch=216\n",
      "2282: loss=0.440, reward_mean=0.300, reward_bound=0.185, batch=216\n",
      "2283: loss=0.451, reward_mean=0.270, reward_bound=0.206, batch=209\n",
      "2284: loss=0.451, reward_mean=0.330, reward_bound=0.229, batch=210\n",
      "2285: loss=0.442, reward_mean=0.340, reward_bound=0.254, batch=203\n",
      "2286: loss=0.438, reward_mean=0.230, reward_bound=0.160, batch=212\n",
      "2287: loss=0.434, reward_mean=0.290, reward_bound=0.229, batch=216\n",
      "2288: loss=0.432, reward_mean=0.300, reward_bound=0.241, batch=221\n",
      "2289: loss=0.440, reward_mean=0.300, reward_bound=0.254, batch=224\n",
      "2290: loss=0.447, reward_mean=0.390, reward_bound=0.282, batch=214\n",
      "2291: loss=0.445, reward_mean=0.330, reward_bound=0.229, batch=219\n",
      "2292: loss=0.445, reward_mean=0.230, reward_bound=0.185, batch=222\n",
      "2293: loss=0.447, reward_mean=0.300, reward_bound=0.254, batch=224\n",
      "2294: loss=0.448, reward_mean=0.300, reward_bound=0.282, batch=226\n",
      "2295: loss=0.455, reward_mean=0.310, reward_bound=0.314, batch=208\n",
      "2296: loss=0.458, reward_mean=0.340, reward_bound=0.237, batch=215\n",
      "2297: loss=0.458, reward_mean=0.350, reward_bound=0.349, batch=184\n",
      "2298: loss=0.443, reward_mean=0.290, reward_bound=0.092, batch=199\n",
      "2299: loss=0.448, reward_mean=0.280, reward_bound=0.127, batch=209\n",
      "2300: loss=0.448, reward_mean=0.330, reward_bound=0.185, batch=215\n",
      "2301: loss=0.456, reward_mean=0.400, reward_bound=0.229, batch=218\n",
      "2302: loss=0.455, reward_mean=0.300, reward_bound=0.254, batch=217\n",
      "2303: loss=0.459, reward_mean=0.300, reward_bound=0.282, batch=215\n",
      "2304: loss=0.469, reward_mean=0.320, reward_bound=0.289, batch=220\n",
      "2305: loss=0.474, reward_mean=0.260, reward_bound=0.314, batch=216\n",
      "2306: loss=0.472, reward_mean=0.380, reward_bound=0.301, batch=221\n",
      "2307: loss=0.460, reward_mean=0.270, reward_bound=0.349, batch=215\n",
      "2308: loss=0.455, reward_mean=0.340, reward_bound=0.356, batch=220\n",
      "2309: loss=0.454, reward_mean=0.260, reward_bound=0.314, batch=223\n",
      "2310: loss=0.465, reward_mean=0.300, reward_bound=0.387, batch=196\n",
      "2311: loss=0.463, reward_mean=0.330, reward_bound=0.241, batch=207\n",
      "2312: loss=0.457, reward_mean=0.310, reward_bound=0.224, batch=215\n",
      "2313: loss=0.463, reward_mean=0.320, reward_bound=0.260, batch=220\n",
      "2314: loss=0.469, reward_mean=0.290, reward_bound=0.282, batch=217\n",
      "2315: loss=0.464, reward_mean=0.390, reward_bound=0.282, batch=221\n",
      "2316: loss=0.463, reward_mean=0.300, reward_bound=0.282, batch=224\n",
      "2317: loss=0.464, reward_mean=0.290, reward_bound=0.280, batch=227\n",
      "2318: loss=0.464, reward_mean=0.380, reward_bound=0.314, batch=220\n",
      "2319: loss=0.461, reward_mean=0.350, reward_bound=0.338, batch=224\n",
      "2320: loss=0.464, reward_mean=0.290, reward_bound=0.349, batch=218\n",
      "2321: loss=0.463, reward_mean=0.310, reward_bound=0.282, batch=220\n",
      "2322: loss=0.464, reward_mean=0.330, reward_bound=0.304, batch=224\n",
      "2323: loss=0.462, reward_mean=0.400, reward_bound=0.314, batch=225\n",
      "2324: loss=0.461, reward_mean=0.310, reward_bound=0.387, batch=218\n",
      "2325: loss=0.460, reward_mean=0.340, reward_bound=0.392, batch=222\n",
      "2326: loss=0.459, reward_mean=0.200, reward_bound=0.349, batch=223\n",
      "2327: loss=0.459, reward_mean=0.360, reward_bound=0.254, batch=225\n",
      "2328: loss=0.461, reward_mean=0.320, reward_bound=0.387, batch=226\n",
      "2329: loss=0.461, reward_mean=0.320, reward_bound=0.356, batch=228\n",
      "2330: loss=0.461, reward_mean=0.300, reward_bound=0.325, batch=229\n",
      "2331: loss=0.459, reward_mean=0.250, reward_bound=0.360, batch=230\n",
      "2332: loss=0.459, reward_mean=0.320, reward_bound=0.387, batch=230\n",
      "2333: loss=0.459, reward_mean=0.300, reward_bound=0.418, batch=231\n",
      "2334: loss=0.470, reward_mean=0.340, reward_bound=0.430, batch=166\n",
      "2335: loss=0.438, reward_mean=0.310, reward_bound=0.068, batch=186\n",
      "2336: loss=0.437, reward_mean=0.300, reward_bound=0.098, batch=199\n",
      "2337: loss=0.428, reward_mean=0.280, reward_bound=0.109, batch=207\n",
      "2338: loss=0.427, reward_mean=0.300, reward_bound=0.132, batch=215\n",
      "2339: loss=0.428, reward_mean=0.290, reward_bound=0.150, batch=216\n",
      "2340: loss=0.443, reward_mean=0.240, reward_bound=0.167, batch=219\n",
      "2341: loss=0.441, reward_mean=0.270, reward_bound=0.185, batch=221\n",
      "2342: loss=0.437, reward_mean=0.300, reward_bound=0.206, batch=216\n",
      "2343: loss=0.443, reward_mean=0.350, reward_bound=0.229, batch=214\n",
      "2344: loss=0.440, reward_mean=0.350, reward_bound=0.254, batch=213\n",
      "2345: loss=0.438, reward_mean=0.290, reward_bound=0.235, batch=219\n",
      "2346: loss=0.449, reward_mean=0.330, reward_bound=0.282, batch=206\n",
      "2347: loss=0.448, reward_mean=0.380, reward_bound=0.284, batch=214\n",
      "2348: loss=0.446, reward_mean=0.310, reward_bound=0.314, batch=207\n",
      "2349: loss=0.455, reward_mean=0.280, reward_bound=0.182, batch=215\n",
      "2350: loss=0.450, reward_mean=0.300, reward_bound=0.282, batch=218\n",
      "2351: loss=0.443, reward_mean=0.340, reward_bound=0.314, batch=221\n",
      "2352: loss=0.440, reward_mean=0.320, reward_bound=0.282, batch=224\n",
      "2353: loss=0.444, reward_mean=0.310, reward_bound=0.349, batch=214\n",
      "2354: loss=0.442, reward_mean=0.300, reward_bound=0.349, batch=219\n",
      "2355: loss=0.448, reward_mean=0.270, reward_bound=0.387, batch=205\n",
      "2356: loss=0.442, reward_mean=0.340, reward_bound=0.289, batch=213\n",
      "2357: loss=0.444, reward_mean=0.340, reward_bound=0.335, batch=219\n",
      "2358: loss=0.440, reward_mean=0.310, reward_bound=0.250, batch=223\n",
      "2359: loss=0.437, reward_mean=0.390, reward_bound=0.282, batch=225\n",
      "2360: loss=0.441, reward_mean=0.300, reward_bound=0.314, batch=225\n",
      "2361: loss=0.445, reward_mean=0.290, reward_bound=0.296, batch=227\n",
      "2362: loss=0.444, reward_mean=0.300, reward_bound=0.342, batch=229\n",
      "2363: loss=0.448, reward_mean=0.350, reward_bound=0.349, batch=227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2364: loss=0.442, reward_mean=0.350, reward_bound=0.387, batch=225\n",
      "2365: loss=0.449, reward_mean=0.270, reward_bound=0.430, batch=200\n",
      "2366: loss=0.440, reward_mean=0.320, reward_bound=0.106, batch=210\n",
      "2367: loss=0.443, reward_mean=0.290, reward_bound=0.180, batch=217\n",
      "2368: loss=0.444, reward_mean=0.310, reward_bound=0.206, batch=220\n",
      "2369: loss=0.439, reward_mean=0.280, reward_bound=0.254, batch=219\n",
      "2370: loss=0.450, reward_mean=0.320, reward_bound=0.328, batch=223\n",
      "2371: loss=0.456, reward_mean=0.310, reward_bound=0.349, batch=220\n",
      "2372: loss=0.458, reward_mean=0.330, reward_bound=0.304, batch=224\n",
      "2373: loss=0.458, reward_mean=0.260, reward_bound=0.252, batch=227\n",
      "2374: loss=0.453, reward_mean=0.340, reward_bound=0.342, batch=229\n",
      "2375: loss=0.451, reward_mean=0.240, reward_bound=0.309, batch=230\n",
      "2376: loss=0.461, reward_mean=0.290, reward_bound=0.376, batch=231\n",
      "2377: loss=0.456, reward_mean=0.340, reward_bound=0.387, batch=221\n",
      "2378: loss=0.453, reward_mean=0.340, reward_bound=0.349, batch=224\n",
      "2379: loss=0.453, reward_mean=0.360, reward_bound=0.387, batch=226\n",
      "2380: loss=0.453, reward_mean=0.390, reward_bound=0.430, batch=218\n",
      "2381: loss=0.449, reward_mean=0.280, reward_bound=0.282, batch=221\n",
      "2382: loss=0.450, reward_mean=0.320, reward_bound=0.314, batch=223\n",
      "2383: loss=0.445, reward_mean=0.410, reward_bound=0.372, batch=226\n",
      "2384: loss=0.450, reward_mean=0.240, reward_bound=0.387, batch=226\n",
      "2385: loss=0.454, reward_mean=0.400, reward_bound=0.430, batch=226\n",
      "2386: loss=0.451, reward_mean=0.270, reward_bound=0.390, batch=228\n",
      "2387: loss=0.453, reward_mean=0.370, reward_bound=0.392, batch=229\n",
      "2388: loss=0.452, reward_mean=0.180, reward_bound=0.250, batch=230\n",
      "2389: loss=0.452, reward_mean=0.280, reward_bound=0.387, batch=230\n",
      "2390: loss=0.452, reward_mean=0.290, reward_bound=0.418, batch=231\n",
      "2391: loss=0.452, reward_mean=0.340, reward_bound=0.430, batch=228\n",
      "2392: loss=0.451, reward_mean=0.310, reward_bound=0.435, batch=229\n",
      "2393: loss=0.451, reward_mean=0.220, reward_bound=0.450, batch=230\n",
      "2394: loss=0.453, reward_mean=0.260, reward_bound=0.304, batch=231\n",
      "2395: loss=0.435, reward_mean=0.310, reward_bound=0.478, batch=156\n",
      "2396: loss=0.410, reward_mean=0.290, reward_bound=0.017, batch=179\n",
      "2397: loss=0.422, reward_mean=0.330, reward_bound=0.052, batch=194\n",
      "2398: loss=0.426, reward_mean=0.270, reward_bound=0.058, batch=205\n",
      "2399: loss=0.446, reward_mean=0.330, reward_bound=0.122, batch=210\n",
      "2400: loss=0.440, reward_mean=0.340, reward_bound=0.150, batch=216\n",
      "2401: loss=0.439, reward_mean=0.360, reward_bound=0.185, batch=219\n",
      "2402: loss=0.451, reward_mean=0.340, reward_bound=0.206, batch=211\n",
      "2403: loss=0.450, reward_mean=0.290, reward_bound=0.229, batch=213\n",
      "2404: loss=0.446, reward_mean=0.280, reward_bound=0.254, batch=211\n",
      "2405: loss=0.445, reward_mean=0.350, reward_bound=0.229, batch=217\n",
      "2406: loss=0.445, reward_mean=0.390, reward_bound=0.282, batch=200\n",
      "2407: loss=0.437, reward_mean=0.290, reward_bound=0.200, batch=210\n",
      "2408: loss=0.437, reward_mean=0.400, reward_bound=0.247, batch=217\n",
      "2409: loss=0.439, reward_mean=0.320, reward_bound=0.254, batch=220\n",
      "2410: loss=0.440, reward_mean=0.290, reward_bound=0.274, batch=224\n",
      "2411: loss=0.444, reward_mean=0.240, reward_bound=0.282, batch=221\n",
      "2412: loss=0.445, reward_mean=0.240, reward_bound=0.314, batch=209\n",
      "2413: loss=0.448, reward_mean=0.320, reward_bound=0.349, batch=196\n",
      "2414: loss=0.445, reward_mean=0.230, reward_bound=0.167, batch=205\n",
      "2415: loss=0.441, reward_mean=0.350, reward_bound=0.185, batch=212\n",
      "2416: loss=0.444, reward_mean=0.310, reward_bound=0.254, batch=217\n",
      "2417: loss=0.438, reward_mean=0.220, reward_bound=0.160, batch=222\n",
      "2418: loss=0.437, reward_mean=0.250, reward_bound=0.236, batch=225\n",
      "2419: loss=0.442, reward_mean=0.290, reward_bound=0.260, batch=227\n",
      "2420: loss=0.450, reward_mean=0.290, reward_bound=0.282, batch=225\n",
      "2421: loss=0.446, reward_mean=0.280, reward_bound=0.260, batch=227\n",
      "2422: loss=0.459, reward_mean=0.280, reward_bound=0.314, batch=226\n",
      "2423: loss=0.458, reward_mean=0.220, reward_bound=0.349, batch=224\n",
      "2424: loss=0.460, reward_mean=0.440, reward_bound=0.314, batch=226\n",
      "2425: loss=0.449, reward_mean=0.280, reward_bound=0.387, batch=205\n",
      "2426: loss=0.444, reward_mean=0.350, reward_bound=0.234, batch=213\n",
      "2427: loss=0.441, reward_mean=0.240, reward_bound=0.282, batch=215\n",
      "2428: loss=0.436, reward_mean=0.380, reward_bound=0.314, batch=217\n",
      "2429: loss=0.438, reward_mean=0.280, reward_bound=0.249, batch=222\n",
      "2430: loss=0.436, reward_mean=0.340, reward_bound=0.282, batch=223\n",
      "2431: loss=0.445, reward_mean=0.290, reward_bound=0.349, batch=222\n",
      "2432: loss=0.443, reward_mean=0.320, reward_bound=0.314, batch=224\n",
      "2433: loss=0.439, reward_mean=0.270, reward_bound=0.308, batch=227\n",
      "2434: loss=0.442, reward_mean=0.290, reward_bound=0.342, batch=229\n",
      "2435: loss=0.440, reward_mean=0.230, reward_bound=0.328, batch=230\n",
      "2436: loss=0.440, reward_mean=0.330, reward_bound=0.349, batch=230\n",
      "2437: loss=0.441, reward_mean=0.270, reward_bound=0.376, batch=231\n",
      "2438: loss=0.446, reward_mean=0.330, reward_bound=0.387, batch=226\n",
      "2439: loss=0.446, reward_mean=0.260, reward_bound=0.430, batch=193\n",
      "2440: loss=0.443, reward_mean=0.260, reward_bound=0.227, batch=205\n",
      "2441: loss=0.433, reward_mean=0.210, reward_bound=0.127, batch=213\n",
      "2442: loss=0.437, reward_mean=0.230, reward_bound=0.254, batch=215\n",
      "2443: loss=0.437, reward_mean=0.310, reward_bound=0.229, batch=219\n",
      "2444: loss=0.438, reward_mean=0.310, reward_bound=0.254, batch=222\n",
      "2445: loss=0.443, reward_mean=0.220, reward_bound=0.282, batch=221\n",
      "2446: loss=0.448, reward_mean=0.280, reward_bound=0.314, batch=219\n",
      "2447: loss=0.448, reward_mean=0.280, reward_bound=0.295, batch=223\n",
      "2448: loss=0.446, reward_mean=0.300, reward_bound=0.314, batch=225\n",
      "2449: loss=0.445, reward_mean=0.150, reward_bound=0.167, batch=226\n",
      "2450: loss=0.442, reward_mean=0.320, reward_bound=0.349, batch=220\n",
      "2451: loss=0.441, reward_mean=0.290, reward_bound=0.314, batch=222\n",
      "2452: loss=0.442, reward_mean=0.240, reward_bound=0.387, batch=215\n",
      "2453: loss=0.438, reward_mean=0.280, reward_bound=0.266, batch=220\n",
      "2454: loss=0.442, reward_mean=0.350, reward_bound=0.338, batch=224\n",
      "2455: loss=0.447, reward_mean=0.290, reward_bound=0.349, batch=225\n",
      "2456: loss=0.445, reward_mean=0.340, reward_bound=0.387, batch=224\n",
      "2457: loss=0.440, reward_mean=0.270, reward_bound=0.311, batch=227\n",
      "2458: loss=0.445, reward_mean=0.250, reward_bound=0.349, batch=228\n",
      "2459: loss=0.442, reward_mean=0.290, reward_bound=0.387, batch=228\n",
      "2460: loss=0.455, reward_mean=0.290, reward_bound=0.430, batch=211\n",
      "2461: loss=0.453, reward_mean=0.340, reward_bound=0.229, batch=216\n",
      "2462: loss=0.454, reward_mean=0.260, reward_bound=0.298, batch=221\n",
      "2463: loss=0.453, reward_mean=0.320, reward_bound=0.349, batch=222\n",
      "2464: loss=0.452, reward_mean=0.340, reward_bound=0.387, batch=221\n",
      "2465: loss=0.454, reward_mean=0.340, reward_bound=0.349, batch=223\n",
      "2466: loss=0.449, reward_mean=0.260, reward_bound=0.430, batch=221\n",
      "2467: loss=0.448, reward_mean=0.220, reward_bound=0.254, batch=223\n",
      "2468: loss=0.452, reward_mean=0.180, reward_bound=0.227, batch=226\n",
      "2469: loss=0.448, reward_mean=0.320, reward_bound=0.314, batch=227\n",
      "2470: loss=0.446, reward_mean=0.190, reward_bound=0.349, batch=228\n",
      "2471: loss=0.449, reward_mean=0.260, reward_bound=0.387, batch=228\n",
      "2472: loss=0.450, reward_mean=0.280, reward_bound=0.430, batch=223\n",
      "2473: loss=0.448, reward_mean=0.320, reward_bound=0.372, batch=226\n",
      "2474: loss=0.450, reward_mean=0.200, reward_bound=0.349, batch=227\n",
      "2475: loss=0.452, reward_mean=0.330, reward_bound=0.387, batch=226\n",
      "2476: loss=0.442, reward_mean=0.320, reward_bound=0.478, batch=177\n",
      "2477: loss=0.422, reward_mean=0.330, reward_bound=0.089, batch=195\n",
      "2478: loss=0.408, reward_mean=0.330, reward_bound=0.101, batch=206\n",
      "2479: loss=0.426, reward_mean=0.270, reward_bound=0.143, batch=214\n",
      "2480: loss=0.431, reward_mean=0.320, reward_bound=0.185, batch=214\n",
      "2481: loss=0.429, reward_mean=0.270, reward_bound=0.206, batch=215\n",
      "2482: loss=0.434, reward_mean=0.280, reward_bound=0.229, batch=217\n",
      "2483: loss=0.431, reward_mean=0.320, reward_bound=0.254, batch=216\n",
      "2484: loss=0.432, reward_mean=0.310, reward_bound=0.282, batch=215\n",
      "2485: loss=0.430, reward_mean=0.270, reward_bound=0.314, batch=212\n",
      "2486: loss=0.429, reward_mean=0.420, reward_bound=0.292, batch=218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2487: loss=0.428, reward_mean=0.240, reward_bound=0.286, batch=222\n",
      "2488: loss=0.431, reward_mean=0.350, reward_bound=0.349, batch=215\n",
      "2489: loss=0.427, reward_mean=0.200, reward_bound=0.161, batch=220\n",
      "2490: loss=0.432, reward_mean=0.310, reward_bound=0.282, batch=222\n",
      "2491: loss=0.435, reward_mean=0.300, reward_bound=0.324, batch=225\n",
      "2492: loss=0.432, reward_mean=0.290, reward_bound=0.321, batch=227\n",
      "2493: loss=0.432, reward_mean=0.250, reward_bound=0.349, batch=226\n",
      "2494: loss=0.431, reward_mean=0.310, reward_bound=0.349, batch=226\n",
      "2495: loss=0.436, reward_mean=0.260, reward_bound=0.387, batch=213\n",
      "2496: loss=0.437, reward_mean=0.330, reward_bound=0.280, batch=219\n",
      "2497: loss=0.427, reward_mean=0.300, reward_bound=0.349, batch=222\n",
      "2498: loss=0.428, reward_mean=0.360, reward_bound=0.360, batch=225\n",
      "2499: loss=0.427, reward_mean=0.310, reward_bound=0.349, batch=226\n",
      "2500: loss=0.427, reward_mean=0.240, reward_bound=0.349, batch=227\n",
      "2501: loss=0.433, reward_mean=0.340, reward_bound=0.387, batch=223\n",
      "2502: loss=0.431, reward_mean=0.300, reward_bound=0.413, batch=226\n",
      "2503: loss=0.427, reward_mean=0.260, reward_bound=0.271, batch=228\n",
      "2504: loss=0.435, reward_mean=0.310, reward_bound=0.349, batch=228\n",
      "2505: loss=0.437, reward_mean=0.350, reward_bound=0.430, batch=204\n",
      "2506: loss=0.428, reward_mean=0.340, reward_bound=0.282, batch=212\n",
      "2507: loss=0.433, reward_mean=0.210, reward_bound=0.263, batch=218\n",
      "2508: loss=0.431, reward_mean=0.260, reward_bound=0.314, batch=220\n",
      "2509: loss=0.434, reward_mean=0.310, reward_bound=0.349, batch=220\n",
      "2510: loss=0.434, reward_mean=0.290, reward_bound=0.247, batch=224\n",
      "2511: loss=0.427, reward_mean=0.200, reward_bound=0.282, batch=225\n",
      "2512: loss=0.429, reward_mean=0.290, reward_bound=0.356, batch=227\n",
      "2513: loss=0.438, reward_mean=0.260, reward_bound=0.387, batch=221\n",
      "2514: loss=0.438, reward_mean=0.300, reward_bound=0.282, batch=221\n",
      "2515: loss=0.436, reward_mean=0.360, reward_bound=0.349, batch=222\n",
      "2516: loss=0.434, reward_mean=0.210, reward_bound=0.349, batch=224\n",
      "2517: loss=0.443, reward_mean=0.320, reward_bound=0.384, batch=227\n",
      "2518: loss=0.444, reward_mean=0.340, reward_bound=0.308, batch=229\n",
      "2519: loss=0.440, reward_mean=0.280, reward_bound=0.387, batch=224\n",
      "2520: loss=0.440, reward_mean=0.360, reward_bound=0.426, batch=227\n",
      "2521: loss=0.440, reward_mean=0.320, reward_bound=0.349, batch=228\n",
      "2522: loss=0.440, reward_mean=0.330, reward_bound=0.392, batch=229\n",
      "2523: loss=0.435, reward_mean=0.350, reward_bound=0.430, batch=219\n",
      "2524: loss=0.438, reward_mean=0.300, reward_bound=0.309, batch=223\n",
      "2525: loss=0.438, reward_mean=0.310, reward_bound=0.349, batch=225\n",
      "2526: loss=0.435, reward_mean=0.240, reward_bound=0.387, batch=226\n",
      "2527: loss=0.435, reward_mean=0.340, reward_bound=0.387, batch=227\n",
      "2528: loss=0.437, reward_mean=0.260, reward_bound=0.185, batch=228\n",
      "2529: loss=0.435, reward_mean=0.340, reward_bound=0.353, batch=229\n",
      "2530: loss=0.435, reward_mean=0.410, reward_bound=0.430, batch=227\n",
      "2531: loss=0.437, reward_mean=0.360, reward_bound=0.469, batch=229\n",
      "2532: loss=0.437, reward_mean=0.360, reward_bound=0.349, batch=229\n",
      "2533: loss=0.439, reward_mean=0.240, reward_bound=0.424, batch=230\n",
      "2534: loss=0.441, reward_mean=0.310, reward_bound=0.464, batch=231\n",
      "2535: loss=0.450, reward_mean=0.310, reward_bound=0.478, batch=204\n",
      "2536: loss=0.445, reward_mean=0.260, reward_bound=0.167, batch=211\n",
      "2537: loss=0.440, reward_mean=0.290, reward_bound=0.185, batch=217\n",
      "2538: loss=0.442, reward_mean=0.300, reward_bound=0.206, batch=221\n",
      "2539: loss=0.436, reward_mean=0.340, reward_bound=0.254, batch=224\n",
      "2540: loss=0.442, reward_mean=0.380, reward_bound=0.282, batch=224\n",
      "2541: loss=0.442, reward_mean=0.380, reward_bound=0.314, batch=223\n",
      "2542: loss=0.445, reward_mean=0.320, reward_bound=0.349, batch=220\n",
      "2543: loss=0.442, reward_mean=0.310, reward_bound=0.376, batch=224\n",
      "2544: loss=0.447, reward_mean=0.300, reward_bound=0.387, batch=219\n",
      "2545: loss=0.445, reward_mean=0.270, reward_bound=0.349, batch=222\n",
      "2546: loss=0.444, reward_mean=0.290, reward_bound=0.292, batch=225\n",
      "2547: loss=0.447, reward_mean=0.310, reward_bound=0.321, batch=227\n",
      "2548: loss=0.448, reward_mean=0.270, reward_bound=0.380, batch=229\n",
      "2549: loss=0.450, reward_mean=0.270, reward_bound=0.364, batch=230\n",
      "2550: loss=0.451, reward_mean=0.320, reward_bound=0.387, batch=226\n",
      "2551: loss=0.453, reward_mean=0.300, reward_bound=0.430, batch=215\n",
      "2552: loss=0.454, reward_mean=0.240, reward_bound=0.282, batch=218\n",
      "2553: loss=0.452, reward_mean=0.350, reward_bound=0.317, batch=222\n",
      "2554: loss=0.451, reward_mean=0.260, reward_bound=0.349, batch=224\n",
      "2555: loss=0.451, reward_mean=0.360, reward_bound=0.387, batch=223\n",
      "2556: loss=0.447, reward_mean=0.340, reward_bound=0.254, batch=225\n",
      "2557: loss=0.449, reward_mean=0.350, reward_bound=0.396, batch=227\n",
      "2558: loss=0.446, reward_mean=0.350, reward_bound=0.422, batch=229\n",
      "2559: loss=0.449, reward_mean=0.260, reward_bound=0.430, batch=226\n",
      "2560: loss=0.448, reward_mean=0.360, reward_bound=0.413, batch=228\n",
      "2561: loss=0.447, reward_mean=0.310, reward_bound=0.330, batch=229\n",
      "2562: loss=0.445, reward_mean=0.320, reward_bound=0.478, batch=232\n",
      "2563: loss=0.448, reward_mean=0.310, reward_bound=0.478, batch=213\n",
      "2564: loss=0.451, reward_mean=0.270, reward_bound=0.149, batch=219\n",
      "2565: loss=0.451, reward_mean=0.250, reward_bound=0.229, batch=221\n",
      "2566: loss=0.447, reward_mean=0.390, reward_bound=0.282, batch=224\n",
      "2567: loss=0.449, reward_mean=0.210, reward_bound=0.314, batch=224\n",
      "2568: loss=0.447, reward_mean=0.290, reward_bound=0.183, batch=227\n",
      "2569: loss=0.447, reward_mean=0.260, reward_bound=0.314, batch=228\n",
      "2570: loss=0.448, reward_mean=0.260, reward_bound=0.349, batch=227\n",
      "2571: loss=0.447, reward_mean=0.390, reward_bound=0.387, batch=228\n",
      "2572: loss=0.450, reward_mean=0.340, reward_bound=0.430, batch=221\n",
      "2573: loss=0.451, reward_mean=0.290, reward_bound=0.430, batch=222\n",
      "2574: loss=0.452, reward_mean=0.330, reward_bound=0.292, batch=225\n",
      "2575: loss=0.449, reward_mean=0.280, reward_bound=0.321, batch=227\n",
      "2576: loss=0.453, reward_mean=0.280, reward_bound=0.349, batch=227\n",
      "2577: loss=0.454, reward_mean=0.280, reward_bound=0.366, batch=229\n",
      "2578: loss=0.452, reward_mean=0.290, reward_bound=0.405, batch=230\n",
      "2579: loss=0.449, reward_mean=0.360, reward_bound=0.430, batch=228\n",
      "2580: loss=0.449, reward_mean=0.380, reward_bound=0.430, batch=228\n",
      "2581: loss=0.448, reward_mean=0.270, reward_bound=0.435, batch=229\n",
      "2582: loss=0.446, reward_mean=0.280, reward_bound=0.478, batch=231\n",
      "2583: loss=0.451, reward_mean=0.390, reward_bound=0.478, batch=220\n",
      "2584: loss=0.448, reward_mean=0.290, reward_bound=0.274, batch=224\n",
      "2585: loss=0.446, reward_mean=0.290, reward_bound=0.314, batch=225\n",
      "2586: loss=0.443, reward_mean=0.230, reward_bound=0.296, batch=227\n",
      "2587: loss=0.446, reward_mean=0.270, reward_bound=0.380, batch=229\n",
      "2588: loss=0.449, reward_mean=0.350, reward_bound=0.430, batch=225\n",
      "2589: loss=0.448, reward_mean=0.300, reward_bound=0.356, batch=227\n",
      "2590: loss=0.445, reward_mean=0.290, reward_bound=0.387, batch=228\n",
      "2591: loss=0.445, reward_mean=0.340, reward_bound=0.392, batch=229\n",
      "2592: loss=0.446, reward_mean=0.370, reward_bound=0.405, batch=230\n",
      "2593: loss=0.448, reward_mean=0.290, reward_bound=0.430, batch=227\n",
      "2594: loss=0.450, reward_mean=0.290, reward_bound=0.430, batch=228\n",
      "2595: loss=0.449, reward_mean=0.320, reward_bound=0.478, batch=231\n",
      "2596: loss=0.451, reward_mean=0.290, reward_bound=0.478, batch=223\n",
      "2597: loss=0.450, reward_mean=0.280, reward_bound=0.349, batch=225\n",
      "2598: loss=0.450, reward_mean=0.310, reward_bound=0.365, batch=227\n",
      "2599: loss=0.448, reward_mean=0.230, reward_bound=0.430, batch=228\n",
      "2600: loss=0.446, reward_mean=0.220, reward_bound=0.392, batch=229\n",
      "2601: loss=0.448, reward_mean=0.380, reward_bound=0.478, batch=231\n",
      "2602: loss=0.448, reward_mean=0.320, reward_bound=0.387, batch=231\n",
      "2603: loss=0.448, reward_mean=0.320, reward_bound=0.430, batch=231\n",
      "2604: loss=0.448, reward_mean=0.310, reward_bound=0.349, batch=231\n",
      "2605: loss=0.448, reward_mean=0.340, reward_bound=0.430, batch=231\n",
      "2606: loss=0.448, reward_mean=0.260, reward_bound=0.387, batch=231\n",
      "2607: loss=0.448, reward_mean=0.330, reward_bound=0.430, batch=231\n",
      "2608: loss=0.448, reward_mean=0.190, reward_bound=0.430, batch=231\n",
      "2609: loss=0.451, reward_mean=0.250, reward_bound=0.478, batch=225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610: loss=0.451, reward_mean=0.230, reward_bound=0.349, batch=226\n",
      "2611: loss=0.451, reward_mean=0.180, reward_bound=0.390, batch=228\n",
      "2612: loss=0.452, reward_mean=0.240, reward_bound=0.392, batch=229\n",
      "2613: loss=0.451, reward_mean=0.330, reward_bound=0.430, batch=226\n",
      "2614: loss=0.449, reward_mean=0.210, reward_bound=0.433, batch=228\n",
      "2615: loss=0.449, reward_mean=0.310, reward_bound=0.430, batch=228\n",
      "2616: loss=0.449, reward_mean=0.280, reward_bound=0.387, batch=228\n",
      "2617: loss=0.449, reward_mean=0.310, reward_bound=0.435, batch=229\n",
      "2618: loss=0.449, reward_mean=0.310, reward_bound=0.343, batch=230\n",
      "2619: loss=0.451, reward_mean=0.360, reward_bound=0.387, batch=230\n",
      "2620: loss=0.450, reward_mean=0.330, reward_bound=0.478, batch=230\n",
      "2621: loss=0.451, reward_mean=0.290, reward_bound=0.418, batch=231\n",
      "2622: loss=0.450, reward_mean=0.270, reward_bound=0.478, batch=230\n",
      "2623: loss=0.450, reward_mean=0.380, reward_bound=0.451, batch=231\n",
      "2624: loss=0.450, reward_mean=0.320, reward_bound=0.430, batch=231\n",
      "2625: loss=0.449, reward_mean=0.240, reward_bound=0.478, batch=231\n",
      "2626: loss=0.449, reward_mean=0.380, reward_bound=0.478, batch=231\n",
      "2627: loss=0.449, reward_mean=0.310, reward_bound=0.430, batch=231\n",
      "2628: loss=0.449, reward_mean=0.270, reward_bound=0.387, batch=231\n",
      "2629: loss=0.449, reward_mean=0.280, reward_bound=0.430, batch=231\n",
      "2630: loss=0.449, reward_mean=0.250, reward_bound=0.430, batch=231\n",
      "2632: loss=0.329, reward_mean=0.310, reward_bound=0.000, batch=31\n",
      "2633: loss=0.334, reward_mean=0.260, reward_bound=0.000, batch=57\n",
      "2634: loss=0.350, reward_mean=0.290, reward_bound=0.000, batch=86\n",
      "2635: loss=0.346, reward_mean=0.310, reward_bound=0.000, batch=117\n",
      "2636: loss=0.338, reward_mean=0.280, reward_bound=0.000, batch=145\n",
      "2637: loss=0.336, reward_mean=0.280, reward_bound=0.002, batch=171\n",
      "2638: loss=0.332, reward_mean=0.290, reward_bound=0.005, batch=189\n",
      "2639: loss=0.339, reward_mean=0.360, reward_bound=0.023, batch=199\n",
      "2640: loss=0.342, reward_mean=0.310, reward_bound=0.031, batch=206\n",
      "2641: loss=0.341, reward_mean=0.360, reward_bound=0.047, batch=211\n",
      "2642: loss=0.349, reward_mean=0.410, reward_bound=0.065, batch=212\n",
      "2643: loss=0.346, reward_mean=0.280, reward_bound=0.074, batch=218\n",
      "2644: loss=0.344, reward_mean=0.290, reward_bound=0.080, batch=218\n",
      "2645: loss=0.346, reward_mean=0.310, reward_bound=0.090, batch=222\n",
      "2646: loss=0.334, reward_mean=0.330, reward_bound=0.098, batch=217\n",
      "2647: loss=0.341, reward_mean=0.350, reward_bound=0.109, batch=235\n",
      "2648: loss=0.340, reward_mean=0.360, reward_bound=0.109, batch=254\n",
      "2649: loss=0.339, reward_mean=0.350, reward_bound=0.109, batch=245\n",
      "2650: loss=0.347, reward_mean=0.290, reward_bound=0.135, batch=226\n",
      "2651: loss=0.345, reward_mean=0.350, reward_bound=0.150, batch=217\n",
      "2652: loss=0.356, reward_mean=0.400, reward_bound=0.167, batch=208\n",
      "2653: loss=0.353, reward_mean=0.360, reward_bound=0.185, batch=200\n",
      "2654: loss=0.351, reward_mean=0.340, reward_bound=0.109, batch=209\n",
      "2655: loss=0.345, reward_mean=0.410, reward_bound=0.206, batch=193\n",
      "2656: loss=0.348, reward_mean=0.280, reward_bound=0.117, batch=205\n",
      "2657: loss=0.345, reward_mean=0.340, reward_bound=0.170, batch=213\n",
      "2658: loss=0.363, reward_mean=0.470, reward_bound=0.229, batch=193\n",
      "2659: loss=0.360, reward_mean=0.280, reward_bound=0.094, batch=205\n",
      "2660: loss=0.364, reward_mean=0.310, reward_bound=0.127, batch=213\n",
      "2661: loss=0.361, reward_mean=0.310, reward_bound=0.198, batch=219\n",
      "2662: loss=0.355, reward_mean=0.290, reward_bound=0.229, batch=220\n",
      "2663: loss=0.355, reward_mean=0.350, reward_bound=0.254, batch=192\n",
      "2664: loss=0.354, reward_mean=0.260, reward_bound=0.092, batch=204\n",
      "2665: loss=0.355, reward_mean=0.300, reward_bound=0.149, batch=213\n",
      "2666: loss=0.353, reward_mean=0.260, reward_bound=0.178, batch=219\n",
      "2667: loss=0.358, reward_mean=0.360, reward_bound=0.185, batch=221\n",
      "2668: loss=0.366, reward_mean=0.340, reward_bound=0.229, batch=222\n",
      "2669: loss=0.374, reward_mean=0.320, reward_bound=0.254, batch=224\n",
      "2670: loss=0.367, reward_mean=0.280, reward_bound=0.282, batch=186\n",
      "2671: loss=0.362, reward_mean=0.400, reward_bound=0.167, batch=197\n",
      "2672: loss=0.362, reward_mean=0.370, reward_bound=0.178, batch=208\n",
      "2673: loss=0.360, reward_mean=0.360, reward_bound=0.206, batch=212\n",
      "2674: loss=0.355, reward_mean=0.390, reward_bound=0.191, batch=218\n",
      "2675: loss=0.353, reward_mean=0.300, reward_bound=0.229, batch=219\n",
      "2676: loss=0.354, reward_mean=0.270, reward_bound=0.254, batch=219\n",
      "2677: loss=0.353, reward_mean=0.350, reward_bound=0.265, batch=223\n",
      "2678: loss=0.363, reward_mean=0.310, reward_bound=0.282, batch=217\n",
      "2679: loss=0.359, reward_mean=0.390, reward_bound=0.308, batch=222\n",
      "2680: loss=0.358, reward_mean=0.320, reward_bound=0.292, batch=225\n",
      "2681: loss=0.356, reward_mean=0.420, reward_bound=0.289, batch=227\n",
      "2682: loss=0.355, reward_mean=0.450, reward_bound=0.314, batch=171\n",
      "2683: loss=0.352, reward_mean=0.320, reward_bound=0.089, batch=187\n",
      "2684: loss=0.342, reward_mean=0.270, reward_bound=0.098, batch=200\n",
      "2685: loss=0.351, reward_mean=0.290, reward_bound=0.118, batch=210\n",
      "2686: loss=0.341, reward_mean=0.350, reward_bound=0.150, batch=214\n",
      "2687: loss=0.342, reward_mean=0.310, reward_bound=0.167, batch=219\n",
      "2688: loss=0.341, reward_mean=0.450, reward_bound=0.229, batch=215\n",
      "2689: loss=0.348, reward_mean=0.390, reward_bound=0.254, batch=216\n",
      "2690: loss=0.359, reward_mean=0.360, reward_bound=0.282, batch=214\n",
      "2691: loss=0.363, reward_mean=0.360, reward_bound=0.311, batch=220\n",
      "2692: loss=0.356, reward_mean=0.340, reward_bound=0.314, batch=214\n",
      "2693: loss=0.354, reward_mean=0.330, reward_bound=0.314, batch=219\n",
      "2694: loss=0.349, reward_mean=0.330, reward_bound=0.349, batch=167\n",
      "2695: loss=0.340, reward_mean=0.310, reward_bound=0.063, batch=187\n",
      "2696: loss=0.347, reward_mean=0.340, reward_bound=0.072, batch=200\n",
      "2697: loss=0.348, reward_mean=0.350, reward_bound=0.131, batch=210\n",
      "2698: loss=0.342, reward_mean=0.390, reward_bound=0.150, batch=216\n",
      "2699: loss=0.339, reward_mean=0.420, reward_bound=0.196, batch=221\n",
      "2700: loss=0.337, reward_mean=0.350, reward_bound=0.206, batch=224\n",
      "2701: loss=0.340, reward_mean=0.370, reward_bound=0.229, batch=219\n",
      "2702: loss=0.341, reward_mean=0.360, reward_bound=0.225, batch=223\n",
      "2703: loss=0.347, reward_mean=0.350, reward_bound=0.254, batch=223\n",
      "2704: loss=0.343, reward_mean=0.430, reward_bound=0.282, batch=217\n",
      "2705: loss=0.349, reward_mean=0.460, reward_bound=0.314, batch=213\n",
      "2706: loss=0.346, reward_mean=0.320, reward_bound=0.198, batch=219\n",
      "2707: loss=0.350, reward_mean=0.400, reward_bound=0.265, batch=223\n",
      "2708: loss=0.347, reward_mean=0.390, reward_bound=0.282, batch=225\n",
      "2709: loss=0.348, reward_mean=0.420, reward_bound=0.314, batch=226\n",
      "2710: loss=0.346, reward_mean=0.390, reward_bound=0.349, batch=208\n",
      "2711: loss=0.346, reward_mean=0.400, reward_bound=0.349, batch=213\n",
      "2712: loss=0.341, reward_mean=0.300, reward_bound=0.290, batch=219\n",
      "2713: loss=0.345, reward_mean=0.380, reward_bound=0.314, batch=222\n",
      "2714: loss=0.343, reward_mean=0.300, reward_bound=0.254, batch=225\n",
      "2715: loss=0.344, reward_mean=0.450, reward_bound=0.349, batch=225\n",
      "2716: loss=0.360, reward_mean=0.360, reward_bound=0.387, batch=149\n",
      "2717: loss=0.354, reward_mean=0.260, reward_bound=0.000, batch=174\n",
      "2718: loss=0.347, reward_mean=0.420, reward_bound=0.047, batch=192\n",
      "2719: loss=0.352, reward_mean=0.440, reward_bound=0.109, batch=203\n",
      "2720: loss=0.347, reward_mean=0.380, reward_bound=0.144, batch=212\n",
      "2721: loss=0.357, reward_mean=0.480, reward_bound=0.167, batch=216\n",
      "2722: loss=0.355, reward_mean=0.460, reward_bound=0.206, batch=219\n",
      "2723: loss=0.348, reward_mean=0.370, reward_bound=0.229, batch=216\n",
      "2724: loss=0.352, reward_mean=0.360, reward_bound=0.254, batch=215\n",
      "2725: loss=0.353, reward_mean=0.360, reward_bound=0.221, batch=220\n",
      "2726: loss=0.358, reward_mean=0.290, reward_bound=0.282, batch=210\n",
      "2727: loss=0.356, reward_mean=0.450, reward_bound=0.254, batch=216\n",
      "2728: loss=0.360, reward_mean=0.320, reward_bound=0.314, batch=203\n",
      "2729: loss=0.359, reward_mean=0.340, reward_bound=0.244, batch=212\n",
      "2730: loss=0.360, reward_mean=0.370, reward_bound=0.254, batch=213\n",
      "2731: loss=0.359, reward_mean=0.370, reward_bound=0.282, batch=216\n",
      "2732: loss=0.357, reward_mean=0.350, reward_bound=0.314, batch=218\n",
      "2733: loss=0.357, reward_mean=0.310, reward_bound=0.208, batch=222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2734: loss=0.359, reward_mean=0.310, reward_bound=0.229, batch=223\n",
      "2735: loss=0.361, reward_mean=0.340, reward_bound=0.271, batch=226\n",
      "2736: loss=0.361, reward_mean=0.350, reward_bound=0.298, batch=228\n",
      "2737: loss=0.365, reward_mean=0.310, reward_bound=0.317, batch=229\n",
      "2738: loss=0.359, reward_mean=0.350, reward_bound=0.349, batch=204\n",
      "2739: loss=0.359, reward_mean=0.310, reward_bound=0.182, batch=213\n",
      "2740: loss=0.361, reward_mean=0.280, reward_bound=0.206, batch=215\n",
      "2741: loss=0.362, reward_mean=0.310, reward_bound=0.210, batch=220\n",
      "2742: loss=0.362, reward_mean=0.320, reward_bound=0.247, batch=224\n",
      "2743: loss=0.362, reward_mean=0.290, reward_bound=0.254, batch=226\n",
      "2744: loss=0.362, reward_mean=0.290, reward_bound=0.282, batch=225\n",
      "2745: loss=0.361, reward_mean=0.320, reward_bound=0.314, batch=222\n",
      "2746: loss=0.364, reward_mean=0.310, reward_bound=0.349, batch=220\n",
      "2747: loss=0.360, reward_mean=0.390, reward_bound=0.349, batch=223\n",
      "2748: loss=0.357, reward_mean=0.360, reward_bound=0.387, batch=194\n",
      "2749: loss=0.359, reward_mean=0.360, reward_bound=0.182, batch=206\n",
      "2750: loss=0.361, reward_mean=0.390, reward_bound=0.229, batch=211\n",
      "2751: loss=0.358, reward_mean=0.330, reward_bound=0.254, batch=214\n",
      "2752: loss=0.353, reward_mean=0.370, reward_bound=0.226, batch=220\n",
      "2753: loss=0.353, reward_mean=0.440, reward_bound=0.247, batch=224\n",
      "2754: loss=0.351, reward_mean=0.340, reward_bound=0.282, batch=223\n",
      "2755: loss=0.358, reward_mean=0.410, reward_bound=0.314, batch=220\n",
      "2756: loss=0.357, reward_mean=0.400, reward_bound=0.282, batch=223\n",
      "2757: loss=0.363, reward_mean=0.470, reward_bound=0.290, batch=226\n",
      "2758: loss=0.351, reward_mean=0.400, reward_bound=0.349, batch=218\n",
      "2759: loss=0.348, reward_mean=0.340, reward_bound=0.317, batch=222\n",
      "2760: loss=0.352, reward_mean=0.320, reward_bound=0.172, batch=225\n",
      "2761: loss=0.348, reward_mean=0.300, reward_bound=0.321, batch=227\n",
      "2762: loss=0.349, reward_mean=0.360, reward_bound=0.349, batch=227\n",
      "2763: loss=0.350, reward_mean=0.280, reward_bound=0.387, batch=219\n",
      "2764: loss=0.348, reward_mean=0.340, reward_bound=0.342, batch=223\n",
      "2765: loss=0.349, reward_mean=0.290, reward_bound=0.254, batch=225\n",
      "2766: loss=0.348, reward_mean=0.310, reward_bound=0.254, batch=226\n",
      "2767: loss=0.349, reward_mean=0.350, reward_bound=0.368, batch=228\n",
      "2768: loss=0.348, reward_mean=0.340, reward_bound=0.392, batch=229\n",
      "2769: loss=0.355, reward_mean=0.450, reward_bound=0.430, batch=114\n",
      "2770: loss=0.348, reward_mean=0.430, reward_bound=0.014, batch=150\n",
      "2771: loss=0.337, reward_mean=0.410, reward_bound=0.030, batch=175\n",
      "2772: loss=0.341, reward_mean=0.360, reward_bound=0.043, batch=192\n",
      "2773: loss=0.337, reward_mean=0.350, reward_bound=0.072, batch=200\n",
      "2774: loss=0.336, reward_mean=0.530, reward_bound=0.122, batch=208\n",
      "2775: loss=0.344, reward_mean=0.270, reward_bound=0.150, batch=210\n",
      "2776: loss=0.352, reward_mean=0.350, reward_bound=0.167, batch=210\n",
      "2777: loss=0.350, reward_mean=0.430, reward_bound=0.185, batch=209\n",
      "2778: loss=0.352, reward_mean=0.380, reward_bound=0.206, batch=207\n",
      "2779: loss=0.344, reward_mean=0.320, reward_bound=0.229, batch=204\n",
      "2780: loss=0.347, reward_mean=0.280, reward_bound=0.149, batch=213\n",
      "2781: loss=0.367, reward_mean=0.340, reward_bound=0.254, batch=203\n",
      "2782: loss=0.360, reward_mean=0.350, reward_bound=0.271, batch=212\n",
      "2783: loss=0.356, reward_mean=0.400, reward_bound=0.282, batch=202\n",
      "2784: loss=0.358, reward_mean=0.320, reward_bound=0.292, batch=211\n",
      "2785: loss=0.356, reward_mean=0.380, reward_bound=0.314, batch=199\n",
      "2786: loss=0.353, reward_mean=0.320, reward_bound=0.148, batch=209\n",
      "2787: loss=0.350, reward_mean=0.410, reward_bound=0.174, batch=216\n",
      "2788: loss=0.351, reward_mean=0.400, reward_bound=0.229, batch=220\n",
      "2789: loss=0.350, reward_mean=0.300, reward_bound=0.254, batch=222\n",
      "2790: loss=0.362, reward_mean=0.480, reward_bound=0.282, batch=219\n",
      "2791: loss=0.376, reward_mean=0.400, reward_bound=0.349, batch=193\n",
      "2792: loss=0.375, reward_mean=0.350, reward_bound=0.206, batch=204\n",
      "2793: loss=0.377, reward_mean=0.380, reward_bound=0.229, batch=212\n",
      "2794: loss=0.377, reward_mean=0.290, reward_bound=0.263, batch=218\n",
      "2795: loss=0.376, reward_mean=0.310, reward_bound=0.282, batch=216\n",
      "2796: loss=0.380, reward_mean=0.280, reward_bound=0.217, batch=221\n",
      "2797: loss=0.377, reward_mean=0.370, reward_bound=0.314, batch=220\n",
      "2798: loss=0.375, reward_mean=0.320, reward_bound=0.349, batch=217\n",
      "2799: loss=0.377, reward_mean=0.350, reward_bound=0.380, batch=222\n",
      "2800: loss=0.377, reward_mean=0.340, reward_bound=0.302, batch=225\n",
      "2801: loss=0.375, reward_mean=0.340, reward_bound=0.321, batch=227\n",
      "2802: loss=0.376, reward_mean=0.360, reward_bound=0.380, batch=229\n",
      "2803: loss=0.375, reward_mean=0.390, reward_bound=0.387, batch=187\n",
      "2804: loss=0.372, reward_mean=0.330, reward_bound=0.119, batch=201\n",
      "2805: loss=0.370, reward_mean=0.330, reward_bound=0.185, batch=210\n",
      "2806: loss=0.369, reward_mean=0.330, reward_bound=0.229, batch=215\n",
      "2807: loss=0.365, reward_mean=0.350, reward_bound=0.229, batch=219\n",
      "2808: loss=0.365, reward_mean=0.380, reward_bound=0.239, batch=223\n",
      "2809: loss=0.366, reward_mean=0.400, reward_bound=0.254, batch=222\n",
      "2810: loss=0.366, reward_mean=0.360, reward_bound=0.282, batch=219\n",
      "2811: loss=0.368, reward_mean=0.340, reward_bound=0.314, batch=215\n",
      "2812: loss=0.371, reward_mean=0.400, reward_bound=0.289, batch=220\n",
      "2813: loss=0.368, reward_mean=0.380, reward_bound=0.338, batch=224\n",
      "2814: loss=0.370, reward_mean=0.360, reward_bound=0.282, batch=226\n",
      "2815: loss=0.374, reward_mean=0.370, reward_bound=0.349, batch=215\n",
      "2816: loss=0.373, reward_mean=0.360, reward_bound=0.321, batch=220\n",
      "2817: loss=0.375, reward_mean=0.330, reward_bound=0.349, batch=222\n",
      "2818: loss=0.373, reward_mean=0.310, reward_bound=0.360, batch=225\n",
      "2819: loss=0.373, reward_mean=0.340, reward_bound=0.387, batch=219\n",
      "2820: loss=0.372, reward_mean=0.320, reward_bound=0.387, batch=222\n",
      "2821: loss=0.373, reward_mean=0.340, reward_bound=0.387, batch=224\n",
      "2822: loss=0.373, reward_mean=0.340, reward_bound=0.339, batch=227\n",
      "2823: loss=0.371, reward_mean=0.380, reward_bound=0.380, batch=229\n",
      "2824: loss=0.373, reward_mean=0.270, reward_bound=0.364, batch=230\n",
      "2825: loss=0.375, reward_mean=0.280, reward_bound=0.418, batch=231\n",
      "2826: loss=0.364, reward_mean=0.380, reward_bound=0.430, batch=170\n",
      "2827: loss=0.347, reward_mean=0.310, reward_bound=0.115, batch=189\n",
      "2828: loss=0.356, reward_mean=0.370, reward_bound=0.150, batch=200\n",
      "2829: loss=0.364, reward_mean=0.370, reward_bound=0.185, batch=203\n",
      "2830: loss=0.362, reward_mean=0.360, reward_bound=0.198, batch=212\n",
      "2831: loss=0.366, reward_mean=0.330, reward_bound=0.206, batch=224\n",
      "2832: loss=0.360, reward_mean=0.320, reward_bound=0.229, batch=219\n",
      "2833: loss=0.350, reward_mean=0.350, reward_bound=0.254, batch=219\n",
      "2834: loss=0.346, reward_mean=0.240, reward_bound=0.194, batch=223\n",
      "2835: loss=0.348, reward_mean=0.390, reward_bound=0.282, batch=219\n",
      "2836: loss=0.354, reward_mean=0.300, reward_bound=0.314, batch=216\n",
      "2837: loss=0.353, reward_mean=0.330, reward_bound=0.241, batch=221\n",
      "2838: loss=0.355, reward_mean=0.370, reward_bound=0.314, batch=224\n",
      "2839: loss=0.359, reward_mean=0.400, reward_bound=0.349, batch=213\n",
      "2840: loss=0.353, reward_mean=0.340, reward_bound=0.229, batch=218\n",
      "2841: loss=0.352, reward_mean=0.250, reward_bound=0.260, batch=222\n",
      "2842: loss=0.359, reward_mean=0.340, reward_bound=0.314, batch=221\n",
      "2843: loss=0.364, reward_mean=0.310, reward_bound=0.349, batch=220\n",
      "2844: loss=0.364, reward_mean=0.360, reward_bound=0.338, batch=224\n",
      "2845: loss=0.364, reward_mean=0.460, reward_bound=0.314, batch=225\n",
      "2846: loss=0.366, reward_mean=0.330, reward_bound=0.387, batch=211\n",
      "2847: loss=0.369, reward_mean=0.310, reward_bound=0.314, batch=216\n",
      "2848: loss=0.371, reward_mean=0.340, reward_bound=0.331, batch=221\n",
      "2849: loss=0.367, reward_mean=0.330, reward_bound=0.349, batch=221\n",
      "2850: loss=0.367, reward_mean=0.340, reward_bound=0.387, batch=222\n",
      "2851: loss=0.366, reward_mean=0.240, reward_bound=0.324, batch=225\n",
      "2852: loss=0.363, reward_mean=0.320, reward_bound=0.289, batch=227\n",
      "2853: loss=0.365, reward_mean=0.350, reward_bound=0.349, batch=228\n",
      "2854: loss=0.365, reward_mean=0.440, reward_bound=0.387, batch=228\n",
      "2855: loss=0.365, reward_mean=0.320, reward_bound=0.430, batch=207\n",
      "2856: loss=0.370, reward_mean=0.290, reward_bound=0.163, batch=215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2857: loss=0.366, reward_mean=0.310, reward_bound=0.210, batch=220\n",
      "2858: loss=0.363, reward_mean=0.220, reward_bound=0.180, batch=224\n",
      "2859: loss=0.355, reward_mean=0.360, reward_bound=0.314, batch=221\n",
      "2860: loss=0.356, reward_mean=0.430, reward_bound=0.349, batch=219\n",
      "2861: loss=0.353, reward_mean=0.420, reward_bound=0.254, batch=221\n",
      "2862: loss=0.357, reward_mean=0.320, reward_bound=0.282, batch=224\n",
      "2863: loss=0.356, reward_mean=0.340, reward_bound=0.349, batch=226\n",
      "2864: loss=0.356, reward_mean=0.290, reward_bound=0.387, batch=223\n",
      "2865: loss=0.356, reward_mean=0.330, reward_bound=0.413, batch=226\n",
      "2866: loss=0.355, reward_mean=0.280, reward_bound=0.351, batch=228\n",
      "2867: loss=0.358, reward_mean=0.350, reward_bound=0.387, batch=228\n",
      "2868: loss=0.360, reward_mean=0.380, reward_bound=0.430, batch=223\n",
      "2869: loss=0.358, reward_mean=0.360, reward_bound=0.398, batch=226\n",
      "2870: loss=0.358, reward_mean=0.340, reward_bound=0.282, batch=227\n",
      "2871: loss=0.358, reward_mean=0.360, reward_bound=0.349, batch=228\n",
      "2872: loss=0.357, reward_mean=0.360, reward_bound=0.392, batch=229\n",
      "2873: loss=0.358, reward_mean=0.350, reward_bound=0.430, batch=227\n",
      "2874: loss=0.359, reward_mean=0.340, reward_bound=0.308, batch=229\n",
      "2875: loss=0.359, reward_mean=0.370, reward_bound=0.405, batch=230\n",
      "2876: loss=0.370, reward_mean=0.340, reward_bound=0.478, batch=114\n",
      "2877: loss=0.326, reward_mean=0.420, reward_bound=0.009, batch=150\n",
      "2878: loss=0.325, reward_mean=0.380, reward_bound=0.032, batch=175\n",
      "2879: loss=0.311, reward_mean=0.310, reward_bound=0.034, batch=191\n",
      "2880: loss=0.320, reward_mean=0.320, reward_bound=0.065, batch=202\n",
      "2881: loss=0.322, reward_mean=0.350, reward_bound=0.089, batch=208\n",
      "2882: loss=0.331, reward_mean=0.300, reward_bound=0.109, batch=212\n",
      "2883: loss=0.328, reward_mean=0.290, reward_bound=0.122, batch=217\n",
      "2884: loss=0.337, reward_mean=0.270, reward_bound=0.147, batch=222\n",
      "2885: loss=0.341, reward_mean=0.380, reward_bound=0.150, batch=224\n",
      "2886: loss=0.344, reward_mean=0.320, reward_bound=0.183, batch=227\n",
      "2887: loss=0.346, reward_mean=0.280, reward_bound=0.185, batch=225\n",
      "2888: loss=0.349, reward_mean=0.390, reward_bound=0.206, batch=217\n",
      "2889: loss=0.356, reward_mean=0.380, reward_bound=0.229, batch=213\n",
      "2890: loss=0.354, reward_mean=0.350, reward_bound=0.220, batch=219\n",
      "2891: loss=0.365, reward_mean=0.430, reward_bound=0.254, batch=215\n",
      "2892: loss=0.363, reward_mean=0.320, reward_bound=0.282, batch=195\n",
      "2893: loss=0.360, reward_mean=0.320, reward_bound=0.210, batch=206\n",
      "2894: loss=0.356, reward_mean=0.390, reward_bound=0.254, batch=213\n",
      "2895: loss=0.357, reward_mean=0.340, reward_bound=0.254, batch=218\n",
      "2896: loss=0.360, reward_mean=0.370, reward_bound=0.282, batch=221\n",
      "2897: loss=0.361, reward_mean=0.290, reward_bound=0.314, batch=197\n",
      "2898: loss=0.362, reward_mean=0.380, reward_bound=0.272, batch=208\n",
      "2899: loss=0.367, reward_mean=0.350, reward_bound=0.282, batch=213\n",
      "2900: loss=0.365, reward_mean=0.320, reward_bound=0.229, batch=218\n",
      "2901: loss=0.360, reward_mean=0.380, reward_bound=0.229, batch=221\n",
      "2902: loss=0.361, reward_mean=0.340, reward_bound=0.314, batch=219\n",
      "2903: loss=0.364, reward_mean=0.370, reward_bound=0.349, batch=189\n",
      "2904: loss=0.358, reward_mean=0.390, reward_bound=0.254, batch=201\n",
      "2905: loss=0.357, reward_mean=0.370, reward_bound=0.229, batch=210\n",
      "2906: loss=0.358, reward_mean=0.370, reward_bound=0.282, batch=214\n",
      "2907: loss=0.361, reward_mean=0.340, reward_bound=0.314, batch=211\n",
      "2908: loss=0.365, reward_mean=0.290, reward_bound=0.206, batch=217\n",
      "2909: loss=0.363, reward_mean=0.380, reward_bound=0.349, batch=212\n",
      "2910: loss=0.360, reward_mean=0.460, reward_bound=0.349, batch=217\n",
      "2911: loss=0.358, reward_mean=0.390, reward_bound=0.349, batch=220\n",
      "2912: loss=0.358, reward_mean=0.350, reward_bound=0.349, batch=222\n",
      "2913: loss=0.360, reward_mean=0.300, reward_bound=0.272, batch=225\n",
      "2914: loss=0.360, reward_mean=0.330, reward_bound=0.314, batch=226\n",
      "2915: loss=0.338, reward_mean=0.400, reward_bound=0.387, batch=197\n",
      "2916: loss=0.326, reward_mean=0.380, reward_bound=0.202, batch=208\n",
      "2917: loss=0.322, reward_mean=0.330, reward_bound=0.229, batch=213\n",
      "2918: loss=0.321, reward_mean=0.320, reward_bound=0.254, batch=218\n",
      "2919: loss=0.319, reward_mean=0.240, reward_bound=0.214, batch=222\n",
      "2920: loss=0.323, reward_mean=0.320, reward_bound=0.282, batch=224\n",
      "2921: loss=0.322, reward_mean=0.300, reward_bound=0.305, batch=227\n",
      "2922: loss=0.319, reward_mean=0.280, reward_bound=0.302, batch=229\n",
      "2923: loss=0.326, reward_mean=0.390, reward_bound=0.314, batch=226\n",
      "2924: loss=0.331, reward_mean=0.440, reward_bound=0.349, batch=219\n",
      "2925: loss=0.331, reward_mean=0.370, reward_bound=0.282, batch=221\n",
      "2926: loss=0.330, reward_mean=0.350, reward_bound=0.387, batch=215\n",
      "2927: loss=0.330, reward_mean=0.300, reward_bound=0.234, batch=220\n",
      "2928: loss=0.332, reward_mean=0.390, reward_bound=0.314, batch=221\n",
      "2929: loss=0.332, reward_mean=0.320, reward_bound=0.206, batch=224\n",
      "2930: loss=0.332, reward_mean=0.250, reward_bound=0.254, batch=225\n",
      "2931: loss=0.332, reward_mean=0.290, reward_bound=0.289, batch=227\n",
      "2932: loss=0.333, reward_mean=0.290, reward_bound=0.314, batch=227\n",
      "2933: loss=0.332, reward_mean=0.330, reward_bound=0.349, batch=227\n",
      "2934: loss=0.332, reward_mean=0.310, reward_bound=0.314, batch=228\n",
      "2935: loss=0.331, reward_mean=0.330, reward_bound=0.314, batch=228\n",
      "2936: loss=0.331, reward_mean=0.260, reward_bound=0.349, batch=228\n",
      "2937: loss=0.329, reward_mean=0.280, reward_bound=0.387, batch=228\n",
      "2938: loss=0.329, reward_mean=0.370, reward_bound=0.392, batch=229\n",
      "2939: loss=0.329, reward_mean=0.330, reward_bound=0.405, batch=230\n",
      "2940: loss=0.328, reward_mean=0.390, reward_bound=0.418, batch=231\n",
      "2941: loss=0.359, reward_mean=0.350, reward_bound=0.430, batch=182\n",
      "2942: loss=0.353, reward_mean=0.290, reward_bound=0.098, batch=196\n",
      "2943: loss=0.351, reward_mean=0.430, reward_bound=0.150, batch=206\n",
      "2944: loss=0.358, reward_mean=0.400, reward_bound=0.254, batch=207\n",
      "2945: loss=0.351, reward_mean=0.350, reward_bound=0.282, batch=207\n",
      "2946: loss=0.346, reward_mean=0.320, reward_bound=0.277, batch=215\n",
      "2947: loss=0.361, reward_mean=0.360, reward_bound=0.314, batch=209\n",
      "2948: loss=0.354, reward_mean=0.290, reward_bound=0.182, batch=216\n",
      "2949: loss=0.353, reward_mean=0.300, reward_bound=0.298, batch=221\n",
      "2950: loss=0.349, reward_mean=0.290, reward_bound=0.314, batch=223\n",
      "2951: loss=0.348, reward_mean=0.340, reward_bound=0.311, batch=226\n",
      "2952: loss=0.352, reward_mean=0.320, reward_bound=0.349, batch=218\n",
      "2953: loss=0.350, reward_mean=0.330, reward_bound=0.208, batch=222\n",
      "2954: loss=0.352, reward_mean=0.330, reward_bound=0.292, batch=225\n",
      "2955: loss=0.354, reward_mean=0.280, reward_bound=0.349, batch=225\n",
      "2956: loss=0.362, reward_mean=0.300, reward_bound=0.387, batch=211\n",
      "2957: loss=0.363, reward_mean=0.320, reward_bound=0.206, batch=216\n",
      "2958: loss=0.355, reward_mean=0.370, reward_bound=0.268, batch=221\n",
      "2959: loss=0.355, reward_mean=0.370, reward_bound=0.314, batch=222\n",
      "2960: loss=0.354, reward_mean=0.310, reward_bound=0.349, batch=222\n",
      "2961: loss=0.353, reward_mean=0.360, reward_bound=0.387, batch=223\n",
      "2962: loss=0.352, reward_mean=0.350, reward_bound=0.387, batch=225\n",
      "2963: loss=0.359, reward_mean=0.300, reward_bound=0.260, batch=227\n",
      "2964: loss=0.351, reward_mean=0.320, reward_bound=0.387, batch=226\n",
      "2965: loss=0.354, reward_mean=0.250, reward_bound=0.430, batch=202\n",
      "2966: loss=0.349, reward_mean=0.270, reward_bound=0.117, batch=211\n",
      "2967: loss=0.350, reward_mean=0.330, reward_bound=0.185, batch=217\n",
      "2968: loss=0.350, reward_mean=0.370, reward_bound=0.249, batch=222\n",
      "2969: loss=0.346, reward_mean=0.270, reward_bound=0.254, batch=223\n",
      "2970: loss=0.353, reward_mean=0.370, reward_bound=0.282, batch=225\n",
      "2971: loss=0.348, reward_mean=0.290, reward_bound=0.314, batch=223\n",
      "2972: loss=0.350, reward_mean=0.310, reward_bound=0.335, batch=226\n",
      "2973: loss=0.355, reward_mean=0.280, reward_bound=0.349, batch=227\n",
      "2974: loss=0.358, reward_mean=0.300, reward_bound=0.335, batch=229\n",
      "2975: loss=0.350, reward_mean=0.290, reward_bound=0.387, batch=219\n",
      "2976: loss=0.348, reward_mean=0.280, reward_bound=0.328, batch=223\n",
      "2977: loss=0.348, reward_mean=0.330, reward_bound=0.349, batch=225\n",
      "2978: loss=0.347, reward_mean=0.280, reward_bound=0.387, batch=225\n",
      "2979: loss=0.347, reward_mean=0.340, reward_bound=0.430, batch=220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2980: loss=0.350, reward_mean=0.340, reward_bound=0.376, batch=224\n",
      "2981: loss=0.352, reward_mean=0.350, reward_bound=0.387, batch=226\n",
      "2982: loss=0.352, reward_mean=0.260, reward_bound=0.390, batch=228\n",
      "2983: loss=0.352, reward_mean=0.380, reward_bound=0.392, batch=229\n",
      "2984: loss=0.355, reward_mean=0.310, reward_bound=0.430, batch=227\n",
      "2985: loss=0.356, reward_mean=0.270, reward_bound=0.380, batch=229\n",
      "2986: loss=0.355, reward_mean=0.270, reward_bound=0.405, batch=230\n",
      "2987: loss=0.354, reward_mean=0.400, reward_bound=0.430, batch=229\n",
      "2988: loss=0.353, reward_mean=0.330, reward_bound=0.478, batch=232\n",
      "2989: loss=0.361, reward_mean=0.280, reward_bound=0.478, batch=158\n",
      "2990: loss=0.352, reward_mean=0.360, reward_bound=0.080, batch=179\n",
      "2991: loss=0.346, reward_mean=0.340, reward_bound=0.109, batch=193\n",
      "2992: loss=0.349, reward_mean=0.270, reward_bound=0.144, batch=205\n",
      "2993: loss=0.351, reward_mean=0.330, reward_bound=0.150, batch=212\n",
      "2994: loss=0.348, reward_mean=0.340, reward_bound=0.172, batch=218\n",
      "2995: loss=0.356, reward_mean=0.270, reward_bound=0.185, batch=217\n",
      "2996: loss=0.353, reward_mean=0.330, reward_bound=0.229, batch=218\n",
      "2997: loss=0.355, reward_mean=0.310, reward_bound=0.254, batch=212\n",
      "2998: loss=0.349, reward_mean=0.320, reward_bound=0.282, batch=207\n",
      "2999: loss=0.348, reward_mean=0.310, reward_bound=0.128, batch=215\n",
      "3000: loss=0.351, reward_mean=0.340, reward_bound=0.229, batch=219\n",
      "3001: loss=0.347, reward_mean=0.310, reward_bound=0.295, batch=223\n",
      "3002: loss=0.347, reward_mean=0.420, reward_bound=0.314, batch=217\n",
      "3003: loss=0.344, reward_mean=0.320, reward_bound=0.277, batch=222\n",
      "3004: loss=0.345, reward_mean=0.340, reward_bound=0.282, batch=224\n",
      "3005: loss=0.350, reward_mean=0.310, reward_bound=0.349, batch=207\n",
      "3006: loss=0.351, reward_mean=0.310, reward_bound=0.109, batch=218\n",
      "3007: loss=0.344, reward_mean=0.300, reward_bound=0.167, batch=220\n",
      "3008: loss=0.352, reward_mean=0.330, reward_bound=0.254, batch=223\n",
      "3009: loss=0.349, reward_mean=0.370, reward_bound=0.282, batch=224\n",
      "3010: loss=0.354, reward_mean=0.320, reward_bound=0.314, batch=226\n",
      "3011: loss=0.343, reward_mean=0.360, reward_bound=0.349, batch=224\n",
      "3012: loss=0.342, reward_mean=0.300, reward_bound=0.311, batch=227\n",
      "3013: loss=0.346, reward_mean=0.350, reward_bound=0.308, batch=229\n",
      "3014: loss=0.345, reward_mean=0.320, reward_bound=0.349, batch=229\n",
      "3015: loss=0.347, reward_mean=0.380, reward_bound=0.387, batch=219\n",
      "3016: loss=0.346, reward_mean=0.410, reward_bound=0.364, batch=223\n",
      "3017: loss=0.345, reward_mean=0.300, reward_bound=0.372, batch=226\n",
      "3018: loss=0.349, reward_mean=0.340, reward_bound=0.409, batch=228\n",
      "3019: loss=0.355, reward_mean=0.320, reward_bound=0.430, batch=193\n",
      "3020: loss=0.347, reward_mean=0.400, reward_bound=0.130, batch=205\n",
      "3021: loss=0.339, reward_mean=0.260, reward_bound=0.135, batch=211\n",
      "3022: loss=0.337, reward_mean=0.430, reward_bound=0.229, batch=216\n",
      "3023: loss=0.333, reward_mean=0.300, reward_bound=0.241, batch=221\n",
      "3024: loss=0.338, reward_mean=0.380, reward_bound=0.254, batch=220\n",
      "3025: loss=0.343, reward_mean=0.330, reward_bound=0.282, batch=221\n",
      "3026: loss=0.341, reward_mean=0.320, reward_bound=0.282, batch=224\n",
      "3027: loss=0.351, reward_mean=0.310, reward_bound=0.314, batch=219\n",
      "3028: loss=0.345, reward_mean=0.410, reward_bound=0.349, batch=218\n",
      "3029: loss=0.341, reward_mean=0.400, reward_bound=0.286, batch=222\n",
      "3030: loss=0.339, reward_mean=0.380, reward_bound=0.349, batch=224\n",
      "3031: loss=0.337, reward_mean=0.290, reward_bound=0.342, batch=227\n",
      "3032: loss=0.345, reward_mean=0.360, reward_bound=0.387, batch=216\n",
      "3033: loss=0.348, reward_mean=0.350, reward_bound=0.282, batch=220\n",
      "3034: loss=0.349, reward_mean=0.370, reward_bound=0.229, batch=223\n",
      "3035: loss=0.351, reward_mean=0.250, reward_bound=0.271, batch=226\n",
      "3036: loss=0.343, reward_mean=0.390, reward_bound=0.349, batch=225\n",
      "3037: loss=0.343, reward_mean=0.400, reward_bound=0.396, batch=227\n",
      "3038: loss=0.347, reward_mean=0.310, reward_bound=0.430, batch=213\n",
      "3039: loss=0.350, reward_mean=0.330, reward_bound=0.282, batch=218\n",
      "3040: loss=0.350, reward_mean=0.270, reward_bound=0.229, batch=221\n",
      "3041: loss=0.348, reward_mean=0.330, reward_bound=0.282, batch=222\n",
      "3042: loss=0.348, reward_mean=0.260, reward_bound=0.349, batch=224\n",
      "3043: loss=0.349, reward_mean=0.290, reward_bound=0.345, batch=227\n",
      "3044: loss=0.349, reward_mean=0.330, reward_bound=0.380, batch=229\n",
      "3045: loss=0.349, reward_mean=0.380, reward_bound=0.387, batch=225\n",
      "3046: loss=0.349, reward_mean=0.310, reward_bound=0.430, batch=222\n",
      "3047: loss=0.349, reward_mean=0.340, reward_bound=0.349, batch=223\n",
      "3048: loss=0.349, reward_mean=0.250, reward_bound=0.349, batch=225\n",
      "3049: loss=0.348, reward_mean=0.310, reward_bound=0.430, batch=226\n",
      "3050: loss=0.349, reward_mean=0.350, reward_bound=0.387, batch=227\n",
      "3051: loss=0.347, reward_mean=0.320, reward_bound=0.430, batch=227\n",
      "3052: loss=0.347, reward_mean=0.340, reward_bound=0.469, batch=229\n",
      "3053: loss=0.348, reward_mean=0.260, reward_bound=0.401, batch=230\n",
      "3054: loss=0.348, reward_mean=0.420, reward_bound=0.387, batch=230\n",
      "3055: loss=0.347, reward_mean=0.360, reward_bound=0.464, batch=231\n",
      "3056: loss=0.357, reward_mean=0.280, reward_bound=0.478, batch=183\n",
      "3057: loss=0.347, reward_mean=0.240, reward_bound=0.098, batch=197\n",
      "3058: loss=0.351, reward_mean=0.380, reward_bound=0.122, batch=207\n",
      "3059: loss=0.351, reward_mean=0.240, reward_bound=0.135, batch=213\n",
      "3060: loss=0.355, reward_mean=0.330, reward_bound=0.167, batch=216\n",
      "3061: loss=0.344, reward_mean=0.250, reward_bound=0.206, batch=216\n",
      "3062: loss=0.348, reward_mean=0.360, reward_bound=0.254, batch=220\n",
      "3063: loss=0.350, reward_mean=0.340, reward_bound=0.282, batch=222\n",
      "3064: loss=0.351, reward_mean=0.310, reward_bound=0.314, batch=216\n",
      "3065: loss=0.346, reward_mean=0.300, reward_bound=0.331, batch=221\n",
      "3066: loss=0.343, reward_mean=0.330, reward_bound=0.349, batch=215\n",
      "3067: loss=0.340, reward_mean=0.400, reward_bound=0.282, batch=218\n",
      "3068: loss=0.342, reward_mean=0.340, reward_bound=0.314, batch=220\n",
      "3069: loss=0.343, reward_mean=0.300, reward_bound=0.338, batch=224\n",
      "3070: loss=0.340, reward_mean=0.370, reward_bound=0.349, batch=224\n",
      "3071: loss=0.351, reward_mean=0.320, reward_bound=0.387, batch=209\n",
      "3072: loss=0.346, reward_mean=0.320, reward_bound=0.239, batch=216\n",
      "3073: loss=0.342, reward_mean=0.280, reward_bound=0.268, batch=221\n",
      "3074: loss=0.344, reward_mean=0.280, reward_bound=0.314, batch=223\n",
      "3075: loss=0.348, reward_mean=0.260, reward_bound=0.349, batch=222\n",
      "3076: loss=0.345, reward_mean=0.260, reward_bound=0.324, batch=225\n",
      "3077: loss=0.347, reward_mean=0.310, reward_bound=0.349, batch=226\n",
      "3078: loss=0.345, reward_mean=0.400, reward_bound=0.387, batch=223\n",
      "3079: loss=0.344, reward_mean=0.320, reward_bound=0.335, batch=226\n",
      "3080: loss=0.346, reward_mean=0.260, reward_bound=0.349, batch=227\n",
      "3081: loss=0.349, reward_mean=0.350, reward_bound=0.380, batch=229\n",
      "3082: loss=0.346, reward_mean=0.360, reward_bound=0.387, batch=229\n",
      "3083: loss=0.347, reward_mean=0.390, reward_bound=0.430, batch=213\n",
      "3084: loss=0.341, reward_mean=0.350, reward_bound=0.229, batch=218\n",
      "3085: loss=0.342, reward_mean=0.280, reward_bound=0.282, batch=221\n",
      "3086: loss=0.341, reward_mean=0.390, reward_bound=0.314, batch=224\n",
      "3087: loss=0.345, reward_mean=0.340, reward_bound=0.349, batch=223\n",
      "3088: loss=0.349, reward_mean=0.290, reward_bound=0.387, batch=223\n",
      "3089: loss=0.350, reward_mean=0.310, reward_bound=0.413, batch=226\n",
      "3090: loss=0.349, reward_mean=0.390, reward_bound=0.409, batch=228\n",
      "3091: loss=0.347, reward_mean=0.320, reward_bound=0.430, batch=221\n",
      "3092: loss=0.347, reward_mean=0.340, reward_bound=0.387, batch=223\n",
      "3093: loss=0.346, reward_mean=0.400, reward_bound=0.413, batch=226\n",
      "3094: loss=0.347, reward_mean=0.340, reward_bound=0.454, batch=228\n",
      "3095: loss=0.348, reward_mean=0.290, reward_bound=0.435, batch=229\n",
      "3096: loss=0.347, reward_mean=0.370, reward_bound=0.450, batch=230\n",
      "3097: loss=0.348, reward_mean=0.250, reward_bound=0.451, batch=231\n",
      "3098: loss=0.356, reward_mean=0.240, reward_bound=0.478, batch=200\n",
      "3099: loss=0.357, reward_mean=0.310, reward_bound=0.222, batch=210\n",
      "3100: loss=0.356, reward_mean=0.330, reward_bound=0.274, batch=217\n",
      "3101: loss=0.354, reward_mean=0.340, reward_bound=0.342, batch=222\n",
      "3102: loss=0.354, reward_mean=0.340, reward_bound=0.349, batch=218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3103: loss=0.355, reward_mean=0.300, reward_bound=0.321, batch=222\n",
      "3104: loss=0.356, reward_mean=0.350, reward_bound=0.292, batch=225\n",
      "3105: loss=0.354, reward_mean=0.350, reward_bound=0.356, batch=227\n",
      "3106: loss=0.352, reward_mean=0.350, reward_bound=0.387, batch=223\n",
      "3107: loss=0.353, reward_mean=0.270, reward_bound=0.358, batch=226\n",
      "3108: loss=0.350, reward_mean=0.280, reward_bound=0.271, batch=228\n",
      "3109: loss=0.353, reward_mean=0.370, reward_bound=0.387, batch=228\n",
      "3110: loss=0.353, reward_mean=0.330, reward_bound=0.387, batch=228\n",
      "3111: loss=0.353, reward_mean=0.420, reward_bound=0.430, batch=220\n",
      "3112: loss=0.353, reward_mean=0.370, reward_bound=0.349, batch=223\n",
      "3113: loss=0.355, reward_mean=0.340, reward_bound=0.387, batch=225\n",
      "3114: loss=0.354, reward_mean=0.360, reward_bound=0.387, batch=226\n",
      "3115: loss=0.354, reward_mean=0.290, reward_bound=0.387, batch=226\n",
      "3116: loss=0.352, reward_mean=0.360, reward_bound=0.409, batch=228\n",
      "3117: loss=0.349, reward_mean=0.200, reward_bound=0.430, batch=224\n",
      "3118: loss=0.349, reward_mean=0.280, reward_bound=0.342, batch=227\n",
      "3119: loss=0.351, reward_mean=0.290, reward_bound=0.422, batch=229\n",
      "3120: loss=0.348, reward_mean=0.360, reward_bound=0.430, batch=229\n",
      "3121: loss=0.349, reward_mean=0.320, reward_bound=0.424, batch=230\n",
      "3122: loss=0.351, reward_mean=0.360, reward_bound=0.478, batch=212\n",
      "3123: loss=0.354, reward_mean=0.380, reward_bound=0.263, batch=218\n",
      "3124: loss=0.353, reward_mean=0.290, reward_bound=0.211, batch=222\n",
      "3125: loss=0.349, reward_mean=0.370, reward_bound=0.302, batch=225\n",
      "3126: loss=0.349, reward_mean=0.300, reward_bound=0.349, batch=224\n",
      "3127: loss=0.349, reward_mean=0.430, reward_bound=0.349, batch=226\n",
      "3128: loss=0.348, reward_mean=0.320, reward_bound=0.387, batch=225\n",
      "3129: loss=0.347, reward_mean=0.350, reward_bound=0.349, batch=226\n",
      "3130: loss=0.348, reward_mean=0.330, reward_bound=0.409, batch=228\n",
      "3131: loss=0.348, reward_mean=0.330, reward_bound=0.392, batch=229\n",
      "3132: loss=0.348, reward_mean=0.280, reward_bound=0.364, batch=230\n",
      "3133: loss=0.349, reward_mean=0.330, reward_bound=0.430, batch=227\n",
      "3134: loss=0.347, reward_mean=0.350, reward_bound=0.452, batch=229\n",
      "3135: loss=0.346, reward_mean=0.310, reward_bound=0.360, batch=230\n",
      "3136: loss=0.347, reward_mean=0.320, reward_bound=0.430, batch=230\n",
      "3137: loss=0.347, reward_mean=0.280, reward_bound=0.464, batch=231\n",
      "3138: loss=0.349, reward_mean=0.250, reward_bound=0.478, batch=220\n",
      "3139: loss=0.347, reward_mean=0.290, reward_bound=0.314, batch=223\n",
      "3140: loss=0.347, reward_mean=0.420, reward_bound=0.430, batch=224\n",
      "3141: loss=0.345, reward_mean=0.360, reward_bound=0.426, batch=227\n",
      "3142: loss=0.346, reward_mean=0.360, reward_bound=0.430, batch=228\n",
      "3143: loss=0.345, reward_mean=0.350, reward_bound=0.478, batch=231\n",
      "3144: loss=0.346, reward_mean=0.290, reward_bound=0.478, batch=226\n",
      "3145: loss=0.347, reward_mean=0.390, reward_bound=0.505, batch=228\n",
      "3146: loss=0.347, reward_mean=0.350, reward_bound=0.435, batch=229\n",
      "3147: loss=0.347, reward_mean=0.340, reward_bound=0.478, batch=232\n",
      "3148: loss=0.347, reward_mean=0.340, reward_bound=0.388, batch=232\n",
      "3149: loss=0.347, reward_mean=0.340, reward_bound=0.445, batch=232\n",
      "3150: loss=0.346, reward_mean=0.350, reward_bound=0.478, batch=231\n",
      "3152: loss=0.296, reward_mean=0.350, reward_bound=0.000, batch=35\n",
      "3153: loss=0.287, reward_mean=0.360, reward_bound=0.000, batch=71\n",
      "3154: loss=0.287, reward_mean=0.370, reward_bound=0.000, batch=108\n",
      "3155: loss=0.288, reward_mean=0.280, reward_bound=0.000, batch=136\n",
      "3156: loss=0.292, reward_mean=0.310, reward_bound=0.001, batch=164\n",
      "3157: loss=0.293, reward_mean=0.240, reward_bound=0.001, batch=185\n",
      "3158: loss=0.294, reward_mean=0.350, reward_bound=0.013, batch=201\n",
      "3159: loss=0.292, reward_mean=0.250, reward_bound=0.018, batch=210\n",
      "3160: loss=0.294, reward_mean=0.320, reward_bound=0.031, batch=214\n",
      "3161: loss=0.297, reward_mean=0.320, reward_bound=0.042, batch=217\n",
      "3162: loss=0.299, reward_mean=0.340, reward_bound=0.058, batch=226\n",
      "3163: loss=0.304, reward_mean=0.340, reward_bound=0.072, batch=222\n",
      "3164: loss=0.305, reward_mean=0.380, reward_bound=0.089, batch=222\n",
      "3165: loss=0.303, reward_mean=0.240, reward_bound=0.098, batch=222\n",
      "3166: loss=0.303, reward_mean=0.280, reward_bound=0.122, batch=211\n",
      "3167: loss=0.315, reward_mean=0.280, reward_bound=0.135, batch=204\n",
      "3168: loss=0.312, reward_mean=0.290, reward_bound=0.135, batch=212\n",
      "3169: loss=0.314, reward_mean=0.350, reward_bound=0.150, batch=213\n",
      "3170: loss=0.321, reward_mean=0.320, reward_bound=0.167, batch=198\n",
      "3171: loss=0.330, reward_mean=0.420, reward_bound=0.185, batch=182\n",
      "3172: loss=0.326, reward_mean=0.280, reward_bound=0.172, batch=197\n",
      "3173: loss=0.325, reward_mean=0.310, reward_bound=0.080, batch=207\n",
      "3174: loss=0.330, reward_mean=0.340, reward_bound=0.206, batch=190\n",
      "3175: loss=0.330, reward_mean=0.310, reward_bound=0.180, batch=203\n",
      "3176: loss=0.330, reward_mean=0.330, reward_bound=0.185, batch=207\n",
      "3177: loss=0.330, reward_mean=0.380, reward_bound=0.220, batch=215\n",
      "3178: loss=0.321, reward_mean=0.310, reward_bound=0.229, batch=200\n",
      "3179: loss=0.319, reward_mean=0.350, reward_bound=0.150, batch=208\n",
      "3180: loss=0.316, reward_mean=0.450, reward_bound=0.206, batch=213\n",
      "3181: loss=0.315, reward_mean=0.290, reward_bound=0.244, batch=219\n",
      "3182: loss=0.313, reward_mean=0.380, reward_bound=0.254, batch=184\n",
      "3183: loss=0.312, reward_mean=0.330, reward_bound=0.122, batch=198\n",
      "3184: loss=0.314, reward_mean=0.330, reward_bound=0.185, batch=207\n",
      "3185: loss=0.315, reward_mean=0.400, reward_bound=0.206, batch=212\n",
      "3186: loss=0.315, reward_mean=0.290, reward_bound=0.213, batch=218\n",
      "3187: loss=0.316, reward_mean=0.300, reward_bound=0.254, batch=217\n",
      "3188: loss=0.333, reward_mean=0.380, reward_bound=0.282, batch=178\n",
      "3189: loss=0.331, reward_mean=0.370, reward_bound=0.167, batch=193\n",
      "3190: loss=0.329, reward_mean=0.320, reward_bound=0.144, batch=205\n",
      "3191: loss=0.320, reward_mean=0.410, reward_bound=0.206, batch=210\n",
      "3192: loss=0.324, reward_mean=0.360, reward_bound=0.206, batch=221\n",
      "3193: loss=0.324, reward_mean=0.320, reward_bound=0.229, batch=218\n",
      "3194: loss=0.326, reward_mean=0.400, reward_bound=0.254, batch=216\n",
      "3195: loss=0.331, reward_mean=0.390, reward_bound=0.282, batch=217\n",
      "3196: loss=0.333, reward_mean=0.320, reward_bound=0.206, batch=221\n",
      "3197: loss=0.324, reward_mean=0.350, reward_bound=0.314, batch=175\n",
      "3198: loss=0.325, reward_mean=0.330, reward_bound=0.051, batch=192\n",
      "3199: loss=0.325, reward_mean=0.330, reward_bound=0.150, batch=202\n",
      "3200: loss=0.332, reward_mean=0.410, reward_bound=0.185, batch=203\n",
      "3201: loss=0.331, reward_mean=0.370, reward_bound=0.185, batch=211\n",
      "3202: loss=0.330, reward_mean=0.300, reward_bound=0.206, batch=209\n",
      "3203: loss=0.325, reward_mean=0.310, reward_bound=0.229, batch=209\n",
      "3204: loss=0.324, reward_mean=0.270, reward_bound=0.167, batch=215\n",
      "3205: loss=0.325, reward_mean=0.340, reward_bound=0.229, batch=219\n",
      "3206: loss=0.323, reward_mean=0.340, reward_bound=0.254, batch=220\n",
      "3207: loss=0.326, reward_mean=0.380, reward_bound=0.282, batch=216\n",
      "3208: loss=0.320, reward_mean=0.390, reward_bound=0.314, batch=214\n",
      "3209: loss=0.321, reward_mean=0.320, reward_bound=0.311, batch=220\n",
      "3210: loss=0.323, reward_mean=0.400, reward_bound=0.349, batch=159\n",
      "3211: loss=0.314, reward_mean=0.360, reward_bound=0.075, batch=181\n",
      "3212: loss=0.308, reward_mean=0.430, reward_bound=0.109, batch=194\n",
      "3213: loss=0.305, reward_mean=0.310, reward_bound=0.122, batch=202\n",
      "3214: loss=0.312, reward_mean=0.450, reward_bound=0.185, batch=206\n",
      "3215: loss=0.300, reward_mean=0.350, reward_bound=0.206, batch=211\n",
      "3216: loss=0.309, reward_mean=0.270, reward_bound=0.229, batch=207\n",
      "3217: loss=0.314, reward_mean=0.350, reward_bound=0.254, batch=208\n",
      "3218: loss=0.314, reward_mean=0.370, reward_bound=0.206, batch=214\n",
      "3219: loss=0.309, reward_mean=0.390, reward_bound=0.229, batch=218\n",
      "3220: loss=0.309, reward_mean=0.350, reward_bound=0.257, batch=222\n",
      "3221: loss=0.316, reward_mean=0.430, reward_bound=0.282, batch=219\n",
      "3222: loss=0.315, reward_mean=0.420, reward_bound=0.278, batch=223\n",
      "3223: loss=0.311, reward_mean=0.310, reward_bound=0.314, batch=216\n",
      "3224: loss=0.311, reward_mean=0.330, reward_bound=0.254, batch=220\n",
      "3225: loss=0.310, reward_mean=0.290, reward_bound=0.349, batch=211\n",
      "3226: loss=0.312, reward_mean=0.480, reward_bound=0.314, batch=217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3227: loss=0.310, reward_mean=0.340, reward_bound=0.282, batch=221\n",
      "3228: loss=0.310, reward_mean=0.380, reward_bound=0.314, batch=224\n",
      "3229: loss=0.314, reward_mean=0.390, reward_bound=0.349, batch=225\n",
      "3230: loss=0.310, reward_mean=0.380, reward_bound=0.387, batch=144\n",
      "3231: loss=0.295, reward_mean=0.370, reward_bound=0.015, batch=171\n",
      "3232: loss=0.295, reward_mean=0.370, reward_bound=0.089, batch=189\n",
      "3233: loss=0.295, reward_mean=0.270, reward_bound=0.098, batch=200\n",
      "3234: loss=0.302, reward_mean=0.300, reward_bound=0.103, batch=210\n",
      "3235: loss=0.296, reward_mean=0.370, reward_bound=0.135, batch=216\n",
      "3236: loss=0.300, reward_mean=0.330, reward_bound=0.150, batch=217\n",
      "3237: loss=0.301, reward_mean=0.360, reward_bound=0.167, batch=220\n",
      "3238: loss=0.297, reward_mean=0.390, reward_bound=0.206, batch=226\n",
      "3239: loss=0.296, reward_mean=0.310, reward_bound=0.206, batch=219\n",
      "3240: loss=0.294, reward_mean=0.340, reward_bound=0.229, batch=215\n",
      "3241: loss=0.300, reward_mean=0.340, reward_bound=0.254, batch=207\n",
      "3242: loss=0.303, reward_mean=0.270, reward_bound=0.220, batch=215\n",
      "3243: loss=0.302, reward_mean=0.330, reward_bound=0.234, batch=220\n",
      "3244: loss=0.300, reward_mean=0.350, reward_bound=0.282, batch=212\n",
      "3245: loss=0.303, reward_mean=0.300, reward_bound=0.314, batch=207\n",
      "3246: loss=0.302, reward_mean=0.370, reward_bound=0.282, batch=213\n",
      "3247: loss=0.302, reward_mean=0.400, reward_bound=0.314, batch=217\n",
      "3248: loss=0.314, reward_mean=0.330, reward_bound=0.349, batch=203\n",
      "3249: loss=0.311, reward_mean=0.430, reward_bound=0.314, batch=211\n",
      "3250: loss=0.310, reward_mean=0.420, reward_bound=0.254, batch=215\n",
      "3251: loss=0.306, reward_mean=0.330, reward_bound=0.260, batch=220\n",
      "3252: loss=0.308, reward_mean=0.320, reward_bound=0.282, batch=221\n",
      "3253: loss=0.309, reward_mean=0.380, reward_bound=0.314, batch=223\n",
      "3254: loss=0.308, reward_mean=0.290, reward_bound=0.314, batch=225\n",
      "3255: loss=0.304, reward_mean=0.410, reward_bound=0.349, batch=226\n",
      "3256: loss=0.306, reward_mean=0.430, reward_bound=0.387, batch=198\n",
      "3257: loss=0.304, reward_mean=0.340, reward_bound=0.154, batch=208\n",
      "3258: loss=0.302, reward_mean=0.330, reward_bound=0.152, batch=215\n",
      "3259: loss=0.304, reward_mean=0.370, reward_bound=0.185, batch=219\n",
      "3260: loss=0.300, reward_mean=0.360, reward_bound=0.229, batch=220\n",
      "3261: loss=0.298, reward_mean=0.340, reward_bound=0.254, batch=218\n",
      "3262: loss=0.299, reward_mean=0.370, reward_bound=0.282, batch=218\n",
      "3263: loss=0.297, reward_mean=0.350, reward_bound=0.231, batch=222\n",
      "3264: loss=0.303, reward_mean=0.320, reward_bound=0.292, batch=225\n",
      "3265: loss=0.302, reward_mean=0.320, reward_bound=0.349, batch=219\n",
      "3266: loss=0.302, reward_mean=0.340, reward_bound=0.282, batch=222\n",
      "3267: loss=0.304, reward_mean=0.290, reward_bound=0.349, batch=224\n",
      "3268: loss=0.303, reward_mean=0.290, reward_bound=0.349, batch=226\n",
      "3269: loss=0.302, reward_mean=0.360, reward_bound=0.387, batch=216\n",
      "3270: loss=0.300, reward_mean=0.450, reward_bound=0.351, batch=221\n",
      "3271: loss=0.298, reward_mean=0.430, reward_bound=0.430, batch=130\n",
      "3272: loss=0.307, reward_mean=0.290, reward_bound=0.000, batch=159\n",
      "3273: loss=0.307, reward_mean=0.320, reward_bound=0.014, batch=181\n",
      "3274: loss=0.306, reward_mean=0.430, reward_bound=0.052, batch=195\n",
      "3275: loss=0.309, reward_mean=0.300, reward_bound=0.072, batch=205\n",
      "3276: loss=0.308, reward_mean=0.470, reward_bound=0.135, batch=210\n",
      "3277: loss=0.305, reward_mean=0.390, reward_bound=0.150, batch=214\n",
      "3278: loss=0.304, reward_mean=0.460, reward_bound=0.167, batch=219\n",
      "3279: loss=0.312, reward_mean=0.340, reward_bound=0.206, batch=204\n",
      "3280: loss=0.307, reward_mean=0.440, reward_bound=0.226, batch=213\n",
      "3281: loss=0.306, reward_mean=0.330, reward_bound=0.229, batch=209\n",
      "3282: loss=0.304, reward_mean=0.430, reward_bound=0.254, batch=202\n",
      "3283: loss=0.307, reward_mean=0.410, reward_bound=0.282, batch=198\n",
      "3284: loss=0.302, reward_mean=0.480, reward_bound=0.187, batch=208\n",
      "3285: loss=0.303, reward_mean=0.350, reward_bound=0.208, batch=215\n",
      "3286: loss=0.302, reward_mean=0.330, reward_bound=0.229, batch=218\n",
      "3287: loss=0.302, reward_mean=0.350, reward_bound=0.282, batch=216\n",
      "3288: loss=0.309, reward_mean=0.310, reward_bound=0.314, batch=205\n",
      "3289: loss=0.307, reward_mean=0.370, reward_bound=0.282, batch=211\n",
      "3290: loss=0.304, reward_mean=0.310, reward_bound=0.282, batch=217\n",
      "3291: loss=0.306, reward_mean=0.350, reward_bound=0.249, batch=222\n",
      "3292: loss=0.309, reward_mean=0.410, reward_bound=0.314, batch=223\n",
      "3293: loss=0.311, reward_mean=0.330, reward_bound=0.349, batch=202\n",
      "3294: loss=0.309, reward_mean=0.430, reward_bound=0.229, batch=209\n",
      "3295: loss=0.305, reward_mean=0.400, reward_bound=0.254, batch=214\n",
      "3296: loss=0.308, reward_mean=0.350, reward_bound=0.282, batch=218\n",
      "3297: loss=0.310, reward_mean=0.370, reward_bound=0.286, batch=222\n",
      "3298: loss=0.309, reward_mean=0.390, reward_bound=0.349, batch=216\n",
      "3299: loss=0.311, reward_mean=0.280, reward_bound=0.298, batch=221\n",
      "3300: loss=0.306, reward_mean=0.370, reward_bound=0.314, batch=223\n",
      "3301: loss=0.307, reward_mean=0.420, reward_bound=0.349, batch=223\n",
      "3302: loss=0.311, reward_mean=0.340, reward_bound=0.387, batch=189\n",
      "3303: loss=0.299, reward_mean=0.290, reward_bound=0.083, batch=202\n",
      "3304: loss=0.307, reward_mean=0.340, reward_bound=0.109, batch=209\n",
      "3305: loss=0.308, reward_mean=0.320, reward_bound=0.150, batch=215\n",
      "3306: loss=0.307, reward_mean=0.430, reward_bound=0.185, batch=218\n",
      "3307: loss=0.306, reward_mean=0.440, reward_bound=0.229, batch=220\n",
      "3308: loss=0.305, reward_mean=0.350, reward_bound=0.254, batch=221\n",
      "3309: loss=0.307, reward_mean=0.390, reward_bound=0.282, batch=215\n",
      "3310: loss=0.307, reward_mean=0.430, reward_bound=0.314, batch=215\n",
      "3311: loss=0.305, reward_mean=0.330, reward_bound=0.289, batch=220\n",
      "3312: loss=0.309, reward_mean=0.330, reward_bound=0.282, batch=223\n",
      "3313: loss=0.306, reward_mean=0.340, reward_bound=0.252, batch=226\n",
      "3314: loss=0.310, reward_mean=0.360, reward_bound=0.314, batch=225\n",
      "3315: loss=0.313, reward_mean=0.360, reward_bound=0.349, batch=219\n",
      "3316: loss=0.309, reward_mean=0.320, reward_bound=0.265, batch=223\n",
      "3317: loss=0.308, reward_mean=0.340, reward_bound=0.271, batch=226\n",
      "3318: loss=0.312, reward_mean=0.400, reward_bound=0.349, batch=226\n",
      "3319: loss=0.312, reward_mean=0.350, reward_bound=0.387, batch=217\n",
      "3320: loss=0.310, reward_mean=0.350, reward_bound=0.401, batch=222\n",
      "3321: loss=0.308, reward_mean=0.380, reward_bound=0.400, batch=225\n",
      "3322: loss=0.309, reward_mean=0.400, reward_bound=0.430, batch=177\n",
      "3323: loss=0.307, reward_mean=0.420, reward_bound=0.150, batch=193\n",
      "3324: loss=0.310, reward_mean=0.400, reward_bound=0.185, batch=204\n",
      "3325: loss=0.305, reward_mean=0.250, reward_bound=0.080, batch=212\n",
      "3326: loss=0.305, reward_mean=0.370, reward_bound=0.179, batch=218\n",
      "3327: loss=0.312, reward_mean=0.360, reward_bound=0.229, batch=219\n",
      "3328: loss=0.315, reward_mean=0.300, reward_bound=0.254, batch=219\n",
      "3329: loss=0.310, reward_mean=0.320, reward_bound=0.282, batch=218\n",
      "3330: loss=0.303, reward_mean=0.230, reward_bound=0.314, batch=213\n",
      "3331: loss=0.302, reward_mean=0.330, reward_bound=0.229, batch=218\n",
      "3332: loss=0.303, reward_mean=0.290, reward_bound=0.317, batch=222\n",
      "3333: loss=0.307, reward_mean=0.430, reward_bound=0.349, batch=215\n",
      "3334: loss=0.304, reward_mean=0.340, reward_bound=0.289, batch=220\n",
      "3335: loss=0.305, reward_mean=0.320, reward_bound=0.274, batch=224\n",
      "3336: loss=0.307, reward_mean=0.290, reward_bound=0.314, batch=223\n",
      "3337: loss=0.307, reward_mean=0.280, reward_bound=0.349, batch=225\n",
      "3338: loss=0.306, reward_mean=0.360, reward_bound=0.356, batch=227\n",
      "3339: loss=0.313, reward_mean=0.380, reward_bound=0.387, batch=213\n",
      "3340: loss=0.315, reward_mean=0.350, reward_bound=0.301, batch=219\n",
      "3341: loss=0.314, reward_mean=0.340, reward_bound=0.225, batch=223\n",
      "3342: loss=0.319, reward_mean=0.270, reward_bound=0.282, batch=225\n",
      "3343: loss=0.317, reward_mean=0.320, reward_bound=0.314, batch=226\n",
      "3344: loss=0.314, reward_mean=0.270, reward_bound=0.349, batch=226\n",
      "3345: loss=0.315, reward_mean=0.420, reward_bound=0.368, batch=228\n",
      "3346: loss=0.314, reward_mean=0.400, reward_bound=0.387, batch=226\n",
      "3347: loss=0.312, reward_mean=0.360, reward_bound=0.390, batch=228\n",
      "3348: loss=0.310, reward_mean=0.320, reward_bound=0.430, batch=211\n",
      "3349: loss=0.309, reward_mean=0.360, reward_bound=0.387, batch=212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3350: loss=0.309, reward_mean=0.330, reward_bound=0.254, batch=218\n",
      "3351: loss=0.306, reward_mean=0.250, reward_bound=0.260, batch=222\n",
      "3352: loss=0.305, reward_mean=0.390, reward_bound=0.387, batch=220\n",
      "3353: loss=0.306, reward_mean=0.350, reward_bound=0.376, batch=224\n",
      "3354: loss=0.308, reward_mean=0.380, reward_bound=0.349, batch=226\n",
      "3355: loss=0.305, reward_mean=0.340, reward_bound=0.387, batch=227\n",
      "3356: loss=0.307, reward_mean=0.340, reward_bound=0.422, batch=229\n",
      "3357: loss=0.308, reward_mean=0.420, reward_bound=0.324, batch=230\n",
      "3358: loss=0.307, reward_mean=0.330, reward_bound=0.430, batch=221\n",
      "3359: loss=0.306, reward_mean=0.310, reward_bound=0.282, batch=224\n",
      "3360: loss=0.308, reward_mean=0.330, reward_bound=0.345, batch=227\n",
      "3361: loss=0.307, reward_mean=0.440, reward_bound=0.387, batch=228\n",
      "3362: loss=0.306, reward_mean=0.400, reward_bound=0.430, batch=225\n",
      "3363: loss=0.305, reward_mean=0.310, reward_bound=0.430, batch=226\n",
      "3364: loss=0.304, reward_mean=0.380, reward_bound=0.430, batch=227\n",
      "3365: loss=0.304, reward_mean=0.370, reward_bound=0.469, batch=229\n",
      "3366: loss=0.304, reward_mean=0.310, reward_bound=0.430, batch=229\n",
      "3367: loss=0.306, reward_mean=0.350, reward_bound=0.381, batch=230\n",
      "3368: loss=0.303, reward_mean=0.340, reward_bound=0.430, batch=230\n",
      "3369: loss=0.304, reward_mean=0.350, reward_bound=0.451, batch=231\n",
      "3370: loss=0.310, reward_mean=0.350, reward_bound=0.478, batch=95\n",
      "3371: loss=0.299, reward_mean=0.360, reward_bound=0.000, batch=131\n",
      "3372: loss=0.294, reward_mean=0.410, reward_bound=0.004, batch=160\n",
      "3373: loss=0.291, reward_mean=0.330, reward_bound=0.018, batch=182\n",
      "3374: loss=0.287, reward_mean=0.360, reward_bound=0.044, batch=197\n",
      "3375: loss=0.275, reward_mean=0.410, reward_bound=0.070, batch=208\n",
      "3376: loss=0.279, reward_mean=0.370, reward_bound=0.098, batch=212\n",
      "3377: loss=0.286, reward_mean=0.310, reward_bound=0.122, batch=211\n",
      "3378: loss=0.282, reward_mean=0.320, reward_bound=0.135, batch=217\n",
      "3379: loss=0.274, reward_mean=0.280, reward_bound=0.150, batch=216\n",
      "3380: loss=0.274, reward_mean=0.350, reward_bound=0.167, batch=217\n",
      "3381: loss=0.282, reward_mean=0.430, reward_bound=0.206, batch=211\n",
      "3382: loss=0.294, reward_mean=0.320, reward_bound=0.229, batch=197\n",
      "3383: loss=0.293, reward_mean=0.360, reward_bound=0.182, batch=208\n",
      "3384: loss=0.293, reward_mean=0.430, reward_bound=0.185, batch=214\n",
      "3385: loss=0.292, reward_mean=0.390, reward_bound=0.229, batch=219\n",
      "3386: loss=0.296, reward_mean=0.300, reward_bound=0.254, batch=207\n",
      "3387: loss=0.297, reward_mean=0.380, reward_bound=0.282, batch=191\n",
      "3388: loss=0.297, reward_mean=0.440, reward_bound=0.206, batch=201\n",
      "3389: loss=0.294, reward_mean=0.340, reward_bound=0.206, batch=210\n",
      "3390: loss=0.295, reward_mean=0.320, reward_bound=0.247, batch=217\n",
      "3391: loss=0.296, reward_mean=0.330, reward_bound=0.229, batch=221\n",
      "3392: loss=0.296, reward_mean=0.350, reward_bound=0.254, batch=220\n",
      "3393: loss=0.300, reward_mean=0.360, reward_bound=0.282, batch=215\n",
      "3394: loss=0.300, reward_mean=0.360, reward_bound=0.266, batch=220\n",
      "3395: loss=0.302, reward_mean=0.350, reward_bound=0.314, batch=192\n",
      "3396: loss=0.302, reward_mean=0.340, reward_bound=0.206, batch=205\n",
      "3397: loss=0.305, reward_mean=0.340, reward_bound=0.206, batch=212\n",
      "3398: loss=0.311, reward_mean=0.360, reward_bound=0.254, batch=215\n",
      "3399: loss=0.310, reward_mean=0.340, reward_bound=0.282, batch=219\n",
      "3400: loss=0.303, reward_mean=0.370, reward_bound=0.314, batch=216\n",
      "3401: loss=0.314, reward_mean=0.360, reward_bound=0.349, batch=187\n",
      "3402: loss=0.312, reward_mean=0.370, reward_bound=0.150, batch=199\n",
      "3403: loss=0.318, reward_mean=0.290, reward_bound=0.097, batch=209\n",
      "3404: loss=0.321, reward_mean=0.320, reward_bound=0.135, batch=214\n",
      "3405: loss=0.319, reward_mean=0.340, reward_bound=0.167, batch=217\n",
      "3406: loss=0.320, reward_mean=0.420, reward_bound=0.229, batch=219\n",
      "3407: loss=0.319, reward_mean=0.440, reward_bound=0.254, batch=221\n",
      "3408: loss=0.321, reward_mean=0.330, reward_bound=0.282, batch=222\n",
      "3409: loss=0.316, reward_mean=0.340, reward_bound=0.314, batch=218\n",
      "3410: loss=0.319, reward_mean=0.430, reward_bound=0.349, batch=216\n",
      "3411: loss=0.318, reward_mean=0.360, reward_bound=0.331, batch=221\n",
      "3412: loss=0.316, reward_mean=0.350, reward_bound=0.314, batch=223\n",
      "3413: loss=0.316, reward_mean=0.350, reward_bound=0.244, batch=226\n",
      "3414: loss=0.315, reward_mean=0.330, reward_bound=0.254, batch=226\n",
      "3415: loss=0.321, reward_mean=0.340, reward_bound=0.349, batch=224\n",
      "3416: loss=0.326, reward_mean=0.330, reward_bound=0.387, batch=175\n",
      "3417: loss=0.323, reward_mean=0.380, reward_bound=0.072, batch=191\n",
      "3418: loss=0.320, reward_mean=0.320, reward_bound=0.109, batch=203\n",
      "3419: loss=0.322, reward_mean=0.270, reward_bound=0.130, batch=212\n",
      "3420: loss=0.321, reward_mean=0.400, reward_bound=0.167, batch=212\n",
      "3421: loss=0.322, reward_mean=0.360, reward_bound=0.206, batch=224\n",
      "3422: loss=0.320, reward_mean=0.270, reward_bound=0.206, batch=224\n",
      "3423: loss=0.317, reward_mean=0.260, reward_bound=0.229, batch=222\n",
      "3424: loss=0.317, reward_mean=0.290, reward_bound=0.254, batch=219\n",
      "3425: loss=0.318, reward_mean=0.400, reward_bound=0.282, batch=220\n",
      "3426: loss=0.319, reward_mean=0.260, reward_bound=0.274, batch=224\n",
      "3427: loss=0.321, reward_mean=0.290, reward_bound=0.311, batch=227\n",
      "3428: loss=0.323, reward_mean=0.330, reward_bound=0.314, batch=221\n",
      "3429: loss=0.323, reward_mean=0.350, reward_bound=0.349, batch=217\n",
      "3430: loss=0.321, reward_mean=0.320, reward_bound=0.314, batch=221\n",
      "3431: loss=0.320, reward_mean=0.350, reward_bound=0.314, batch=223\n",
      "3432: loss=0.319, reward_mean=0.320, reward_bound=0.322, batch=226\n",
      "3433: loss=0.320, reward_mean=0.280, reward_bound=0.349, batch=224\n",
      "3434: loss=0.318, reward_mean=0.330, reward_bound=0.345, batch=227\n",
      "3435: loss=0.318, reward_mean=0.350, reward_bound=0.349, batch=227\n",
      "3436: loss=0.322, reward_mean=0.410, reward_bound=0.387, batch=204\n",
      "3437: loss=0.324, reward_mean=0.350, reward_bound=0.254, batch=212\n",
      "3438: loss=0.326, reward_mean=0.310, reward_bound=0.292, batch=218\n",
      "3439: loss=0.323, reward_mean=0.280, reward_bound=0.317, batch=222\n",
      "3440: loss=0.325, reward_mean=0.360, reward_bound=0.349, batch=216\n",
      "3441: loss=0.324, reward_mean=0.360, reward_bound=0.387, batch=217\n",
      "3442: loss=0.326, reward_mean=0.390, reward_bound=0.349, batch=218\n",
      "3443: loss=0.329, reward_mean=0.390, reward_bound=0.349, batch=220\n",
      "3444: loss=0.329, reward_mean=0.300, reward_bound=0.314, batch=223\n",
      "3445: loss=0.326, reward_mean=0.420, reward_bound=0.387, batch=225\n",
      "3446: loss=0.324, reward_mean=0.390, reward_bound=0.430, batch=160\n",
      "3447: loss=0.318, reward_mean=0.280, reward_bound=0.043, batch=182\n",
      "3448: loss=0.311, reward_mean=0.380, reward_bound=0.092, batch=197\n",
      "3449: loss=0.310, reward_mean=0.350, reward_bound=0.109, batch=212\n",
      "3450: loss=0.315, reward_mean=0.300, reward_bound=0.113, batch=218\n",
      "3451: loss=0.299, reward_mean=0.450, reward_bound=0.135, batch=221\n",
      "3452: loss=0.304, reward_mean=0.330, reward_bound=0.167, batch=221\n",
      "3453: loss=0.302, reward_mean=0.280, reward_bound=0.185, batch=224\n",
      "3454: loss=0.303, reward_mean=0.420, reward_bound=0.229, batch=219\n",
      "3455: loss=0.310, reward_mean=0.370, reward_bound=0.254, batch=216\n",
      "3456: loss=0.308, reward_mean=0.340, reward_bound=0.282, batch=208\n",
      "3457: loss=0.306, reward_mean=0.310, reward_bound=0.150, batch=214\n",
      "3458: loss=0.308, reward_mean=0.420, reward_bound=0.311, batch=220\n",
      "3459: loss=0.308, reward_mean=0.310, reward_bound=0.304, batch=224\n",
      "3460: loss=0.307, reward_mean=0.350, reward_bound=0.311, batch=227\n",
      "3461: loss=0.311, reward_mean=0.440, reward_bound=0.314, batch=209\n",
      "3462: loss=0.307, reward_mean=0.270, reward_bound=0.182, batch=216\n",
      "3463: loss=0.310, reward_mean=0.290, reward_bound=0.229, batch=219\n",
      "3464: loss=0.308, reward_mean=0.310, reward_bound=0.295, batch=223\n",
      "3465: loss=0.309, reward_mean=0.370, reward_bound=0.314, batch=221\n",
      "3466: loss=0.318, reward_mean=0.400, reward_bound=0.349, batch=210\n",
      "3467: loss=0.327, reward_mean=0.300, reward_bound=0.240, batch=217\n",
      "3468: loss=0.312, reward_mean=0.410, reward_bound=0.314, batch=221\n",
      "3469: loss=0.314, reward_mean=0.330, reward_bound=0.282, batch=224\n",
      "3470: loss=0.323, reward_mean=0.480, reward_bound=0.387, batch=207\n",
      "3471: loss=0.318, reward_mean=0.310, reward_bound=0.206, batch=214\n",
      "3472: loss=0.317, reward_mean=0.390, reward_bound=0.204, batch=220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3473: loss=0.322, reward_mean=0.280, reward_bound=0.229, batch=222\n",
      "3474: loss=0.318, reward_mean=0.360, reward_bound=0.254, batch=223\n",
      "3475: loss=0.318, reward_mean=0.400, reward_bound=0.282, batch=223\n",
      "3476: loss=0.321, reward_mean=0.390, reward_bound=0.314, batch=221\n",
      "3477: loss=0.318, reward_mean=0.370, reward_bound=0.349, batch=223\n",
      "3478: loss=0.320, reward_mean=0.400, reward_bound=0.387, batch=219\n",
      "3479: loss=0.321, reward_mean=0.370, reward_bound=0.387, batch=222\n",
      "3480: loss=0.321, reward_mean=0.390, reward_bound=0.373, batch=225\n",
      "3481: loss=0.319, reward_mean=0.310, reward_bound=0.396, batch=227\n",
      "3482: loss=0.319, reward_mean=0.280, reward_bound=0.380, batch=229\n",
      "3483: loss=0.319, reward_mean=0.360, reward_bound=0.405, batch=230\n",
      "3484: loss=0.313, reward_mean=0.360, reward_bound=0.430, batch=202\n",
      "3485: loss=0.312, reward_mean=0.320, reward_bound=0.236, batch=211\n",
      "3486: loss=0.310, reward_mean=0.250, reward_bound=0.185, batch=217\n",
      "3487: loss=0.312, reward_mean=0.350, reward_bound=0.254, batch=221\n",
      "3488: loss=0.308, reward_mean=0.320, reward_bound=0.314, batch=217\n",
      "3489: loss=0.307, reward_mean=0.290, reward_bound=0.308, batch=222\n",
      "3490: loss=0.304, reward_mean=0.340, reward_bound=0.263, batch=225\n",
      "3491: loss=0.305, reward_mean=0.230, reward_bound=0.289, batch=227\n",
      "3492: loss=0.302, reward_mean=0.300, reward_bound=0.314, batch=228\n",
      "3493: loss=0.307, reward_mean=0.330, reward_bound=0.349, batch=224\n",
      "3494: loss=0.308, reward_mean=0.300, reward_bound=0.387, batch=222\n",
      "3495: loss=0.308, reward_mean=0.270, reward_bound=0.360, batch=225\n",
      "3496: loss=0.308, reward_mean=0.380, reward_bound=0.387, batch=225\n",
      "3497: loss=0.308, reward_mean=0.280, reward_bound=0.356, batch=227\n",
      "3498: loss=0.306, reward_mean=0.390, reward_bound=0.387, batch=228\n",
      "3499: loss=0.306, reward_mean=0.310, reward_bound=0.392, batch=229\n",
      "3500: loss=0.307, reward_mean=0.340, reward_bound=0.292, batch=230\n",
      "3501: loss=0.306, reward_mean=0.360, reward_bound=0.329, batch=231\n",
      "3502: loss=0.306, reward_mean=0.300, reward_bound=0.387, batch=231\n",
      "3503: loss=0.313, reward_mean=0.430, reward_bound=0.430, batch=221\n",
      "3504: loss=0.311, reward_mean=0.430, reward_bound=0.314, batch=224\n",
      "3505: loss=0.312, reward_mean=0.300, reward_bound=0.349, batch=226\n",
      "3506: loss=0.310, reward_mean=0.300, reward_bound=0.351, batch=228\n",
      "3507: loss=0.309, reward_mean=0.320, reward_bound=0.387, batch=226\n",
      "3508: loss=0.310, reward_mean=0.300, reward_bound=0.351, batch=228\n",
      "3509: loss=0.310, reward_mean=0.290, reward_bound=0.392, batch=229\n",
      "3510: loss=0.311, reward_mean=0.380, reward_bound=0.430, batch=226\n",
      "3511: loss=0.310, reward_mean=0.370, reward_bound=0.301, batch=228\n",
      "3512: loss=0.310, reward_mean=0.320, reward_bound=0.435, batch=229\n",
      "3513: loss=0.310, reward_mean=0.300, reward_bound=0.478, batch=232\n",
      "3514: loss=0.310, reward_mean=0.320, reward_bound=0.445, batch=232\n",
      "3515: loss=0.313, reward_mean=0.370, reward_bound=0.478, batch=156\n",
      "3516: loss=0.301, reward_mean=0.340, reward_bound=0.047, batch=179\n",
      "3517: loss=0.295, reward_mean=0.400, reward_bound=0.055, batch=195\n",
      "3518: loss=0.294, reward_mean=0.280, reward_bound=0.073, batch=206\n",
      "3519: loss=0.295, reward_mean=0.360, reward_bound=0.122, batch=212\n",
      "3520: loss=0.298, reward_mean=0.380, reward_bound=0.167, batch=214\n",
      "3521: loss=0.296, reward_mean=0.270, reward_bound=0.204, batch=220\n",
      "3522: loss=0.300, reward_mean=0.420, reward_bound=0.206, batch=228\n",
      "3523: loss=0.306, reward_mean=0.340, reward_bound=0.206, batch=219\n",
      "3524: loss=0.308, reward_mean=0.410, reward_bound=0.229, batch=220\n",
      "3525: loss=0.309, reward_mean=0.350, reward_bound=0.254, batch=214\n",
      "3526: loss=0.315, reward_mean=0.350, reward_bound=0.282, batch=214\n",
      "3527: loss=0.314, reward_mean=0.350, reward_bound=0.305, batch=220\n",
      "3528: loss=0.310, reward_mean=0.330, reward_bound=0.314, batch=210\n",
      "3529: loss=0.311, reward_mean=0.330, reward_bound=0.282, batch=214\n",
      "3530: loss=0.320, reward_mean=0.340, reward_bound=0.349, batch=202\n",
      "3531: loss=0.321, reward_mean=0.360, reward_bound=0.140, batch=211\n",
      "3532: loss=0.311, reward_mean=0.330, reward_bound=0.206, batch=216\n",
      "3533: loss=0.312, reward_mean=0.400, reward_bound=0.229, batch=219\n",
      "3534: loss=0.314, reward_mean=0.280, reward_bound=0.254, batch=221\n",
      "3535: loss=0.312, reward_mean=0.360, reward_bound=0.282, batch=219\n",
      "3536: loss=0.311, reward_mean=0.320, reward_bound=0.254, batch=222\n",
      "3537: loss=0.311, reward_mean=0.330, reward_bound=0.324, batch=225\n",
      "3538: loss=0.311, reward_mean=0.340, reward_bound=0.349, batch=217\n",
      "3539: loss=0.310, reward_mean=0.300, reward_bound=0.277, batch=222\n",
      "3540: loss=0.312, reward_mean=0.400, reward_bound=0.349, batch=223\n",
      "3541: loss=0.309, reward_mean=0.280, reward_bound=0.301, batch=226\n",
      "3542: loss=0.307, reward_mean=0.270, reward_bound=0.217, batch=228\n",
      "3543: loss=0.310, reward_mean=0.310, reward_bound=0.317, batch=229\n",
      "3544: loss=0.312, reward_mean=0.360, reward_bound=0.364, batch=230\n",
      "3545: loss=0.313, reward_mean=0.280, reward_bound=0.387, batch=208\n",
      "3546: loss=0.314, reward_mean=0.250, reward_bound=0.152, batch=215\n",
      "3547: loss=0.308, reward_mean=0.250, reward_bound=0.234, batch=220\n",
      "3548: loss=0.312, reward_mean=0.370, reward_bound=0.274, batch=224\n",
      "3549: loss=0.317, reward_mean=0.310, reward_bound=0.314, batch=223\n",
      "3550: loss=0.320, reward_mean=0.370, reward_bound=0.349, batch=221\n",
      "3551: loss=0.320, reward_mean=0.290, reward_bound=0.314, batch=223\n",
      "3552: loss=0.323, reward_mean=0.280, reward_bound=0.345, batch=226\n",
      "3553: loss=0.322, reward_mean=0.330, reward_bound=0.316, batch=228\n",
      "3554: loss=0.324, reward_mean=0.410, reward_bound=0.387, batch=222\n",
      "3555: loss=0.324, reward_mean=0.290, reward_bound=0.400, batch=225\n",
      "3556: loss=0.324, reward_mean=0.320, reward_bound=0.430, batch=198\n",
      "3557: loss=0.322, reward_mean=0.270, reward_bound=0.185, batch=207\n",
      "3558: loss=0.320, reward_mean=0.290, reward_bound=0.206, batch=213\n",
      "3559: loss=0.319, reward_mean=0.360, reward_bound=0.229, batch=218\n",
      "3560: loss=0.316, reward_mean=0.280, reward_bound=0.208, batch=222\n",
      "3561: loss=0.320, reward_mean=0.360, reward_bound=0.292, batch=225\n",
      "3562: loss=0.322, reward_mean=0.370, reward_bound=0.314, batch=223\n",
      "3563: loss=0.329, reward_mean=0.410, reward_bound=0.349, batch=220\n",
      "3564: loss=0.332, reward_mean=0.340, reward_bound=0.329, batch=224\n",
      "3565: loss=0.332, reward_mean=0.430, reward_bound=0.349, batch=224\n",
      "3566: loss=0.333, reward_mean=0.370, reward_bound=0.387, batch=223\n",
      "3567: loss=0.332, reward_mean=0.400, reward_bound=0.387, batch=225\n",
      "3568: loss=0.331, reward_mean=0.210, reward_bound=0.396, batch=227\n",
      "3569: loss=0.331, reward_mean=0.360, reward_bound=0.349, batch=228\n",
      "3570: loss=0.321, reward_mean=0.210, reward_bound=0.430, batch=212\n",
      "3571: loss=0.328, reward_mean=0.350, reward_bound=0.263, batch=218\n",
      "3572: loss=0.328, reward_mean=0.320, reward_bound=0.282, batch=219\n",
      "3573: loss=0.328, reward_mean=0.260, reward_bound=0.314, batch=222\n",
      "3574: loss=0.321, reward_mean=0.470, reward_bound=0.349, batch=222\n",
      "3575: loss=0.320, reward_mean=0.370, reward_bound=0.387, batch=219\n",
      "3576: loss=0.317, reward_mean=0.250, reward_bound=0.265, batch=223\n",
      "3577: loss=0.317, reward_mean=0.350, reward_bound=0.282, batch=222\n",
      "3578: loss=0.320, reward_mean=0.260, reward_bound=0.349, batch=224\n",
      "3579: loss=0.321, reward_mean=0.380, reward_bound=0.387, batch=226\n",
      "3580: loss=0.320, reward_mean=0.350, reward_bound=0.368, batch=228\n",
      "3581: loss=0.320, reward_mean=0.280, reward_bound=0.387, batch=228\n",
      "3582: loss=0.320, reward_mean=0.320, reward_bound=0.387, batch=228\n",
      "3583: loss=0.317, reward_mean=0.260, reward_bound=0.430, batch=221\n",
      "3584: loss=0.317, reward_mean=0.370, reward_bound=0.282, batch=224\n",
      "3585: loss=0.316, reward_mean=0.350, reward_bound=0.387, batch=224\n",
      "3586: loss=0.317, reward_mean=0.290, reward_bound=0.349, batch=226\n",
      "3587: loss=0.316, reward_mean=0.310, reward_bound=0.430, batch=227\n",
      "3588: loss=0.315, reward_mean=0.370, reward_bound=0.302, batch=229\n",
      "3589: loss=0.316, reward_mean=0.330, reward_bound=0.364, batch=230\n",
      "3590: loss=0.316, reward_mean=0.320, reward_bound=0.376, batch=231\n",
      "3591: loss=0.317, reward_mean=0.310, reward_bound=0.387, batch=231\n",
      "3592: loss=0.316, reward_mean=0.330, reward_bound=0.430, batch=230\n",
      "3593: loss=0.316, reward_mean=0.270, reward_bound=0.464, batch=231\n",
      "3594: loss=0.315, reward_mean=0.320, reward_bound=0.387, batch=231\n",
      "3595: loss=0.313, reward_mean=0.320, reward_bound=0.478, batch=181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3596: loss=0.304, reward_mean=0.270, reward_bound=0.080, batch=196\n",
      "3597: loss=0.302, reward_mean=0.340, reward_bound=0.122, batch=204\n",
      "3598: loss=0.299, reward_mean=0.310, reward_bound=0.135, batch=212\n",
      "3599: loss=0.303, reward_mean=0.360, reward_bound=0.191, batch=218\n",
      "3600: loss=0.303, reward_mean=0.310, reward_bound=0.229, batch=221\n",
      "3601: loss=0.308, reward_mean=0.440, reward_bound=0.254, batch=220\n",
      "3602: loss=0.313, reward_mean=0.240, reward_bound=0.282, batch=220\n",
      "3603: loss=0.317, reward_mean=0.420, reward_bound=0.314, batch=214\n",
      "3604: loss=0.316, reward_mean=0.370, reward_bound=0.185, batch=219\n",
      "3605: loss=0.317, reward_mean=0.310, reward_bound=0.254, batch=222\n",
      "3606: loss=0.317, reward_mean=0.400, reward_bound=0.314, batch=224\n",
      "3607: loss=0.316, reward_mean=0.320, reward_bound=0.345, batch=227\n",
      "3608: loss=0.320, reward_mean=0.350, reward_bound=0.349, batch=216\n",
      "3609: loss=0.321, reward_mean=0.440, reward_bound=0.331, batch=221\n",
      "3610: loss=0.321, reward_mean=0.350, reward_bound=0.314, batch=223\n",
      "3611: loss=0.319, reward_mean=0.310, reward_bound=0.322, batch=226\n",
      "3612: loss=0.320, reward_mean=0.330, reward_bound=0.349, batch=225\n",
      "3613: loss=0.318, reward_mean=0.490, reward_bound=0.387, batch=208\n",
      "3614: loss=0.319, reward_mean=0.390, reward_bound=0.289, batch=215\n",
      "3615: loss=0.320, reward_mean=0.380, reward_bound=0.349, batch=219\n",
      "3616: loss=0.321, reward_mean=0.350, reward_bound=0.215, batch=223\n",
      "3617: loss=0.327, reward_mean=0.380, reward_bound=0.254, batch=224\n",
      "3618: loss=0.322, reward_mean=0.330, reward_bound=0.314, batch=226\n",
      "3619: loss=0.317, reward_mean=0.300, reward_bound=0.349, batch=227\n",
      "3620: loss=0.315, reward_mean=0.340, reward_bound=0.387, batch=221\n",
      "3621: loss=0.315, reward_mean=0.370, reward_bound=0.387, batch=223\n",
      "3622: loss=0.314, reward_mean=0.420, reward_bound=0.314, batch=225\n",
      "3623: loss=0.314, reward_mean=0.310, reward_bound=0.387, batch=225\n",
      "3624: loss=0.313, reward_mean=0.290, reward_bound=0.329, batch=227\n",
      "3625: loss=0.312, reward_mean=0.390, reward_bound=0.373, batch=229\n",
      "3626: loss=0.311, reward_mean=0.430, reward_bound=0.387, batch=229\n",
      "3627: loss=0.306, reward_mean=0.430, reward_bound=0.430, batch=206\n",
      "3628: loss=0.305, reward_mean=0.310, reward_bound=0.282, batch=212\n",
      "3629: loss=0.305, reward_mean=0.290, reward_bound=0.292, batch=218\n",
      "3630: loss=0.306, reward_mean=0.320, reward_bound=0.314, batch=220\n",
      "3631: loss=0.305, reward_mean=0.380, reward_bound=0.304, batch=224\n",
      "3632: loss=0.305, reward_mean=0.330, reward_bound=0.349, batch=221\n",
      "3633: loss=0.303, reward_mean=0.300, reward_bound=0.206, batch=224\n",
      "3634: loss=0.306, reward_mean=0.350, reward_bound=0.314, batch=225\n",
      "3635: loss=0.305, reward_mean=0.350, reward_bound=0.387, batch=219\n",
      "3636: loss=0.304, reward_mean=0.340, reward_bound=0.387, batch=220\n",
      "3637: loss=0.302, reward_mean=0.250, reward_bound=0.304, batch=224\n",
      "3638: loss=0.307, reward_mean=0.340, reward_bound=0.314, batch=224\n",
      "3639: loss=0.305, reward_mean=0.310, reward_bound=0.345, batch=227\n",
      "3640: loss=0.306, reward_mean=0.370, reward_bound=0.349, batch=227\n",
      "3641: loss=0.304, reward_mean=0.410, reward_bound=0.387, batch=228\n",
      "3642: loss=0.302, reward_mean=0.310, reward_bound=0.430, batch=218\n",
      "3643: loss=0.306, reward_mean=0.340, reward_bound=0.387, batch=221\n",
      "3644: loss=0.304, reward_mean=0.360, reward_bound=0.314, batch=223\n",
      "3645: loss=0.304, reward_mean=0.320, reward_bound=0.282, batch=225\n",
      "3646: loss=0.302, reward_mean=0.410, reward_bound=0.314, batch=226\n",
      "3647: loss=0.305, reward_mean=0.430, reward_bound=0.409, batch=228\n",
      "3648: loss=0.305, reward_mean=0.350, reward_bound=0.387, batch=228\n",
      "3649: loss=0.301, reward_mean=0.350, reward_bound=0.430, batch=222\n",
      "3650: loss=0.298, reward_mean=0.310, reward_bound=0.360, batch=225\n",
      "3651: loss=0.300, reward_mean=0.370, reward_bound=0.387, batch=226\n",
      "3652: loss=0.298, reward_mean=0.370, reward_bound=0.413, batch=228\n",
      "3653: loss=0.298, reward_mean=0.340, reward_bound=0.430, batch=228\n",
      "3654: loss=0.299, reward_mean=0.370, reward_bound=0.293, batch=229\n",
      "3655: loss=0.298, reward_mean=0.280, reward_bound=0.343, batch=230\n",
      "3656: loss=0.297, reward_mean=0.260, reward_bound=0.376, batch=231\n",
      "3657: loss=0.299, reward_mean=0.340, reward_bound=0.430, batch=229\n",
      "3658: loss=0.299, reward_mean=0.390, reward_bound=0.424, batch=230\n",
      "3659: loss=0.299, reward_mean=0.400, reward_bound=0.418, batch=231\n",
      "3660: loss=0.298, reward_mean=0.300, reward_bound=0.430, batch=231\n",
      "3661: loss=0.307, reward_mean=0.410, reward_bound=0.478, batch=203\n",
      "3662: loss=0.306, reward_mean=0.440, reward_bound=0.254, batch=211\n",
      "3663: loss=0.307, reward_mean=0.380, reward_bound=0.229, batch=215\n",
      "3664: loss=0.303, reward_mean=0.340, reward_bound=0.282, batch=217\n",
      "3665: loss=0.299, reward_mean=0.320, reward_bound=0.314, batch=220\n",
      "3666: loss=0.304, reward_mean=0.350, reward_bound=0.338, batch=224\n",
      "3667: loss=0.305, reward_mean=0.270, reward_bound=0.349, batch=224\n",
      "3668: loss=0.306, reward_mean=0.350, reward_bound=0.387, batch=219\n",
      "3669: loss=0.308, reward_mean=0.340, reward_bound=0.328, batch=223\n",
      "3670: loss=0.310, reward_mean=0.330, reward_bound=0.335, batch=226\n",
      "3671: loss=0.308, reward_mean=0.410, reward_bound=0.368, batch=228\n",
      "3672: loss=0.308, reward_mean=0.290, reward_bound=0.387, batch=228\n",
      "3673: loss=0.308, reward_mean=0.410, reward_bound=0.430, batch=217\n",
      "3674: loss=0.306, reward_mean=0.370, reward_bound=0.314, batch=220\n",
      "3675: loss=0.309, reward_mean=0.370, reward_bound=0.349, batch=221\n",
      "3676: loss=0.308, reward_mean=0.310, reward_bound=0.282, batch=224\n",
      "3677: loss=0.309, reward_mean=0.300, reward_bound=0.349, batch=226\n",
      "3678: loss=0.307, reward_mean=0.330, reward_bound=0.368, batch=228\n",
      "3679: loss=0.312, reward_mean=0.410, reward_bound=0.387, batch=226\n",
      "3680: loss=0.310, reward_mean=0.230, reward_bound=0.356, batch=228\n",
      "3681: loss=0.308, reward_mean=0.380, reward_bound=0.430, batch=226\n",
      "3682: loss=0.308, reward_mean=0.280, reward_bound=0.356, batch=228\n",
      "3683: loss=0.308, reward_mean=0.330, reward_bound=0.430, batch=228\n",
      "3684: loss=0.316, reward_mean=0.390, reward_bound=0.392, batch=229\n",
      "3685: loss=0.307, reward_mean=0.290, reward_bound=0.430, batch=229\n",
      "3686: loss=0.308, reward_mean=0.340, reward_bound=0.450, batch=230\n",
      "3687: loss=0.307, reward_mean=0.400, reward_bound=0.464, batch=231\n",
      "3688: loss=0.309, reward_mean=0.290, reward_bound=0.478, batch=216\n",
      "3689: loss=0.309, reward_mean=0.400, reward_bound=0.314, batch=220\n",
      "3690: loss=0.309, reward_mean=0.350, reward_bound=0.376, batch=224\n",
      "3691: loss=0.312, reward_mean=0.310, reward_bound=0.345, batch=227\n",
      "3692: loss=0.311, reward_mean=0.200, reward_bound=0.335, batch=229\n",
      "3693: loss=0.310, reward_mean=0.390, reward_bound=0.349, batch=227\n",
      "3694: loss=0.311, reward_mean=0.320, reward_bound=0.342, batch=229\n",
      "3695: loss=0.310, reward_mean=0.340, reward_bound=0.349, batch=229\n",
      "3696: loss=0.309, reward_mean=0.440, reward_bound=0.364, batch=230\n",
      "3697: loss=0.313, reward_mean=0.470, reward_bound=0.387, batch=229\n",
      "3698: loss=0.314, reward_mean=0.430, reward_bound=0.381, batch=230\n",
      "3699: loss=0.314, reward_mean=0.340, reward_bound=0.418, batch=231\n",
      "3700: loss=0.314, reward_mean=0.250, reward_bound=0.349, batch=231\n",
      "3701: loss=0.311, reward_mean=0.320, reward_bound=0.430, batch=225\n",
      "3702: loss=0.309, reward_mean=0.240, reward_bound=0.356, batch=227\n",
      "3703: loss=0.309, reward_mean=0.270, reward_bound=0.342, batch=229\n",
      "3704: loss=0.309, reward_mean=0.390, reward_bound=0.387, batch=228\n",
      "3705: loss=0.309, reward_mean=0.390, reward_bound=0.387, batch=228\n",
      "3706: loss=0.309, reward_mean=0.310, reward_bound=0.392, batch=229\n",
      "3707: loss=0.308, reward_mean=0.370, reward_bound=0.430, batch=229\n",
      "3708: loss=0.307, reward_mean=0.350, reward_bound=0.405, batch=230\n",
      "3709: loss=0.306, reward_mean=0.350, reward_bound=0.418, batch=231\n",
      "3710: loss=0.307, reward_mean=0.370, reward_bound=0.430, batch=230\n",
      "3711: loss=0.307, reward_mean=0.260, reward_bound=0.429, batch=231\n",
      "3712: loss=0.306, reward_mean=0.360, reward_bound=0.478, batch=221\n",
      "3713: loss=0.308, reward_mean=0.280, reward_bound=0.254, batch=223\n",
      "3714: loss=0.308, reward_mean=0.330, reward_bound=0.282, batch=225\n",
      "3715: loss=0.306, reward_mean=0.420, reward_bound=0.396, batch=227\n",
      "3716: loss=0.306, reward_mean=0.290, reward_bound=0.302, batch=229\n",
      "3717: loss=0.306, reward_mean=0.370, reward_bound=0.360, batch=230\n",
      "3718: loss=0.306, reward_mean=0.280, reward_bound=0.282, batch=230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3719: loss=0.306, reward_mean=0.360, reward_bound=0.365, batch=231\n",
      "3720: loss=0.307, reward_mean=0.420, reward_bound=0.387, batch=231\n",
      "3721: loss=0.306, reward_mean=0.370, reward_bound=0.430, batch=228\n",
      "3722: loss=0.306, reward_mean=0.350, reward_bound=0.478, batch=230\n",
      "3723: loss=0.306, reward_mean=0.280, reward_bound=0.464, batch=231\n",
      "3724: loss=0.307, reward_mean=0.330, reward_bound=0.478, batch=224\n",
      "3725: loss=0.307, reward_mean=0.350, reward_bound=0.349, batch=226\n",
      "3726: loss=0.305, reward_mean=0.290, reward_bound=0.387, batch=227\n",
      "3727: loss=0.306, reward_mean=0.330, reward_bound=0.430, batch=228\n",
      "3728: loss=0.305, reward_mean=0.320, reward_bound=0.478, batch=230\n",
      "3729: loss=0.305, reward_mean=0.310, reward_bound=0.478, batch=229\n",
      "3730: loss=0.303, reward_mean=0.280, reward_bound=0.478, batch=231\n",
      "3731: loss=0.304, reward_mean=0.340, reward_bound=0.478, batch=230\n",
      "3732: loss=0.305, reward_mean=0.280, reward_bound=0.320, batch=231\n",
      "3733: loss=0.304, reward_mean=0.330, reward_bound=0.430, batch=231\n",
      "3734: loss=0.303, reward_mean=0.320, reward_bound=0.478, batch=231\n",
      "3735: loss=0.303, reward_mean=0.360, reward_bound=0.430, batch=231\n",
      "3736: loss=0.303, reward_mean=0.300, reward_bound=0.387, batch=231\n",
      "3738: loss=0.302, reward_mean=0.300, reward_bound=0.000, batch=30\n",
      "3739: loss=0.292, reward_mean=0.270, reward_bound=0.000, batch=57\n",
      "3740: loss=0.286, reward_mean=0.370, reward_bound=0.000, batch=94\n",
      "3741: loss=0.288, reward_mean=0.320, reward_bound=0.000, batch=126\n",
      "3742: loss=0.292, reward_mean=0.340, reward_bound=0.000, batch=158\n",
      "3743: loss=0.285, reward_mean=0.320, reward_bound=0.002, batch=180\n",
      "3744: loss=0.289, reward_mean=0.340, reward_bound=0.009, batch=196\n",
      "3745: loss=0.290, reward_mean=0.330, reward_bound=0.025, batch=203\n",
      "3746: loss=0.291, reward_mean=0.320, reward_bound=0.042, batch=208\n",
      "3747: loss=0.293, reward_mean=0.410, reward_bound=0.058, batch=211\n",
      "3748: loss=0.292, reward_mean=0.400, reward_bound=0.072, batch=213\n",
      "3749: loss=0.295, reward_mean=0.310, reward_bound=0.080, batch=218\n",
      "3750: loss=0.298, reward_mean=0.230, reward_bound=0.089, batch=215\n",
      "3751: loss=0.294, reward_mean=0.430, reward_bound=0.112, batch=220\n",
      "3752: loss=0.296, reward_mean=0.410, reward_bound=0.122, batch=221\n",
      "3753: loss=0.292, reward_mean=0.390, reward_bound=0.135, batch=210\n",
      "3754: loss=0.294, reward_mean=0.410, reward_bound=0.150, batch=206\n",
      "3755: loss=0.301, reward_mean=0.500, reward_bound=0.167, batch=191\n",
      "3756: loss=0.298, reward_mean=0.350, reward_bound=0.150, batch=203\n",
      "3757: loss=0.301, reward_mean=0.480, reward_bound=0.185, batch=201\n",
      "3758: loss=0.300, reward_mean=0.370, reward_bound=0.206, batch=189\n",
      "3759: loss=0.299, reward_mean=0.270, reward_bound=0.164, batch=202\n",
      "3760: loss=0.298, reward_mean=0.420, reward_bound=0.206, batch=214\n",
      "3761: loss=0.299, reward_mean=0.290, reward_bound=0.204, batch=220\n",
      "3762: loss=0.295, reward_mean=0.390, reward_bound=0.222, batch=224\n",
      "3763: loss=0.293, reward_mean=0.360, reward_bound=0.229, batch=199\n",
      "3764: loss=0.294, reward_mean=0.430, reward_bound=0.254, batch=162\n",
      "3765: loss=0.289, reward_mean=0.380, reward_bound=0.098, batch=181\n",
      "3766: loss=0.296, reward_mean=0.330, reward_bound=0.109, batch=196\n",
      "3767: loss=0.288, reward_mean=0.370, reward_bound=0.135, batch=205\n",
      "3768: loss=0.284, reward_mean=0.350, reward_bound=0.138, batch=213\n",
      "3769: loss=0.289, reward_mean=0.320, reward_bound=0.178, batch=219\n",
      "3770: loss=0.286, reward_mean=0.410, reward_bound=0.206, batch=220\n",
      "3771: loss=0.285, reward_mean=0.340, reward_bound=0.229, batch=219\n",
      "3772: loss=0.285, reward_mean=0.310, reward_bound=0.254, batch=214\n",
      "3773: loss=0.284, reward_mean=0.310, reward_bound=0.280, batch=220\n",
      "3774: loss=0.281, reward_mean=0.440, reward_bound=0.282, batch=184\n",
      "3775: loss=0.281, reward_mean=0.320, reward_bound=0.107, batch=199\n",
      "3776: loss=0.280, reward_mean=0.300, reward_bound=0.109, batch=208\n",
      "3777: loss=0.286, reward_mean=0.420, reward_bound=0.187, batch=215\n",
      "3778: loss=0.288, reward_mean=0.340, reward_bound=0.229, batch=219\n",
      "3779: loss=0.289, reward_mean=0.370, reward_bound=0.254, batch=217\n",
      "3780: loss=0.284, reward_mean=0.340, reward_bound=0.282, batch=218\n",
      "3781: loss=0.284, reward_mean=0.330, reward_bound=0.257, batch=222\n",
      "3782: loss=0.297, reward_mean=0.350, reward_bound=0.314, batch=161\n",
      "3783: loss=0.283, reward_mean=0.290, reward_bound=0.020, batch=182\n",
      "3784: loss=0.288, reward_mean=0.350, reward_bound=0.069, batch=197\n",
      "3785: loss=0.286, reward_mean=0.430, reward_bound=0.098, batch=205\n",
      "3786: loss=0.280, reward_mean=0.360, reward_bound=0.135, batch=212\n",
      "3787: loss=0.277, reward_mean=0.420, reward_bound=0.172, batch=218\n",
      "3788: loss=0.278, reward_mean=0.390, reward_bound=0.187, batch=222\n",
      "3789: loss=0.281, reward_mean=0.380, reward_bound=0.206, batch=230\n",
      "3790: loss=0.279, reward_mean=0.380, reward_bound=0.229, batch=229\n",
      "3791: loss=0.280, reward_mean=0.270, reward_bound=0.254, batch=214\n",
      "3792: loss=0.281, reward_mean=0.420, reward_bound=0.282, batch=207\n",
      "3793: loss=0.278, reward_mean=0.320, reward_bound=0.308, batch=215\n",
      "3794: loss=0.286, reward_mean=0.310, reward_bound=0.314, batch=208\n",
      "3795: loss=0.285, reward_mean=0.350, reward_bound=0.231, batch=215\n",
      "3796: loss=0.289, reward_mean=0.390, reward_bound=0.289, batch=220\n",
      "3797: loss=0.289, reward_mean=0.310, reward_bound=0.304, batch=224\n",
      "3798: loss=0.289, reward_mean=0.330, reward_bound=0.314, batch=223\n",
      "3799: loss=0.279, reward_mean=0.410, reward_bound=0.349, batch=156\n",
      "3800: loss=0.274, reward_mean=0.340, reward_bound=0.036, batch=179\n",
      "3801: loss=0.275, reward_mean=0.370, reward_bound=0.083, batch=195\n",
      "3802: loss=0.273, reward_mean=0.370, reward_bound=0.122, batch=205\n",
      "3803: loss=0.276, reward_mean=0.380, reward_bound=0.138, batch=213\n",
      "3804: loss=0.272, reward_mean=0.480, reward_bound=0.167, batch=218\n",
      "3805: loss=0.278, reward_mean=0.360, reward_bound=0.185, batch=213\n",
      "3806: loss=0.277, reward_mean=0.400, reward_bound=0.206, batch=218\n",
      "3807: loss=0.277, reward_mean=0.390, reward_bound=0.229, batch=213\n",
      "3808: loss=0.279, reward_mean=0.440, reward_bound=0.254, batch=212\n",
      "3809: loss=0.283, reward_mean=0.430, reward_bound=0.282, batch=212\n",
      "3810: loss=0.280, reward_mean=0.280, reward_bound=0.263, batch=218\n",
      "3811: loss=0.280, reward_mean=0.460, reward_bound=0.314, batch=206\n",
      "3812: loss=0.281, reward_mean=0.410, reward_bound=0.217, batch=214\n",
      "3813: loss=0.282, reward_mean=0.320, reward_bound=0.150, batch=219\n",
      "3814: loss=0.282, reward_mean=0.400, reward_bound=0.229, batch=220\n",
      "3815: loss=0.279, reward_mean=0.370, reward_bound=0.247, batch=224\n",
      "3816: loss=0.278, reward_mean=0.340, reward_bound=0.254, batch=226\n",
      "3817: loss=0.282, reward_mean=0.380, reward_bound=0.314, batch=224\n",
      "3818: loss=0.285, reward_mean=0.450, reward_bound=0.349, batch=203\n",
      "3819: loss=0.282, reward_mean=0.310, reward_bound=0.160, batch=212\n",
      "3820: loss=0.280, reward_mean=0.280, reward_bound=0.191, batch=218\n",
      "3821: loss=0.284, reward_mean=0.410, reward_bound=0.229, batch=221\n",
      "3822: loss=0.284, reward_mean=0.390, reward_bound=0.254, batch=224\n",
      "3823: loss=0.284, reward_mean=0.350, reward_bound=0.282, batch=224\n",
      "3824: loss=0.282, reward_mean=0.360, reward_bound=0.314, batch=223\n",
      "3825: loss=0.284, reward_mean=0.330, reward_bound=0.349, batch=223\n",
      "3826: loss=0.273, reward_mean=0.320, reward_bound=0.387, batch=150\n",
      "3827: loss=0.259, reward_mean=0.350, reward_bound=0.047, batch=174\n",
      "3828: loss=0.257, reward_mean=0.370, reward_bound=0.089, batch=190\n",
      "3829: loss=0.251, reward_mean=0.340, reward_bound=0.135, batch=199\n",
      "3830: loss=0.253, reward_mean=0.310, reward_bound=0.150, batch=203\n",
      "3831: loss=0.260, reward_mean=0.360, reward_bound=0.185, batch=203\n",
      "3832: loss=0.257, reward_mean=0.360, reward_bound=0.167, batch=211\n",
      "3833: loss=0.261, reward_mean=0.320, reward_bound=0.206, batch=204\n",
      "3834: loss=0.256, reward_mean=0.360, reward_bound=0.185, batch=212\n",
      "3835: loss=0.263, reward_mean=0.340, reward_bound=0.229, batch=210\n",
      "3836: loss=0.268, reward_mean=0.340, reward_bound=0.206, batch=218\n",
      "3837: loss=0.267, reward_mean=0.330, reward_bound=0.206, batch=220\n",
      "3838: loss=0.266, reward_mean=0.360, reward_bound=0.254, batch=212\n",
      "3839: loss=0.267, reward_mean=0.400, reward_bound=0.282, batch=211\n",
      "3840: loss=0.264, reward_mean=0.310, reward_bound=0.254, batch=217\n",
      "3841: loss=0.263, reward_mean=0.390, reward_bound=0.282, batch=220\n",
      "3842: loss=0.264, reward_mean=0.390, reward_bound=0.314, batch=216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3843: loss=0.266, reward_mean=0.270, reward_bound=0.284, batch=221\n",
      "3844: loss=0.267, reward_mean=0.270, reward_bound=0.254, batch=224\n",
      "3845: loss=0.263, reward_mean=0.400, reward_bound=0.349, batch=206\n",
      "3846: loss=0.265, reward_mean=0.380, reward_bound=0.241, batch=214\n",
      "3847: loss=0.262, reward_mean=0.350, reward_bound=0.254, batch=217\n",
      "3848: loss=0.256, reward_mean=0.390, reward_bound=0.282, batch=221\n",
      "3849: loss=0.257, reward_mean=0.520, reward_bound=0.314, batch=221\n",
      "3850: loss=0.262, reward_mean=0.370, reward_bound=0.349, batch=219\n",
      "3851: loss=0.262, reward_mean=0.360, reward_bound=0.309, batch=223\n",
      "3852: loss=0.262, reward_mean=0.400, reward_bound=0.335, batch=226\n",
      "3853: loss=0.263, reward_mean=0.310, reward_bound=0.387, batch=200\n",
      "3854: loss=0.262, reward_mean=0.450, reward_bound=0.314, batch=208\n",
      "3855: loss=0.260, reward_mean=0.440, reward_bound=0.229, batch=213\n",
      "3856: loss=0.264, reward_mean=0.400, reward_bound=0.282, batch=217\n",
      "3857: loss=0.266, reward_mean=0.400, reward_bound=0.308, batch=222\n",
      "3858: loss=0.266, reward_mean=0.440, reward_bound=0.314, batch=223\n",
      "3859: loss=0.264, reward_mean=0.420, reward_bound=0.349, batch=220\n",
      "3860: loss=0.268, reward_mean=0.370, reward_bound=0.254, batch=223\n",
      "3861: loss=0.271, reward_mean=0.340, reward_bound=0.290, batch=226\n",
      "3862: loss=0.270, reward_mean=0.310, reward_bound=0.331, batch=228\n",
      "3863: loss=0.268, reward_mean=0.400, reward_bound=0.387, batch=221\n",
      "3864: loss=0.270, reward_mean=0.320, reward_bound=0.349, batch=224\n",
      "3865: loss=0.271, reward_mean=0.290, reward_bound=0.275, batch=227\n",
      "3866: loss=0.268, reward_mean=0.290, reward_bound=0.387, batch=226\n",
      "3867: loss=0.267, reward_mean=0.360, reward_bound=0.430, batch=129\n",
      "3868: loss=0.268, reward_mean=0.420, reward_bound=0.028, batch=159\n",
      "3869: loss=0.267, reward_mean=0.340, reward_bound=0.032, batch=181\n",
      "3870: loss=0.251, reward_mean=0.390, reward_bound=0.080, batch=195\n",
      "3871: loss=0.253, reward_mean=0.390, reward_bound=0.112, batch=206\n",
      "3872: loss=0.242, reward_mean=0.370, reward_bound=0.150, batch=211\n",
      "3873: loss=0.243, reward_mean=0.280, reward_bound=0.167, batch=213\n",
      "3874: loss=0.246, reward_mean=0.330, reward_bound=0.185, batch=209\n",
      "3875: loss=0.248, reward_mean=0.370, reward_bound=0.206, batch=204\n",
      "3876: loss=0.249, reward_mean=0.300, reward_bound=0.182, batch=213\n",
      "3877: loss=0.247, reward_mean=0.360, reward_bound=0.206, batch=218\n",
      "3878: loss=0.249, reward_mean=0.380, reward_bound=0.229, batch=214\n",
      "3879: loss=0.250, reward_mean=0.340, reward_bound=0.254, batch=202\n",
      "3880: loss=0.249, reward_mean=0.360, reward_bound=0.263, batch=211\n",
      "3881: loss=0.252, reward_mean=0.330, reward_bound=0.282, batch=203\n",
      "3882: loss=0.249, reward_mean=0.390, reward_bound=0.271, batch=212\n",
      "3883: loss=0.246, reward_mean=0.450, reward_bound=0.263, batch=218\n",
      "3884: loss=0.254, reward_mean=0.430, reward_bound=0.314, batch=204\n",
      "3885: loss=0.254, reward_mean=0.310, reward_bound=0.223, batch=213\n",
      "3886: loss=0.258, reward_mean=0.310, reward_bound=0.229, batch=216\n",
      "3887: loss=0.261, reward_mean=0.350, reward_bound=0.254, batch=219\n",
      "3888: loss=0.261, reward_mean=0.400, reward_bound=0.265, batch=223\n",
      "3889: loss=0.260, reward_mean=0.400, reward_bound=0.301, batch=226\n",
      "3890: loss=0.260, reward_mean=0.360, reward_bound=0.331, batch=228\n",
      "3891: loss=0.255, reward_mean=0.340, reward_bound=0.349, batch=204\n",
      "3892: loss=0.252, reward_mean=0.360, reward_bound=0.280, batch=213\n",
      "3893: loss=0.249, reward_mean=0.340, reward_bound=0.198, batch=219\n",
      "3894: loss=0.249, reward_mean=0.370, reward_bound=0.239, batch=223\n",
      "3895: loss=0.249, reward_mean=0.410, reward_bound=0.254, batch=225\n",
      "3896: loss=0.253, reward_mean=0.310, reward_bound=0.282, batch=225\n",
      "3897: loss=0.253, reward_mean=0.470, reward_bound=0.314, batch=226\n",
      "3898: loss=0.256, reward_mean=0.390, reward_bound=0.349, batch=226\n",
      "3899: loss=0.257, reward_mean=0.360, reward_bound=0.368, batch=228\n",
      "3900: loss=0.261, reward_mean=0.490, reward_bound=0.387, batch=195\n",
      "3901: loss=0.250, reward_mean=0.310, reward_bound=0.170, batch=206\n",
      "3902: loss=0.252, reward_mean=0.400, reward_bound=0.206, batch=213\n",
      "3903: loss=0.252, reward_mean=0.460, reward_bound=0.244, batch=219\n",
      "3904: loss=0.258, reward_mean=0.330, reward_bound=0.254, batch=215\n",
      "3905: loss=0.258, reward_mean=0.380, reward_bound=0.282, batch=215\n",
      "3906: loss=0.258, reward_mean=0.420, reward_bound=0.260, batch=220\n",
      "3907: loss=0.254, reward_mean=0.310, reward_bound=0.304, batch=224\n",
      "3908: loss=0.257, reward_mean=0.310, reward_bound=0.314, batch=223\n",
      "3909: loss=0.257, reward_mean=0.380, reward_bound=0.322, batch=226\n",
      "3910: loss=0.254, reward_mean=0.390, reward_bound=0.349, batch=220\n",
      "3911: loss=0.252, reward_mean=0.310, reward_bound=0.247, batch=224\n",
      "3912: loss=0.252, reward_mean=0.270, reward_bound=0.345, batch=227\n",
      "3913: loss=0.254, reward_mean=0.470, reward_bound=0.380, batch=229\n",
      "3914: loss=0.255, reward_mean=0.360, reward_bound=0.387, batch=222\n",
      "3915: loss=0.254, reward_mean=0.340, reward_bound=0.400, batch=225\n",
      "3916: loss=0.254, reward_mean=0.430, reward_bound=0.430, batch=171\n",
      "3917: loss=0.261, reward_mean=0.350, reward_bound=0.052, batch=188\n",
      "3918: loss=0.260, reward_mean=0.320, reward_bound=0.090, batch=201\n",
      "3919: loss=0.249, reward_mean=0.400, reward_bound=0.122, batch=207\n",
      "3920: loss=0.252, reward_mean=0.370, reward_bound=0.167, batch=206\n",
      "3921: loss=0.253, reward_mean=0.360, reward_bound=0.185, batch=213\n",
      "3922: loss=0.247, reward_mean=0.390, reward_bound=0.220, batch=219\n",
      "3923: loss=0.248, reward_mean=0.290, reward_bound=0.229, batch=220\n",
      "3924: loss=0.247, reward_mean=0.390, reward_bound=0.254, batch=220\n",
      "3925: loss=0.248, reward_mean=0.320, reward_bound=0.282, batch=220\n",
      "3926: loss=0.254, reward_mean=0.430, reward_bound=0.314, batch=216\n",
      "3927: loss=0.256, reward_mean=0.360, reward_bound=0.229, batch=220\n",
      "3928: loss=0.251, reward_mean=0.470, reward_bound=0.349, batch=213\n",
      "3929: loss=0.251, reward_mean=0.370, reward_bound=0.235, batch=219\n",
      "3930: loss=0.251, reward_mean=0.330, reward_bound=0.282, batch=222\n",
      "3931: loss=0.251, reward_mean=0.380, reward_bound=0.336, batch=225\n",
      "3932: loss=0.252, reward_mean=0.460, reward_bound=0.387, batch=206\n",
      "3933: loss=0.249, reward_mean=0.330, reward_bound=0.314, batch=213\n",
      "3934: loss=0.257, reward_mean=0.450, reward_bound=0.349, batch=217\n",
      "3935: loss=0.258, reward_mean=0.440, reward_bound=0.335, batch=222\n",
      "3936: loss=0.255, reward_mean=0.390, reward_bound=0.387, batch=217\n",
      "3937: loss=0.254, reward_mean=0.410, reward_bound=0.342, batch=222\n",
      "3938: loss=0.252, reward_mean=0.430, reward_bound=0.263, batch=225\n",
      "3939: loss=0.251, reward_mean=0.340, reward_bound=0.314, batch=226\n",
      "3940: loss=0.252, reward_mean=0.450, reward_bound=0.349, batch=225\n",
      "3941: loss=0.256, reward_mean=0.350, reward_bound=0.387, batch=221\n",
      "3942: loss=0.254, reward_mean=0.400, reward_bound=0.387, batch=223\n",
      "3943: loss=0.256, reward_mean=0.360, reward_bound=0.413, batch=226\n",
      "3944: loss=0.256, reward_mean=0.380, reward_bound=0.387, batch=227\n",
      "3945: loss=0.255, reward_mean=0.380, reward_bound=0.314, batch=228\n",
      "3946: loss=0.259, reward_mean=0.350, reward_bound=0.430, batch=206\n",
      "3947: loss=0.258, reward_mean=0.400, reward_bound=0.168, batch=214\n",
      "3948: loss=0.258, reward_mean=0.430, reward_bound=0.314, batch=215\n",
      "3949: loss=0.257, reward_mean=0.420, reward_bound=0.282, batch=219\n",
      "3950: loss=0.255, reward_mean=0.290, reward_bound=0.163, batch=223\n",
      "3951: loss=0.258, reward_mean=0.460, reward_bound=0.271, batch=226\n",
      "3952: loss=0.258, reward_mean=0.410, reward_bound=0.314, batch=226\n",
      "3953: loss=0.257, reward_mean=0.450, reward_bound=0.316, batch=228\n",
      "3954: loss=0.257, reward_mean=0.310, reward_bound=0.349, batch=225\n",
      "3955: loss=0.255, reward_mean=0.360, reward_bound=0.321, batch=227\n",
      "3956: loss=0.257, reward_mean=0.380, reward_bound=0.387, batch=222\n",
      "3957: loss=0.257, reward_mean=0.390, reward_bound=0.400, batch=225\n",
      "3958: loss=0.258, reward_mean=0.400, reward_bound=0.356, batch=227\n",
      "3959: loss=0.262, reward_mean=0.350, reward_bound=0.302, batch=229\n",
      "3960: loss=0.256, reward_mean=0.350, reward_bound=0.387, batch=229\n",
      "3961: loss=0.260, reward_mean=0.450, reward_bound=0.430, batch=223\n",
      "3962: loss=0.261, reward_mean=0.340, reward_bound=0.349, batch=225\n",
      "3963: loss=0.261, reward_mean=0.360, reward_bound=0.430, batch=226\n",
      "3964: loss=0.261, reward_mean=0.380, reward_bound=0.331, batch=228\n",
      "3965: loss=0.262, reward_mean=0.330, reward_bound=0.478, batch=230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3966: loss=0.261, reward_mean=0.340, reward_bound=0.464, batch=231\n",
      "3967: loss=0.259, reward_mean=0.420, reward_bound=0.478, batch=95\n",
      "3968: loss=0.247, reward_mean=0.350, reward_bound=0.000, batch=130\n",
      "3969: loss=0.234, reward_mean=0.350, reward_bound=0.003, batch=161\n",
      "3970: loss=0.231, reward_mean=0.370, reward_bound=0.013, batch=181\n",
      "3971: loss=0.236, reward_mean=0.330, reward_bound=0.031, batch=195\n",
      "3972: loss=0.233, reward_mean=0.310, reward_bound=0.059, batch=206\n",
      "3973: loss=0.225, reward_mean=0.470, reward_bound=0.098, batch=206\n",
      "3974: loss=0.220, reward_mean=0.350, reward_bound=0.122, batch=202\n",
      "3975: loss=0.223, reward_mean=0.400, reward_bound=0.135, batch=207\n",
      "3976: loss=0.229, reward_mean=0.410, reward_bound=0.150, batch=214\n",
      "3977: loss=0.240, reward_mean=0.350, reward_bound=0.167, batch=211\n",
      "3978: loss=0.235, reward_mean=0.320, reward_bound=0.185, batch=211\n",
      "3979: loss=0.237, reward_mean=0.440, reward_bound=0.206, batch=204\n",
      "3980: loss=0.240, reward_mean=0.390, reward_bound=0.204, batch=213\n",
      "3981: loss=0.241, reward_mean=0.350, reward_bound=0.206, batch=217\n",
      "3982: loss=0.246, reward_mean=0.400, reward_bound=0.229, batch=213\n",
      "3983: loss=0.254, reward_mean=0.410, reward_bound=0.254, batch=198\n",
      "3984: loss=0.254, reward_mean=0.360, reward_bound=0.135, batch=207\n",
      "3985: loss=0.249, reward_mean=0.360, reward_bound=0.182, batch=215\n",
      "3986: loss=0.258, reward_mean=0.380, reward_bound=0.229, batch=219\n",
      "3987: loss=0.260, reward_mean=0.350, reward_bound=0.254, batch=220\n",
      "3988: loss=0.264, reward_mean=0.310, reward_bound=0.282, batch=192\n",
      "3989: loss=0.262, reward_mean=0.410, reward_bound=0.150, batch=203\n",
      "3990: loss=0.260, reward_mean=0.270, reward_bound=0.167, batch=211\n",
      "3991: loss=0.257, reward_mean=0.350, reward_bound=0.206, batch=216\n",
      "3992: loss=0.259, reward_mean=0.430, reward_bound=0.229, batch=219\n",
      "3993: loss=0.260, reward_mean=0.350, reward_bound=0.254, batch=219\n",
      "3994: loss=0.259, reward_mean=0.390, reward_bound=0.282, batch=217\n",
      "3995: loss=0.254, reward_mean=0.380, reward_bound=0.314, batch=191\n",
      "3996: loss=0.255, reward_mean=0.440, reward_bound=0.229, batch=202\n",
      "3997: loss=0.248, reward_mean=0.390, reward_bound=0.126, batch=211\n",
      "3998: loss=0.250, reward_mean=0.280, reward_bound=0.206, batch=216\n",
      "3999: loss=0.252, reward_mean=0.360, reward_bound=0.241, batch=221\n",
      "4000: loss=0.256, reward_mean=0.340, reward_bound=0.254, batch=224\n",
      "4001: loss=0.254, reward_mean=0.380, reward_bound=0.282, batch=223\n",
      "4002: loss=0.261, reward_mean=0.330, reward_bound=0.314, batch=220\n",
      "4003: loss=0.260, reward_mean=0.380, reward_bound=0.274, batch=224\n",
      "4004: loss=0.274, reward_mean=0.310, reward_bound=0.349, batch=182\n",
      "4005: loss=0.276, reward_mean=0.420, reward_bound=0.135, batch=196\n",
      "4006: loss=0.271, reward_mean=0.370, reward_bound=0.185, batch=205\n",
      "4007: loss=0.281, reward_mean=0.370, reward_bound=0.229, batch=209\n",
      "4008: loss=0.280, reward_mean=0.400, reward_bound=0.239, batch=216\n",
      "4009: loss=0.270, reward_mean=0.340, reward_bound=0.254, batch=217\n",
      "4010: loss=0.267, reward_mean=0.390, reward_bound=0.282, batch=215\n",
      "4011: loss=0.269, reward_mean=0.390, reward_bound=0.314, batch=215\n",
      "4012: loss=0.270, reward_mean=0.390, reward_bound=0.349, batch=211\n",
      "4013: loss=0.270, reward_mean=0.420, reward_bound=0.254, batch=216\n",
      "4014: loss=0.268, reward_mean=0.400, reward_bound=0.282, batch=220\n",
      "4015: loss=0.270, reward_mean=0.470, reward_bound=0.349, batch=220\n",
      "4016: loss=0.267, reward_mean=0.290, reward_bound=0.365, batch=224\n",
      "4017: loss=0.266, reward_mean=0.380, reward_bound=0.349, batch=226\n",
      "4018: loss=0.264, reward_mean=0.380, reward_bound=0.298, batch=228\n",
      "4019: loss=0.263, reward_mean=0.360, reward_bound=0.321, batch=229\n",
      "4020: loss=0.259, reward_mean=0.400, reward_bound=0.387, batch=184\n",
      "4021: loss=0.258, reward_mean=0.420, reward_bound=0.183, batch=199\n",
      "4022: loss=0.257, reward_mean=0.380, reward_bound=0.194, batch=209\n",
      "4023: loss=0.255, reward_mean=0.320, reward_bound=0.206, batch=210\n",
      "4024: loss=0.256, reward_mean=0.400, reward_bound=0.247, batch=217\n",
      "4025: loss=0.262, reward_mean=0.430, reward_bound=0.254, batch=216\n",
      "4026: loss=0.264, reward_mean=0.330, reward_bound=0.282, batch=211\n",
      "4027: loss=0.260, reward_mean=0.210, reward_bound=0.150, batch=217\n",
      "4028: loss=0.263, reward_mean=0.440, reward_bound=0.254, batch=220\n",
      "4029: loss=0.262, reward_mean=0.450, reward_bound=0.314, batch=217\n",
      "4030: loss=0.263, reward_mean=0.390, reward_bound=0.342, batch=222\n",
      "4031: loss=0.269, reward_mean=0.360, reward_bound=0.349, batch=218\n",
      "4032: loss=0.267, reward_mean=0.300, reward_bound=0.387, batch=212\n",
      "4033: loss=0.269, reward_mean=0.400, reward_bound=0.349, batch=217\n",
      "4034: loss=0.269, reward_mean=0.310, reward_bound=0.314, batch=220\n",
      "4035: loss=0.268, reward_mean=0.310, reward_bound=0.338, batch=224\n",
      "4036: loss=0.265, reward_mean=0.430, reward_bound=0.384, batch=227\n",
      "4037: loss=0.267, reward_mean=0.370, reward_bound=0.387, batch=222\n",
      "4038: loss=0.265, reward_mean=0.380, reward_bound=0.400, batch=225\n",
      "4039: loss=0.264, reward_mean=0.400, reward_bound=0.365, batch=227\n",
      "4040: loss=0.263, reward_mean=0.290, reward_bound=0.380, batch=229\n",
      "4041: loss=0.262, reward_mean=0.300, reward_bound=0.405, batch=230\n",
      "4042: loss=0.262, reward_mean=0.380, reward_bound=0.430, batch=180\n",
      "4043: loss=0.252, reward_mean=0.360, reward_bound=0.185, batch=194\n",
      "4044: loss=0.255, reward_mean=0.380, reward_bound=0.147, batch=206\n",
      "4045: loss=0.249, reward_mean=0.380, reward_bound=0.206, batch=209\n",
      "4046: loss=0.252, reward_mean=0.330, reward_bound=0.229, batch=212\n",
      "4047: loss=0.254, reward_mean=0.380, reward_bound=0.254, batch=217\n",
      "4048: loss=0.254, reward_mean=0.400, reward_bound=0.282, batch=215\n",
      "4049: loss=0.261, reward_mean=0.390, reward_bound=0.314, batch=211\n",
      "4050: loss=0.264, reward_mean=0.320, reward_bound=0.229, batch=217\n",
      "4051: loss=0.261, reward_mean=0.410, reward_bound=0.277, batch=222\n",
      "4052: loss=0.257, reward_mean=0.330, reward_bound=0.282, batch=223\n",
      "4053: loss=0.262, reward_mean=0.300, reward_bound=0.349, batch=213\n",
      "4054: loss=0.263, reward_mean=0.420, reward_bound=0.335, batch=219\n",
      "4055: loss=0.263, reward_mean=0.360, reward_bound=0.194, batch=223\n",
      "4056: loss=0.263, reward_mean=0.360, reward_bound=0.271, batch=226\n",
      "4057: loss=0.262, reward_mean=0.390, reward_bound=0.314, batch=227\n",
      "4058: loss=0.261, reward_mean=0.270, reward_bound=0.349, batch=226\n",
      "4059: loss=0.266, reward_mean=0.300, reward_bound=0.387, batch=210\n",
      "4060: loss=0.266, reward_mean=0.350, reward_bound=0.200, batch=217\n",
      "4061: loss=0.264, reward_mean=0.260, reward_bound=0.229, batch=220\n",
      "4062: loss=0.269, reward_mean=0.350, reward_bound=0.274, batch=224\n",
      "4063: loss=0.266, reward_mean=0.410, reward_bound=0.282, batch=226\n",
      "4064: loss=0.263, reward_mean=0.410, reward_bound=0.314, batch=227\n",
      "4065: loss=0.258, reward_mean=0.330, reward_bound=0.349, batch=227\n",
      "4066: loss=0.257, reward_mean=0.330, reward_bound=0.349, batch=228\n",
      "4067: loss=0.260, reward_mean=0.360, reward_bound=0.387, batch=224\n",
      "4068: loss=0.255, reward_mean=0.340, reward_bound=0.430, batch=203\n",
      "4069: loss=0.253, reward_mean=0.340, reward_bound=0.254, batch=211\n",
      "4070: loss=0.250, reward_mean=0.360, reward_bound=0.282, batch=217\n",
      "4071: loss=0.255, reward_mean=0.470, reward_bound=0.314, batch=221\n",
      "4072: loss=0.254, reward_mean=0.380, reward_bound=0.349, batch=214\n",
      "4073: loss=0.252, reward_mean=0.360, reward_bound=0.254, batch=216\n",
      "4074: loss=0.252, reward_mean=0.430, reward_bound=0.349, batch=219\n",
      "4075: loss=0.253, reward_mean=0.300, reward_bound=0.328, batch=223\n",
      "4076: loss=0.253, reward_mean=0.510, reward_bound=0.335, batch=226\n",
      "4077: loss=0.254, reward_mean=0.410, reward_bound=0.349, batch=227\n",
      "4078: loss=0.251, reward_mean=0.400, reward_bound=0.387, batch=221\n",
      "4079: loss=0.252, reward_mean=0.380, reward_bound=0.387, batch=224\n",
      "4080: loss=0.253, reward_mean=0.310, reward_bound=0.311, batch=227\n",
      "4081: loss=0.254, reward_mean=0.290, reward_bound=0.380, batch=229\n",
      "4082: loss=0.253, reward_mean=0.400, reward_bound=0.387, batch=229\n",
      "4083: loss=0.254, reward_mean=0.280, reward_bound=0.430, batch=216\n",
      "4084: loss=0.257, reward_mean=0.320, reward_bound=0.387, batch=220\n",
      "4085: loss=0.258, reward_mean=0.430, reward_bound=0.406, batch=224\n",
      "4086: loss=0.257, reward_mean=0.330, reward_bound=0.314, batch=226\n",
      "4087: loss=0.257, reward_mean=0.390, reward_bound=0.368, batch=228\n",
      "4088: loss=0.257, reward_mean=0.330, reward_bound=0.289, batch=229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4089: loss=0.260, reward_mean=0.330, reward_bound=0.387, batch=229\n",
      "4090: loss=0.256, reward_mean=0.350, reward_bound=0.430, batch=225\n",
      "4091: loss=0.247, reward_mean=0.350, reward_bound=0.478, batch=147\n",
      "4092: loss=0.242, reward_mean=0.340, reward_bound=0.033, batch=173\n",
      "4093: loss=0.234, reward_mean=0.370, reward_bound=0.050, batch=191\n",
      "4094: loss=0.238, reward_mean=0.400, reward_bound=0.098, batch=201\n",
      "4095: loss=0.238, reward_mean=0.390, reward_bound=0.122, batch=210\n",
      "4096: loss=0.234, reward_mean=0.350, reward_bound=0.150, batch=216\n",
      "4097: loss=0.225, reward_mean=0.380, reward_bound=0.206, batch=217\n",
      "4098: loss=0.234, reward_mean=0.360, reward_bound=0.229, batch=211\n",
      "4099: loss=0.246, reward_mean=0.310, reward_bound=0.254, batch=209\n",
      "4100: loss=0.246, reward_mean=0.410, reward_bound=0.282, batch=204\n",
      "4101: loss=0.241, reward_mean=0.330, reward_bound=0.183, batch=213\n",
      "4102: loss=0.246, reward_mean=0.370, reward_bound=0.229, batch=218\n",
      "4103: loss=0.247, reward_mean=0.470, reward_bound=0.257, batch=222\n",
      "4104: loss=0.246, reward_mean=0.480, reward_bound=0.292, batch=225\n",
      "4105: loss=0.235, reward_mean=0.430, reward_bound=0.314, batch=213\n",
      "4106: loss=0.237, reward_mean=0.380, reward_bound=0.349, batch=199\n",
      "4107: loss=0.233, reward_mean=0.340, reward_bound=0.185, batch=207\n",
      "4108: loss=0.231, reward_mean=0.400, reward_bound=0.202, batch=215\n",
      "4109: loss=0.227, reward_mean=0.340, reward_bound=0.206, batch=219\n",
      "4110: loss=0.226, reward_mean=0.390, reward_bound=0.239, batch=223\n",
      "4111: loss=0.228, reward_mean=0.350, reward_bound=0.282, batch=221\n",
      "4112: loss=0.233, reward_mean=0.460, reward_bound=0.314, batch=219\n",
      "4113: loss=0.234, reward_mean=0.310, reward_bound=0.349, batch=213\n",
      "4114: loss=0.238, reward_mean=0.340, reward_bound=0.358, batch=219\n",
      "4115: loss=0.236, reward_mean=0.410, reward_bound=0.309, batch=223\n",
      "4116: loss=0.233, reward_mean=0.360, reward_bound=0.372, batch=226\n",
      "4117: loss=0.237, reward_mean=0.320, reward_bound=0.387, batch=205\n",
      "4118: loss=0.232, reward_mean=0.370, reward_bound=0.167, batch=212\n",
      "4119: loss=0.232, reward_mean=0.330, reward_bound=0.263, batch=218\n",
      "4120: loss=0.233, reward_mean=0.400, reward_bound=0.282, batch=220\n",
      "4121: loss=0.232, reward_mean=0.390, reward_bound=0.304, batch=224\n",
      "4122: loss=0.234, reward_mean=0.410, reward_bound=0.314, batch=223\n",
      "4123: loss=0.236, reward_mean=0.360, reward_bound=0.349, batch=217\n",
      "4124: loss=0.236, reward_mean=0.320, reward_bound=0.314, batch=221\n",
      "4125: loss=0.234, reward_mean=0.350, reward_bound=0.349, batch=222\n",
      "4126: loss=0.232, reward_mean=0.290, reward_bound=0.236, batch=225\n",
      "4127: loss=0.232, reward_mean=0.380, reward_bound=0.329, batch=227\n",
      "4128: loss=0.234, reward_mean=0.360, reward_bound=0.387, batch=227\n",
      "4129: loss=0.233, reward_mean=0.270, reward_bound=0.373, batch=229\n",
      "4130: loss=0.232, reward_mean=0.380, reward_bound=0.405, batch=230\n",
      "4131: loss=0.232, reward_mean=0.380, reward_bound=0.406, batch=231\n",
      "4132: loss=0.239, reward_mean=0.410, reward_bound=0.430, batch=196\n",
      "4133: loss=0.243, reward_mean=0.340, reward_bound=0.176, batch=207\n",
      "4134: loss=0.243, reward_mean=0.320, reward_bound=0.206, batch=213\n",
      "4135: loss=0.237, reward_mean=0.360, reward_bound=0.254, batch=217\n",
      "4136: loss=0.232, reward_mean=0.390, reward_bound=0.277, batch=222\n",
      "4137: loss=0.235, reward_mean=0.290, reward_bound=0.282, batch=221\n",
      "4138: loss=0.233, reward_mean=0.370, reward_bound=0.314, batch=219\n",
      "4139: loss=0.232, reward_mean=0.210, reward_bound=0.254, batch=221\n",
      "4140: loss=0.235, reward_mean=0.360, reward_bound=0.349, batch=220\n",
      "4141: loss=0.236, reward_mean=0.390, reward_bound=0.338, batch=224\n",
      "4142: loss=0.239, reward_mean=0.420, reward_bound=0.349, batch=226\n",
      "4143: loss=0.239, reward_mean=0.440, reward_bound=0.387, batch=215\n",
      "4144: loss=0.248, reward_mean=0.370, reward_bound=0.321, batch=220\n",
      "4145: loss=0.247, reward_mean=0.310, reward_bound=0.313, batch=224\n",
      "4146: loss=0.245, reward_mean=0.300, reward_bound=0.282, batch=226\n",
      "4147: loss=0.245, reward_mean=0.360, reward_bound=0.349, batch=226\n",
      "4148: loss=0.246, reward_mean=0.370, reward_bound=0.349, batch=227\n",
      "4149: loss=0.242, reward_mean=0.320, reward_bound=0.387, batch=226\n",
      "4150: loss=0.240, reward_mean=0.390, reward_bound=0.430, batch=216\n",
      "4151: loss=0.236, reward_mean=0.320, reward_bound=0.331, batch=221\n",
      "4152: loss=0.235, reward_mean=0.390, reward_bound=0.254, batch=224\n",
      "4153: loss=0.238, reward_mean=0.380, reward_bound=0.387, batch=222\n",
      "4154: loss=0.238, reward_mean=0.420, reward_bound=0.349, batch=224\n",
      "4155: loss=0.238, reward_mean=0.360, reward_bound=0.345, batch=227\n",
      "4156: loss=0.237, reward_mean=0.350, reward_bound=0.342, batch=229\n",
      "4157: loss=0.238, reward_mean=0.310, reward_bound=0.349, batch=229\n",
      "4158: loss=0.241, reward_mean=0.390, reward_bound=0.387, batch=229\n",
      "4159: loss=0.240, reward_mean=0.370, reward_bound=0.430, batch=224\n",
      "4160: loss=0.239, reward_mean=0.330, reward_bound=0.349, batch=226\n",
      "4161: loss=0.242, reward_mean=0.320, reward_bound=0.387, batch=227\n",
      "4162: loss=0.241, reward_mean=0.350, reward_bound=0.407, batch=229\n",
      "4163: loss=0.240, reward_mean=0.280, reward_bound=0.430, batch=229\n",
      "4164: loss=0.240, reward_mean=0.300, reward_bound=0.405, batch=230\n",
      "4165: loss=0.239, reward_mean=0.400, reward_bound=0.418, batch=231\n",
      "4166: loss=0.239, reward_mean=0.430, reward_bound=0.430, batch=231\n",
      "4167: loss=0.248, reward_mean=0.290, reward_bound=0.478, batch=180\n",
      "4168: loss=0.249, reward_mean=0.390, reward_bound=0.167, batch=195\n",
      "4169: loss=0.249, reward_mean=0.340, reward_bound=0.135, batch=205\n",
      "4170: loss=0.250, reward_mean=0.350, reward_bound=0.185, batch=209\n",
      "4171: loss=0.248, reward_mean=0.360, reward_bound=0.229, batch=214\n",
      "4172: loss=0.238, reward_mean=0.390, reward_bound=0.254, batch=219\n",
      "4173: loss=0.241, reward_mean=0.340, reward_bound=0.282, batch=216\n",
      "4174: loss=0.242, reward_mean=0.300, reward_bound=0.268, batch=221\n",
      "4175: loss=0.246, reward_mean=0.400, reward_bound=0.314, batch=214\n",
      "4176: loss=0.243, reward_mean=0.410, reward_bound=0.277, batch=220\n",
      "4177: loss=0.243, reward_mean=0.440, reward_bound=0.304, batch=224\n",
      "4178: loss=0.248, reward_mean=0.320, reward_bound=0.314, batch=223\n",
      "4179: loss=0.249, reward_mean=0.330, reward_bound=0.314, batch=225\n",
      "4180: loss=0.250, reward_mean=0.370, reward_bound=0.349, batch=218\n",
      "4181: loss=0.252, reward_mean=0.380, reward_bound=0.264, batch=222\n",
      "4182: loss=0.252, reward_mean=0.420, reward_bound=0.387, batch=213\n",
      "4183: loss=0.251, reward_mean=0.320, reward_bound=0.206, batch=218\n",
      "4184: loss=0.252, reward_mean=0.400, reward_bound=0.317, batch=222\n",
      "4185: loss=0.252, reward_mean=0.370, reward_bound=0.265, batch=225\n",
      "4186: loss=0.252, reward_mean=0.350, reward_bound=0.349, batch=225\n",
      "4187: loss=0.252, reward_mean=0.300, reward_bound=0.253, batch=227\n",
      "4188: loss=0.250, reward_mean=0.240, reward_bound=0.342, batch=229\n",
      "4189: loss=0.249, reward_mean=0.440, reward_bound=0.328, batch=230\n",
      "4190: loss=0.258, reward_mean=0.290, reward_bound=0.349, batch=230\n",
      "4191: loss=0.258, reward_mean=0.300, reward_bound=0.347, batch=231\n",
      "4192: loss=0.255, reward_mean=0.340, reward_bound=0.387, batch=226\n",
      "4193: loss=0.261, reward_mean=0.380, reward_bound=0.430, batch=203\n",
      "4194: loss=0.264, reward_mean=0.330, reward_bound=0.229, batch=211\n",
      "4195: loss=0.269, reward_mean=0.400, reward_bound=0.254, batch=216\n",
      "4196: loss=0.269, reward_mean=0.350, reward_bound=0.282, batch=219\n",
      "4197: loss=0.269, reward_mean=0.310, reward_bound=0.314, batch=222\n",
      "4198: loss=0.277, reward_mean=0.390, reward_bound=0.324, batch=225\n",
      "4199: loss=0.275, reward_mean=0.350, reward_bound=0.260, batch=227\n",
      "4200: loss=0.273, reward_mean=0.350, reward_bound=0.349, batch=220\n",
      "4201: loss=0.270, reward_mean=0.360, reward_bound=0.296, batch=224\n",
      "4202: loss=0.269, reward_mean=0.300, reward_bound=0.349, batch=226\n",
      "4203: loss=0.269, reward_mean=0.360, reward_bound=0.387, batch=218\n",
      "4204: loss=0.266, reward_mean=0.390, reward_bound=0.392, batch=222\n",
      "4205: loss=0.263, reward_mean=0.370, reward_bound=0.272, batch=225\n",
      "4206: loss=0.263, reward_mean=0.370, reward_bound=0.289, batch=227\n",
      "4207: loss=0.263, reward_mean=0.320, reward_bound=0.387, batch=227\n",
      "4208: loss=0.262, reward_mean=0.400, reward_bound=0.422, batch=229\n",
      "4209: loss=0.262, reward_mean=0.290, reward_bound=0.430, batch=219\n",
      "4210: loss=0.265, reward_mean=0.330, reward_bound=0.265, batch=223\n",
      "4211: loss=0.262, reward_mean=0.360, reward_bound=0.282, batch=223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4212: loss=0.264, reward_mean=0.330, reward_bound=0.301, batch=226\n",
      "4213: loss=0.266, reward_mean=0.250, reward_bound=0.298, batch=228\n",
      "4214: loss=0.266, reward_mean=0.300, reward_bound=0.314, batch=228\n",
      "4215: loss=0.264, reward_mean=0.260, reward_bound=0.349, batch=225\n",
      "4216: loss=0.263, reward_mean=0.400, reward_bound=0.387, batch=226\n",
      "4217: loss=0.262, reward_mean=0.330, reward_bound=0.430, batch=223\n",
      "4218: loss=0.263, reward_mean=0.350, reward_bound=0.398, batch=226\n",
      "4219: loss=0.264, reward_mean=0.340, reward_bound=0.409, batch=228\n",
      "4220: loss=0.264, reward_mean=0.360, reward_bound=0.317, batch=229\n",
      "4221: loss=0.264, reward_mean=0.310, reward_bound=0.292, batch=230\n",
      "4222: loss=0.262, reward_mean=0.380, reward_bound=0.376, batch=231\n",
      "4223: loss=0.262, reward_mean=0.330, reward_bound=0.387, batch=230\n",
      "4224: loss=0.262, reward_mean=0.470, reward_bound=0.418, batch=231\n",
      "4225: loss=0.262, reward_mean=0.340, reward_bound=0.430, batch=226\n",
      "4226: loss=0.260, reward_mean=0.280, reward_bound=0.390, batch=228\n",
      "4227: loss=0.261, reward_mean=0.340, reward_bound=0.430, batch=227\n",
      "4228: loss=0.262, reward_mean=0.380, reward_bound=0.469, batch=229\n",
      "4229: loss=0.261, reward_mean=0.440, reward_bound=0.380, batch=230\n",
      "4230: loss=0.261, reward_mean=0.320, reward_bound=0.420, batch=231\n",
      "4231: loss=0.252, reward_mean=0.430, reward_bound=0.478, batch=202\n",
      "4232: loss=0.247, reward_mean=0.380, reward_bound=0.229, batch=210\n",
      "4233: loss=0.245, reward_mean=0.350, reward_bound=0.206, batch=218\n",
      "4234: loss=0.245, reward_mean=0.420, reward_bound=0.282, batch=219\n",
      "4235: loss=0.249, reward_mean=0.300, reward_bound=0.314, batch=219\n",
      "4236: loss=0.248, reward_mean=0.300, reward_bound=0.295, batch=223\n",
      "4237: loss=0.250, reward_mean=0.350, reward_bound=0.314, batch=224\n",
      "4238: loss=0.249, reward_mean=0.390, reward_bound=0.345, batch=227\n",
      "4239: loss=0.249, reward_mean=0.330, reward_bound=0.302, batch=229\n",
      "4240: loss=0.244, reward_mean=0.410, reward_bound=0.349, batch=223\n",
      "4241: loss=0.246, reward_mean=0.420, reward_bound=0.372, batch=226\n",
      "4242: loss=0.246, reward_mean=0.350, reward_bound=0.298, batch=228\n",
      "4243: loss=0.245, reward_mean=0.380, reward_bound=0.349, batch=228\n",
      "4244: loss=0.247, reward_mean=0.390, reward_bound=0.387, batch=227\n",
      "4245: loss=0.246, reward_mean=0.360, reward_bound=0.387, batch=228\n",
      "4246: loss=0.250, reward_mean=0.420, reward_bound=0.430, batch=215\n",
      "4247: loss=0.249, reward_mean=0.290, reward_bound=0.321, batch=220\n",
      "4248: loss=0.250, reward_mean=0.240, reward_bound=0.314, batch=223\n",
      "4249: loss=0.251, reward_mean=0.340, reward_bound=0.244, batch=226\n",
      "4250: loss=0.248, reward_mean=0.350, reward_bound=0.331, batch=228\n",
      "4251: loss=0.249, reward_mean=0.460, reward_bound=0.349, batch=227\n",
      "4252: loss=0.251, reward_mean=0.370, reward_bound=0.387, batch=221\n",
      "4253: loss=0.251, reward_mean=0.510, reward_bound=0.430, batch=222\n",
      "4254: loss=0.252, reward_mean=0.400, reward_bound=0.400, batch=225\n",
      "4255: loss=0.250, reward_mean=0.350, reward_bound=0.430, batch=225\n",
      "4256: loss=0.252, reward_mean=0.340, reward_bound=0.356, batch=227\n",
      "4257: loss=0.251, reward_mean=0.290, reward_bound=0.361, batch=229\n",
      "4258: loss=0.252, reward_mean=0.350, reward_bound=0.364, batch=230\n",
      "4259: loss=0.250, reward_mean=0.380, reward_bound=0.418, batch=231\n",
      "4260: loss=0.251, reward_mean=0.380, reward_bound=0.430, batch=230\n",
      "4261: loss=0.255, reward_mean=0.350, reward_bound=0.478, batch=216\n",
      "4262: loss=0.252, reward_mean=0.280, reward_bound=0.198, batch=221\n",
      "4263: loss=0.254, reward_mean=0.390, reward_bound=0.314, batch=223\n",
      "4264: loss=0.253, reward_mean=0.340, reward_bound=0.349, batch=225\n",
      "4265: loss=0.251, reward_mean=0.380, reward_bound=0.356, batch=227\n",
      "4266: loss=0.252, reward_mean=0.410, reward_bound=0.387, batch=224\n",
      "4267: loss=0.253, reward_mean=0.360, reward_bound=0.308, batch=227\n",
      "4268: loss=0.252, reward_mean=0.330, reward_bound=0.387, batch=228\n",
      "4269: loss=0.253, reward_mean=0.310, reward_bound=0.430, batch=223\n",
      "4270: loss=0.252, reward_mean=0.340, reward_bound=0.244, batch=226\n",
      "4271: loss=0.252, reward_mean=0.420, reward_bound=0.368, batch=228\n",
      "4272: loss=0.252, reward_mean=0.300, reward_bound=0.387, batch=226\n",
      "4273: loss=0.250, reward_mean=0.460, reward_bound=0.298, batch=228\n",
      "4274: loss=0.251, reward_mean=0.390, reward_bound=0.387, batch=227\n",
      "4275: loss=0.250, reward_mean=0.320, reward_bound=0.277, batch=229\n",
      "4276: loss=0.250, reward_mean=0.430, reward_bound=0.405, batch=230\n",
      "4277: loss=0.249, reward_mean=0.390, reward_bound=0.406, batch=231\n",
      "4278: loss=0.255, reward_mean=0.350, reward_bound=0.478, batch=221\n",
      "4279: loss=0.255, reward_mean=0.260, reward_bound=0.314, batch=223\n",
      "4280: loss=0.255, reward_mean=0.290, reward_bound=0.358, batch=226\n",
      "4281: loss=0.257, reward_mean=0.440, reward_bound=0.314, batch=227\n",
      "4282: loss=0.258, reward_mean=0.370, reward_bound=0.349, batch=228\n",
      "4283: loss=0.258, reward_mean=0.310, reward_bound=0.353, batch=229\n",
      "4284: loss=0.257, reward_mean=0.380, reward_bound=0.328, batch=230\n",
      "4285: loss=0.256, reward_mean=0.280, reward_bound=0.387, batch=226\n",
      "4286: loss=0.254, reward_mean=0.260, reward_bound=0.454, batch=228\n",
      "4287: loss=0.254, reward_mean=0.410, reward_bound=0.478, batch=230\n",
      "4288: loss=0.256, reward_mean=0.390, reward_bound=0.478, batch=224\n",
      "4289: loss=0.255, reward_mean=0.360, reward_bound=0.380, batch=227\n",
      "4290: loss=0.257, reward_mean=0.430, reward_bound=0.422, batch=229\n",
      "4291: loss=0.256, reward_mean=0.360, reward_bound=0.381, batch=230\n",
      "4292: loss=0.255, reward_mean=0.310, reward_bound=0.406, batch=231\n",
      "4293: loss=0.257, reward_mean=0.340, reward_bound=0.430, batch=229\n",
      "4294: loss=0.257, reward_mean=0.360, reward_bound=0.387, batch=229\n",
      "4295: loss=0.257, reward_mean=0.350, reward_bound=0.450, batch=230\n",
      "4296: loss=0.256, reward_mean=0.330, reward_bound=0.439, batch=231\n",
      "4297: loss=0.259, reward_mean=0.300, reward_bound=0.478, batch=228\n",
      "4298: loss=0.260, reward_mean=0.320, reward_bound=0.317, batch=229\n",
      "4299: loss=0.257, reward_mean=0.300, reward_bound=0.349, batch=229\n",
      "4300: loss=0.259, reward_mean=0.380, reward_bound=0.430, batch=229\n",
      "4301: loss=0.261, reward_mean=0.360, reward_bound=0.405, batch=230\n",
      "4302: loss=0.260, reward_mean=0.400, reward_bound=0.395, batch=231\n",
      "4303: loss=0.257, reward_mean=0.430, reward_bound=0.430, batch=231\n",
      "4304: loss=0.260, reward_mean=0.320, reward_bound=0.478, batch=231\n",
      "4305: loss=0.260, reward_mean=0.340, reward_bound=0.430, batch=231\n",
      "4307: loss=0.192, reward_mean=0.380, reward_bound=0.000, batch=38\n",
      "4308: loss=0.219, reward_mean=0.400, reward_bound=0.000, batch=78\n",
      "4309: loss=0.225, reward_mean=0.360, reward_bound=0.000, batch=114\n",
      "4310: loss=0.224, reward_mean=0.450, reward_bound=0.003, batch=150\n",
      "4311: loss=0.221, reward_mean=0.270, reward_bound=0.002, batch=175\n",
      "4312: loss=0.225, reward_mean=0.380, reward_bound=0.009, batch=190\n",
      "4313: loss=0.230, reward_mean=0.440, reward_bound=0.025, batch=201\n",
      "4314: loss=0.237, reward_mean=0.430, reward_bound=0.047, batch=204\n",
      "4315: loss=0.233, reward_mean=0.330, reward_bound=0.058, batch=208\n",
      "4316: loss=0.231, reward_mean=0.360, reward_bound=0.072, batch=210\n",
      "4317: loss=0.227, reward_mean=0.380, reward_bound=0.089, batch=207\n",
      "4318: loss=0.222, reward_mean=0.340, reward_bound=0.098, batch=207\n",
      "4319: loss=0.219, reward_mean=0.340, reward_bound=0.109, batch=225\n",
      "4320: loss=0.218, reward_mean=0.390, reward_bound=0.109, batch=239\n",
      "4321: loss=0.216, reward_mean=0.410, reward_bound=0.122, batch=225\n",
      "4322: loss=0.213, reward_mean=0.330, reward_bound=0.135, batch=215\n",
      "4323: loss=0.225, reward_mean=0.380, reward_bound=0.150, batch=208\n",
      "4324: loss=0.227, reward_mean=0.380, reward_bound=0.167, batch=201\n",
      "4325: loss=0.223, reward_mean=0.320, reward_bound=0.185, batch=191\n",
      "4326: loss=0.223, reward_mean=0.300, reward_bound=0.098, batch=201\n",
      "4327: loss=0.229, reward_mean=0.360, reward_bound=0.206, batch=182\n",
      "4328: loss=0.228, reward_mean=0.410, reward_bound=0.150, batch=196\n",
      "4329: loss=0.226, reward_mean=0.390, reward_bound=0.185, batch=202\n",
      "4330: loss=0.226, reward_mean=0.350, reward_bound=0.185, batch=210\n",
      "4331: loss=0.223, reward_mean=0.420, reward_bound=0.229, batch=191\n",
      "4332: loss=0.226, reward_mean=0.370, reward_bound=0.229, batch=202\n",
      "4333: loss=0.226, reward_mean=0.370, reward_bound=0.213, batch=211\n",
      "4334: loss=0.223, reward_mean=0.340, reward_bound=0.229, batch=217\n",
      "4335: loss=0.228, reward_mean=0.420, reward_bound=0.254, batch=192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4336: loss=0.223, reward_mean=0.440, reward_bound=0.263, batch=204\n",
      "4337: loss=0.219, reward_mean=0.440, reward_bound=0.249, batch=213\n",
      "4338: loss=0.220, reward_mean=0.360, reward_bound=0.254, batch=217\n",
      "4339: loss=0.220, reward_mean=0.470, reward_bound=0.245, batch=222\n",
      "4340: loss=0.222, reward_mean=0.350, reward_bound=0.282, batch=187\n",
      "4341: loss=0.220, reward_mean=0.350, reward_bound=0.167, batch=200\n",
      "4342: loss=0.224, reward_mean=0.340, reward_bound=0.185, batch=207\n",
      "4343: loss=0.219, reward_mean=0.420, reward_bound=0.254, batch=212\n",
      "4344: loss=0.221, reward_mean=0.360, reward_bound=0.206, batch=219\n",
      "4345: loss=0.223, reward_mean=0.320, reward_bound=0.239, batch=223\n",
      "4346: loss=0.222, reward_mean=0.420, reward_bound=0.282, batch=219\n",
      "4347: loss=0.236, reward_mean=0.440, reward_bound=0.314, batch=180\n",
      "4348: loss=0.230, reward_mean=0.310, reward_bound=0.075, batch=196\n",
      "4349: loss=0.220, reward_mean=0.480, reward_bound=0.158, batch=207\n",
      "4350: loss=0.226, reward_mean=0.450, reward_bound=0.206, batch=211\n",
      "4351: loss=0.225, reward_mean=0.350, reward_bound=0.185, batch=217\n",
      "4352: loss=0.221, reward_mean=0.400, reward_bound=0.229, batch=220\n",
      "4353: loss=0.226, reward_mean=0.390, reward_bound=0.254, batch=221\n",
      "4354: loss=0.224, reward_mean=0.370, reward_bound=0.282, batch=217\n",
      "4355: loss=0.223, reward_mean=0.310, reward_bound=0.282, batch=221\n",
      "4356: loss=0.227, reward_mean=0.340, reward_bound=0.314, batch=219\n",
      "4357: loss=0.237, reward_mean=0.360, reward_bound=0.349, batch=158\n",
      "4358: loss=0.216, reward_mean=0.390, reward_bound=0.091, batch=180\n",
      "4359: loss=0.215, reward_mean=0.330, reward_bound=0.080, batch=195\n",
      "4360: loss=0.222, reward_mean=0.380, reward_bound=0.112, batch=206\n",
      "4361: loss=0.226, reward_mean=0.360, reward_bound=0.122, batch=213\n",
      "4362: loss=0.226, reward_mean=0.420, reward_bound=0.150, batch=218\n",
      "4363: loss=0.228, reward_mean=0.310, reward_bound=0.185, batch=216\n",
      "4364: loss=0.230, reward_mean=0.380, reward_bound=0.206, batch=220\n",
      "4365: loss=0.231, reward_mean=0.350, reward_bound=0.229, batch=223\n",
      "4366: loss=0.229, reward_mean=0.310, reward_bound=0.254, batch=209\n",
      "4367: loss=0.226, reward_mean=0.390, reward_bound=0.250, batch=216\n",
      "4368: loss=0.226, reward_mean=0.330, reward_bound=0.282, batch=209\n",
      "4369: loss=0.228, reward_mean=0.380, reward_bound=0.314, batch=204\n",
      "4370: loss=0.227, reward_mean=0.410, reward_bound=0.229, batch=211\n",
      "4371: loss=0.227, reward_mean=0.390, reward_bound=0.206, batch=216\n",
      "4372: loss=0.226, reward_mean=0.370, reward_bound=0.254, batch=215\n",
      "4373: loss=0.223, reward_mean=0.350, reward_bound=0.210, batch=220\n",
      "4374: loss=0.226, reward_mean=0.320, reward_bound=0.274, batch=224\n",
      "4375: loss=0.228, reward_mean=0.280, reward_bound=0.282, batch=225\n",
      "4376: loss=0.230, reward_mean=0.400, reward_bound=0.314, batch=223\n",
      "4377: loss=0.230, reward_mean=0.320, reward_bound=0.335, batch=226\n",
      "4378: loss=0.230, reward_mean=0.380, reward_bound=0.314, batch=227\n",
      "4379: loss=0.234, reward_mean=0.330, reward_bound=0.349, batch=210\n",
      "4380: loss=0.233, reward_mean=0.430, reward_bound=0.304, batch=217\n",
      "4381: loss=0.229, reward_mean=0.460, reward_bound=0.314, batch=221\n",
      "4382: loss=0.231, reward_mean=0.430, reward_bound=0.349, batch=224\n",
      "4383: loss=0.228, reward_mean=0.300, reward_bound=0.167, batch=226\n",
      "4384: loss=0.230, reward_mean=0.300, reward_bound=0.196, batch=228\n",
      "4385: loss=0.228, reward_mean=0.380, reward_bound=0.289, batch=229\n",
      "4386: loss=0.231, reward_mean=0.350, reward_bound=0.364, batch=230\n",
      "4387: loss=0.236, reward_mean=0.380, reward_bound=0.387, batch=151\n",
      "4388: loss=0.219, reward_mean=0.330, reward_bound=0.028, batch=174\n",
      "4389: loss=0.229, reward_mean=0.370, reward_bound=0.064, batch=192\n",
      "4390: loss=0.216, reward_mean=0.430, reward_bound=0.089, batch=203\n",
      "4391: loss=0.218, reward_mean=0.360, reward_bound=0.122, batch=207\n",
      "4392: loss=0.219, reward_mean=0.330, reward_bound=0.135, batch=214\n",
      "4393: loss=0.220, reward_mean=0.380, reward_bound=0.167, batch=211\n",
      "4394: loss=0.224, reward_mean=0.320, reward_bound=0.185, batch=213\n",
      "4395: loss=0.227, reward_mean=0.500, reward_bound=0.206, batch=218\n",
      "4396: loss=0.221, reward_mean=0.380, reward_bound=0.229, batch=210\n",
      "4397: loss=0.225, reward_mean=0.420, reward_bound=0.254, batch=210\n",
      "4398: loss=0.228, reward_mean=0.410, reward_bound=0.254, batch=216\n",
      "4399: loss=0.235, reward_mean=0.450, reward_bound=0.282, batch=214\n",
      "4400: loss=0.231, reward_mean=0.390, reward_bound=0.165, batch=220\n",
      "4401: loss=0.231, reward_mean=0.350, reward_bound=0.247, batch=224\n",
      "4402: loss=0.235, reward_mean=0.360, reward_bound=0.314, batch=210\n",
      "4403: loss=0.238, reward_mean=0.290, reward_bound=0.206, batch=218\n",
      "4404: loss=0.235, reward_mean=0.380, reward_bound=0.206, batch=221\n",
      "4405: loss=0.235, reward_mean=0.410, reward_bound=0.254, batch=223\n",
      "4406: loss=0.234, reward_mean=0.290, reward_bound=0.254, batch=225\n",
      "4407: loss=0.236, reward_mean=0.390, reward_bound=0.282, batch=223\n",
      "4408: loss=0.237, reward_mean=0.350, reward_bound=0.314, batch=225\n",
      "4409: loss=0.231, reward_mean=0.430, reward_bound=0.349, batch=201\n",
      "4410: loss=0.226, reward_mean=0.340, reward_bound=0.167, batch=209\n",
      "4411: loss=0.230, reward_mean=0.380, reward_bound=0.239, batch=216\n",
      "4412: loss=0.232, reward_mean=0.400, reward_bound=0.282, batch=218\n",
      "4413: loss=0.232, reward_mean=0.340, reward_bound=0.314, batch=219\n",
      "4414: loss=0.233, reward_mean=0.390, reward_bound=0.349, batch=218\n",
      "4415: loss=0.235, reward_mean=0.440, reward_bound=0.317, batch=222\n",
      "4416: loss=0.233, reward_mean=0.330, reward_bound=0.292, batch=225\n",
      "4417: loss=0.231, reward_mean=0.410, reward_bound=0.321, batch=227\n",
      "4418: loss=0.228, reward_mean=0.420, reward_bound=0.380, batch=229\n",
      "4419: loss=0.233, reward_mean=0.350, reward_bound=0.387, batch=210\n",
      "4420: loss=0.233, reward_mean=0.350, reward_bound=0.240, batch=217\n",
      "4421: loss=0.231, reward_mean=0.410, reward_bound=0.254, batch=219\n",
      "4422: loss=0.233, reward_mean=0.360, reward_bound=0.349, batch=220\n",
      "4423: loss=0.233, reward_mean=0.360, reward_bound=0.222, batch=224\n",
      "4424: loss=0.231, reward_mean=0.310, reward_bound=0.282, batch=225\n",
      "4425: loss=0.230, reward_mean=0.360, reward_bound=0.356, batch=227\n",
      "4426: loss=0.230, reward_mean=0.350, reward_bound=0.387, batch=225\n",
      "4427: loss=0.221, reward_mean=0.360, reward_bound=0.430, batch=131\n",
      "4428: loss=0.216, reward_mean=0.380, reward_bound=0.006, batch=161\n",
      "4429: loss=0.219, reward_mean=0.460, reward_bound=0.042, batch=182\n",
      "4430: loss=0.213, reward_mean=0.310, reward_bound=0.054, batch=197\n",
      "4431: loss=0.221, reward_mean=0.290, reward_bound=0.080, batch=206\n",
      "4432: loss=0.216, reward_mean=0.380, reward_bound=0.109, batch=211\n",
      "4433: loss=0.210, reward_mean=0.460, reward_bound=0.135, batch=213\n",
      "4434: loss=0.214, reward_mean=0.320, reward_bound=0.150, batch=216\n",
      "4435: loss=0.214, reward_mean=0.410, reward_bound=0.185, batch=211\n",
      "4436: loss=0.213, reward_mean=0.400, reward_bound=0.206, batch=212\n",
      "4437: loss=0.213, reward_mean=0.330, reward_bound=0.229, batch=213\n",
      "4438: loss=0.210, reward_mean=0.290, reward_bound=0.185, batch=218\n",
      "4439: loss=0.211, reward_mean=0.420, reward_bound=0.254, batch=204\n",
      "4440: loss=0.215, reward_mean=0.370, reward_bound=0.254, batch=212\n",
      "4441: loss=0.214, reward_mean=0.370, reward_bound=0.282, batch=199\n",
      "4442: loss=0.219, reward_mean=0.330, reward_bound=0.239, batch=209\n",
      "4443: loss=0.218, reward_mean=0.420, reward_bound=0.265, batch=216\n",
      "4444: loss=0.220, reward_mean=0.300, reward_bound=0.298, batch=221\n",
      "4445: loss=0.223, reward_mean=0.400, reward_bound=0.314, batch=208\n",
      "4446: loss=0.237, reward_mean=0.370, reward_bound=0.349, batch=192\n",
      "4447: loss=0.231, reward_mean=0.410, reward_bound=0.185, batch=203\n",
      "4448: loss=0.230, reward_mean=0.420, reward_bound=0.220, batch=212\n",
      "4449: loss=0.229, reward_mean=0.400, reward_bound=0.229, batch=209\n",
      "4450: loss=0.232, reward_mean=0.450, reward_bound=0.254, batch=215\n",
      "4451: loss=0.232, reward_mean=0.440, reward_bound=0.282, batch=218\n",
      "4452: loss=0.232, reward_mean=0.350, reward_bound=0.208, batch=222\n",
      "4453: loss=0.232, reward_mean=0.420, reward_bound=0.314, batch=219\n",
      "4454: loss=0.235, reward_mean=0.390, reward_bound=0.282, batch=222\n",
      "4455: loss=0.235, reward_mean=0.350, reward_bound=0.292, batch=225\n",
      "4456: loss=0.234, reward_mean=0.430, reward_bound=0.321, batch=227\n",
      "4457: loss=0.235, reward_mean=0.310, reward_bound=0.349, batch=219\n",
      "4458: loss=0.235, reward_mean=0.370, reward_bound=0.387, batch=186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4459: loss=0.238, reward_mean=0.370, reward_bound=0.176, batch=200\n",
      "4460: loss=0.235, reward_mean=0.400, reward_bound=0.247, batch=210\n",
      "4461: loss=0.235, reward_mean=0.390, reward_bound=0.254, batch=213\n",
      "4462: loss=0.237, reward_mean=0.370, reward_bound=0.282, batch=213\n",
      "4463: loss=0.236, reward_mean=0.330, reward_bound=0.198, batch=219\n",
      "4464: loss=0.236, reward_mean=0.430, reward_bound=0.254, batch=222\n",
      "4465: loss=0.238, reward_mean=0.350, reward_bound=0.282, batch=224\n",
      "4466: loss=0.238, reward_mean=0.290, reward_bound=0.229, batch=226\n",
      "4467: loss=0.234, reward_mean=0.390, reward_bound=0.314, batch=221\n",
      "4468: loss=0.230, reward_mean=0.450, reward_bound=0.349, batch=212\n",
      "4469: loss=0.229, reward_mean=0.450, reward_bound=0.236, batch=218\n",
      "4470: loss=0.226, reward_mean=0.320, reward_bound=0.254, batch=220\n",
      "4471: loss=0.222, reward_mean=0.280, reward_bound=0.304, batch=224\n",
      "4472: loss=0.225, reward_mean=0.350, reward_bound=0.349, batch=222\n",
      "4473: loss=0.228, reward_mean=0.400, reward_bound=0.360, batch=225\n",
      "4474: loss=0.225, reward_mean=0.410, reward_bound=0.387, batch=217\n",
      "4475: loss=0.225, reward_mean=0.410, reward_bound=0.380, batch=222\n",
      "4476: loss=0.227, reward_mean=0.340, reward_bound=0.292, batch=225\n",
      "4477: loss=0.224, reward_mean=0.410, reward_bound=0.387, batch=224\n",
      "4478: loss=0.225, reward_mean=0.370, reward_bound=0.345, batch=227\n",
      "4479: loss=0.223, reward_mean=0.370, reward_bound=0.349, batch=228\n",
      "4480: loss=0.224, reward_mean=0.390, reward_bound=0.387, batch=227\n",
      "4481: loss=0.224, reward_mean=0.360, reward_bound=0.349, batch=228\n",
      "4482: loss=0.220, reward_mean=0.330, reward_bound=0.430, batch=189\n",
      "4483: loss=0.226, reward_mean=0.410, reward_bound=0.174, batch=202\n",
      "4484: loss=0.228, reward_mean=0.410, reward_bound=0.155, batch=211\n",
      "4485: loss=0.226, reward_mean=0.320, reward_bound=0.185, batch=216\n",
      "4486: loss=0.220, reward_mean=0.400, reward_bound=0.229, batch=220\n",
      "4487: loss=0.220, reward_mean=0.370, reward_bound=0.254, batch=222\n",
      "4488: loss=0.221, reward_mean=0.440, reward_bound=0.282, batch=219\n",
      "4489: loss=0.219, reward_mean=0.370, reward_bound=0.314, batch=221\n",
      "4490: loss=0.219, reward_mean=0.380, reward_bound=0.314, batch=224\n",
      "4491: loss=0.219, reward_mean=0.300, reward_bound=0.314, batch=226\n",
      "4492: loss=0.218, reward_mean=0.400, reward_bound=0.349, batch=221\n",
      "4493: loss=0.220, reward_mean=0.410, reward_bound=0.314, batch=224\n",
      "4494: loss=0.222, reward_mean=0.420, reward_bound=0.311, batch=227\n",
      "4495: loss=0.221, reward_mean=0.410, reward_bound=0.349, batch=227\n",
      "4496: loss=0.220, reward_mean=0.430, reward_bound=0.349, batch=228\n",
      "4497: loss=0.220, reward_mean=0.340, reward_bound=0.353, batch=229\n",
      "4498: loss=0.222, reward_mean=0.400, reward_bound=0.387, batch=214\n",
      "4499: loss=0.219, reward_mean=0.410, reward_bound=0.314, batch=218\n",
      "4500: loss=0.217, reward_mean=0.420, reward_bound=0.317, batch=222\n",
      "4501: loss=0.217, reward_mean=0.410, reward_bound=0.349, batch=224\n",
      "4502: loss=0.217, reward_mean=0.420, reward_bound=0.349, batch=226\n",
      "4503: loss=0.223, reward_mean=0.430, reward_bound=0.387, batch=225\n",
      "4504: loss=0.217, reward_mean=0.430, reward_bound=0.430, batch=209\n",
      "4505: loss=0.217, reward_mean=0.420, reward_bound=0.282, batch=215\n",
      "4506: loss=0.215, reward_mean=0.360, reward_bound=0.321, batch=220\n",
      "4507: loss=0.214, reward_mean=0.420, reward_bound=0.320, batch=224\n",
      "4508: loss=0.217, reward_mean=0.350, reward_bound=0.342, batch=227\n",
      "4509: loss=0.220, reward_mean=0.370, reward_bound=0.349, batch=224\n",
      "4510: loss=0.222, reward_mean=0.500, reward_bound=0.349, batch=226\n",
      "4511: loss=0.221, reward_mean=0.400, reward_bound=0.387, batch=224\n",
      "4512: loss=0.221, reward_mean=0.410, reward_bound=0.349, batch=226\n",
      "4513: loss=0.220, reward_mean=0.420, reward_bound=0.430, batch=218\n",
      "4514: loss=0.218, reward_mean=0.340, reward_bound=0.234, batch=222\n",
      "4515: loss=0.221, reward_mean=0.440, reward_bound=0.314, batch=224\n",
      "4516: loss=0.223, reward_mean=0.410, reward_bound=0.384, batch=227\n",
      "4517: loss=0.222, reward_mean=0.410, reward_bound=0.366, batch=229\n",
      "4518: loss=0.221, reward_mean=0.460, reward_bound=0.387, batch=225\n",
      "4519: loss=0.221, reward_mean=0.400, reward_bound=0.387, batch=226\n",
      "4520: loss=0.222, reward_mean=0.430, reward_bound=0.430, batch=226\n",
      "4521: loss=0.223, reward_mean=0.340, reward_bound=0.454, batch=228\n",
      "4522: loss=0.222, reward_mean=0.440, reward_bound=0.478, batch=231\n",
      "4523: loss=0.225, reward_mean=0.380, reward_bound=0.478, batch=81\n",
      "4524: loss=0.218, reward_mean=0.380, reward_bound=0.000, batch=119\n",
      "4525: loss=0.199, reward_mean=0.290, reward_bound=0.000, batch=148\n",
      "4526: loss=0.207, reward_mean=0.340, reward_bound=0.001, batch=173\n",
      "4527: loss=0.209, reward_mean=0.270, reward_bound=0.008, batch=191\n",
      "4528: loss=0.216, reward_mean=0.380, reward_bound=0.031, batch=202\n",
      "4529: loss=0.208, reward_mean=0.410, reward_bound=0.065, batch=205\n",
      "4530: loss=0.213, reward_mean=0.450, reward_bound=0.098, batch=210\n",
      "4531: loss=0.209, reward_mean=0.500, reward_bound=0.122, batch=213\n",
      "4532: loss=0.214, reward_mean=0.310, reward_bound=0.135, batch=213\n",
      "4533: loss=0.224, reward_mean=0.390, reward_bound=0.150, batch=210\n",
      "4534: loss=0.221, reward_mean=0.370, reward_bound=0.167, batch=214\n",
      "4535: loss=0.214, reward_mean=0.480, reward_bound=0.185, batch=211\n",
      "4536: loss=0.208, reward_mean=0.340, reward_bound=0.206, batch=195\n",
      "4537: loss=0.208, reward_mean=0.350, reward_bound=0.141, batch=206\n",
      "4538: loss=0.205, reward_mean=0.290, reward_bound=0.167, batch=213\n",
      "4539: loss=0.206, reward_mean=0.420, reward_bound=0.206, batch=216\n",
      "4540: loss=0.211, reward_mean=0.350, reward_bound=0.229, batch=199\n",
      "4541: loss=0.210, reward_mean=0.430, reward_bound=0.167, batch=208\n",
      "4542: loss=0.207, reward_mean=0.440, reward_bound=0.206, batch=214\n",
      "4543: loss=0.209, reward_mean=0.350, reward_bound=0.229, batch=219\n",
      "4544: loss=0.201, reward_mean=0.410, reward_bound=0.254, batch=201\n",
      "4545: loss=0.199, reward_mean=0.360, reward_bound=0.254, batch=210\n",
      "4546: loss=0.193, reward_mean=0.340, reward_bound=0.282, batch=196\n",
      "4547: loss=0.197, reward_mean=0.400, reward_bound=0.284, batch=207\n",
      "4548: loss=0.195, reward_mean=0.440, reward_bound=0.314, batch=182\n",
      "4549: loss=0.195, reward_mean=0.390, reward_bound=0.172, batch=197\n",
      "4550: loss=0.188, reward_mean=0.400, reward_bound=0.147, batch=208\n",
      "4551: loss=0.190, reward_mean=0.480, reward_bound=0.206, batch=213\n",
      "4552: loss=0.196, reward_mean=0.400, reward_bound=0.185, batch=218\n",
      "4553: loss=0.195, reward_mean=0.380, reward_bound=0.231, batch=222\n",
      "4554: loss=0.189, reward_mean=0.390, reward_bound=0.254, batch=221\n",
      "4555: loss=0.189, reward_mean=0.290, reward_bound=0.282, batch=216\n",
      "4556: loss=0.187, reward_mean=0.450, reward_bound=0.314, batch=213\n",
      "4557: loss=0.189, reward_mean=0.470, reward_bound=0.335, batch=219\n",
      "4558: loss=0.198, reward_mean=0.370, reward_bound=0.349, batch=180\n",
      "4559: loss=0.186, reward_mean=0.380, reward_bound=0.167, batch=194\n",
      "4560: loss=0.184, reward_mean=0.450, reward_bound=0.204, batch=206\n",
      "4561: loss=0.182, reward_mean=0.440, reward_bound=0.241, batch=214\n",
      "4562: loss=0.183, reward_mean=0.480, reward_bound=0.254, batch=218\n",
      "4563: loss=0.188, reward_mean=0.350, reward_bound=0.234, batch=222\n",
      "4564: loss=0.190, reward_mean=0.440, reward_bound=0.282, batch=220\n",
      "4565: loss=0.196, reward_mean=0.350, reward_bound=0.229, batch=223\n",
      "4566: loss=0.195, reward_mean=0.430, reward_bound=0.271, batch=226\n",
      "4567: loss=0.194, reward_mean=0.360, reward_bound=0.314, batch=214\n",
      "4568: loss=0.193, reward_mean=0.420, reward_bound=0.226, batch=220\n",
      "4569: loss=0.195, reward_mean=0.370, reward_bound=0.247, batch=224\n",
      "4570: loss=0.196, reward_mean=0.330, reward_bound=0.282, batch=226\n",
      "4571: loss=0.192, reward_mean=0.360, reward_bound=0.349, batch=216\n",
      "4572: loss=0.208, reward_mean=0.460, reward_bound=0.387, batch=169\n",
      "4573: loss=0.212, reward_mean=0.470, reward_bound=0.141, batch=188\n",
      "4574: loss=0.212, reward_mean=0.360, reward_bound=0.137, batch=201\n",
      "4575: loss=0.208, reward_mean=0.400, reward_bound=0.167, batch=208\n",
      "4576: loss=0.208, reward_mean=0.340, reward_bound=0.206, batch=211\n",
      "4577: loss=0.212, reward_mean=0.470, reward_bound=0.229, batch=209\n",
      "4578: loss=0.209, reward_mean=0.440, reward_bound=0.225, batch=216\n",
      "4579: loss=0.210, reward_mean=0.300, reward_bound=0.254, batch=217\n",
      "4580: loss=0.213, reward_mean=0.430, reward_bound=0.282, batch=218\n",
      "4581: loss=0.208, reward_mean=0.510, reward_bound=0.314, batch=219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4582: loss=0.202, reward_mean=0.360, reward_bound=0.349, batch=213\n",
      "4583: loss=0.206, reward_mean=0.340, reward_bound=0.335, batch=219\n",
      "4584: loss=0.207, reward_mean=0.360, reward_bound=0.282, batch=222\n",
      "4585: loss=0.206, reward_mean=0.390, reward_bound=0.292, batch=225\n",
      "4586: loss=0.204, reward_mean=0.320, reward_bound=0.321, batch=227\n",
      "4587: loss=0.202, reward_mean=0.380, reward_bound=0.349, batch=228\n",
      "4588: loss=0.209, reward_mean=0.350, reward_bound=0.387, batch=210\n",
      "4589: loss=0.211, reward_mean=0.340, reward_bound=0.167, batch=216\n",
      "4590: loss=0.210, reward_mean=0.320, reward_bound=0.254, batch=218\n",
      "4591: loss=0.210, reward_mean=0.350, reward_bound=0.286, batch=222\n",
      "4592: loss=0.214, reward_mean=0.510, reward_bound=0.314, batch=224\n",
      "4593: loss=0.213, reward_mean=0.380, reward_bound=0.349, batch=224\n",
      "4594: loss=0.212, reward_mean=0.380, reward_bound=0.345, batch=227\n",
      "4595: loss=0.212, reward_mean=0.380, reward_bound=0.277, batch=229\n",
      "4596: loss=0.209, reward_mean=0.450, reward_bound=0.295, batch=230\n",
      "4597: loss=0.209, reward_mean=0.460, reward_bound=0.338, batch=231\n",
      "4598: loss=0.208, reward_mean=0.360, reward_bound=0.387, batch=225\n",
      "4599: loss=0.208, reward_mean=0.510, reward_bound=0.349, batch=226\n",
      "4600: loss=0.209, reward_mean=0.370, reward_bound=0.409, batch=228\n",
      "4601: loss=0.211, reward_mean=0.350, reward_bound=0.392, batch=229\n",
      "4602: loss=0.225, reward_mean=0.290, reward_bound=0.430, batch=144\n",
      "4603: loss=0.213, reward_mean=0.440, reward_bound=0.034, batch=171\n",
      "4604: loss=0.213, reward_mean=0.340, reward_bound=0.065, batch=189\n",
      "4605: loss=0.215, reward_mean=0.460, reward_bound=0.122, batch=197\n",
      "4606: loss=0.221, reward_mean=0.310, reward_bound=0.132, batch=208\n",
      "4607: loss=0.234, reward_mean=0.460, reward_bound=0.150, batch=214\n",
      "4608: loss=0.230, reward_mean=0.470, reward_bound=0.185, batch=214\n",
      "4609: loss=0.224, reward_mean=0.330, reward_bound=0.206, batch=213\n",
      "4610: loss=0.220, reward_mean=0.380, reward_bound=0.229, batch=214\n",
      "4611: loss=0.218, reward_mean=0.410, reward_bound=0.254, batch=210\n",
      "4612: loss=0.216, reward_mean=0.350, reward_bound=0.274, batch=217\n",
      "4613: loss=0.219, reward_mean=0.380, reward_bound=0.254, batch=220\n",
      "4614: loss=0.218, reward_mean=0.420, reward_bound=0.229, batch=223\n",
      "4615: loss=0.217, reward_mean=0.360, reward_bound=0.282, batch=212\n",
      "4616: loss=0.215, reward_mean=0.390, reward_bound=0.263, batch=218\n",
      "4617: loss=0.212, reward_mean=0.340, reward_bound=0.257, batch=222\n",
      "4618: loss=0.214, reward_mean=0.400, reward_bound=0.282, batch=224\n",
      "4619: loss=0.223, reward_mean=0.410, reward_bound=0.314, batch=213\n",
      "4620: loss=0.224, reward_mean=0.390, reward_bound=0.244, batch=219\n",
      "4621: loss=0.223, reward_mean=0.380, reward_bound=0.349, batch=203\n",
      "4622: loss=0.221, reward_mean=0.340, reward_bound=0.244, batch=212\n",
      "4623: loss=0.219, reward_mean=0.360, reward_bound=0.282, batch=213\n",
      "4624: loss=0.224, reward_mean=0.480, reward_bound=0.301, batch=219\n",
      "4625: loss=0.218, reward_mean=0.310, reward_bound=0.314, batch=220\n",
      "4626: loss=0.221, reward_mean=0.500, reward_bound=0.349, batch=217\n",
      "4627: loss=0.223, reward_mean=0.460, reward_bound=0.342, batch=222\n",
      "4628: loss=0.224, reward_mean=0.390, reward_bound=0.263, batch=225\n",
      "4629: loss=0.222, reward_mean=0.400, reward_bound=0.314, batch=226\n",
      "4630: loss=0.220, reward_mean=0.370, reward_bound=0.349, batch=223\n",
      "4631: loss=0.220, reward_mean=0.390, reward_bound=0.335, batch=226\n",
      "4632: loss=0.220, reward_mean=0.420, reward_bound=0.349, batch=226\n",
      "4633: loss=0.224, reward_mean=0.380, reward_bound=0.387, batch=203\n",
      "4634: loss=0.221, reward_mean=0.410, reward_bound=0.185, batch=210\n",
      "4635: loss=0.221, reward_mean=0.400, reward_bound=0.254, batch=215\n",
      "4636: loss=0.223, reward_mean=0.410, reward_bound=0.314, batch=219\n",
      "4637: loss=0.219, reward_mean=0.440, reward_bound=0.314, batch=222\n",
      "4638: loss=0.220, reward_mean=0.380, reward_bound=0.349, batch=216\n",
      "4639: loss=0.217, reward_mean=0.440, reward_bound=0.284, batch=221\n",
      "4640: loss=0.219, reward_mean=0.390, reward_bound=0.314, batch=221\n",
      "4641: loss=0.218, reward_mean=0.390, reward_bound=0.282, batch=223\n",
      "4642: loss=0.222, reward_mean=0.380, reward_bound=0.301, batch=226\n",
      "4643: loss=0.219, reward_mean=0.440, reward_bound=0.314, batch=225\n",
      "4644: loss=0.222, reward_mean=0.320, reward_bound=0.349, batch=223\n",
      "4645: loss=0.222, reward_mean=0.380, reward_bound=0.322, batch=226\n",
      "4646: loss=0.222, reward_mean=0.430, reward_bound=0.387, batch=219\n",
      "4647: loss=0.220, reward_mean=0.520, reward_bound=0.405, batch=223\n",
      "4648: loss=0.219, reward_mean=0.370, reward_bound=0.413, batch=226\n",
      "4649: loss=0.221, reward_mean=0.540, reward_bound=0.409, batch=228\n",
      "4650: loss=0.220, reward_mean=0.490, reward_bound=0.392, batch=229\n",
      "4651: loss=0.219, reward_mean=0.370, reward_bound=0.405, batch=230\n",
      "4652: loss=0.219, reward_mean=0.300, reward_bound=0.430, batch=187\n",
      "4653: loss=0.215, reward_mean=0.430, reward_bound=0.163, batch=201\n",
      "4654: loss=0.215, reward_mean=0.370, reward_bound=0.229, batch=207\n",
      "4655: loss=0.220, reward_mean=0.410, reward_bound=0.150, batch=214\n",
      "4656: loss=0.216, reward_mean=0.400, reward_bound=0.254, batch=215\n",
      "4657: loss=0.213, reward_mean=0.380, reward_bound=0.254, batch=219\n",
      "4658: loss=0.212, reward_mean=0.380, reward_bound=0.282, batch=218\n",
      "4659: loss=0.213, reward_mean=0.380, reward_bound=0.286, batch=222\n",
      "4660: loss=0.212, reward_mean=0.340, reward_bound=0.292, batch=225\n",
      "4661: loss=0.214, reward_mean=0.330, reward_bound=0.314, batch=218\n",
      "4662: loss=0.215, reward_mean=0.470, reward_bound=0.349, batch=217\n",
      "4663: loss=0.219, reward_mean=0.400, reward_bound=0.387, batch=208\n",
      "4664: loss=0.216, reward_mean=0.450, reward_bound=0.257, batch=215\n",
      "4665: loss=0.218, reward_mean=0.320, reward_bound=0.194, batch=220\n",
      "4666: loss=0.217, reward_mean=0.390, reward_bound=0.282, batch=221\n",
      "4667: loss=0.220, reward_mean=0.410, reward_bound=0.314, batch=219\n",
      "4668: loss=0.218, reward_mean=0.360, reward_bound=0.265, batch=223\n",
      "4669: loss=0.222, reward_mean=0.460, reward_bound=0.314, batch=224\n",
      "4670: loss=0.219, reward_mean=0.380, reward_bound=0.349, batch=224\n",
      "4671: loss=0.219, reward_mean=0.400, reward_bound=0.311, batch=227\n",
      "4672: loss=0.219, reward_mean=0.450, reward_bound=0.349, batch=228\n",
      "4673: loss=0.219, reward_mean=0.370, reward_bound=0.387, batch=224\n",
      "4674: loss=0.218, reward_mean=0.420, reward_bound=0.349, batch=226\n",
      "4675: loss=0.217, reward_mean=0.360, reward_bound=0.368, batch=228\n",
      "4676: loss=0.218, reward_mean=0.460, reward_bound=0.392, batch=229\n",
      "4677: loss=0.215, reward_mean=0.460, reward_bound=0.430, batch=211\n",
      "4678: loss=0.214, reward_mean=0.360, reward_bound=0.229, batch=217\n",
      "4679: loss=0.220, reward_mean=0.410, reward_bound=0.282, batch=221\n",
      "4680: loss=0.222, reward_mean=0.420, reward_bound=0.349, batch=220\n",
      "4681: loss=0.216, reward_mean=0.390, reward_bound=0.387, batch=215\n",
      "4682: loss=0.214, reward_mean=0.410, reward_bound=0.254, batch=219\n",
      "4683: loss=0.215, reward_mean=0.350, reward_bound=0.349, batch=222\n",
      "4684: loss=0.214, reward_mean=0.460, reward_bound=0.324, batch=225\n",
      "4685: loss=0.215, reward_mean=0.320, reward_bound=0.365, batch=227\n",
      "4686: loss=0.215, reward_mean=0.420, reward_bound=0.349, batch=228\n",
      "4687: loss=0.214, reward_mean=0.440, reward_bound=0.353, batch=229\n",
      "4688: loss=0.213, reward_mean=0.420, reward_bound=0.364, batch=230\n",
      "4689: loss=0.214, reward_mean=0.480, reward_bound=0.387, batch=229\n",
      "4690: loss=0.214, reward_mean=0.470, reward_bound=0.405, batch=230\n",
      "4691: loss=0.214, reward_mean=0.400, reward_bound=0.430, batch=226\n",
      "4692: loss=0.226, reward_mean=0.450, reward_bound=0.478, batch=143\n",
      "4693: loss=0.219, reward_mean=0.320, reward_bound=0.005, batch=169\n",
      "4694: loss=0.221, reward_mean=0.410, reward_bound=0.072, batch=185\n",
      "4695: loss=0.222, reward_mean=0.450, reward_bound=0.101, batch=199\n",
      "4696: loss=0.215, reward_mean=0.360, reward_bound=0.109, batch=207\n",
      "4697: loss=0.208, reward_mean=0.410, reward_bound=0.147, batch=215\n",
      "4698: loss=0.207, reward_mean=0.330, reward_bound=0.150, batch=215\n",
      "4699: loss=0.214, reward_mean=0.490, reward_bound=0.167, batch=215\n",
      "4700: loss=0.215, reward_mean=0.380, reward_bound=0.185, batch=212\n",
      "4701: loss=0.212, reward_mean=0.440, reward_bound=0.206, batch=220\n",
      "4702: loss=0.208, reward_mean=0.400, reward_bound=0.229, batch=217\n",
      "4703: loss=0.210, reward_mean=0.450, reward_bound=0.254, batch=215\n",
      "4704: loss=0.211, reward_mean=0.380, reward_bound=0.234, batch=220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4705: loss=0.208, reward_mean=0.340, reward_bound=0.282, batch=201\n",
      "4706: loss=0.205, reward_mean=0.370, reward_bound=0.229, batch=209\n",
      "4707: loss=0.199, reward_mean=0.330, reward_bound=0.194, batch=216\n",
      "4708: loss=0.201, reward_mean=0.350, reward_bound=0.282, batch=217\n",
      "4709: loss=0.210, reward_mean=0.410, reward_bound=0.314, batch=199\n",
      "4710: loss=0.201, reward_mean=0.420, reward_bound=0.194, batch=209\n",
      "4711: loss=0.207, reward_mean=0.390, reward_bound=0.239, batch=216\n",
      "4712: loss=0.208, reward_mean=0.410, reward_bound=0.268, batch=221\n",
      "4713: loss=0.210, reward_mean=0.410, reward_bound=0.282, batch=222\n",
      "4714: loss=0.209, reward_mean=0.440, reward_bound=0.314, batch=217\n",
      "4715: loss=0.207, reward_mean=0.460, reward_bound=0.349, batch=205\n",
      "4716: loss=0.202, reward_mean=0.470, reward_bound=0.206, batch=212\n",
      "4717: loss=0.205, reward_mean=0.420, reward_bound=0.229, batch=216\n",
      "4718: loss=0.205, reward_mean=0.410, reward_bound=0.282, batch=220\n",
      "4719: loss=0.204, reward_mean=0.410, reward_bound=0.314, batch=223\n",
      "4720: loss=0.205, reward_mean=0.480, reward_bound=0.349, batch=217\n",
      "4721: loss=0.201, reward_mean=0.480, reward_bound=0.349, batch=221\n",
      "4722: loss=0.200, reward_mean=0.360, reward_bound=0.314, batch=224\n",
      "4723: loss=0.200, reward_mean=0.370, reward_bound=0.308, batch=227\n",
      "4724: loss=0.199, reward_mean=0.350, reward_bound=0.342, batch=229\n",
      "4725: loss=0.197, reward_mean=0.340, reward_bound=0.364, batch=230\n",
      "4726: loss=0.207, reward_mean=0.390, reward_bound=0.387, batch=196\n",
      "4727: loss=0.206, reward_mean=0.360, reward_bound=0.176, batch=207\n",
      "4728: loss=0.206, reward_mean=0.370, reward_bound=0.249, batch=215\n",
      "4729: loss=0.205, reward_mean=0.360, reward_bound=0.229, batch=217\n",
      "4730: loss=0.205, reward_mean=0.420, reward_bound=0.254, batch=221\n",
      "4731: loss=0.200, reward_mean=0.430, reward_bound=0.282, batch=221\n",
      "4732: loss=0.203, reward_mean=0.460, reward_bound=0.314, batch=220\n",
      "4733: loss=0.207, reward_mean=0.410, reward_bound=0.349, batch=217\n",
      "4734: loss=0.207, reward_mean=0.370, reward_bound=0.254, batch=221\n",
      "4735: loss=0.204, reward_mean=0.310, reward_bound=0.229, batch=224\n",
      "4736: loss=0.206, reward_mean=0.460, reward_bound=0.280, batch=227\n",
      "4737: loss=0.208, reward_mean=0.420, reward_bound=0.314, batch=228\n",
      "4738: loss=0.205, reward_mean=0.430, reward_bound=0.349, batch=227\n",
      "4739: loss=0.207, reward_mean=0.380, reward_bound=0.387, batch=218\n",
      "4740: loss=0.209, reward_mean=0.430, reward_bound=0.392, batch=222\n",
      "4741: loss=0.209, reward_mean=0.320, reward_bound=0.349, batch=222\n",
      "4742: loss=0.207, reward_mean=0.370, reward_bound=0.360, batch=225\n",
      "4743: loss=0.207, reward_mean=0.360, reward_bound=0.356, batch=227\n",
      "4744: loss=0.208, reward_mean=0.400, reward_bound=0.387, batch=228\n",
      "4745: loss=0.208, reward_mean=0.470, reward_bound=0.392, batch=229\n",
      "4746: loss=0.208, reward_mean=0.370, reward_bound=0.405, batch=230\n",
      "4747: loss=0.207, reward_mean=0.380, reward_bound=0.418, batch=231\n",
      "4748: loss=0.207, reward_mean=0.440, reward_bound=0.387, batch=231\n",
      "4749: loss=0.207, reward_mean=0.400, reward_bound=0.387, batch=231\n",
      "4750: loss=0.207, reward_mean=0.350, reward_bound=0.349, batch=231\n",
      "4751: loss=0.207, reward_mean=0.410, reward_bound=0.314, batch=231\n",
      "4752: loss=0.214, reward_mean=0.340, reward_bound=0.430, batch=191\n",
      "4753: loss=0.215, reward_mean=0.430, reward_bound=0.185, batch=202\n",
      "4754: loss=0.216, reward_mean=0.430, reward_bound=0.191, batch=211\n",
      "4755: loss=0.213, reward_mean=0.370, reward_bound=0.206, batch=213\n",
      "4756: loss=0.207, reward_mean=0.420, reward_bound=0.229, batch=215\n",
      "4757: loss=0.207, reward_mean=0.310, reward_bound=0.254, batch=216\n",
      "4758: loss=0.203, reward_mean=0.380, reward_bound=0.206, batch=220\n",
      "4759: loss=0.208, reward_mean=0.350, reward_bound=0.282, batch=220\n",
      "4760: loss=0.203, reward_mean=0.500, reward_bound=0.314, batch=219\n",
      "4761: loss=0.203, reward_mean=0.410, reward_bound=0.328, batch=223\n",
      "4762: loss=0.202, reward_mean=0.340, reward_bound=0.314, batch=225\n",
      "4763: loss=0.206, reward_mean=0.480, reward_bound=0.349, batch=216\n",
      "4764: loss=0.201, reward_mean=0.400, reward_bound=0.331, batch=221\n",
      "4765: loss=0.201, reward_mean=0.350, reward_bound=0.314, batch=224\n",
      "4766: loss=0.199, reward_mean=0.340, reward_bound=0.282, batch=226\n",
      "4767: loss=0.203, reward_mean=0.370, reward_bound=0.349, batch=222\n",
      "4768: loss=0.205, reward_mean=0.350, reward_bound=0.387, batch=215\n",
      "4769: loss=0.204, reward_mean=0.400, reward_bound=0.189, batch=220\n",
      "4770: loss=0.207, reward_mean=0.450, reward_bound=0.282, batch=223\n",
      "4771: loss=0.207, reward_mean=0.380, reward_bound=0.335, batch=226\n",
      "4772: loss=0.206, reward_mean=0.420, reward_bound=0.349, batch=224\n",
      "4773: loss=0.209, reward_mean=0.470, reward_bound=0.311, batch=227\n",
      "4774: loss=0.205, reward_mean=0.460, reward_bound=0.380, batch=229\n",
      "4775: loss=0.205, reward_mean=0.460, reward_bound=0.364, batch=230\n",
      "4776: loss=0.203, reward_mean=0.410, reward_bound=0.387, batch=229\n",
      "4777: loss=0.209, reward_mean=0.480, reward_bound=0.430, batch=209\n",
      "4778: loss=0.204, reward_mean=0.450, reward_bound=0.265, batch=216\n",
      "4779: loss=0.208, reward_mean=0.410, reward_bound=0.268, batch=221\n",
      "4780: loss=0.207, reward_mean=0.380, reward_bound=0.314, batch=221\n",
      "4781: loss=0.209, reward_mean=0.440, reward_bound=0.254, batch=224\n",
      "4782: loss=0.209, reward_mean=0.430, reward_bound=0.345, batch=227\n",
      "4783: loss=0.209, reward_mean=0.360, reward_bound=0.349, batch=223\n",
      "4784: loss=0.210, reward_mean=0.450, reward_bound=0.372, batch=226\n",
      "4785: loss=0.210, reward_mean=0.330, reward_bound=0.368, batch=228\n",
      "4786: loss=0.208, reward_mean=0.420, reward_bound=0.387, batch=225\n",
      "4787: loss=0.206, reward_mean=0.340, reward_bound=0.234, batch=227\n",
      "4788: loss=0.211, reward_mean=0.440, reward_bound=0.308, batch=229\n",
      "4789: loss=0.208, reward_mean=0.380, reward_bound=0.349, batch=229\n",
      "4790: loss=0.207, reward_mean=0.390, reward_bound=0.364, batch=230\n",
      "4791: loss=0.210, reward_mean=0.360, reward_bound=0.430, batch=216\n",
      "4792: loss=0.213, reward_mean=0.450, reward_bound=0.229, batch=219\n",
      "4793: loss=0.211, reward_mean=0.330, reward_bound=0.250, batch=223\n",
      "4794: loss=0.212, reward_mean=0.410, reward_bound=0.282, batch=225\n",
      "4795: loss=0.212, reward_mean=0.400, reward_bound=0.314, batch=225\n",
      "4796: loss=0.211, reward_mean=0.370, reward_bound=0.260, batch=227\n",
      "4797: loss=0.209, reward_mean=0.450, reward_bound=0.380, batch=229\n",
      "4798: loss=0.208, reward_mean=0.420, reward_bound=0.387, batch=228\n",
      "4799: loss=0.210, reward_mean=0.400, reward_bound=0.430, batch=226\n",
      "4800: loss=0.209, reward_mean=0.420, reward_bound=0.316, batch=228\n",
      "4801: loss=0.210, reward_mean=0.390, reward_bound=0.317, batch=229\n",
      "4802: loss=0.212, reward_mean=0.410, reward_bound=0.405, batch=230\n",
      "4803: loss=0.212, reward_mean=0.350, reward_bound=0.430, batch=230\n",
      "4804: loss=0.219, reward_mean=0.400, reward_bound=0.478, batch=185\n",
      "4805: loss=0.218, reward_mean=0.460, reward_bound=0.206, batch=194\n",
      "4806: loss=0.217, reward_mean=0.460, reward_bound=0.185, batch=205\n",
      "4807: loss=0.217, reward_mean=0.370, reward_bound=0.210, batch=213\n",
      "4808: loss=0.222, reward_mean=0.410, reward_bound=0.160, batch=219\n",
      "4809: loss=0.223, reward_mean=0.390, reward_bound=0.229, batch=222\n",
      "4810: loss=0.222, reward_mean=0.460, reward_bound=0.254, batch=224\n",
      "4811: loss=0.221, reward_mean=0.300, reward_bound=0.282, batch=219\n",
      "4812: loss=0.221, reward_mean=0.350, reward_bound=0.282, batch=222\n",
      "4813: loss=0.219, reward_mean=0.440, reward_bound=0.314, batch=220\n",
      "4814: loss=0.218, reward_mean=0.480, reward_bound=0.338, batch=224\n",
      "4815: loss=0.217, reward_mean=0.420, reward_bound=0.339, batch=227\n",
      "4816: loss=0.217, reward_mean=0.490, reward_bound=0.349, batch=220\n",
      "4817: loss=0.218, reward_mean=0.440, reward_bound=0.376, batch=224\n",
      "4818: loss=0.217, reward_mean=0.370, reward_bound=0.374, batch=227\n",
      "4819: loss=0.216, reward_mean=0.440, reward_bound=0.349, batch=228\n",
      "4820: loss=0.213, reward_mean=0.430, reward_bound=0.387, batch=215\n",
      "4821: loss=0.213, reward_mean=0.370, reward_bound=0.329, batch=220\n",
      "4822: loss=0.212, reward_mean=0.360, reward_bound=0.304, batch=224\n",
      "4823: loss=0.212, reward_mean=0.350, reward_bound=0.204, batch=227\n",
      "4824: loss=0.211, reward_mean=0.310, reward_bound=0.282, batch=228\n",
      "4825: loss=0.214, reward_mean=0.400, reward_bound=0.349, batch=228\n",
      "4826: loss=0.215, reward_mean=0.330, reward_bound=0.387, batch=223\n",
      "4827: loss=0.221, reward_mean=0.420, reward_bound=0.413, batch=226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4828: loss=0.225, reward_mean=0.410, reward_bound=0.430, batch=206\n",
      "4829: loss=0.223, reward_mean=0.380, reward_bound=0.241, batch=214\n",
      "4830: loss=0.221, reward_mean=0.390, reward_bound=0.252, batch=220\n",
      "4831: loss=0.220, reward_mean=0.360, reward_bound=0.185, batch=223\n",
      "4832: loss=0.222, reward_mean=0.380, reward_bound=0.254, batch=223\n",
      "4833: loss=0.225, reward_mean=0.420, reward_bound=0.282, batch=225\n",
      "4834: loss=0.223, reward_mean=0.420, reward_bound=0.314, batch=224\n",
      "4835: loss=0.224, reward_mean=0.370, reward_bound=0.345, batch=227\n",
      "4836: loss=0.224, reward_mean=0.430, reward_bound=0.349, batch=227\n",
      "4837: loss=0.225, reward_mean=0.430, reward_bound=0.292, batch=229\n",
      "4838: loss=0.223, reward_mean=0.320, reward_bound=0.314, batch=229\n",
      "4839: loss=0.222, reward_mean=0.400, reward_bound=0.364, batch=230\n",
      "4840: loss=0.221, reward_mean=0.390, reward_bound=0.387, batch=225\n",
      "4841: loss=0.220, reward_mean=0.380, reward_bound=0.365, batch=227\n",
      "4842: loss=0.219, reward_mean=0.370, reward_bound=0.282, batch=228\n",
      "4843: loss=0.218, reward_mean=0.360, reward_bound=0.392, batch=229\n",
      "4844: loss=0.224, reward_mean=0.330, reward_bound=0.430, batch=221\n",
      "4845: loss=0.223, reward_mean=0.370, reward_bound=0.254, batch=224\n",
      "4846: loss=0.221, reward_mean=0.310, reward_bound=0.384, batch=227\n",
      "4847: loss=0.220, reward_mean=0.380, reward_bound=0.373, batch=229\n",
      "4848: loss=0.222, reward_mean=0.380, reward_bound=0.387, batch=227\n",
      "4849: loss=0.222, reward_mean=0.260, reward_bound=0.314, batch=228\n",
      "4850: loss=0.222, reward_mean=0.360, reward_bound=0.387, batch=228\n",
      "4851: loss=0.221, reward_mean=0.490, reward_bound=0.430, batch=228\n",
      "4852: loss=0.221, reward_mean=0.400, reward_bound=0.387, batch=228\n",
      "4853: loss=0.222, reward_mean=0.390, reward_bound=0.392, batch=229\n",
      "4854: loss=0.219, reward_mean=0.410, reward_bound=0.450, batch=230\n",
      "4855: loss=0.219, reward_mean=0.390, reward_bound=0.464, batch=231\n",
      "4856: loss=0.226, reward_mean=0.350, reward_bound=0.478, batch=201\n",
      "4857: loss=0.223, reward_mean=0.310, reward_bound=0.135, batch=210\n",
      "4858: loss=0.226, reward_mean=0.280, reward_bound=0.167, batch=216\n",
      "4859: loss=0.224, reward_mean=0.370, reward_bound=0.185, batch=216\n",
      "4860: loss=0.224, reward_mean=0.350, reward_bound=0.196, batch=221\n",
      "4861: loss=0.224, reward_mean=0.440, reward_bound=0.254, batch=223\n",
      "4862: loss=0.221, reward_mean=0.390, reward_bound=0.282, batch=220\n",
      "4863: loss=0.222, reward_mean=0.410, reward_bound=0.274, batch=224\n",
      "4864: loss=0.227, reward_mean=0.390, reward_bound=0.314, batch=222\n",
      "4865: loss=0.221, reward_mean=0.450, reward_bound=0.349, batch=220\n",
      "4866: loss=0.220, reward_mean=0.360, reward_bound=0.349, batch=222\n",
      "4867: loss=0.223, reward_mean=0.430, reward_bound=0.324, batch=225\n",
      "4868: loss=0.219, reward_mean=0.500, reward_bound=0.356, batch=227\n",
      "4869: loss=0.226, reward_mean=0.430, reward_bound=0.387, batch=217\n",
      "4870: loss=0.223, reward_mean=0.300, reward_bound=0.308, batch=222\n",
      "4871: loss=0.223, reward_mean=0.340, reward_bound=0.314, batch=224\n",
      "4872: loss=0.222, reward_mean=0.430, reward_bound=0.254, batch=226\n",
      "4873: loss=0.224, reward_mean=0.450, reward_bound=0.368, batch=228\n",
      "4874: loss=0.223, reward_mean=0.390, reward_bound=0.353, batch=229\n",
      "4875: loss=0.225, reward_mean=0.420, reward_bound=0.343, batch=230\n",
      "4876: loss=0.221, reward_mean=0.530, reward_bound=0.387, batch=225\n",
      "4877: loss=0.220, reward_mean=0.480, reward_bound=0.356, batch=227\n",
      "4878: loss=0.218, reward_mean=0.460, reward_bound=0.380, batch=229\n",
      "4879: loss=0.219, reward_mean=0.340, reward_bound=0.387, batch=227\n",
      "4880: loss=0.220, reward_mean=0.440, reward_bound=0.349, batch=228\n",
      "4881: loss=0.218, reward_mean=0.450, reward_bound=0.321, batch=229\n",
      "4882: loss=0.218, reward_mean=0.400, reward_bound=0.364, batch=230\n",
      "4883: loss=0.219, reward_mean=0.410, reward_bound=0.387, batch=230\n",
      "4884: loss=0.220, reward_mean=0.490, reward_bound=0.418, batch=231\n",
      "4885: loss=0.220, reward_mean=0.430, reward_bound=0.430, batch=215\n",
      "4886: loss=0.218, reward_mean=0.400, reward_bound=0.329, batch=220\n",
      "4887: loss=0.215, reward_mean=0.420, reward_bound=0.338, batch=224\n",
      "4888: loss=0.217, reward_mean=0.380, reward_bound=0.349, batch=225\n",
      "4889: loss=0.216, reward_mean=0.450, reward_bound=0.356, batch=227\n",
      "4890: loss=0.218, reward_mean=0.430, reward_bound=0.387, batch=223\n",
      "4891: loss=0.216, reward_mean=0.450, reward_bound=0.372, batch=226\n",
      "4892: loss=0.219, reward_mean=0.350, reward_bound=0.298, batch=228\n",
      "4893: loss=0.218, reward_mean=0.420, reward_bound=0.430, batch=222\n",
      "4894: loss=0.219, reward_mean=0.390, reward_bound=0.292, batch=225\n",
      "4895: loss=0.216, reward_mean=0.330, reward_bound=0.314, batch=226\n",
      "4896: loss=0.219, reward_mean=0.400, reward_bound=0.349, batch=227\n",
      "4897: loss=0.218, reward_mean=0.360, reward_bound=0.387, batch=226\n",
      "4898: loss=0.217, reward_mean=0.360, reward_bound=0.368, batch=228\n",
      "4899: loss=0.222, reward_mean=0.490, reward_bound=0.392, batch=229\n",
      "4900: loss=0.219, reward_mean=0.340, reward_bound=0.430, batch=225\n",
      "4901: loss=0.218, reward_mean=0.460, reward_bound=0.430, batch=226\n",
      "4902: loss=0.219, reward_mean=0.360, reward_bound=0.430, batch=227\n",
      "4903: loss=0.219, reward_mean=0.370, reward_bound=0.373, batch=229\n",
      "4904: loss=0.219, reward_mean=0.400, reward_bound=0.282, batch=229\n",
      "4905: loss=0.221, reward_mean=0.430, reward_bound=0.405, batch=230\n",
      "4906: loss=0.218, reward_mean=0.450, reward_bound=0.430, batch=230\n",
      "4907: loss=0.217, reward_mean=0.410, reward_bound=0.365, batch=231\n",
      "4908: loss=0.223, reward_mean=0.380, reward_bound=0.478, batch=213\n",
      "4909: loss=0.225, reward_mean=0.400, reward_bound=0.349, batch=216\n",
      "4910: loss=0.223, reward_mean=0.360, reward_bound=0.331, batch=221\n",
      "4911: loss=0.222, reward_mean=0.440, reward_bound=0.349, batch=222\n",
      "4912: loss=0.221, reward_mean=0.370, reward_bound=0.292, batch=225\n",
      "4913: loss=0.220, reward_mean=0.460, reward_bound=0.349, batch=226\n",
      "4914: loss=0.219, reward_mean=0.450, reward_bound=0.387, batch=224\n",
      "4915: loss=0.220, reward_mean=0.420, reward_bound=0.426, batch=227\n",
      "4916: loss=0.219, reward_mean=0.400, reward_bound=0.380, batch=229\n",
      "4917: loss=0.218, reward_mean=0.360, reward_bound=0.364, batch=230\n",
      "4918: loss=0.218, reward_mean=0.380, reward_bound=0.430, batch=225\n",
      "4919: loss=0.217, reward_mean=0.410, reward_bound=0.387, batch=226\n",
      "4920: loss=0.218, reward_mean=0.360, reward_bound=0.454, batch=228\n",
      "4921: loss=0.217, reward_mean=0.380, reward_bound=0.397, batch=229\n",
      "4922: loss=0.219, reward_mean=0.500, reward_bound=0.478, batch=231\n",
      "4923: loss=0.219, reward_mean=0.460, reward_bound=0.387, batch=231\n",
      "4924: loss=0.218, reward_mean=0.380, reward_bound=0.478, batch=221\n",
      "4925: loss=0.219, reward_mean=0.500, reward_bound=0.349, batch=223\n",
      "4926: loss=0.219, reward_mean=0.400, reward_bound=0.335, batch=226\n",
      "4927: loss=0.219, reward_mean=0.430, reward_bound=0.387, batch=226\n",
      "4928: loss=0.216, reward_mean=0.410, reward_bound=0.430, batch=223\n",
      "4929: loss=0.218, reward_mean=0.350, reward_bound=0.372, batch=226\n",
      "4930: loss=0.216, reward_mean=0.520, reward_bound=0.387, batch=226\n",
      "4931: loss=0.213, reward_mean=0.420, reward_bound=0.430, batch=227\n",
      "4932: loss=0.213, reward_mean=0.340, reward_bound=0.430, batch=228\n",
      "4933: loss=0.213, reward_mean=0.410, reward_bound=0.435, batch=229\n",
      "4934: loss=0.211, reward_mean=0.440, reward_bound=0.478, batch=231\n",
      "4935: loss=0.216, reward_mean=0.380, reward_bound=0.478, batch=224\n",
      "4936: loss=0.217, reward_mean=0.410, reward_bound=0.349, batch=226\n",
      "4937: loss=0.217, reward_mean=0.510, reward_bound=0.430, batch=227\n",
      "4938: loss=0.218, reward_mean=0.340, reward_bound=0.460, batch=229\n",
      "4939: loss=0.220, reward_mean=0.450, reward_bound=0.405, batch=230\n",
      "4940: loss=0.223, reward_mean=0.350, reward_bound=0.206, batch=232\n",
      "4941: loss=0.220, reward_mean=0.460, reward_bound=0.387, batch=230\n",
      "4942: loss=0.219, reward_mean=0.440, reward_bound=0.387, batch=230\n",
      "4943: loss=0.220, reward_mean=0.430, reward_bound=0.418, batch=231\n",
      "4944: loss=0.220, reward_mean=0.360, reward_bound=0.387, batch=231\n",
      "4945: loss=0.220, reward_mean=0.380, reward_bound=0.387, batch=231\n",
      "4946: loss=0.220, reward_mean=0.380, reward_bound=0.387, batch=231\n",
      "4947: loss=0.217, reward_mean=0.360, reward_bound=0.478, batch=228\n",
      "4948: loss=0.217, reward_mean=0.300, reward_bound=0.330, batch=229\n",
      "4949: loss=0.217, reward_mean=0.440, reward_bound=0.424, batch=230\n",
      "4950: loss=0.216, reward_mean=0.360, reward_bound=0.478, batch=230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4951: loss=0.216, reward_mean=0.360, reward_bound=0.430, batch=230\n",
      "4952: loss=0.215, reward_mean=0.340, reward_bound=0.477, batch=231\n",
      "4954: loss=0.183, reward_mean=0.490, reward_bound=0.000, batch=49\n",
      "4955: loss=0.205, reward_mean=0.490, reward_bound=0.000, batch=98\n",
      "4956: loss=0.202, reward_mean=0.480, reward_bound=0.001, batch=138\n",
      "4957: loss=0.199, reward_mean=0.370, reward_bound=0.003, batch=166\n",
      "4958: loss=0.207, reward_mean=0.490, reward_bound=0.015, batch=184\n",
      "4959: loss=0.214, reward_mean=0.490, reward_bound=0.028, batch=197\n",
      "4960: loss=0.208, reward_mean=0.490, reward_bound=0.042, batch=208\n",
      "4961: loss=0.211, reward_mean=0.320, reward_bound=0.053, batch=215\n",
      "4962: loss=0.206, reward_mean=0.350, reward_bound=0.072, batch=209\n",
      "4963: loss=0.205, reward_mean=0.400, reward_bound=0.089, batch=205\n",
      "4964: loss=0.206, reward_mean=0.410, reward_bound=0.098, batch=208\n",
      "4965: loss=0.199, reward_mean=0.400, reward_bound=0.122, batch=210\n",
      "4966: loss=0.191, reward_mean=0.430, reward_bound=0.135, batch=203\n",
      "4967: loss=0.194, reward_mean=0.470, reward_bound=0.109, batch=211\n",
      "4968: loss=0.194, reward_mean=0.440, reward_bound=0.150, batch=202\n",
      "4969: loss=0.187, reward_mean=0.520, reward_bound=0.167, batch=191\n",
      "4970: loss=0.191, reward_mean=0.390, reward_bound=0.135, batch=203\n",
      "4971: loss=0.193, reward_mean=0.360, reward_bound=0.109, batch=211\n",
      "4972: loss=0.197, reward_mean=0.460, reward_bound=0.185, batch=199\n",
      "4973: loss=0.196, reward_mean=0.420, reward_bound=0.157, batch=209\n",
      "4974: loss=0.198, reward_mean=0.450, reward_bound=0.194, batch=216\n",
      "4975: loss=0.200, reward_mean=0.480, reward_bound=0.206, batch=207\n",
      "4976: loss=0.198, reward_mean=0.460, reward_bound=0.224, batch=215\n",
      "4977: loss=0.202, reward_mean=0.500, reward_bound=0.229, batch=197\n",
      "4978: loss=0.202, reward_mean=0.410, reward_bound=0.185, batch=207\n",
      "4979: loss=0.204, reward_mean=0.460, reward_bound=0.254, batch=192\n",
      "4980: loss=0.198, reward_mean=0.490, reward_bound=0.179, batch=204\n",
      "4981: loss=0.198, reward_mean=0.360, reward_bound=0.204, batch=213\n",
      "4982: loss=0.198, reward_mean=0.490, reward_bound=0.220, batch=219\n",
      "4983: loss=0.198, reward_mean=0.450, reward_bound=0.239, batch=223\n",
      "4984: loss=0.196, reward_mean=0.380, reward_bound=0.254, batch=215\n",
      "4985: loss=0.195, reward_mean=0.390, reward_bound=0.282, batch=187\n",
      "4986: loss=0.195, reward_mean=0.480, reward_bound=0.182, batch=201\n",
      "4987: loss=0.195, reward_mean=0.420, reward_bound=0.150, batch=210\n",
      "4988: loss=0.198, reward_mean=0.430, reward_bound=0.185, batch=213\n",
      "4989: loss=0.193, reward_mean=0.470, reward_bound=0.229, batch=216\n",
      "4990: loss=0.198, reward_mean=0.450, reward_bound=0.282, batch=219\n",
      "4991: loss=0.196, reward_mean=0.410, reward_bound=0.314, batch=173\n",
      "4992: loss=0.190, reward_mean=0.420, reward_bound=0.095, batch=191\n",
      "4993: loss=0.186, reward_mean=0.460, reward_bound=0.122, batch=203\n",
      "4994: loss=0.192, reward_mean=0.370, reward_bound=0.150, batch=208\n",
      "4995: loss=0.195, reward_mean=0.370, reward_bound=0.167, batch=211\n",
      "4996: loss=0.194, reward_mean=0.400, reward_bound=0.185, batch=216\n",
      "4997: loss=0.196, reward_mean=0.450, reward_bound=0.206, batch=218\n",
      "4998: loss=0.191, reward_mean=0.480, reward_bound=0.229, batch=218\n",
      "4999: loss=0.196, reward_mean=0.410, reward_bound=0.254, batch=212\n",
      "5000: loss=0.199, reward_mean=0.440, reward_bound=0.282, batch=203\n",
      "5001: loss=0.202, reward_mean=0.390, reward_bound=0.150, batch=211\n",
      "5002: loss=0.199, reward_mean=0.470, reward_bound=0.229, batch=215\n",
      "5003: loss=0.196, reward_mean=0.480, reward_bound=0.254, batch=219\n",
      "5004: loss=0.199, reward_mean=0.470, reward_bound=0.282, batch=221\n",
      "5005: loss=0.198, reward_mean=0.440, reward_bound=0.254, batch=224\n",
      "5006: loss=0.202, reward_mean=0.490, reward_bound=0.311, batch=227\n",
      "5007: loss=0.200, reward_mean=0.500, reward_bound=0.314, batch=218\n",
      "5008: loss=0.201, reward_mean=0.340, reward_bound=0.314, batch=221\n",
      "5009: loss=0.199, reward_mean=0.340, reward_bound=0.254, batch=224\n",
      "5010: loss=0.201, reward_mean=0.410, reward_bound=0.314, batch=226\n",
      "5011: loss=0.206, reward_mean=0.480, reward_bound=0.349, batch=159\n",
      "5012: loss=0.210, reward_mean=0.400, reward_bound=0.042, batch=181\n",
      "5013: loss=0.210, reward_mean=0.450, reward_bound=0.080, batch=195\n",
      "5014: loss=0.213, reward_mean=0.370, reward_bound=0.124, batch=206\n",
      "5015: loss=0.223, reward_mean=0.480, reward_bound=0.167, batch=211\n",
      "5016: loss=0.224, reward_mean=0.450, reward_bound=0.185, batch=215\n",
      "5017: loss=0.219, reward_mean=0.490, reward_bound=0.206, batch=213\n",
      "5018: loss=0.214, reward_mean=0.410, reward_bound=0.229, batch=213\n",
      "5019: loss=0.212, reward_mean=0.360, reward_bound=0.254, batch=214\n",
      "5020: loss=0.214, reward_mean=0.400, reward_bound=0.254, batch=219\n",
      "5021: loss=0.210, reward_mean=0.440, reward_bound=0.282, batch=212\n",
      "5022: loss=0.210, reward_mean=0.440, reward_bound=0.245, batch=218\n",
      "5023: loss=0.207, reward_mean=0.480, reward_bound=0.282, batch=221\n",
      "5024: loss=0.205, reward_mean=0.380, reward_bound=0.254, batch=223\n",
      "5025: loss=0.204, reward_mean=0.460, reward_bound=0.282, batch=225\n",
      "5026: loss=0.208, reward_mean=0.430, reward_bound=0.314, batch=215\n",
      "5027: loss=0.210, reward_mean=0.480, reward_bound=0.296, batch=220\n",
      "5028: loss=0.201, reward_mean=0.400, reward_bound=0.349, batch=203\n",
      "5029: loss=0.199, reward_mean=0.380, reward_bound=0.171, batch=212\n",
      "5030: loss=0.198, reward_mean=0.450, reward_bound=0.206, batch=220\n",
      "5031: loss=0.194, reward_mean=0.450, reward_bound=0.247, batch=224\n",
      "5032: loss=0.198, reward_mean=0.400, reward_bound=0.254, batch=226\n",
      "5033: loss=0.194, reward_mean=0.460, reward_bound=0.282, batch=222\n",
      "5034: loss=0.200, reward_mean=0.470, reward_bound=0.314, batch=222\n",
      "5035: loss=0.207, reward_mean=0.420, reward_bound=0.349, batch=220\n",
      "5036: loss=0.204, reward_mean=0.490, reward_bound=0.338, batch=224\n",
      "5037: loss=0.203, reward_mean=0.390, reward_bound=0.280, batch=227\n",
      "5038: loss=0.205, reward_mean=0.510, reward_bound=0.349, batch=226\n",
      "5039: loss=0.201, reward_mean=0.410, reward_bound=0.387, batch=153\n",
      "5040: loss=0.202, reward_mean=0.420, reward_bound=0.047, batch=175\n",
      "5041: loss=0.195, reward_mean=0.420, reward_bound=0.065, batch=191\n",
      "5042: loss=0.200, reward_mean=0.440, reward_bound=0.098, batch=202\n",
      "5043: loss=0.202, reward_mean=0.390, reward_bound=0.135, batch=207\n",
      "5044: loss=0.196, reward_mean=0.410, reward_bound=0.144, batch=215\n",
      "5045: loss=0.193, reward_mean=0.520, reward_bound=0.167, batch=215\n",
      "5046: loss=0.195, reward_mean=0.460, reward_bound=0.185, batch=219\n",
      "5047: loss=0.190, reward_mean=0.470, reward_bound=0.215, batch=223\n",
      "5048: loss=0.191, reward_mean=0.390, reward_bound=0.229, batch=223\n",
      "5049: loss=0.192, reward_mean=0.360, reward_bound=0.254, batch=220\n",
      "5050: loss=0.189, reward_mean=0.360, reward_bound=0.282, batch=213\n",
      "5051: loss=0.190, reward_mean=0.480, reward_bound=0.314, batch=206\n",
      "5052: loss=0.186, reward_mean=0.350, reward_bound=0.229, batch=213\n",
      "5053: loss=0.188, reward_mean=0.440, reward_bound=0.254, batch=218\n",
      "5054: loss=0.187, reward_mean=0.430, reward_bound=0.349, batch=210\n",
      "5055: loss=0.188, reward_mean=0.410, reward_bound=0.282, batch=216\n",
      "5056: loss=0.191, reward_mean=0.450, reward_bound=0.268, batch=221\n",
      "5057: loss=0.186, reward_mean=0.410, reward_bound=0.282, batch=223\n",
      "5058: loss=0.186, reward_mean=0.420, reward_bound=0.290, batch=226\n",
      "5059: loss=0.185, reward_mean=0.470, reward_bound=0.349, batch=224\n",
      "5060: loss=0.190, reward_mean=0.430, reward_bound=0.387, batch=200\n",
      "5061: loss=0.189, reward_mean=0.500, reward_bound=0.329, batch=210\n",
      "5062: loss=0.189, reward_mean=0.430, reward_bound=0.254, batch=216\n",
      "5063: loss=0.188, reward_mean=0.500, reward_bound=0.314, batch=220\n",
      "5064: loss=0.189, reward_mean=0.430, reward_bound=0.349, batch=220\n",
      "5065: loss=0.187, reward_mean=0.380, reward_bound=0.247, batch=224\n",
      "5066: loss=0.185, reward_mean=0.430, reward_bound=0.314, batch=226\n",
      "5067: loss=0.188, reward_mean=0.460, reward_bound=0.387, batch=217\n",
      "5068: loss=0.185, reward_mean=0.510, reward_bound=0.282, batch=221\n",
      "5069: loss=0.186, reward_mean=0.400, reward_bound=0.314, batch=224\n",
      "5070: loss=0.185, reward_mean=0.440, reward_bound=0.387, batch=226\n",
      "5071: loss=0.185, reward_mean=0.500, reward_bound=0.390, batch=228\n",
      "5072: loss=0.192, reward_mean=0.430, reward_bound=0.430, batch=128\n",
      "5073: loss=0.198, reward_mean=0.480, reward_bound=0.059, batch=159\n",
      "5074: loss=0.190, reward_mean=0.410, reward_bound=0.075, batch=181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5075: loss=0.190, reward_mean=0.460, reward_bound=0.109, batch=193\n",
      "5076: loss=0.200, reward_mean=0.420, reward_bound=0.135, batch=201\n",
      "5077: loss=0.201, reward_mean=0.460, reward_bound=0.167, batch=205\n",
      "5078: loss=0.193, reward_mean=0.370, reward_bound=0.185, batch=207\n",
      "5079: loss=0.197, reward_mean=0.440, reward_bound=0.206, batch=209\n",
      "5080: loss=0.200, reward_mean=0.400, reward_bound=0.229, batch=211\n",
      "5081: loss=0.199, reward_mean=0.430, reward_bound=0.206, batch=217\n",
      "5082: loss=0.195, reward_mean=0.460, reward_bound=0.254, batch=207\n",
      "5083: loss=0.193, reward_mean=0.380, reward_bound=0.185, batch=214\n",
      "5084: loss=0.196, reward_mean=0.460, reward_bound=0.254, batch=219\n",
      "5085: loss=0.199, reward_mean=0.420, reward_bound=0.282, batch=203\n",
      "5086: loss=0.196, reward_mean=0.410, reward_bound=0.229, batch=211\n",
      "5087: loss=0.190, reward_mean=0.400, reward_bound=0.314, batch=199\n",
      "5088: loss=0.194, reward_mean=0.520, reward_bound=0.250, batch=209\n",
      "5089: loss=0.191, reward_mean=0.530, reward_bound=0.295, batch=216\n",
      "5090: loss=0.189, reward_mean=0.410, reward_bound=0.314, batch=217\n",
      "5091: loss=0.190, reward_mean=0.380, reward_bound=0.163, batch=222\n",
      "5092: loss=0.185, reward_mean=0.350, reward_bound=0.206, batch=229\n",
      "5093: loss=0.188, reward_mean=0.380, reward_bound=0.206, batch=227\n",
      "5094: loss=0.189, reward_mean=0.460, reward_bound=0.308, batch=229\n",
      "5095: loss=0.194, reward_mean=0.390, reward_bound=0.349, batch=198\n",
      "5096: loss=0.194, reward_mean=0.450, reward_bound=0.254, batch=206\n",
      "5097: loss=0.190, reward_mean=0.490, reward_bound=0.241, batch=214\n",
      "5098: loss=0.194, reward_mean=0.390, reward_bound=0.254, batch=218\n",
      "5099: loss=0.196, reward_mean=0.400, reward_bound=0.231, batch=222\n",
      "5100: loss=0.194, reward_mean=0.480, reward_bound=0.282, batch=222\n",
      "5101: loss=0.196, reward_mean=0.410, reward_bound=0.314, batch=222\n",
      "5102: loss=0.197, reward_mean=0.510, reward_bound=0.314, batch=224\n",
      "5103: loss=0.197, reward_mean=0.470, reward_bound=0.339, batch=227\n",
      "5104: loss=0.197, reward_mean=0.410, reward_bound=0.349, batch=221\n",
      "5105: loss=0.198, reward_mean=0.460, reward_bound=0.387, batch=190\n",
      "5106: loss=0.194, reward_mean=0.450, reward_bound=0.131, batch=203\n",
      "5107: loss=0.196, reward_mean=0.450, reward_bound=0.178, batch=212\n",
      "5108: loss=0.192, reward_mean=0.420, reward_bound=0.206, batch=220\n",
      "5109: loss=0.192, reward_mean=0.330, reward_bound=0.222, batch=224\n",
      "5110: loss=0.197, reward_mean=0.430, reward_bound=0.254, batch=225\n",
      "5111: loss=0.195, reward_mean=0.410, reward_bound=0.282, batch=225\n",
      "5112: loss=0.193, reward_mean=0.410, reward_bound=0.314, batch=221\n",
      "5113: loss=0.194, reward_mean=0.470, reward_bound=0.349, batch=218\n",
      "5114: loss=0.194, reward_mean=0.440, reward_bound=0.349, batch=221\n",
      "5115: loss=0.194, reward_mean=0.420, reward_bound=0.387, batch=207\n",
      "5116: loss=0.195, reward_mean=0.540, reward_bound=0.314, batch=214\n",
      "5117: loss=0.191, reward_mean=0.410, reward_bound=0.349, batch=218\n",
      "5118: loss=0.190, reward_mean=0.430, reward_bound=0.264, batch=222\n",
      "5119: loss=0.190, reward_mean=0.450, reward_bound=0.349, batch=223\n",
      "5120: loss=0.190, reward_mean=0.440, reward_bound=0.387, batch=221\n",
      "5121: loss=0.188, reward_mean=0.400, reward_bound=0.387, batch=223\n",
      "5122: loss=0.186, reward_mean=0.380, reward_bound=0.335, batch=226\n",
      "5123: loss=0.187, reward_mean=0.580, reward_bound=0.349, batch=227\n",
      "5124: loss=0.187, reward_mean=0.330, reward_bound=0.387, batch=226\n",
      "5125: loss=0.187, reward_mean=0.530, reward_bound=0.356, batch=228\n",
      "5126: loss=0.184, reward_mean=0.400, reward_bound=0.430, batch=174\n",
      "5127: loss=0.182, reward_mean=0.440, reward_bound=0.089, batch=190\n",
      "5128: loss=0.180, reward_mean=0.360, reward_bound=0.131, batch=203\n",
      "5129: loss=0.181, reward_mean=0.510, reward_bound=0.198, batch=212\n",
      "5130: loss=0.183, reward_mean=0.450, reward_bound=0.229, batch=214\n",
      "5131: loss=0.182, reward_mean=0.480, reward_bound=0.254, batch=214\n",
      "5132: loss=0.187, reward_mean=0.420, reward_bound=0.254, batch=219\n",
      "5133: loss=0.184, reward_mean=0.460, reward_bound=0.282, batch=214\n",
      "5134: loss=0.187, reward_mean=0.510, reward_bound=0.282, batch=217\n",
      "5135: loss=0.189, reward_mean=0.460, reward_bound=0.314, batch=213\n",
      "5136: loss=0.185, reward_mean=0.500, reward_bound=0.271, batch=219\n",
      "5137: loss=0.184, reward_mean=0.460, reward_bound=0.295, batch=223\n",
      "5138: loss=0.183, reward_mean=0.390, reward_bound=0.301, batch=226\n",
      "5139: loss=0.186, reward_mean=0.540, reward_bound=0.331, batch=228\n",
      "5140: loss=0.190, reward_mean=0.510, reward_bound=0.349, batch=215\n",
      "5141: loss=0.189, reward_mean=0.470, reward_bound=0.216, batch=220\n",
      "5142: loss=0.192, reward_mean=0.510, reward_bound=0.282, batch=223\n",
      "5143: loss=0.192, reward_mean=0.520, reward_bound=0.314, batch=225\n",
      "5144: loss=0.191, reward_mean=0.400, reward_bound=0.321, batch=227\n",
      "5145: loss=0.193, reward_mean=0.430, reward_bound=0.314, batch=228\n",
      "5146: loss=0.197, reward_mean=0.470, reward_bound=0.349, batch=228\n",
      "5147: loss=0.190, reward_mean=0.500, reward_bound=0.387, batch=211\n",
      "5148: loss=0.185, reward_mean=0.370, reward_bound=0.229, batch=217\n",
      "5149: loss=0.191, reward_mean=0.460, reward_bound=0.254, batch=221\n",
      "5150: loss=0.193, reward_mean=0.420, reward_bound=0.282, batch=223\n",
      "5151: loss=0.197, reward_mean=0.460, reward_bound=0.335, batch=226\n",
      "5152: loss=0.194, reward_mean=0.410, reward_bound=0.349, batch=221\n",
      "5153: loss=0.195, reward_mean=0.410, reward_bound=0.387, batch=219\n",
      "5154: loss=0.194, reward_mean=0.380, reward_bound=0.282, batch=222\n",
      "5155: loss=0.194, reward_mean=0.420, reward_bound=0.324, batch=225\n",
      "5156: loss=0.193, reward_mean=0.520, reward_bound=0.387, batch=224\n",
      "5157: loss=0.193, reward_mean=0.450, reward_bound=0.387, batch=226\n",
      "5158: loss=0.194, reward_mean=0.500, reward_bound=0.390, batch=228\n",
      "5159: loss=0.194, reward_mean=0.450, reward_bound=0.430, batch=209\n",
      "5160: loss=0.190, reward_mean=0.510, reward_bound=0.295, batch=216\n",
      "5161: loss=0.188, reward_mean=0.430, reward_bound=0.241, batch=221\n",
      "5162: loss=0.189, reward_mean=0.380, reward_bound=0.314, batch=221\n",
      "5163: loss=0.195, reward_mean=0.560, reward_bound=0.387, batch=219\n",
      "5164: loss=0.194, reward_mean=0.430, reward_bound=0.387, batch=221\n",
      "5165: loss=0.195, reward_mean=0.570, reward_bound=0.349, batch=223\n",
      "5166: loss=0.192, reward_mean=0.390, reward_bound=0.430, batch=218\n",
      "5167: loss=0.190, reward_mean=0.430, reward_bound=0.353, batch=222\n",
      "5168: loss=0.190, reward_mean=0.430, reward_bound=0.349, batch=222\n",
      "5169: loss=0.190, reward_mean=0.410, reward_bound=0.360, batch=225\n",
      "5170: loss=0.189, reward_mean=0.450, reward_bound=0.356, batch=227\n",
      "5171: loss=0.188, reward_mean=0.310, reward_bound=0.387, batch=227\n",
      "5172: loss=0.188, reward_mean=0.380, reward_bound=0.342, batch=229\n",
      "5173: loss=0.188, reward_mean=0.330, reward_bound=0.430, batch=226\n",
      "5174: loss=0.188, reward_mean=0.430, reward_bound=0.430, batch=227\n",
      "5175: loss=0.189, reward_mean=0.390, reward_bound=0.314, batch=228\n",
      "5176: loss=0.189, reward_mean=0.410, reward_bound=0.349, batch=228\n",
      "5177: loss=0.189, reward_mean=0.430, reward_bound=0.241, batch=229\n",
      "5178: loss=0.190, reward_mean=0.470, reward_bound=0.387, batch=229\n",
      "5179: loss=0.189, reward_mean=0.420, reward_bound=0.430, batch=228\n",
      "5180: loss=0.189, reward_mean=0.420, reward_bound=0.357, batch=229\n",
      "5181: loss=0.188, reward_mean=0.440, reward_bound=0.430, batch=229\n",
      "5182: loss=0.188, reward_mean=0.440, reward_bound=0.405, batch=230\n",
      "5183: loss=0.187, reward_mean=0.450, reward_bound=0.430, batch=230\n",
      "5184: loss=0.187, reward_mean=0.470, reward_bound=0.395, batch=231\n",
      "5185: loss=0.191, reward_mean=0.480, reward_bound=0.478, batch=94\n",
      "5186: loss=0.185, reward_mean=0.340, reward_bound=0.000, batch=128\n",
      "5187: loss=0.164, reward_mean=0.410, reward_bound=0.003, batch=159\n",
      "5188: loss=0.166, reward_mean=0.400, reward_bound=0.013, batch=179\n",
      "5189: loss=0.164, reward_mean=0.490, reward_bound=0.047, batch=193\n",
      "5190: loss=0.176, reward_mean=0.380, reward_bound=0.072, batch=203\n",
      "5191: loss=0.176, reward_mean=0.300, reward_bound=0.080, batch=211\n",
      "5192: loss=0.178, reward_mean=0.480, reward_bound=0.098, batch=214\n",
      "5193: loss=0.178, reward_mean=0.470, reward_bound=0.122, batch=218\n",
      "5194: loss=0.172, reward_mean=0.420, reward_bound=0.150, batch=216\n",
      "5195: loss=0.170, reward_mean=0.500, reward_bound=0.167, batch=218\n",
      "5196: loss=0.174, reward_mean=0.390, reward_bound=0.185, batch=219\n",
      "5197: loss=0.163, reward_mean=0.500, reward_bound=0.206, batch=216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5198: loss=0.166, reward_mean=0.370, reward_bound=0.229, batch=209\n",
      "5199: loss=0.162, reward_mean=0.470, reward_bound=0.254, batch=197\n",
      "5200: loss=0.162, reward_mean=0.510, reward_bound=0.254, batch=207\n",
      "5201: loss=0.162, reward_mean=0.390, reward_bound=0.249, batch=215\n",
      "5202: loss=0.164, reward_mean=0.480, reward_bound=0.282, batch=203\n",
      "5203: loss=0.166, reward_mean=0.510, reward_bound=0.229, batch=211\n",
      "5204: loss=0.165, reward_mean=0.450, reward_bound=0.206, batch=217\n",
      "5205: loss=0.160, reward_mean=0.430, reward_bound=0.254, batch=220\n",
      "5206: loss=0.164, reward_mean=0.450, reward_bound=0.282, batch=220\n",
      "5207: loss=0.168, reward_mean=0.500, reward_bound=0.314, batch=194\n",
      "5208: loss=0.164, reward_mean=0.340, reward_bound=0.135, batch=205\n",
      "5209: loss=0.167, reward_mean=0.450, reward_bound=0.185, batch=211\n",
      "5210: loss=0.167, reward_mean=0.460, reward_bound=0.254, batch=215\n",
      "5211: loss=0.167, reward_mean=0.430, reward_bound=0.282, batch=216\n",
      "5212: loss=0.165, reward_mean=0.440, reward_bound=0.314, batch=215\n",
      "5213: loss=0.164, reward_mean=0.550, reward_bound=0.314, batch=219\n",
      "5214: loss=0.170, reward_mean=0.470, reward_bound=0.349, batch=182\n",
      "5215: loss=0.172, reward_mean=0.410, reward_bound=0.155, batch=197\n",
      "5216: loss=0.175, reward_mean=0.480, reward_bound=0.135, batch=205\n",
      "5217: loss=0.169, reward_mean=0.490, reward_bound=0.170, batch=213\n",
      "5218: loss=0.170, reward_mean=0.460, reward_bound=0.206, batch=215\n",
      "5219: loss=0.170, reward_mean=0.460, reward_bound=0.254, batch=210\n",
      "5220: loss=0.169, reward_mean=0.520, reward_bound=0.282, batch=216\n",
      "5221: loss=0.168, reward_mean=0.440, reward_bound=0.230, batch=221\n",
      "5222: loss=0.167, reward_mean=0.440, reward_bound=0.314, batch=220\n",
      "5223: loss=0.167, reward_mean=0.460, reward_bound=0.228, batch=224\n",
      "5224: loss=0.167, reward_mean=0.440, reward_bound=0.229, batch=225\n",
      "5225: loss=0.168, reward_mean=0.450, reward_bound=0.314, batch=226\n",
      "5226: loss=0.167, reward_mean=0.370, reward_bound=0.349, batch=216\n",
      "5227: loss=0.165, reward_mean=0.480, reward_bound=0.331, batch=221\n",
      "5228: loss=0.166, reward_mean=0.350, reward_bound=0.349, batch=222\n",
      "5229: loss=0.171, reward_mean=0.390, reward_bound=0.387, batch=185\n",
      "5230: loss=0.179, reward_mean=0.360, reward_bound=0.145, batch=199\n",
      "5231: loss=0.177, reward_mean=0.480, reward_bound=0.185, batch=208\n",
      "5232: loss=0.169, reward_mean=0.450, reward_bound=0.206, batch=213\n",
      "5233: loss=0.175, reward_mean=0.480, reward_bound=0.229, batch=218\n",
      "5234: loss=0.177, reward_mean=0.370, reward_bound=0.231, batch=222\n",
      "5235: loss=0.177, reward_mean=0.470, reward_bound=0.263, batch=225\n",
      "5236: loss=0.176, reward_mean=0.550, reward_bound=0.282, batch=225\n",
      "5237: loss=0.176, reward_mean=0.430, reward_bound=0.314, batch=225\n",
      "5238: loss=0.175, reward_mean=0.400, reward_bound=0.349, batch=215\n",
      "5239: loss=0.175, reward_mean=0.530, reward_bound=0.210, batch=220\n",
      "5240: loss=0.174, reward_mean=0.500, reward_bound=0.282, batch=223\n",
      "5241: loss=0.172, reward_mean=0.460, reward_bound=0.314, batch=225\n",
      "5242: loss=0.172, reward_mean=0.520, reward_bound=0.349, batch=226\n",
      "5243: loss=0.171, reward_mean=0.350, reward_bound=0.331, batch=228\n",
      "5244: loss=0.171, reward_mean=0.450, reward_bound=0.387, batch=215\n",
      "5245: loss=0.171, reward_mean=0.560, reward_bound=0.396, batch=220\n",
      "5246: loss=0.173, reward_mean=0.500, reward_bound=0.387, batch=222\n",
      "5247: loss=0.172, reward_mean=0.450, reward_bound=0.324, batch=225\n",
      "5248: loss=0.173, reward_mean=0.440, reward_bound=0.387, batch=225\n",
      "5249: loss=0.174, reward_mean=0.450, reward_bound=0.387, batch=226\n",
      "5250: loss=0.174, reward_mean=0.450, reward_bound=0.368, batch=228\n",
      "5251: loss=0.171, reward_mean=0.440, reward_bound=0.430, batch=175\n",
      "5252: loss=0.165, reward_mean=0.460, reward_bound=0.150, batch=190\n",
      "5253: loss=0.160, reward_mean=0.500, reward_bound=0.206, batch=205\n",
      "5254: loss=0.164, reward_mean=0.480, reward_bound=0.206, batch=207\n",
      "5255: loss=0.167, reward_mean=0.480, reward_bound=0.229, batch=211\n",
      "5256: loss=0.169, reward_mean=0.540, reward_bound=0.254, batch=206\n",
      "5257: loss=0.169, reward_mean=0.470, reward_bound=0.268, batch=214\n",
      "5258: loss=0.168, reward_mean=0.430, reward_bound=0.280, batch=220\n",
      "5259: loss=0.165, reward_mean=0.490, reward_bound=0.282, batch=218\n",
      "5260: loss=0.162, reward_mean=0.390, reward_bound=0.286, batch=222\n",
      "5261: loss=0.171, reward_mean=0.420, reward_bound=0.314, batch=214\n",
      "5262: loss=0.169, reward_mean=0.430, reward_bound=0.345, batch=220\n",
      "5263: loss=0.159, reward_mean=0.420, reward_bound=0.349, batch=209\n",
      "5264: loss=0.160, reward_mean=0.380, reward_bound=0.225, batch=216\n",
      "5265: loss=0.165, reward_mean=0.430, reward_bound=0.298, batch=221\n",
      "5266: loss=0.161, reward_mean=0.360, reward_bound=0.314, batch=222\n",
      "5267: loss=0.162, reward_mean=0.470, reward_bound=0.292, batch=225\n",
      "5268: loss=0.159, reward_mean=0.500, reward_bound=0.349, batch=222\n",
      "5269: loss=0.160, reward_mean=0.470, reward_bound=0.349, batch=224\n",
      "5270: loss=0.159, reward_mean=0.480, reward_bound=0.384, batch=227\n",
      "5271: loss=0.159, reward_mean=0.370, reward_bound=0.387, batch=220\n",
      "5272: loss=0.162, reward_mean=0.420, reward_bound=0.418, batch=224\n",
      "5273: loss=0.163, reward_mean=0.520, reward_bound=0.387, batch=225\n",
      "5274: loss=0.161, reward_mean=0.470, reward_bound=0.430, batch=207\n",
      "5275: loss=0.164, reward_mean=0.420, reward_bound=0.202, batch=215\n",
      "5276: loss=0.162, reward_mean=0.500, reward_bound=0.229, batch=218\n",
      "5277: loss=0.158, reward_mean=0.440, reward_bound=0.282, batch=221\n",
      "5278: loss=0.161, reward_mean=0.450, reward_bound=0.314, batch=221\n",
      "5279: loss=0.162, reward_mean=0.470, reward_bound=0.349, batch=220\n",
      "5280: loss=0.163, reward_mean=0.390, reward_bound=0.296, batch=224\n",
      "5281: loss=0.164, reward_mean=0.410, reward_bound=0.311, batch=227\n",
      "5282: loss=0.165, reward_mean=0.420, reward_bound=0.308, batch=229\n",
      "5283: loss=0.163, reward_mean=0.470, reward_bound=0.387, batch=224\n",
      "5284: loss=0.161, reward_mean=0.480, reward_bound=0.430, batch=217\n",
      "5285: loss=0.161, reward_mean=0.520, reward_bound=0.342, batch=222\n",
      "5286: loss=0.161, reward_mean=0.490, reward_bound=0.360, batch=225\n",
      "5287: loss=0.162, reward_mean=0.530, reward_bound=0.387, batch=225\n",
      "5288: loss=0.160, reward_mean=0.430, reward_bound=0.430, batch=220\n",
      "5289: loss=0.160, reward_mean=0.520, reward_bound=0.282, batch=223\n",
      "5290: loss=0.159, reward_mean=0.460, reward_bound=0.314, batch=225\n",
      "5291: loss=0.157, reward_mean=0.540, reward_bound=0.349, batch=226\n",
      "5292: loss=0.162, reward_mean=0.410, reward_bound=0.409, batch=228\n",
      "5293: loss=0.159, reward_mean=0.420, reward_bound=0.430, batch=225\n",
      "5294: loss=0.159, reward_mean=0.420, reward_bound=0.440, batch=227\n",
      "5295: loss=0.158, reward_mean=0.530, reward_bound=0.430, batch=228\n",
      "5296: loss=0.160, reward_mean=0.430, reward_bound=0.362, batch=229\n",
      "5297: loss=0.159, reward_mean=0.450, reward_bound=0.450, batch=230\n",
      "5298: loss=0.159, reward_mean=0.440, reward_bound=0.430, batch=230\n",
      "5299: loss=0.159, reward_mean=0.410, reward_bound=0.464, batch=231\n",
      "5300: loss=0.176, reward_mean=0.430, reward_bound=0.478, batch=151\n",
      "5301: loss=0.185, reward_mean=0.390, reward_bound=0.052, batch=173\n",
      "5302: loss=0.175, reward_mean=0.480, reward_bound=0.098, batch=190\n",
      "5303: loss=0.163, reward_mean=0.490, reward_bound=0.106, batch=203\n",
      "5304: loss=0.152, reward_mean=0.440, reward_bound=0.135, batch=208\n",
      "5305: loss=0.165, reward_mean=0.460, reward_bound=0.167, batch=213\n",
      "5306: loss=0.158, reward_mean=0.460, reward_bound=0.185, batch=217\n",
      "5307: loss=0.162, reward_mean=0.460, reward_bound=0.206, batch=213\n",
      "5308: loss=0.162, reward_mean=0.520, reward_bound=0.229, batch=211\n",
      "5309: loss=0.164, reward_mean=0.450, reward_bound=0.254, batch=214\n",
      "5310: loss=0.169, reward_mean=0.490, reward_bound=0.282, batch=212\n",
      "5311: loss=0.168, reward_mean=0.520, reward_bound=0.292, batch=218\n",
      "5312: loss=0.167, reward_mean=0.590, reward_bound=0.234, batch=222\n",
      "5313: loss=0.167, reward_mean=0.420, reward_bound=0.292, batch=225\n",
      "5314: loss=0.170, reward_mean=0.490, reward_bound=0.314, batch=213\n",
      "5315: loss=0.174, reward_mean=0.540, reward_bound=0.349, batch=196\n",
      "5316: loss=0.171, reward_mean=0.400, reward_bound=0.128, batch=207\n",
      "5317: loss=0.173, reward_mean=0.470, reward_bound=0.254, batch=214\n",
      "5318: loss=0.174, reward_mean=0.490, reward_bound=0.282, batch=215\n",
      "5319: loss=0.176, reward_mean=0.370, reward_bound=0.266, batch=220\n",
      "5320: loss=0.174, reward_mean=0.540, reward_bound=0.314, batch=215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5321: loss=0.174, reward_mean=0.410, reward_bound=0.314, batch=219\n",
      "5322: loss=0.173, reward_mean=0.450, reward_bound=0.349, batch=218\n",
      "5323: loss=0.172, reward_mean=0.500, reward_bound=0.282, batch=221\n",
      "5324: loss=0.172, reward_mean=0.420, reward_bound=0.282, batch=224\n",
      "5325: loss=0.175, reward_mean=0.440, reward_bound=0.345, batch=227\n",
      "5326: loss=0.174, reward_mean=0.400, reward_bound=0.380, batch=229\n",
      "5327: loss=0.175, reward_mean=0.480, reward_bound=0.387, batch=205\n",
      "5328: loss=0.177, reward_mean=0.460, reward_bound=0.282, batch=211\n",
      "5329: loss=0.178, reward_mean=0.350, reward_bound=0.229, batch=217\n",
      "5330: loss=0.176, reward_mean=0.490, reward_bound=0.249, batch=222\n",
      "5331: loss=0.177, reward_mean=0.300, reward_bound=0.229, batch=223\n",
      "5332: loss=0.175, reward_mean=0.490, reward_bound=0.282, batch=222\n",
      "5333: loss=0.176, reward_mean=0.470, reward_bound=0.314, batch=223\n",
      "5334: loss=0.176, reward_mean=0.410, reward_bound=0.314, batch=225\n",
      "5335: loss=0.170, reward_mean=0.420, reward_bound=0.349, batch=220\n",
      "5336: loss=0.170, reward_mean=0.410, reward_bound=0.349, batch=223\n",
      "5337: loss=0.171, reward_mean=0.360, reward_bound=0.314, batch=225\n",
      "5338: loss=0.171, reward_mean=0.380, reward_bound=0.349, batch=225\n",
      "5339: loss=0.171, reward_mean=0.400, reward_bound=0.289, batch=227\n",
      "5340: loss=0.172, reward_mean=0.410, reward_bound=0.387, batch=214\n",
      "5341: loss=0.172, reward_mean=0.480, reward_bound=0.349, batch=218\n",
      "5342: loss=0.177, reward_mean=0.510, reward_bound=0.353, batch=222\n",
      "5343: loss=0.178, reward_mean=0.540, reward_bound=0.314, batch=224\n",
      "5344: loss=0.178, reward_mean=0.430, reward_bound=0.384, batch=227\n",
      "5345: loss=0.175, reward_mean=0.610, reward_bound=0.387, batch=225\n",
      "5346: loss=0.174, reward_mean=0.390, reward_bound=0.356, batch=227\n",
      "5347: loss=0.175, reward_mean=0.430, reward_bound=0.373, batch=229\n",
      "5348: loss=0.175, reward_mean=0.400, reward_bound=0.387, batch=229\n",
      "5349: loss=0.179, reward_mean=0.410, reward_bound=0.430, batch=189\n",
      "5350: loss=0.184, reward_mean=0.450, reward_bound=0.194, batch=202\n",
      "5351: loss=0.181, reward_mean=0.440, reward_bound=0.206, batch=212\n",
      "5352: loss=0.180, reward_mean=0.430, reward_bound=0.236, batch=218\n",
      "5353: loss=0.185, reward_mean=0.420, reward_bound=0.254, batch=214\n",
      "5354: loss=0.185, reward_mean=0.500, reward_bound=0.282, batch=215\n",
      "5355: loss=0.183, reward_mean=0.390, reward_bound=0.254, batch=219\n",
      "5356: loss=0.182, reward_mean=0.410, reward_bound=0.314, batch=220\n",
      "5357: loss=0.178, reward_mean=0.450, reward_bound=0.222, batch=224\n",
      "5358: loss=0.180, reward_mean=0.350, reward_bound=0.314, batch=225\n",
      "5359: loss=0.179, reward_mean=0.370, reward_bound=0.321, batch=227\n",
      "5360: loss=0.179, reward_mean=0.450, reward_bound=0.349, batch=222\n",
      "5361: loss=0.181, reward_mean=0.540, reward_bound=0.387, batch=215\n",
      "5362: loss=0.180, reward_mean=0.420, reward_bound=0.321, batch=220\n",
      "5363: loss=0.180, reward_mean=0.450, reward_bound=0.282, batch=223\n",
      "5364: loss=0.180, reward_mean=0.370, reward_bound=0.314, batch=224\n",
      "5365: loss=0.181, reward_mean=0.480, reward_bound=0.349, batch=224\n",
      "5366: loss=0.181, reward_mean=0.420, reward_bound=0.282, batch=226\n",
      "5367: loss=0.179, reward_mean=0.440, reward_bound=0.314, batch=227\n",
      "5368: loss=0.180, reward_mean=0.490, reward_bound=0.349, batch=227\n",
      "5369: loss=0.181, reward_mean=0.420, reward_bound=0.366, batch=229\n",
      "5370: loss=0.181, reward_mean=0.440, reward_bound=0.387, batch=226\n",
      "5371: loss=0.181, reward_mean=0.460, reward_bound=0.430, batch=214\n",
      "5372: loss=0.181, reward_mean=0.480, reward_bound=0.282, batch=218\n",
      "5373: loss=0.181, reward_mean=0.460, reward_bound=0.314, batch=221\n",
      "5374: loss=0.186, reward_mean=0.440, reward_bound=0.349, batch=224\n",
      "5375: loss=0.185, reward_mean=0.420, reward_bound=0.345, batch=227\n",
      "5376: loss=0.186, reward_mean=0.460, reward_bound=0.349, batch=228\n",
      "5377: loss=0.191, reward_mean=0.500, reward_bound=0.387, batch=226\n",
      "5378: loss=0.191, reward_mean=0.510, reward_bound=0.372, batch=228\n",
      "5379: loss=0.187, reward_mean=0.360, reward_bound=0.430, batch=223\n",
      "5380: loss=0.186, reward_mean=0.480, reward_bound=0.398, batch=226\n",
      "5381: loss=0.187, reward_mean=0.480, reward_bound=0.390, batch=228\n",
      "5382: loss=0.186, reward_mean=0.400, reward_bound=0.430, batch=224\n",
      "5383: loss=0.185, reward_mean=0.480, reward_bound=0.314, batch=225\n",
      "5384: loss=0.185, reward_mean=0.410, reward_bound=0.289, batch=227\n",
      "5385: loss=0.186, reward_mean=0.350, reward_bound=0.349, batch=228\n",
      "5386: loss=0.185, reward_mean=0.400, reward_bound=0.353, batch=229\n",
      "5387: loss=0.188, reward_mean=0.450, reward_bound=0.387, batch=228\n",
      "5388: loss=0.188, reward_mean=0.320, reward_bound=0.392, batch=229\n",
      "5389: loss=0.187, reward_mean=0.380, reward_bound=0.430, batch=227\n",
      "5390: loss=0.186, reward_mean=0.480, reward_bound=0.422, batch=229\n",
      "5391: loss=0.185, reward_mean=0.440, reward_bound=0.405, batch=230\n",
      "5392: loss=0.184, reward_mean=0.400, reward_bound=0.418, batch=231\n",
      "5393: loss=0.184, reward_mean=0.380, reward_bound=0.314, batch=231\n",
      "5394: loss=0.185, reward_mean=0.480, reward_bound=0.430, batch=230\n",
      "5395: loss=0.186, reward_mean=0.450, reward_bound=0.451, batch=231\n",
      "5396: loss=0.186, reward_mean=0.490, reward_bound=0.387, batch=231\n",
      "5397: loss=0.186, reward_mean=0.370, reward_bound=0.387, batch=231\n",
      "5398: loss=0.180, reward_mean=0.400, reward_bound=0.478, batch=185\n",
      "5399: loss=0.176, reward_mean=0.400, reward_bound=0.091, batch=199\n",
      "5400: loss=0.181, reward_mean=0.420, reward_bound=0.157, batch=209\n",
      "5401: loss=0.184, reward_mean=0.420, reward_bound=0.185, batch=209\n",
      "5402: loss=0.176, reward_mean=0.550, reward_bound=0.206, batch=215\n",
      "5403: loss=0.171, reward_mean=0.400, reward_bound=0.229, batch=217\n",
      "5404: loss=0.168, reward_mean=0.370, reward_bound=0.254, batch=217\n",
      "5405: loss=0.178, reward_mean=0.420, reward_bound=0.282, batch=217\n",
      "5406: loss=0.173, reward_mean=0.480, reward_bound=0.314, batch=212\n",
      "5407: loss=0.172, reward_mean=0.430, reward_bound=0.263, batch=218\n",
      "5408: loss=0.178, reward_mean=0.540, reward_bound=0.314, batch=220\n",
      "5409: loss=0.178, reward_mean=0.480, reward_bound=0.282, batch=223\n",
      "5410: loss=0.174, reward_mean=0.530, reward_bound=0.349, batch=217\n",
      "5411: loss=0.172, reward_mean=0.380, reward_bound=0.237, batch=222\n",
      "5412: loss=0.176, reward_mean=0.440, reward_bound=0.324, batch=225\n",
      "5413: loss=0.176, reward_mean=0.550, reward_bound=0.356, batch=227\n",
      "5414: loss=0.172, reward_mean=0.460, reward_bound=0.387, batch=216\n",
      "5415: loss=0.174, reward_mean=0.490, reward_bound=0.409, batch=221\n",
      "5416: loss=0.180, reward_mean=0.370, reward_bound=0.430, batch=209\n",
      "5417: loss=0.182, reward_mean=0.490, reward_bound=0.282, batch=214\n",
      "5418: loss=0.182, reward_mean=0.530, reward_bound=0.345, batch=220\n",
      "5419: loss=0.183, reward_mean=0.460, reward_bound=0.349, batch=221\n",
      "5420: loss=0.185, reward_mean=0.380, reward_bound=0.206, batch=224\n",
      "5421: loss=0.181, reward_mean=0.430, reward_bound=0.345, batch=227\n",
      "5422: loss=0.180, reward_mean=0.470, reward_bound=0.342, batch=229\n",
      "5423: loss=0.183, reward_mean=0.460, reward_bound=0.349, batch=227\n",
      "5424: loss=0.184, reward_mean=0.520, reward_bound=0.380, batch=229\n",
      "5425: loss=0.182, reward_mean=0.390, reward_bound=0.387, batch=224\n",
      "5426: loss=0.177, reward_mean=0.440, reward_bound=0.430, batch=222\n",
      "5427: loss=0.176, reward_mean=0.470, reward_bound=0.349, batch=224\n",
      "5428: loss=0.176, reward_mean=0.440, reward_bound=0.254, batch=226\n",
      "5429: loss=0.174, reward_mean=0.460, reward_bound=0.298, batch=228\n",
      "5430: loss=0.174, reward_mean=0.450, reward_bound=0.392, batch=229\n",
      "5431: loss=0.174, reward_mean=0.340, reward_bound=0.324, batch=230\n",
      "5432: loss=0.174, reward_mean=0.430, reward_bound=0.430, batch=230\n",
      "5433: loss=0.179, reward_mean=0.410, reward_bound=0.478, batch=201\n",
      "5434: loss=0.173, reward_mean=0.480, reward_bound=0.206, batch=207\n",
      "5435: loss=0.172, reward_mean=0.480, reward_bound=0.282, batch=211\n",
      "5436: loss=0.168, reward_mean=0.530, reward_bound=0.282, batch=216\n",
      "5437: loss=0.171, reward_mean=0.510, reward_bound=0.314, batch=216\n",
      "5438: loss=0.168, reward_mean=0.450, reward_bound=0.268, batch=221\n",
      "5439: loss=0.172, reward_mean=0.500, reward_bound=0.349, batch=223\n",
      "5440: loss=0.172, reward_mean=0.470, reward_bound=0.387, batch=218\n",
      "5441: loss=0.170, reward_mean=0.470, reward_bound=0.353, batch=222\n",
      "5442: loss=0.173, reward_mean=0.460, reward_bound=0.387, batch=223\n",
      "5443: loss=0.174, reward_mean=0.440, reward_bound=0.349, batch=225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5444: loss=0.172, reward_mean=0.360, reward_bound=0.430, batch=219\n",
      "5445: loss=0.173, reward_mean=0.440, reward_bound=0.265, batch=223\n",
      "5446: loss=0.174, reward_mean=0.540, reward_bound=0.372, batch=226\n",
      "5447: loss=0.173, reward_mean=0.440, reward_bound=0.349, batch=227\n",
      "5448: loss=0.173, reward_mean=0.440, reward_bound=0.349, batch=228\n",
      "5449: loss=0.173, reward_mean=0.400, reward_bound=0.392, batch=229\n",
      "5450: loss=0.175, reward_mean=0.530, reward_bound=0.430, batch=224\n",
      "5451: loss=0.174, reward_mean=0.390, reward_bound=0.387, batch=226\n",
      "5452: loss=0.173, reward_mean=0.500, reward_bound=0.368, batch=228\n",
      "5453: loss=0.175, reward_mean=0.400, reward_bound=0.430, batch=227\n",
      "5454: loss=0.176, reward_mean=0.420, reward_bound=0.422, batch=229\n",
      "5455: loss=0.176, reward_mean=0.420, reward_bound=0.478, batch=231\n",
      "5456: loss=0.176, reward_mean=0.460, reward_bound=0.387, batch=231\n",
      "5457: loss=0.177, reward_mean=0.450, reward_bound=0.478, batch=213\n",
      "5458: loss=0.180, reward_mean=0.380, reward_bound=0.301, batch=219\n",
      "5459: loss=0.172, reward_mean=0.480, reward_bound=0.314, batch=222\n",
      "5460: loss=0.171, reward_mean=0.480, reward_bound=0.349, batch=224\n",
      "5461: loss=0.178, reward_mean=0.350, reward_bound=0.387, batch=221\n",
      "5462: loss=0.177, reward_mean=0.460, reward_bound=0.314, batch=224\n",
      "5463: loss=0.177, reward_mean=0.490, reward_bound=0.387, batch=224\n",
      "5464: loss=0.179, reward_mean=0.470, reward_bound=0.426, batch=227\n",
      "5465: loss=0.181, reward_mean=0.430, reward_bound=0.314, batch=228\n",
      "5466: loss=0.180, reward_mean=0.390, reward_bound=0.430, batch=222\n",
      "5467: loss=0.179, reward_mean=0.460, reward_bound=0.387, batch=224\n",
      "5468: loss=0.182, reward_mean=0.370, reward_bound=0.305, batch=227\n",
      "5469: loss=0.181, reward_mean=0.470, reward_bound=0.380, batch=229\n",
      "5470: loss=0.178, reward_mean=0.450, reward_bound=0.387, batch=226\n",
      "5471: loss=0.179, reward_mean=0.420, reward_bound=0.454, batch=228\n",
      "5472: loss=0.181, reward_mean=0.370, reward_bound=0.362, batch=229\n",
      "5473: loss=0.181, reward_mean=0.370, reward_bound=0.314, batch=229\n",
      "5474: loss=0.180, reward_mean=0.390, reward_bound=0.405, batch=230\n",
      "5475: loss=0.181, reward_mean=0.440, reward_bound=0.464, batch=231\n",
      "5476: loss=0.179, reward_mean=0.380, reward_bound=0.478, batch=226\n",
      "5477: loss=0.179, reward_mean=0.510, reward_bound=0.356, batch=228\n",
      "5478: loss=0.179, reward_mean=0.410, reward_bound=0.357, batch=229\n",
      "5479: loss=0.180, reward_mean=0.470, reward_bound=0.450, batch=230\n",
      "5480: loss=0.181, reward_mean=0.450, reward_bound=0.478, batch=230\n",
      "5481: loss=0.181, reward_mean=0.420, reward_bound=0.430, batch=230\n",
      "5482: loss=0.181, reward_mean=0.410, reward_bound=0.488, batch=231\n",
      "5483: loss=0.181, reward_mean=0.400, reward_bound=0.430, batch=231\n",
      "5484: loss=0.181, reward_mean=0.500, reward_bound=0.430, batch=231\n",
      "5485: loss=0.181, reward_mean=0.520, reward_bound=0.478, batch=231\n",
      "5486: loss=0.181, reward_mean=0.410, reward_bound=0.387, batch=231\n",
      "5488: loss=0.188, reward_mean=0.480, reward_bound=0.000, batch=48\n",
      "5489: loss=0.191, reward_mean=0.570, reward_bound=0.000, batch=103\n",
      "5490: loss=0.192, reward_mean=0.400, reward_bound=0.000, batch=142\n",
      "5491: loss=0.197, reward_mean=0.440, reward_bound=0.002, batch=168\n",
      "5492: loss=0.197, reward_mean=0.530, reward_bound=0.013, batch=186\n",
      "5493: loss=0.198, reward_mean=0.370, reward_bound=0.024, batch=200\n",
      "5494: loss=0.191, reward_mean=0.470, reward_bound=0.038, batch=205\n",
      "5495: loss=0.196, reward_mean=0.400, reward_bound=0.047, batch=210\n",
      "5496: loss=0.192, reward_mean=0.460, reward_bound=0.058, batch=214\n",
      "5497: loss=0.194, reward_mean=0.500, reward_bound=0.080, batch=215\n",
      "5498: loss=0.186, reward_mean=0.400, reward_bound=0.098, batch=209\n",
      "5499: loss=0.180, reward_mean=0.440, reward_bound=0.109, batch=209\n",
      "5500: loss=0.183, reward_mean=0.460, reward_bound=0.122, batch=211\n",
      "5501: loss=0.178, reward_mean=0.520, reward_bound=0.135, batch=215\n",
      "5502: loss=0.176, reward_mean=0.570, reward_bound=0.150, batch=218\n",
      "5503: loss=0.174, reward_mean=0.430, reward_bound=0.167, batch=212\n",
      "5504: loss=0.173, reward_mean=0.490, reward_bound=0.185, batch=200\n",
      "5505: loss=0.172, reward_mean=0.490, reward_bound=0.206, batch=213\n",
      "5506: loss=0.177, reward_mean=0.490, reward_bound=0.206, batch=200\n",
      "5507: loss=0.177, reward_mean=0.430, reward_bound=0.131, batch=210\n",
      "5508: loss=0.187, reward_mean=0.530, reward_bound=0.229, batch=181\n",
      "5509: loss=0.190, reward_mean=0.410, reward_bound=0.109, batch=196\n",
      "5510: loss=0.187, reward_mean=0.430, reward_bound=0.158, batch=207\n",
      "5511: loss=0.189, reward_mean=0.460, reward_bound=0.185, batch=212\n",
      "5512: loss=0.182, reward_mean=0.530, reward_bound=0.229, batch=217\n",
      "5513: loss=0.181, reward_mean=0.430, reward_bound=0.249, batch=222\n",
      "5514: loss=0.178, reward_mean=0.370, reward_bound=0.254, batch=193\n",
      "5515: loss=0.176, reward_mean=0.390, reward_bound=0.160, batch=205\n",
      "5516: loss=0.174, reward_mean=0.360, reward_bound=0.216, batch=213\n",
      "5517: loss=0.179, reward_mean=0.480, reward_bound=0.282, batch=176\n",
      "5518: loss=0.175, reward_mean=0.520, reward_bound=0.136, batch=193\n",
      "5519: loss=0.171, reward_mean=0.520, reward_bound=0.206, batch=203\n",
      "5520: loss=0.174, reward_mean=0.350, reward_bound=0.160, batch=212\n",
      "5521: loss=0.171, reward_mean=0.420, reward_bound=0.229, batch=216\n",
      "5522: loss=0.171, reward_mean=0.500, reward_bound=0.254, batch=216\n",
      "5523: loss=0.174, reward_mean=0.450, reward_bound=0.268, batch=221\n",
      "5524: loss=0.173, reward_mean=0.310, reward_bound=0.282, batch=219\n",
      "5525: loss=0.173, reward_mean=0.410, reward_bound=0.206, batch=221\n",
      "5526: loss=0.186, reward_mean=0.400, reward_bound=0.314, batch=181\n",
      "5527: loss=0.186, reward_mean=0.430, reward_bound=0.150, batch=195\n",
      "5528: loss=0.184, reward_mean=0.410, reward_bound=0.185, batch=203\n",
      "5529: loss=0.187, reward_mean=0.490, reward_bound=0.229, batch=210\n",
      "5530: loss=0.188, reward_mean=0.330, reward_bound=0.254, batch=214\n",
      "5531: loss=0.184, reward_mean=0.500, reward_bound=0.282, batch=215\n",
      "5532: loss=0.186, reward_mean=0.450, reward_bound=0.314, batch=210\n",
      "5533: loss=0.186, reward_mean=0.490, reward_bound=0.282, batch=216\n",
      "5534: loss=0.177, reward_mean=0.410, reward_bound=0.349, batch=151\n",
      "5535: loss=0.183, reward_mean=0.400, reward_bound=0.031, batch=175\n",
      "5536: loss=0.180, reward_mean=0.360, reward_bound=0.082, batch=192\n",
      "5537: loss=0.182, reward_mean=0.440, reward_bound=0.122, batch=200\n",
      "5538: loss=0.182, reward_mean=0.420, reward_bound=0.162, batch=210\n",
      "5539: loss=0.182, reward_mean=0.430, reward_bound=0.167, batch=216\n",
      "5540: loss=0.177, reward_mean=0.440, reward_bound=0.185, batch=218\n",
      "5541: loss=0.176, reward_mean=0.490, reward_bound=0.206, batch=216\n",
      "5542: loss=0.183, reward_mean=0.440, reward_bound=0.229, batch=209\n",
      "5543: loss=0.183, reward_mean=0.420, reward_bound=0.206, batch=214\n",
      "5544: loss=0.187, reward_mean=0.490, reward_bound=0.254, batch=209\n",
      "5545: loss=0.184, reward_mean=0.420, reward_bound=0.265, batch=216\n",
      "5546: loss=0.184, reward_mean=0.460, reward_bound=0.282, batch=213\n",
      "5547: loss=0.183, reward_mean=0.400, reward_bound=0.206, batch=218\n",
      "5548: loss=0.183, reward_mean=0.520, reward_bound=0.254, batch=221\n",
      "5549: loss=0.181, reward_mean=0.360, reward_bound=0.282, batch=223\n",
      "5550: loss=0.178, reward_mean=0.450, reward_bound=0.314, batch=212\n",
      "5551: loss=0.177, reward_mean=0.350, reward_bound=0.324, batch=218\n",
      "5552: loss=0.175, reward_mean=0.420, reward_bound=0.349, batch=205\n",
      "5553: loss=0.177, reward_mean=0.410, reward_bound=0.289, batch=213\n",
      "5554: loss=0.175, reward_mean=0.530, reward_bound=0.314, batch=216\n",
      "5555: loss=0.175, reward_mean=0.470, reward_bound=0.349, batch=219\n",
      "5556: loss=0.185, reward_mean=0.530, reward_bound=0.387, batch=151\n",
      "5557: loss=0.182, reward_mean=0.400, reward_bound=0.052, batch=174\n",
      "5558: loss=0.182, reward_mean=0.450, reward_bound=0.108, batch=192\n",
      "5559: loss=0.184, reward_mean=0.430, reward_bound=0.135, batch=200\n",
      "5560: loss=0.182, reward_mean=0.420, reward_bound=0.131, batch=210\n",
      "5561: loss=0.186, reward_mean=0.410, reward_bound=0.167, batch=208\n",
      "5562: loss=0.190, reward_mean=0.510, reward_bound=0.185, batch=212\n",
      "5563: loss=0.189, reward_mean=0.440, reward_bound=0.206, batch=227\n",
      "5564: loss=0.183, reward_mean=0.360, reward_bound=0.206, batch=221\n",
      "5565: loss=0.187, reward_mean=0.410, reward_bound=0.229, batch=213\n",
      "5566: loss=0.184, reward_mean=0.440, reward_bound=0.254, batch=206\n",
      "5567: loss=0.185, reward_mean=0.460, reward_bound=0.268, batch=214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5568: loss=0.187, reward_mean=0.420, reward_bound=0.280, batch=220\n",
      "5569: loss=0.189, reward_mean=0.460, reward_bound=0.282, batch=213\n",
      "5570: loss=0.189, reward_mean=0.430, reward_bound=0.282, batch=218\n",
      "5571: loss=0.189, reward_mean=0.430, reward_bound=0.314, batch=213\n",
      "5572: loss=0.184, reward_mean=0.380, reward_bound=0.349, batch=205\n",
      "5573: loss=0.185, reward_mean=0.370, reward_bound=0.234, batch=213\n",
      "5574: loss=0.184, reward_mean=0.440, reward_bound=0.271, batch=219\n",
      "5575: loss=0.177, reward_mean=0.430, reward_bound=0.282, batch=217\n",
      "5576: loss=0.177, reward_mean=0.450, reward_bound=0.308, batch=222\n",
      "5577: loss=0.180, reward_mean=0.450, reward_bound=0.272, batch=225\n",
      "5578: loss=0.185, reward_mean=0.430, reward_bound=0.349, batch=225\n",
      "5579: loss=0.184, reward_mean=0.440, reward_bound=0.329, batch=227\n",
      "5580: loss=0.184, reward_mean=0.420, reward_bound=0.308, batch=229\n",
      "5581: loss=0.186, reward_mean=0.390, reward_bound=0.387, batch=198\n",
      "5582: loss=0.184, reward_mean=0.450, reward_bound=0.229, batch=207\n",
      "5583: loss=0.182, reward_mean=0.460, reward_bound=0.277, batch=215\n",
      "5584: loss=0.181, reward_mean=0.360, reward_bound=0.234, batch=220\n",
      "5585: loss=0.180, reward_mean=0.450, reward_bound=0.304, batch=224\n",
      "5586: loss=0.186, reward_mean=0.410, reward_bound=0.314, batch=222\n",
      "5587: loss=0.185, reward_mean=0.430, reward_bound=0.349, batch=220\n",
      "5588: loss=0.185, reward_mean=0.520, reward_bound=0.365, batch=224\n",
      "5589: loss=0.185, reward_mean=0.390, reward_bound=0.349, batch=226\n",
      "5590: loss=0.186, reward_mean=0.410, reward_bound=0.387, batch=216\n",
      "5591: loss=0.187, reward_mean=0.410, reward_bound=0.316, batch=221\n",
      "5592: loss=0.187, reward_mean=0.390, reward_bound=0.282, batch=224\n",
      "5593: loss=0.188, reward_mean=0.470, reward_bound=0.349, batch=226\n",
      "5594: loss=0.186, reward_mean=0.390, reward_bound=0.387, batch=226\n",
      "5595: loss=0.179, reward_mean=0.500, reward_bound=0.430, batch=110\n",
      "5596: loss=0.174, reward_mean=0.320, reward_bound=0.000, batch=142\n",
      "5597: loss=0.175, reward_mean=0.480, reward_bound=0.026, batch=169\n",
      "5598: loss=0.179, reward_mean=0.420, reward_bound=0.055, batch=188\n",
      "5599: loss=0.172, reward_mean=0.440, reward_bound=0.072, batch=200\n",
      "5600: loss=0.170, reward_mean=0.400, reward_bound=0.098, batch=204\n",
      "5601: loss=0.164, reward_mean=0.360, reward_bound=0.122, batch=210\n",
      "5602: loss=0.170, reward_mean=0.400, reward_bound=0.146, batch=217\n",
      "5603: loss=0.169, reward_mean=0.340, reward_bound=0.150, batch=218\n",
      "5604: loss=0.173, reward_mean=0.490, reward_bound=0.169, batch=222\n",
      "5605: loss=0.168, reward_mean=0.520, reward_bound=0.206, batch=229\n",
      "5606: loss=0.162, reward_mean=0.610, reward_bound=0.206, batch=225\n",
      "5607: loss=0.157, reward_mean=0.480, reward_bound=0.229, batch=218\n",
      "5608: loss=0.154, reward_mean=0.550, reward_bound=0.254, batch=207\n",
      "5609: loss=0.151, reward_mean=0.550, reward_bound=0.245, batch=215\n",
      "5610: loss=0.155, reward_mean=0.380, reward_bound=0.282, batch=202\n",
      "5611: loss=0.151, reward_mean=0.430, reward_bound=0.206, batch=212\n",
      "5612: loss=0.152, reward_mean=0.340, reward_bound=0.206, batch=220\n",
      "5613: loss=0.152, reward_mean=0.430, reward_bound=0.206, batch=226\n",
      "5614: loss=0.152, reward_mean=0.450, reward_bound=0.254, batch=223\n",
      "5615: loss=0.151, reward_mean=0.440, reward_bound=0.211, batch=226\n",
      "5616: loss=0.159, reward_mean=0.450, reward_bound=0.314, batch=208\n",
      "5617: loss=0.157, reward_mean=0.430, reward_bound=0.286, batch=215\n",
      "5618: loss=0.159, reward_mean=0.420, reward_bound=0.314, batch=217\n",
      "5619: loss=0.159, reward_mean=0.450, reward_bound=0.229, batch=220\n",
      "5620: loss=0.165, reward_mean=0.440, reward_bound=0.349, batch=193\n",
      "5621: loss=0.164, reward_mean=0.450, reward_bound=0.282, batch=204\n",
      "5622: loss=0.168, reward_mean=0.480, reward_bound=0.280, batch=213\n",
      "5623: loss=0.167, reward_mean=0.420, reward_bound=0.282, batch=216\n",
      "5624: loss=0.165, reward_mean=0.490, reward_bound=0.314, batch=215\n",
      "5625: loss=0.164, reward_mean=0.410, reward_bound=0.254, batch=219\n",
      "5626: loss=0.162, reward_mean=0.450, reward_bound=0.314, batch=222\n",
      "5627: loss=0.167, reward_mean=0.490, reward_bound=0.360, batch=225\n",
      "5628: loss=0.169, reward_mean=0.420, reward_bound=0.303, batch=227\n",
      "5629: loss=0.168, reward_mean=0.450, reward_bound=0.380, batch=229\n",
      "5630: loss=0.173, reward_mean=0.510, reward_bound=0.387, batch=186\n",
      "5631: loss=0.176, reward_mean=0.470, reward_bound=0.135, batch=199\n",
      "5632: loss=0.171, reward_mean=0.430, reward_bound=0.174, batch=209\n",
      "5633: loss=0.169, reward_mean=0.400, reward_bound=0.194, batch=216\n",
      "5634: loss=0.164, reward_mean=0.390, reward_bound=0.229, batch=215\n",
      "5635: loss=0.164, reward_mean=0.380, reward_bound=0.282, batch=212\n",
      "5636: loss=0.163, reward_mean=0.500, reward_bound=0.292, batch=218\n",
      "5637: loss=0.166, reward_mean=0.440, reward_bound=0.314, batch=218\n",
      "5638: loss=0.163, reward_mean=0.440, reward_bound=0.286, batch=222\n",
      "5639: loss=0.164, reward_mean=0.420, reward_bound=0.263, batch=225\n",
      "5640: loss=0.163, reward_mean=0.370, reward_bound=0.321, batch=227\n",
      "5641: loss=0.164, reward_mean=0.420, reward_bound=0.342, batch=229\n",
      "5642: loss=0.162, reward_mean=0.420, reward_bound=0.349, batch=216\n",
      "5643: loss=0.163, reward_mean=0.400, reward_bound=0.298, batch=221\n",
      "5644: loss=0.163, reward_mean=0.420, reward_bound=0.254, batch=224\n",
      "5645: loss=0.163, reward_mean=0.410, reward_bound=0.311, batch=227\n",
      "5646: loss=0.165, reward_mean=0.450, reward_bound=0.314, batch=226\n",
      "5647: loss=0.161, reward_mean=0.490, reward_bound=0.349, batch=226\n",
      "5648: loss=0.167, reward_mean=0.540, reward_bound=0.387, batch=217\n",
      "5649: loss=0.165, reward_mean=0.420, reward_bound=0.380, batch=222\n",
      "5650: loss=0.163, reward_mean=0.430, reward_bound=0.236, batch=225\n",
      "5651: loss=0.165, reward_mean=0.520, reward_bound=0.356, batch=227\n",
      "5652: loss=0.166, reward_mean=0.400, reward_bound=0.349, batch=228\n",
      "5653: loss=0.168, reward_mean=0.400, reward_bound=0.392, batch=229\n",
      "5654: loss=0.172, reward_mean=0.360, reward_bound=0.430, batch=177\n",
      "5655: loss=0.171, reward_mean=0.370, reward_bound=0.147, batch=194\n",
      "5656: loss=0.176, reward_mean=0.440, reward_bound=0.150, batch=205\n",
      "5657: loss=0.175, reward_mean=0.340, reward_bound=0.134, batch=213\n",
      "5658: loss=0.173, reward_mean=0.510, reward_bound=0.206, batch=218\n",
      "5659: loss=0.176, reward_mean=0.440, reward_bound=0.254, batch=213\n",
      "5660: loss=0.175, reward_mean=0.400, reward_bound=0.282, batch=207\n",
      "5661: loss=0.174, reward_mean=0.480, reward_bound=0.229, batch=214\n",
      "5662: loss=0.174, reward_mean=0.460, reward_bound=0.282, batch=219\n",
      "5663: loss=0.168, reward_mean=0.420, reward_bound=0.314, batch=211\n",
      "5664: loss=0.169, reward_mean=0.280, reward_bound=0.254, batch=217\n",
      "5665: loss=0.171, reward_mean=0.370, reward_bound=0.277, batch=222\n",
      "5666: loss=0.170, reward_mean=0.400, reward_bound=0.254, batch=224\n",
      "5667: loss=0.169, reward_mean=0.380, reward_bound=0.282, batch=223\n",
      "5668: loss=0.168, reward_mean=0.410, reward_bound=0.301, batch=226\n",
      "5669: loss=0.171, reward_mean=0.350, reward_bound=0.314, batch=225\n",
      "5670: loss=0.173, reward_mean=0.460, reward_bound=0.349, batch=208\n",
      "5671: loss=0.177, reward_mean=0.460, reward_bound=0.231, batch=215\n",
      "5672: loss=0.175, reward_mean=0.300, reward_bound=0.254, batch=219\n",
      "5673: loss=0.173, reward_mean=0.370, reward_bound=0.314, batch=222\n",
      "5674: loss=0.173, reward_mean=0.390, reward_bound=0.349, batch=223\n",
      "5675: loss=0.173, reward_mean=0.370, reward_bound=0.345, batch=226\n",
      "5676: loss=0.173, reward_mean=0.410, reward_bound=0.349, batch=227\n",
      "5677: loss=0.169, reward_mean=0.420, reward_bound=0.387, batch=212\n",
      "5678: loss=0.163, reward_mean=0.400, reward_bound=0.161, batch=218\n",
      "5679: loss=0.165, reward_mean=0.420, reward_bound=0.206, batch=221\n",
      "5680: loss=0.163, reward_mean=0.500, reward_bound=0.282, batch=224\n",
      "5681: loss=0.162, reward_mean=0.410, reward_bound=0.311, batch=227\n",
      "5682: loss=0.165, reward_mean=0.490, reward_bound=0.349, batch=228\n",
      "5683: loss=0.167, reward_mean=0.460, reward_bound=0.387, batch=224\n",
      "5684: loss=0.168, reward_mean=0.420, reward_bound=0.430, batch=205\n",
      "5685: loss=0.172, reward_mean=0.400, reward_bound=0.296, batch=213\n",
      "5686: loss=0.167, reward_mean=0.420, reward_bound=0.349, batch=216\n",
      "5687: loss=0.165, reward_mean=0.370, reward_bound=0.207, batch=221\n",
      "5688: loss=0.169, reward_mean=0.430, reward_bound=0.314, batch=224\n",
      "5689: loss=0.169, reward_mean=0.430, reward_bound=0.349, batch=225\n",
      "5690: loss=0.169, reward_mean=0.510, reward_bound=0.349, batch=225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5691: loss=0.168, reward_mean=0.460, reward_bound=0.387, batch=221\n",
      "5692: loss=0.170, reward_mean=0.480, reward_bound=0.282, batch=224\n",
      "5693: loss=0.171, reward_mean=0.400, reward_bound=0.314, batch=226\n",
      "5694: loss=0.175, reward_mean=0.450, reward_bound=0.349, batch=227\n",
      "5695: loss=0.177, reward_mean=0.360, reward_bound=0.373, batch=229\n",
      "5696: loss=0.173, reward_mean=0.380, reward_bound=0.387, batch=226\n",
      "5697: loss=0.173, reward_mean=0.430, reward_bound=0.368, batch=228\n",
      "5698: loss=0.167, reward_mean=0.420, reward_bound=0.430, batch=220\n",
      "5699: loss=0.169, reward_mean=0.440, reward_bound=0.314, batch=223\n",
      "5700: loss=0.166, reward_mean=0.470, reward_bound=0.387, batch=225\n",
      "5701: loss=0.166, reward_mean=0.400, reward_bound=0.365, batch=227\n",
      "5702: loss=0.165, reward_mean=0.470, reward_bound=0.414, batch=229\n",
      "5703: loss=0.165, reward_mean=0.460, reward_bound=0.430, batch=223\n",
      "5704: loss=0.167, reward_mean=0.420, reward_bound=0.413, batch=226\n",
      "5705: loss=0.169, reward_mean=0.430, reward_bound=0.351, batch=228\n",
      "5706: loss=0.167, reward_mean=0.410, reward_bound=0.392, batch=229\n",
      "5707: loss=0.166, reward_mean=0.370, reward_bound=0.430, batch=227\n",
      "5708: loss=0.169, reward_mean=0.410, reward_bound=0.277, batch=229\n",
      "5709: loss=0.169, reward_mean=0.410, reward_bound=0.450, batch=230\n",
      "5710: loss=0.168, reward_mean=0.410, reward_bound=0.304, batch=231\n",
      "5711: loss=0.169, reward_mean=0.390, reward_bound=0.430, batch=230\n",
      "5712: loss=0.169, reward_mean=0.350, reward_bound=0.390, batch=231\n",
      "5713: loss=0.182, reward_mean=0.400, reward_bound=0.478, batch=108\n",
      "5714: loss=0.170, reward_mean=0.490, reward_bound=0.014, batch=145\n",
      "5715: loss=0.177, reward_mean=0.490, reward_bound=0.032, batch=171\n",
      "5716: loss=0.178, reward_mean=0.410, reward_bound=0.042, batch=189\n",
      "5717: loss=0.185, reward_mean=0.370, reward_bound=0.072, batch=200\n",
      "5718: loss=0.196, reward_mean=0.400, reward_bound=0.098, batch=207\n",
      "5719: loss=0.188, reward_mean=0.470, reward_bound=0.109, batch=224\n",
      "5720: loss=0.184, reward_mean=0.370, reward_bound=0.122, batch=221\n",
      "5721: loss=0.186, reward_mean=0.410, reward_bound=0.150, batch=223\n",
      "5722: loss=0.183, reward_mean=0.370, reward_bound=0.167, batch=224\n",
      "5723: loss=0.184, reward_mean=0.430, reward_bound=0.185, batch=223\n",
      "5724: loss=0.187, reward_mean=0.380, reward_bound=0.206, batch=210\n",
      "5725: loss=0.185, reward_mean=0.380, reward_bound=0.229, batch=204\n",
      "5726: loss=0.185, reward_mean=0.440, reward_bound=0.206, batch=212\n",
      "5727: loss=0.186, reward_mean=0.400, reward_bound=0.254, batch=204\n",
      "5728: loss=0.180, reward_mean=0.380, reward_bound=0.164, batch=213\n",
      "5729: loss=0.182, reward_mean=0.390, reward_bound=0.206, batch=216\n",
      "5730: loss=0.181, reward_mean=0.370, reward_bound=0.229, batch=218\n",
      "5731: loss=0.183, reward_mean=0.420, reward_bound=0.254, batch=220\n",
      "5732: loss=0.181, reward_mean=0.330, reward_bound=0.274, batch=224\n",
      "5733: loss=0.178, reward_mean=0.470, reward_bound=0.282, batch=212\n",
      "5734: loss=0.179, reward_mean=0.330, reward_bound=0.263, batch=218\n",
      "5735: loss=0.172, reward_mean=0.500, reward_bound=0.314, batch=192\n",
      "5736: loss=0.174, reward_mean=0.340, reward_bound=0.135, batch=203\n",
      "5737: loss=0.170, reward_mean=0.390, reward_bound=0.185, batch=209\n",
      "5738: loss=0.169, reward_mean=0.460, reward_bound=0.229, batch=214\n",
      "5739: loss=0.169, reward_mean=0.380, reward_bound=0.254, batch=218\n",
      "5740: loss=0.170, reward_mean=0.470, reward_bound=0.286, batch=222\n",
      "5741: loss=0.171, reward_mean=0.360, reward_bound=0.282, batch=224\n",
      "5742: loss=0.170, reward_mean=0.420, reward_bound=0.314, batch=225\n",
      "5743: loss=0.181, reward_mean=0.440, reward_bound=0.349, batch=197\n",
      "5744: loss=0.179, reward_mean=0.470, reward_bound=0.224, batch=208\n",
      "5745: loss=0.181, reward_mean=0.450, reward_bound=0.190, batch=215\n",
      "5746: loss=0.181, reward_mean=0.350, reward_bound=0.229, batch=218\n",
      "5747: loss=0.175, reward_mean=0.510, reward_bound=0.282, batch=219\n",
      "5748: loss=0.177, reward_mean=0.470, reward_bound=0.314, batch=218\n",
      "5749: loss=0.176, reward_mean=0.450, reward_bound=0.257, batch=222\n",
      "5750: loss=0.175, reward_mean=0.410, reward_bound=0.263, batch=225\n",
      "5751: loss=0.177, reward_mean=0.420, reward_bound=0.282, batch=225\n",
      "5752: loss=0.177, reward_mean=0.400, reward_bound=0.321, batch=227\n",
      "5753: loss=0.178, reward_mean=0.350, reward_bound=0.349, batch=223\n",
      "5754: loss=0.176, reward_mean=0.520, reward_bound=0.358, batch=226\n",
      "5755: loss=0.176, reward_mean=0.460, reward_bound=0.321, batch=228\n",
      "5756: loss=0.176, reward_mean=0.320, reward_bound=0.349, batch=228\n",
      "5757: loss=0.176, reward_mean=0.460, reward_bound=0.353, batch=229\n",
      "5758: loss=0.173, reward_mean=0.420, reward_bound=0.387, batch=192\n",
      "5759: loss=0.172, reward_mean=0.380, reward_bound=0.092, batch=204\n",
      "5760: loss=0.174, reward_mean=0.380, reward_bound=0.135, batch=212\n",
      "5761: loss=0.171, reward_mean=0.360, reward_bound=0.167, batch=217\n",
      "5762: loss=0.167, reward_mean=0.420, reward_bound=0.229, batch=220\n",
      "5763: loss=0.168, reward_mean=0.400, reward_bound=0.254, batch=221\n",
      "5764: loss=0.169, reward_mean=0.360, reward_bound=0.282, batch=219\n",
      "5765: loss=0.168, reward_mean=0.380, reward_bound=0.239, batch=223\n",
      "5766: loss=0.173, reward_mean=0.420, reward_bound=0.314, batch=219\n",
      "5767: loss=0.172, reward_mean=0.390, reward_bound=0.328, batch=223\n",
      "5768: loss=0.171, reward_mean=0.440, reward_bound=0.301, batch=226\n",
      "5769: loss=0.174, reward_mean=0.490, reward_bound=0.349, batch=221\n",
      "5770: loss=0.172, reward_mean=0.310, reward_bound=0.387, batch=212\n",
      "5771: loss=0.176, reward_mean=0.360, reward_bound=0.272, batch=218\n",
      "5772: loss=0.174, reward_mean=0.400, reward_bound=0.314, batch=221\n",
      "5773: loss=0.176, reward_mean=0.330, reward_bound=0.254, batch=223\n",
      "5774: loss=0.171, reward_mean=0.500, reward_bound=0.349, batch=224\n",
      "5775: loss=0.171, reward_mean=0.410, reward_bound=0.282, batch=226\n",
      "5776: loss=0.170, reward_mean=0.510, reward_bound=0.349, batch=226\n",
      "5777: loss=0.169, reward_mean=0.430, reward_bound=0.387, batch=221\n",
      "5778: loss=0.166, reward_mean=0.430, reward_bound=0.430, batch=175\n",
      "5779: loss=0.171, reward_mean=0.340, reward_bound=0.135, batch=191\n",
      "5780: loss=0.166, reward_mean=0.400, reward_bound=0.122, batch=203\n",
      "5781: loss=0.166, reward_mean=0.570, reward_bound=0.185, batch=210\n",
      "5782: loss=0.165, reward_mean=0.430, reward_bound=0.229, batch=210\n",
      "5783: loss=0.162, reward_mean=0.490, reward_bound=0.254, batch=216\n",
      "5784: loss=0.162, reward_mean=0.380, reward_bound=0.282, batch=215\n",
      "5785: loss=0.163, reward_mean=0.460, reward_bound=0.314, batch=215\n",
      "5786: loss=0.165, reward_mean=0.400, reward_bound=0.282, batch=219\n",
      "5787: loss=0.163, reward_mean=0.340, reward_bound=0.215, batch=223\n",
      "5788: loss=0.164, reward_mean=0.470, reward_bound=0.290, batch=226\n",
      "5789: loss=0.166, reward_mean=0.380, reward_bound=0.331, batch=228\n",
      "5790: loss=0.166, reward_mean=0.420, reward_bound=0.317, batch=229\n",
      "5791: loss=0.169, reward_mean=0.340, reward_bound=0.349, batch=208\n",
      "5792: loss=0.169, reward_mean=0.350, reward_bound=0.206, batch=213\n",
      "5793: loss=0.172, reward_mean=0.490, reward_bound=0.254, batch=218\n",
      "5794: loss=0.172, reward_mean=0.460, reward_bound=0.254, batch=221\n",
      "5795: loss=0.171, reward_mean=0.450, reward_bound=0.314, batch=221\n",
      "5796: loss=0.169, reward_mean=0.430, reward_bound=0.349, batch=220\n",
      "5797: loss=0.170, reward_mean=0.420, reward_bound=0.365, batch=224\n",
      "5798: loss=0.169, reward_mean=0.340, reward_bound=0.282, batch=226\n",
      "5799: loss=0.169, reward_mean=0.350, reward_bound=0.349, batch=226\n",
      "5800: loss=0.168, reward_mean=0.420, reward_bound=0.368, batch=228\n",
      "5801: loss=0.168, reward_mean=0.460, reward_bound=0.387, batch=211\n",
      "5802: loss=0.170, reward_mean=0.440, reward_bound=0.349, batch=216\n",
      "5803: loss=0.169, reward_mean=0.330, reward_bound=0.298, batch=221\n",
      "5804: loss=0.169, reward_mean=0.350, reward_bound=0.254, batch=224\n",
      "5805: loss=0.167, reward_mean=0.420, reward_bound=0.349, batch=225\n",
      "5806: loss=0.170, reward_mean=0.370, reward_bound=0.387, batch=222\n",
      "5807: loss=0.170, reward_mean=0.420, reward_bound=0.336, batch=225\n",
      "5808: loss=0.169, reward_mean=0.340, reward_bound=0.356, batch=227\n",
      "5809: loss=0.170, reward_mean=0.430, reward_bound=0.342, batch=229\n",
      "5810: loss=0.168, reward_mean=0.580, reward_bound=0.364, batch=230\n",
      "5811: loss=0.170, reward_mean=0.370, reward_bound=0.387, batch=230\n",
      "5812: loss=0.172, reward_mean=0.440, reward_bound=0.430, batch=207\n",
      "5813: loss=0.177, reward_mean=0.420, reward_bound=0.314, batch=213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5814: loss=0.175, reward_mean=0.450, reward_bound=0.282, batch=218\n",
      "5815: loss=0.174, reward_mean=0.460, reward_bound=0.260, batch=222\n",
      "5816: loss=0.175, reward_mean=0.480, reward_bound=0.314, batch=222\n",
      "5817: loss=0.176, reward_mean=0.400, reward_bound=0.324, batch=225\n",
      "5818: loss=0.177, reward_mean=0.350, reward_bound=0.349, batch=222\n",
      "5819: loss=0.176, reward_mean=0.480, reward_bound=0.360, batch=225\n",
      "5820: loss=0.176, reward_mean=0.440, reward_bound=0.387, batch=226\n",
      "5821: loss=0.174, reward_mean=0.480, reward_bound=0.409, batch=228\n",
      "5822: loss=0.174, reward_mean=0.370, reward_bound=0.387, batch=228\n",
      "5823: loss=0.173, reward_mean=0.400, reward_bound=0.430, batch=217\n",
      "5824: loss=0.174, reward_mean=0.380, reward_bound=0.335, batch=222\n",
      "5825: loss=0.175, reward_mean=0.440, reward_bound=0.349, batch=223\n",
      "5826: loss=0.174, reward_mean=0.400, reward_bound=0.387, batch=220\n",
      "5827: loss=0.176, reward_mean=0.420, reward_bound=0.282, batch=222\n",
      "5828: loss=0.177, reward_mean=0.410, reward_bound=0.213, batch=225\n",
      "5829: loss=0.175, reward_mean=0.370, reward_bound=0.260, batch=227\n",
      "5830: loss=0.175, reward_mean=0.410, reward_bound=0.314, batch=228\n",
      "5831: loss=0.175, reward_mean=0.390, reward_bound=0.387, batch=226\n",
      "5832: loss=0.175, reward_mean=0.430, reward_bound=0.241, batch=228\n",
      "5833: loss=0.175, reward_mean=0.400, reward_bound=0.387, batch=227\n",
      "5834: loss=0.175, reward_mean=0.410, reward_bound=0.335, batch=229\n",
      "5835: loss=0.175, reward_mean=0.370, reward_bound=0.309, batch=230\n",
      "5836: loss=0.174, reward_mean=0.420, reward_bound=0.376, batch=231\n",
      "5837: loss=0.176, reward_mean=0.450, reward_bound=0.387, batch=230\n",
      "5838: loss=0.177, reward_mean=0.450, reward_bound=0.430, batch=227\n",
      "5839: loss=0.177, reward_mean=0.450, reward_bound=0.349, batch=228\n",
      "5840: loss=0.178, reward_mean=0.360, reward_bound=0.392, batch=229\n",
      "5841: loss=0.176, reward_mean=0.490, reward_bound=0.450, batch=230\n",
      "5842: loss=0.176, reward_mean=0.390, reward_bound=0.365, batch=231\n",
      "5843: loss=0.176, reward_mean=0.350, reward_bound=0.430, batch=231\n",
      "5844: loss=0.179, reward_mean=0.390, reward_bound=0.478, batch=149\n",
      "5845: loss=0.181, reward_mean=0.390, reward_bound=0.049, batch=174\n",
      "5846: loss=0.176, reward_mean=0.460, reward_bound=0.058, batch=191\n",
      "5847: loss=0.177, reward_mean=0.390, reward_bound=0.089, batch=201\n",
      "5848: loss=0.174, reward_mean=0.300, reward_bound=0.109, batch=210\n",
      "5849: loss=0.177, reward_mean=0.450, reward_bound=0.150, batch=216\n",
      "5850: loss=0.179, reward_mean=0.440, reward_bound=0.167, batch=220\n",
      "5851: loss=0.179, reward_mean=0.440, reward_bound=0.206, batch=229\n",
      "5852: loss=0.180, reward_mean=0.430, reward_bound=0.229, batch=225\n",
      "5853: loss=0.178, reward_mean=0.370, reward_bound=0.254, batch=221\n",
      "5854: loss=0.184, reward_mean=0.440, reward_bound=0.282, batch=208\n",
      "5855: loss=0.178, reward_mean=0.350, reward_bound=0.211, batch=215\n",
      "5856: loss=0.180, reward_mean=0.370, reward_bound=0.282, batch=219\n",
      "5857: loss=0.181, reward_mean=0.360, reward_bound=0.282, batch=222\n",
      "5858: loss=0.179, reward_mean=0.300, reward_bound=0.292, batch=225\n",
      "5859: loss=0.183, reward_mean=0.390, reward_bound=0.314, batch=206\n",
      "5860: loss=0.184, reward_mean=0.440, reward_bound=0.268, batch=214\n",
      "5861: loss=0.183, reward_mean=0.500, reward_bound=0.282, batch=219\n",
      "5862: loss=0.181, reward_mean=0.410, reward_bound=0.314, batch=220\n",
      "5863: loss=0.180, reward_mean=0.340, reward_bound=0.266, batch=224\n",
      "5864: loss=0.179, reward_mean=0.370, reward_bound=0.345, batch=227\n",
      "5865: loss=0.178, reward_mean=0.380, reward_bound=0.349, batch=207\n",
      "5866: loss=0.179, reward_mean=0.390, reward_bound=0.308, batch=215\n",
      "5867: loss=0.179, reward_mean=0.400, reward_bound=0.289, batch=220\n",
      "5868: loss=0.178, reward_mean=0.420, reward_bound=0.296, batch=224\n",
      "5869: loss=0.176, reward_mean=0.460, reward_bound=0.311, batch=227\n",
      "5870: loss=0.179, reward_mean=0.510, reward_bound=0.314, batch=227\n",
      "5871: loss=0.178, reward_mean=0.410, reward_bound=0.335, batch=229\n",
      "5872: loss=0.179, reward_mean=0.470, reward_bound=0.328, batch=230\n",
      "5873: loss=0.178, reward_mean=0.380, reward_bound=0.349, batch=227\n",
      "5874: loss=0.182, reward_mean=0.380, reward_bound=0.308, batch=229\n",
      "5875: loss=0.180, reward_mean=0.310, reward_bound=0.314, batch=229\n",
      "5876: loss=0.178, reward_mean=0.440, reward_bound=0.349, batch=228\n",
      "5877: loss=0.178, reward_mean=0.500, reward_bound=0.387, batch=201\n",
      "5878: loss=0.183, reward_mean=0.380, reward_bound=0.185, batch=209\n",
      "5879: loss=0.183, reward_mean=0.440, reward_bound=0.206, batch=215\n",
      "5880: loss=0.182, reward_mean=0.300, reward_bound=0.210, batch=220\n",
      "5881: loss=0.179, reward_mean=0.480, reward_bound=0.254, batch=222\n",
      "5882: loss=0.177, reward_mean=0.380, reward_bound=0.314, batch=221\n",
      "5883: loss=0.179, reward_mean=0.310, reward_bound=0.254, batch=224\n",
      "5884: loss=0.177, reward_mean=0.420, reward_bound=0.349, batch=223\n",
      "5885: loss=0.179, reward_mean=0.420, reward_bound=0.387, batch=220\n",
      "5886: loss=0.178, reward_mean=0.390, reward_bound=0.314, batch=223\n",
      "5887: loss=0.177, reward_mean=0.460, reward_bound=0.413, batch=226\n",
      "5888: loss=0.179, reward_mean=0.360, reward_bound=0.390, batch=228\n",
      "5889: loss=0.178, reward_mean=0.400, reward_bound=0.392, batch=229\n",
      "5890: loss=0.179, reward_mean=0.430, reward_bound=0.405, batch=230\n",
      "5891: loss=0.179, reward_mean=0.470, reward_bound=0.418, batch=231\n",
      "5892: loss=0.177, reward_mean=0.410, reward_bound=0.430, batch=204\n",
      "5893: loss=0.175, reward_mean=0.430, reward_bound=0.202, batch=213\n",
      "5894: loss=0.178, reward_mean=0.450, reward_bound=0.244, batch=219\n",
      "5895: loss=0.175, reward_mean=0.420, reward_bound=0.282, batch=222\n",
      "5896: loss=0.180, reward_mean=0.490, reward_bound=0.314, batch=223\n",
      "5897: loss=0.179, reward_mean=0.390, reward_bound=0.314, batch=225\n",
      "5898: loss=0.180, reward_mean=0.360, reward_bound=0.349, batch=224\n",
      "5899: loss=0.179, reward_mean=0.490, reward_bound=0.345, batch=227\n",
      "5900: loss=0.180, reward_mean=0.500, reward_bound=0.380, batch=229\n",
      "5901: loss=0.178, reward_mean=0.440, reward_bound=0.387, batch=219\n",
      "5902: loss=0.181, reward_mean=0.430, reward_bound=0.328, batch=223\n",
      "5903: loss=0.178, reward_mean=0.440, reward_bound=0.372, batch=226\n",
      "5904: loss=0.177, reward_mean=0.420, reward_bound=0.368, batch=228\n",
      "5905: loss=0.177, reward_mean=0.460, reward_bound=0.353, batch=229\n",
      "5906: loss=0.180, reward_mean=0.350, reward_bound=0.387, batch=225\n",
      "5907: loss=0.181, reward_mean=0.370, reward_bound=0.387, batch=226\n",
      "5908: loss=0.180, reward_mean=0.510, reward_bound=0.409, batch=228\n",
      "5909: loss=0.181, reward_mean=0.500, reward_bound=0.392, batch=229\n",
      "5910: loss=0.178, reward_mean=0.470, reward_bound=0.430, batch=219\n",
      "5911: loss=0.177, reward_mean=0.450, reward_bound=0.349, batch=221\n",
      "5912: loss=0.176, reward_mean=0.360, reward_bound=0.387, batch=224\n",
      "5913: loss=0.176, reward_mean=0.410, reward_bound=0.345, batch=227\n",
      "5914: loss=0.177, reward_mean=0.440, reward_bound=0.380, batch=229\n",
      "5915: loss=0.177, reward_mean=0.440, reward_bound=0.387, batch=228\n",
      "5916: loss=0.177, reward_mean=0.370, reward_bound=0.392, batch=229\n",
      "5917: loss=0.177, reward_mean=0.420, reward_bound=0.430, batch=227\n",
      "5918: loss=0.177, reward_mean=0.420, reward_bound=0.460, batch=229\n",
      "5919: loss=0.176, reward_mean=0.490, reward_bound=0.478, batch=231\n",
      "5920: loss=0.176, reward_mean=0.480, reward_bound=0.430, batch=231\n",
      "5921: loss=0.176, reward_mean=0.340, reward_bound=0.430, batch=231\n",
      "5922: loss=0.176, reward_mean=0.360, reward_bound=0.349, batch=231\n",
      "5923: loss=0.175, reward_mean=0.440, reward_bound=0.478, batch=182\n",
      "5924: loss=0.175, reward_mean=0.410, reward_bound=0.155, batch=197\n",
      "5925: loss=0.176, reward_mean=0.430, reward_bound=0.167, batch=207\n",
      "5926: loss=0.175, reward_mean=0.450, reward_bound=0.185, batch=214\n",
      "5927: loss=0.182, reward_mean=0.420, reward_bound=0.206, batch=219\n",
      "5928: loss=0.178, reward_mean=0.390, reward_bound=0.229, batch=220\n",
      "5929: loss=0.180, reward_mean=0.390, reward_bound=0.254, batch=222\n",
      "5930: loss=0.177, reward_mean=0.370, reward_bound=0.282, batch=222\n",
      "5931: loss=0.179, reward_mean=0.380, reward_bound=0.314, batch=215\n",
      "5932: loss=0.179, reward_mean=0.370, reward_bound=0.260, batch=220\n",
      "5933: loss=0.179, reward_mean=0.410, reward_bound=0.274, batch=224\n",
      "5934: loss=0.178, reward_mean=0.460, reward_bound=0.280, batch=227\n",
      "5935: loss=0.177, reward_mean=0.450, reward_bound=0.314, batch=227\n",
      "5936: loss=0.173, reward_mean=0.340, reward_bound=0.349, batch=218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5937: loss=0.173, reward_mean=0.460, reward_bound=0.217, batch=222\n",
      "5938: loss=0.171, reward_mean=0.370, reward_bound=0.324, batch=225\n",
      "5939: loss=0.171, reward_mean=0.370, reward_bound=0.356, batch=227\n",
      "5940: loss=0.170, reward_mean=0.400, reward_bound=0.380, batch=229\n",
      "5941: loss=0.168, reward_mean=0.450, reward_bound=0.387, batch=216\n",
      "5942: loss=0.168, reward_mean=0.450, reward_bound=0.298, batch=221\n",
      "5943: loss=0.169, reward_mean=0.410, reward_bound=0.349, batch=224\n",
      "5944: loss=0.168, reward_mean=0.320, reward_bound=0.374, batch=227\n",
      "5945: loss=0.167, reward_mean=0.340, reward_bound=0.277, batch=229\n",
      "5946: loss=0.166, reward_mean=0.310, reward_bound=0.265, batch=230\n",
      "5947: loss=0.167, reward_mean=0.430, reward_bound=0.282, batch=230\n",
      "5948: loss=0.167, reward_mean=0.340, reward_bound=0.314, batch=230\n",
      "5949: loss=0.167, reward_mean=0.380, reward_bound=0.349, batch=230\n",
      "5950: loss=0.166, reward_mean=0.470, reward_bound=0.387, batch=229\n",
      "5951: loss=0.170, reward_mean=0.370, reward_bound=0.430, batch=207\n",
      "5952: loss=0.174, reward_mean=0.330, reward_bound=0.245, batch=215\n",
      "5953: loss=0.177, reward_mean=0.490, reward_bound=0.254, batch=215\n",
      "5954: loss=0.177, reward_mean=0.380, reward_bound=0.189, batch=220\n",
      "5955: loss=0.179, reward_mean=0.420, reward_bound=0.282, batch=223\n",
      "5956: loss=0.174, reward_mean=0.380, reward_bound=0.314, batch=225\n",
      "5957: loss=0.175, reward_mean=0.480, reward_bound=0.321, batch=227\n",
      "5958: loss=0.170, reward_mean=0.410, reward_bound=0.349, batch=225\n",
      "5959: loss=0.166, reward_mean=0.500, reward_bound=0.387, batch=219\n",
      "5960: loss=0.167, reward_mean=0.440, reward_bound=0.328, batch=223\n",
      "5961: loss=0.166, reward_mean=0.470, reward_bound=0.349, batch=223\n",
      "5962: loss=0.165, reward_mean=0.520, reward_bound=0.314, batch=224\n",
      "5963: loss=0.165, reward_mean=0.390, reward_bound=0.349, batch=226\n",
      "5964: loss=0.167, reward_mean=0.420, reward_bound=0.387, batch=227\n",
      "5965: loss=0.165, reward_mean=0.440, reward_bound=0.422, batch=229\n",
      "5966: loss=0.167, reward_mean=0.350, reward_bound=0.381, batch=230\n",
      "5967: loss=0.169, reward_mean=0.450, reward_bound=0.430, batch=218\n",
      "5968: loss=0.170, reward_mean=0.340, reward_bound=0.185, batch=220\n",
      "5969: loss=0.168, reward_mean=0.400, reward_bound=0.229, batch=223\n",
      "5970: loss=0.171, reward_mean=0.450, reward_bound=0.335, batch=226\n",
      "5971: loss=0.173, reward_mean=0.440, reward_bound=0.349, batch=227\n",
      "5972: loss=0.173, reward_mean=0.420, reward_bound=0.380, batch=229\n",
      "5973: loss=0.173, reward_mean=0.420, reward_bound=0.387, batch=226\n",
      "5974: loss=0.171, reward_mean=0.380, reward_bound=0.316, batch=228\n",
      "5975: loss=0.168, reward_mean=0.400, reward_bound=0.430, batch=224\n",
      "5976: loss=0.168, reward_mean=0.460, reward_bound=0.349, batch=226\n",
      "5977: loss=0.168, reward_mean=0.430, reward_bound=0.368, batch=228\n",
      "5978: loss=0.169, reward_mean=0.460, reward_bound=0.387, batch=228\n",
      "5979: loss=0.168, reward_mean=0.500, reward_bound=0.435, batch=229\n",
      "5980: loss=0.168, reward_mean=0.520, reward_bound=0.478, batch=231\n",
      "5981: loss=0.173, reward_mean=0.390, reward_bound=0.478, batch=203\n",
      "5982: loss=0.177, reward_mean=0.380, reward_bound=0.254, batch=211\n",
      "5983: loss=0.177, reward_mean=0.500, reward_bound=0.282, batch=216\n",
      "5984: loss=0.173, reward_mean=0.330, reward_bound=0.314, batch=216\n",
      "5985: loss=0.171, reward_mean=0.540, reward_bound=0.331, batch=221\n",
      "5986: loss=0.170, reward_mean=0.460, reward_bound=0.314, batch=224\n",
      "5987: loss=0.172, reward_mean=0.430, reward_bound=0.349, batch=224\n",
      "5988: loss=0.171, reward_mean=0.430, reward_bound=0.349, batch=226\n",
      "5989: loss=0.174, reward_mean=0.390, reward_bound=0.387, batch=218\n",
      "5990: loss=0.177, reward_mean=0.470, reward_bound=0.349, batch=221\n",
      "5991: loss=0.176, reward_mean=0.410, reward_bound=0.314, batch=223\n",
      "5992: loss=0.176, reward_mean=0.410, reward_bound=0.311, batch=226\n",
      "5993: loss=0.172, reward_mean=0.400, reward_bound=0.387, batch=225\n",
      "5994: loss=0.172, reward_mean=0.450, reward_bound=0.356, batch=227\n",
      "5995: loss=0.172, reward_mean=0.390, reward_bound=0.387, batch=227\n",
      "5996: loss=0.174, reward_mean=0.400, reward_bound=0.349, batch=228\n",
      "5997: loss=0.171, reward_mean=0.390, reward_bound=0.392, batch=229\n",
      "5998: loss=0.171, reward_mean=0.360, reward_bound=0.360, batch=230\n",
      "5999: loss=0.171, reward_mean=0.370, reward_bound=0.418, batch=231\n",
      "6000: loss=0.175, reward_mean=0.460, reward_bound=0.430, batch=220\n",
      "6001: loss=0.175, reward_mean=0.450, reward_bound=0.349, batch=222\n",
      "6002: loss=0.176, reward_mean=0.420, reward_bound=0.324, batch=225\n",
      "6003: loss=0.175, reward_mean=0.390, reward_bound=0.387, batch=222\n",
      "6004: loss=0.175, reward_mean=0.430, reward_bound=0.387, batch=224\n",
      "6005: loss=0.175, reward_mean=0.430, reward_bound=0.314, batch=226\n",
      "6006: loss=0.177, reward_mean=0.410, reward_bound=0.387, batch=227\n",
      "6007: loss=0.176, reward_mean=0.380, reward_bound=0.387, batch=228\n",
      "6008: loss=0.174, reward_mean=0.530, reward_bound=0.430, batch=224\n",
      "6009: loss=0.173, reward_mean=0.450, reward_bound=0.426, batch=227\n",
      "6010: loss=0.173, reward_mean=0.360, reward_bound=0.349, batch=228\n",
      "6011: loss=0.173, reward_mean=0.330, reward_bound=0.353, batch=229\n",
      "6012: loss=0.172, reward_mean=0.420, reward_bound=0.430, batch=229\n",
      "6013: loss=0.173, reward_mean=0.350, reward_bound=0.478, batch=231\n",
      "6014: loss=0.176, reward_mean=0.470, reward_bound=0.478, batch=216\n",
      "6015: loss=0.174, reward_mean=0.450, reward_bound=0.368, batch=221\n",
      "6016: loss=0.173, reward_mean=0.350, reward_bound=0.314, batch=223\n",
      "6017: loss=0.176, reward_mean=0.430, reward_bound=0.387, batch=223\n",
      "6018: loss=0.173, reward_mean=0.370, reward_bound=0.430, batch=224\n",
      "6019: loss=0.173, reward_mean=0.470, reward_bound=0.430, batch=224\n",
      "6020: loss=0.175, reward_mean=0.500, reward_bound=0.349, batch=226\n",
      "6021: loss=0.173, reward_mean=0.390, reward_bound=0.430, batch=227\n",
      "6022: loss=0.174, reward_mean=0.370, reward_bound=0.469, batch=229\n",
      "6023: loss=0.175, reward_mean=0.470, reward_bound=0.478, batch=231\n",
      "6024: loss=0.175, reward_mean=0.450, reward_bound=0.430, batch=231\n",
      "6025: loss=0.175, reward_mean=0.430, reward_bound=0.478, batch=221\n",
      "6026: loss=0.174, reward_mean=0.350, reward_bound=0.314, batch=222\n",
      "6027: loss=0.172, reward_mean=0.430, reward_bound=0.324, batch=225\n",
      "6028: loss=0.175, reward_mean=0.440, reward_bound=0.430, batch=224\n",
      "6029: loss=0.175, reward_mean=0.460, reward_bound=0.384, batch=227\n",
      "6030: loss=0.173, reward_mean=0.370, reward_bound=0.342, batch=229\n",
      "6031: loss=0.173, reward_mean=0.430, reward_bound=0.364, batch=230\n",
      "6032: loss=0.174, reward_mean=0.400, reward_bound=0.387, batch=228\n",
      "6033: loss=0.173, reward_mean=0.370, reward_bound=0.392, batch=229\n",
      "6034: loss=0.174, reward_mean=0.320, reward_bound=0.430, batch=229\n",
      "6035: loss=0.175, reward_mean=0.380, reward_bound=0.364, batch=230\n",
      "6036: loss=0.174, reward_mean=0.500, reward_bound=0.387, batch=229\n",
      "6037: loss=0.176, reward_mean=0.370, reward_bound=0.424, batch=230\n",
      "6038: loss=0.176, reward_mean=0.290, reward_bound=0.439, batch=231\n",
      "6039: loss=0.175, reward_mean=0.310, reward_bound=0.478, batch=227\n",
      "6040: loss=0.174, reward_mean=0.420, reward_bound=0.430, batch=228\n",
      "6041: loss=0.174, reward_mean=0.300, reward_bound=0.349, batch=228\n",
      "6042: loss=0.174, reward_mean=0.390, reward_bound=0.441, batch=229\n",
      "6043: loss=0.174, reward_mean=0.290, reward_bound=0.500, batch=230\n",
      "6044: loss=0.173, reward_mean=0.480, reward_bound=0.418, batch=231\n",
      "6045: loss=0.175, reward_mean=0.460, reward_bound=0.430, batch=231\n",
      "6046: loss=0.175, reward_mean=0.470, reward_bound=0.430, batch=231\n",
      "6047: loss=0.175, reward_mean=0.420, reward_bound=0.430, batch=231\n",
      "6048: loss=0.175, reward_mean=0.520, reward_bound=0.430, batch=231\n",
      "6049: loss=0.173, reward_mean=0.470, reward_bound=0.478, batch=231\n",
      "6050: loss=0.173, reward_mean=0.380, reward_bound=0.430, batch=231\n",
      "6051: loss=0.173, reward_mean=0.440, reward_bound=0.430, batch=231\n",
      "6052: loss=0.173, reward_mean=0.510, reward_bound=0.478, batch=231\n",
      "6054: loss=0.202, reward_mean=0.370, reward_bound=0.000, batch=37\n",
      "6055: loss=0.204, reward_mean=0.390, reward_bound=0.000, batch=76\n",
      "6056: loss=0.200, reward_mean=0.340, reward_bound=0.000, batch=110\n",
      "6057: loss=0.198, reward_mean=0.490, reward_bound=0.004, batch=147\n",
      "6058: loss=0.195, reward_mean=0.430, reward_bound=0.007, batch=172\n",
      "6059: loss=0.194, reward_mean=0.500, reward_bound=0.016, batch=189\n",
      "6060: loss=0.190, reward_mean=0.390, reward_bound=0.025, batch=199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6061: loss=0.184, reward_mean=0.360, reward_bound=0.038, batch=206\n",
      "6062: loss=0.190, reward_mean=0.480, reward_bound=0.052, batch=211\n",
      "6063: loss=0.190, reward_mean=0.390, reward_bound=0.072, batch=215\n",
      "6064: loss=0.193, reward_mean=0.400, reward_bound=0.089, batch=221\n",
      "6065: loss=0.196, reward_mean=0.460, reward_bound=0.098, batch=220\n",
      "6066: loss=0.192, reward_mean=0.410, reward_bound=0.122, batch=208\n",
      "6067: loss=0.186, reward_mean=0.390, reward_bound=0.135, batch=207\n",
      "6068: loss=0.194, reward_mean=0.450, reward_bound=0.150, batch=198\n",
      "6069: loss=0.188, reward_mean=0.490, reward_bound=0.167, batch=185\n",
      "6070: loss=0.185, reward_mean=0.540, reward_bound=0.185, batch=177\n",
      "6071: loss=0.184, reward_mean=0.480, reward_bound=0.163, batch=194\n",
      "6072: loss=0.183, reward_mean=0.350, reward_bound=0.167, batch=205\n",
      "6073: loss=0.185, reward_mean=0.500, reward_bound=0.206, batch=184\n",
      "6074: loss=0.186, reward_mean=0.440, reward_bound=0.165, batch=199\n",
      "6075: loss=0.186, reward_mean=0.410, reward_bound=0.167, batch=208\n",
      "6076: loss=0.192, reward_mean=0.440, reward_bound=0.229, batch=184\n",
      "6077: loss=0.186, reward_mean=0.350, reward_bound=0.108, batch=199\n",
      "6078: loss=0.185, reward_mean=0.410, reward_bound=0.157, batch=209\n",
      "6079: loss=0.183, reward_mean=0.450, reward_bound=0.215, batch=216\n",
      "6080: loss=0.187, reward_mean=0.480, reward_bound=0.229, batch=214\n",
      "6081: loss=0.188, reward_mean=0.360, reward_bound=0.150, batch=219\n",
      "6082: loss=0.194, reward_mean=0.380, reward_bound=0.254, batch=189\n",
      "6083: loss=0.199, reward_mean=0.320, reward_bound=0.150, batch=201\n",
      "6084: loss=0.195, reward_mean=0.460, reward_bound=0.185, batch=209\n",
      "6085: loss=0.195, reward_mean=0.410, reward_bound=0.229, batch=214\n",
      "6086: loss=0.195, reward_mean=0.370, reward_bound=0.254, batch=217\n",
      "6087: loss=0.194, reward_mean=0.390, reward_bound=0.254, batch=221\n",
      "6088: loss=0.196, reward_mean=0.420, reward_bound=0.282, batch=184\n",
      "6089: loss=0.198, reward_mean=0.410, reward_bound=0.119, batch=199\n",
      "6090: loss=0.195, reward_mean=0.380, reward_bound=0.135, batch=208\n",
      "6091: loss=0.194, reward_mean=0.310, reward_bound=0.185, batch=213\n",
      "6092: loss=0.193, reward_mean=0.480, reward_bound=0.220, batch=219\n",
      "6093: loss=0.191, reward_mean=0.320, reward_bound=0.167, batch=222\n",
      "6094: loss=0.193, reward_mean=0.380, reward_bound=0.236, batch=225\n",
      "6095: loss=0.196, reward_mean=0.450, reward_bound=0.254, batch=219\n",
      "6096: loss=0.196, reward_mean=0.320, reward_bound=0.239, batch=223\n",
      "6097: loss=0.198, reward_mean=0.580, reward_bound=0.282, batch=221\n",
      "6098: loss=0.197, reward_mean=0.390, reward_bound=0.282, batch=224\n",
      "6099: loss=0.204, reward_mean=0.330, reward_bound=0.314, batch=172\n",
      "6100: loss=0.198, reward_mean=0.500, reward_bound=0.145, batch=190\n",
      "6101: loss=0.198, reward_mean=0.450, reward_bound=0.167, batch=201\n",
      "6102: loss=0.195, reward_mean=0.410, reward_bound=0.109, batch=209\n",
      "6103: loss=0.195, reward_mean=0.400, reward_bound=0.185, batch=215\n",
      "6104: loss=0.196, reward_mean=0.390, reward_bound=0.229, batch=219\n",
      "6105: loss=0.198, reward_mean=0.370, reward_bound=0.254, batch=213\n",
      "6106: loss=0.203, reward_mean=0.430, reward_bound=0.282, batch=208\n",
      "6107: loss=0.205, reward_mean=0.440, reward_bound=0.286, batch=215\n",
      "6108: loss=0.204, reward_mean=0.430, reward_bound=0.314, batch=208\n",
      "6109: loss=0.203, reward_mean=0.480, reward_bound=0.257, batch=215\n",
      "6110: loss=0.201, reward_mean=0.490, reward_bound=0.282, batch=218\n",
      "6111: loss=0.203, reward_mean=0.390, reward_bound=0.314, batch=218\n",
      "6112: loss=0.202, reward_mean=0.420, reward_bound=0.317, batch=222\n",
      "6113: loss=0.202, reward_mean=0.440, reward_bound=0.314, batch=224\n",
      "6114: loss=0.202, reward_mean=0.400, reward_bound=0.314, batch=226\n",
      "6115: loss=0.200, reward_mean=0.400, reward_bound=0.349, batch=164\n",
      "6116: loss=0.191, reward_mean=0.440, reward_bound=0.135, batch=184\n",
      "6117: loss=0.192, reward_mean=0.530, reward_bound=0.167, batch=196\n",
      "6118: loss=0.192, reward_mean=0.410, reward_bound=0.185, batch=206\n",
      "6119: loss=0.186, reward_mean=0.460, reward_bound=0.206, batch=213\n",
      "6120: loss=0.190, reward_mean=0.440, reward_bound=0.229, batch=214\n",
      "6121: loss=0.191, reward_mean=0.390, reward_bound=0.249, batch=220\n",
      "6122: loss=0.192, reward_mean=0.490, reward_bound=0.254, batch=215\n",
      "6123: loss=0.191, reward_mean=0.370, reward_bound=0.210, batch=220\n",
      "6124: loss=0.193, reward_mean=0.490, reward_bound=0.254, batch=223\n",
      "6125: loss=0.192, reward_mean=0.430, reward_bound=0.282, batch=216\n",
      "6126: loss=0.192, reward_mean=0.370, reward_bound=0.230, batch=221\n",
      "6127: loss=0.193, reward_mean=0.490, reward_bound=0.254, batch=224\n",
      "6128: loss=0.192, reward_mean=0.330, reward_bound=0.311, batch=227\n",
      "6129: loss=0.192, reward_mean=0.360, reward_bound=0.314, batch=213\n",
      "6130: loss=0.192, reward_mean=0.460, reward_bound=0.261, batch=219\n",
      "6131: loss=0.192, reward_mean=0.330, reward_bound=0.282, batch=222\n",
      "6132: loss=0.189, reward_mean=0.440, reward_bound=0.314, batch=224\n",
      "6133: loss=0.189, reward_mean=0.440, reward_bound=0.345, batch=227\n",
      "6134: loss=0.189, reward_mean=0.390, reward_bound=0.342, batch=229\n",
      "6135: loss=0.194, reward_mean=0.460, reward_bound=0.349, batch=212\n",
      "6136: loss=0.192, reward_mean=0.440, reward_bound=0.282, batch=217\n",
      "6137: loss=0.194, reward_mean=0.400, reward_bound=0.314, batch=220\n",
      "6138: loss=0.196, reward_mean=0.470, reward_bound=0.376, batch=224\n",
      "6139: loss=0.195, reward_mean=0.460, reward_bound=0.384, batch=227\n",
      "6140: loss=0.195, reward_mean=0.350, reward_bound=0.380, batch=229\n",
      "6141: loss=0.199, reward_mean=0.350, reward_bound=0.387, batch=151\n",
      "6142: loss=0.202, reward_mean=0.490, reward_bound=0.052, batch=175\n",
      "6143: loss=0.202, reward_mean=0.370, reward_bound=0.112, batch=192\n",
      "6144: loss=0.204, reward_mean=0.440, reward_bound=0.113, batch=204\n",
      "6145: loss=0.199, reward_mean=0.470, reward_bound=0.149, batch=213\n",
      "6146: loss=0.195, reward_mean=0.290, reward_bound=0.150, batch=215\n",
      "6147: loss=0.196, reward_mean=0.450, reward_bound=0.185, batch=216\n",
      "6148: loss=0.196, reward_mean=0.430, reward_bound=0.206, batch=217\n",
      "6149: loss=0.194, reward_mean=0.390, reward_bound=0.229, batch=218\n",
      "6150: loss=0.195, reward_mean=0.410, reward_bound=0.254, batch=210\n",
      "6151: loss=0.194, reward_mean=0.460, reward_bound=0.206, batch=219\n",
      "6152: loss=0.194, reward_mean=0.500, reward_bound=0.206, batch=218\n",
      "6153: loss=0.194, reward_mean=0.430, reward_bound=0.282, batch=207\n",
      "6154: loss=0.192, reward_mean=0.400, reward_bound=0.254, batch=213\n",
      "6155: loss=0.197, reward_mean=0.480, reward_bound=0.282, batch=217\n",
      "6156: loss=0.197, reward_mean=0.370, reward_bound=0.297, batch=222\n",
      "6157: loss=0.200, reward_mean=0.440, reward_bound=0.314, batch=207\n",
      "6158: loss=0.200, reward_mean=0.470, reward_bound=0.335, batch=215\n",
      "6159: loss=0.198, reward_mean=0.420, reward_bound=0.254, batch=219\n",
      "6160: loss=0.199, reward_mean=0.410, reward_bound=0.282, batch=222\n",
      "6161: loss=0.199, reward_mean=0.330, reward_bound=0.314, batch=222\n",
      "6162: loss=0.194, reward_mean=0.440, reward_bound=0.349, batch=202\n",
      "6163: loss=0.198, reward_mean=0.380, reward_bound=0.191, batch=211\n",
      "6164: loss=0.194, reward_mean=0.530, reward_bound=0.229, batch=216\n",
      "6165: loss=0.193, reward_mean=0.370, reward_bound=0.196, batch=221\n",
      "6166: loss=0.197, reward_mean=0.440, reward_bound=0.254, batch=224\n",
      "6167: loss=0.197, reward_mean=0.420, reward_bound=0.282, batch=225\n",
      "6168: loss=0.197, reward_mean=0.350, reward_bound=0.314, batch=226\n",
      "6169: loss=0.195, reward_mean=0.490, reward_bound=0.349, batch=219\n",
      "6170: loss=0.195, reward_mean=0.430, reward_bound=0.309, batch=223\n",
      "6171: loss=0.194, reward_mean=0.380, reward_bound=0.314, batch=225\n",
      "6172: loss=0.195, reward_mean=0.400, reward_bound=0.356, batch=227\n",
      "6173: loss=0.195, reward_mean=0.410, reward_bound=0.373, batch=229\n",
      "6174: loss=0.203, reward_mean=0.440, reward_bound=0.387, batch=204\n",
      "6175: loss=0.204, reward_mean=0.430, reward_bound=0.311, batch=213\n",
      "6176: loss=0.203, reward_mean=0.410, reward_bound=0.229, batch=218\n",
      "6177: loss=0.204, reward_mean=0.420, reward_bound=0.257, batch=222\n",
      "6178: loss=0.204, reward_mean=0.380, reward_bound=0.282, batch=224\n",
      "6179: loss=0.204, reward_mean=0.420, reward_bound=0.314, batch=224\n",
      "6180: loss=0.204, reward_mean=0.400, reward_bound=0.345, batch=227\n",
      "6181: loss=0.207, reward_mean=0.420, reward_bound=0.349, batch=227\n",
      "6182: loss=0.207, reward_mean=0.470, reward_bound=0.387, batch=223\n",
      "6183: loss=0.206, reward_mean=0.430, reward_bound=0.349, batch=225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6184: loss=0.207, reward_mean=0.400, reward_bound=0.387, batch=226\n",
      "6185: loss=0.207, reward_mean=0.410, reward_bound=0.372, batch=228\n",
      "6186: loss=0.199, reward_mean=0.430, reward_bound=0.430, batch=124\n",
      "6187: loss=0.182, reward_mean=0.490, reward_bound=0.024, batch=157\n",
      "6188: loss=0.198, reward_mean=0.420, reward_bound=0.031, batch=179\n",
      "6189: loss=0.198, reward_mean=0.410, reward_bound=0.080, batch=191\n",
      "6190: loss=0.202, reward_mean=0.430, reward_bound=0.098, batch=200\n",
      "6191: loss=0.205, reward_mean=0.500, reward_bound=0.122, batch=200\n",
      "6192: loss=0.204, reward_mean=0.390, reward_bound=0.135, batch=206\n",
      "6193: loss=0.207, reward_mean=0.430, reward_bound=0.150, batch=212\n",
      "6194: loss=0.200, reward_mean=0.500, reward_bound=0.206, batch=222\n",
      "6195: loss=0.201, reward_mean=0.480, reward_bound=0.206, batch=234\n",
      "6196: loss=0.196, reward_mean=0.460, reward_bound=0.226, batch=234\n",
      "6197: loss=0.201, reward_mean=0.480, reward_bound=0.229, batch=230\n",
      "6198: loss=0.205, reward_mean=0.510, reward_bound=0.254, batch=216\n",
      "6199: loss=0.206, reward_mean=0.340, reward_bound=0.206, batch=220\n",
      "6200: loss=0.208, reward_mean=0.420, reward_bound=0.282, batch=207\n",
      "6201: loss=0.206, reward_mean=0.340, reward_bound=0.135, batch=214\n",
      "6202: loss=0.210, reward_mean=0.370, reward_bound=0.229, batch=217\n",
      "6203: loss=0.209, reward_mean=0.420, reward_bound=0.277, batch=222\n",
      "6204: loss=0.209, reward_mean=0.370, reward_bound=0.282, batch=223\n",
      "6205: loss=0.211, reward_mean=0.360, reward_bound=0.314, batch=193\n",
      "6206: loss=0.207, reward_mean=0.470, reward_bound=0.220, batch=205\n",
      "6207: loss=0.206, reward_mean=0.410, reward_bound=0.167, batch=212\n",
      "6208: loss=0.211, reward_mean=0.410, reward_bound=0.229, batch=216\n",
      "6209: loss=0.210, reward_mean=0.490, reward_bound=0.254, batch=217\n",
      "6210: loss=0.211, reward_mean=0.430, reward_bound=0.282, batch=215\n",
      "6211: loss=0.206, reward_mean=0.470, reward_bound=0.314, batch=208\n",
      "6212: loss=0.206, reward_mean=0.400, reward_bound=0.234, batch=215\n",
      "6213: loss=0.206, reward_mean=0.440, reward_bound=0.289, batch=220\n",
      "6214: loss=0.207, reward_mean=0.400, reward_bound=0.338, batch=224\n",
      "6215: loss=0.206, reward_mean=0.370, reward_bound=0.311, batch=227\n",
      "6216: loss=0.202, reward_mean=0.420, reward_bound=0.349, batch=201\n",
      "6217: loss=0.200, reward_mean=0.400, reward_bound=0.185, batch=210\n",
      "6218: loss=0.198, reward_mean=0.470, reward_bound=0.247, batch=217\n",
      "6219: loss=0.199, reward_mean=0.410, reward_bound=0.308, batch=222\n",
      "6220: loss=0.201, reward_mean=0.430, reward_bound=0.314, batch=219\n",
      "6221: loss=0.199, reward_mean=0.390, reward_bound=0.349, batch=218\n",
      "6222: loss=0.198, reward_mean=0.440, reward_bound=0.387, batch=178\n",
      "6223: loss=0.198, reward_mean=0.470, reward_bound=0.185, batch=192\n",
      "6224: loss=0.195, reward_mean=0.400, reward_bound=0.167, batch=203\n",
      "6225: loss=0.193, reward_mean=0.460, reward_bound=0.220, batch=212\n",
      "6226: loss=0.191, reward_mean=0.400, reward_bound=0.229, batch=216\n",
      "6227: loss=0.195, reward_mean=0.520, reward_bound=0.254, batch=215\n",
      "6228: loss=0.194, reward_mean=0.380, reward_bound=0.229, batch=218\n",
      "6229: loss=0.197, reward_mean=0.430, reward_bound=0.257, batch=222\n",
      "6230: loss=0.199, reward_mean=0.460, reward_bound=0.282, batch=217\n",
      "6231: loss=0.199, reward_mean=0.380, reward_bound=0.314, batch=210\n",
      "6232: loss=0.197, reward_mean=0.450, reward_bound=0.274, batch=217\n",
      "6233: loss=0.195, reward_mean=0.320, reward_bound=0.272, batch=222\n",
      "6234: loss=0.194, reward_mean=0.560, reward_bound=0.324, batch=225\n",
      "6235: loss=0.195, reward_mean=0.420, reward_bound=0.349, batch=213\n",
      "6236: loss=0.196, reward_mean=0.430, reward_bound=0.335, batch=219\n",
      "6237: loss=0.195, reward_mean=0.380, reward_bound=0.239, batch=223\n",
      "6238: loss=0.194, reward_mean=0.470, reward_bound=0.314, batch=224\n",
      "6239: loss=0.196, reward_mean=0.390, reward_bound=0.349, batch=221\n",
      "6240: loss=0.197, reward_mean=0.380, reward_bound=0.282, batch=224\n",
      "6241: loss=0.196, reward_mean=0.460, reward_bound=0.384, batch=227\n",
      "6242: loss=0.196, reward_mean=0.400, reward_bound=0.380, batch=229\n",
      "6243: loss=0.198, reward_mean=0.450, reward_bound=0.387, batch=218\n",
      "6244: loss=0.199, reward_mean=0.470, reward_bound=0.314, batch=220\n",
      "6245: loss=0.198, reward_mean=0.470, reward_bound=0.274, batch=224\n",
      "6246: loss=0.197, reward_mean=0.420, reward_bound=0.314, batch=226\n",
      "6247: loss=0.201, reward_mean=0.460, reward_bound=0.387, batch=225\n",
      "6248: loss=0.205, reward_mean=0.460, reward_bound=0.430, batch=181\n",
      "6249: loss=0.203, reward_mean=0.340, reward_bound=0.135, batch=195\n",
      "6250: loss=0.198, reward_mean=0.360, reward_bound=0.138, batch=206\n",
      "6251: loss=0.199, reward_mean=0.440, reward_bound=0.196, batch=214\n",
      "6252: loss=0.197, reward_mean=0.340, reward_bound=0.202, batch=220\n",
      "6253: loss=0.191, reward_mean=0.400, reward_bound=0.229, batch=222\n",
      "6254: loss=0.189, reward_mean=0.510, reward_bound=0.254, batch=219\n",
      "6255: loss=0.195, reward_mean=0.450, reward_bound=0.282, batch=211\n",
      "6256: loss=0.201, reward_mean=0.400, reward_bound=0.314, batch=212\n",
      "6257: loss=0.200, reward_mean=0.330, reward_bound=0.314, batch=217\n",
      "6258: loss=0.201, reward_mean=0.480, reward_bound=0.314, batch=220\n",
      "6259: loss=0.201, reward_mean=0.600, reward_bound=0.349, batch=220\n",
      "6260: loss=0.199, reward_mean=0.310, reward_bound=0.282, batch=223\n",
      "6261: loss=0.198, reward_mean=0.380, reward_bound=0.349, batch=224\n",
      "6262: loss=0.198, reward_mean=0.350, reward_bound=0.387, batch=218\n",
      "6263: loss=0.198, reward_mean=0.380, reward_bound=0.321, batch=222\n",
      "6264: loss=0.197, reward_mean=0.410, reward_bound=0.360, batch=225\n",
      "6265: loss=0.199, reward_mean=0.470, reward_bound=0.329, batch=227\n",
      "6266: loss=0.198, reward_mean=0.400, reward_bound=0.361, batch=229\n",
      "6267: loss=0.200, reward_mean=0.390, reward_bound=0.387, batch=229\n",
      "6268: loss=0.200, reward_mean=0.450, reward_bound=0.387, batch=229\n",
      "6269: loss=0.200, reward_mean=0.460, reward_bound=0.405, batch=230\n",
      "6270: loss=0.203, reward_mean=0.470, reward_bound=0.430, batch=217\n",
      "6271: loss=0.202, reward_mean=0.410, reward_bound=0.272, batch=222\n",
      "6272: loss=0.205, reward_mean=0.440, reward_bound=0.314, batch=224\n",
      "6273: loss=0.206, reward_mean=0.390, reward_bound=0.377, batch=227\n",
      "6274: loss=0.207, reward_mean=0.370, reward_bound=0.380, batch=229\n",
      "6275: loss=0.204, reward_mean=0.390, reward_bound=0.387, batch=224\n",
      "6276: loss=0.204, reward_mean=0.420, reward_bound=0.345, batch=227\n",
      "6277: loss=0.203, reward_mean=0.470, reward_bound=0.380, batch=229\n",
      "6278: loss=0.203, reward_mean=0.310, reward_bound=0.387, batch=227\n",
      "6279: loss=0.205, reward_mean=0.370, reward_bound=0.282, batch=228\n",
      "6280: loss=0.203, reward_mean=0.400, reward_bound=0.349, batch=227\n",
      "6281: loss=0.204, reward_mean=0.430, reward_bound=0.380, batch=229\n",
      "6282: loss=0.204, reward_mean=0.510, reward_bound=0.430, batch=227\n",
      "6283: loss=0.204, reward_mean=0.440, reward_bound=0.430, batch=228\n",
      "6284: loss=0.204, reward_mean=0.460, reward_bound=0.392, batch=229\n",
      "6285: loss=0.203, reward_mean=0.390, reward_bound=0.405, batch=230\n",
      "6286: loss=0.203, reward_mean=0.430, reward_bound=0.376, batch=231\n",
      "6287: loss=0.203, reward_mean=0.470, reward_bound=0.430, batch=230\n",
      "6288: loss=0.204, reward_mean=0.390, reward_bound=0.418, batch=231\n",
      "6289: loss=0.204, reward_mean=0.440, reward_bound=0.430, batch=231\n",
      "6290: loss=0.220, reward_mean=0.460, reward_bound=0.478, batch=84\n",
      "6291: loss=0.202, reward_mean=0.450, reward_bound=0.000, batch=129\n",
      "6292: loss=0.199, reward_mean=0.480, reward_bound=0.010, batch=160\n",
      "6293: loss=0.197, reward_mean=0.370, reward_bound=0.018, batch=181\n",
      "6294: loss=0.202, reward_mean=0.400, reward_bound=0.031, batch=194\n",
      "6295: loss=0.205, reward_mean=0.370, reward_bound=0.047, batch=204\n",
      "6296: loss=0.201, reward_mean=0.420, reward_bound=0.080, batch=205\n",
      "6297: loss=0.199, reward_mean=0.500, reward_bound=0.109, batch=215\n",
      "6298: loss=0.195, reward_mean=0.390, reward_bound=0.135, batch=204\n",
      "6299: loss=0.197, reward_mean=0.380, reward_bound=0.150, batch=210\n",
      "6300: loss=0.200, reward_mean=0.440, reward_bound=0.167, batch=209\n",
      "6301: loss=0.194, reward_mean=0.380, reward_bound=0.185, batch=201\n",
      "6302: loss=0.199, reward_mean=0.420, reward_bound=0.206, batch=196\n",
      "6303: loss=0.196, reward_mean=0.520, reward_bound=0.229, batch=193\n",
      "6304: loss=0.192, reward_mean=0.390, reward_bound=0.150, batch=201\n",
      "6305: loss=0.193, reward_mean=0.330, reward_bound=0.206, batch=210\n",
      "6306: loss=0.192, reward_mean=0.410, reward_bound=0.229, batch=212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6307: loss=0.189, reward_mean=0.420, reward_bound=0.254, batch=199\n",
      "6308: loss=0.187, reward_mean=0.430, reward_bound=0.215, batch=209\n",
      "6309: loss=0.189, reward_mean=0.520, reward_bound=0.229, batch=213\n",
      "6310: loss=0.187, reward_mean=0.420, reward_bound=0.254, batch=218\n",
      "6311: loss=0.187, reward_mean=0.410, reward_bound=0.282, batch=196\n",
      "6312: loss=0.185, reward_mean=0.530, reward_bound=0.168, batch=207\n",
      "6313: loss=0.186, reward_mean=0.530, reward_bound=0.308, batch=215\n",
      "6314: loss=0.185, reward_mean=0.370, reward_bound=0.289, batch=220\n",
      "6315: loss=0.183, reward_mean=0.450, reward_bound=0.314, batch=204\n",
      "6316: loss=0.177, reward_mean=0.440, reward_bound=0.206, batch=212\n",
      "6317: loss=0.178, reward_mean=0.470, reward_bound=0.236, batch=218\n",
      "6318: loss=0.182, reward_mean=0.420, reward_bound=0.257, batch=222\n",
      "6319: loss=0.181, reward_mean=0.480, reward_bound=0.314, batch=220\n",
      "6320: loss=0.182, reward_mean=0.480, reward_bound=0.349, batch=182\n",
      "6321: loss=0.183, reward_mean=0.480, reward_bound=0.089, batch=195\n",
      "6322: loss=0.178, reward_mean=0.490, reward_bound=0.185, batch=202\n",
      "6323: loss=0.178, reward_mean=0.500, reward_bound=0.236, batch=211\n",
      "6324: loss=0.178, reward_mean=0.420, reward_bound=0.229, batch=217\n",
      "6325: loss=0.184, reward_mean=0.480, reward_bound=0.254, batch=216\n",
      "6326: loss=0.183, reward_mean=0.420, reward_bound=0.282, batch=217\n",
      "6327: loss=0.183, reward_mean=0.490, reward_bound=0.314, batch=215\n",
      "6328: loss=0.184, reward_mean=0.470, reward_bound=0.234, batch=220\n",
      "6329: loss=0.184, reward_mean=0.480, reward_bound=0.304, batch=224\n",
      "6330: loss=0.182, reward_mean=0.480, reward_bound=0.314, batch=225\n",
      "6331: loss=0.181, reward_mean=0.440, reward_bound=0.296, batch=227\n",
      "6332: loss=0.179, reward_mean=0.440, reward_bound=0.349, batch=220\n",
      "6333: loss=0.191, reward_mean=0.480, reward_bound=0.387, batch=176\n",
      "6334: loss=0.192, reward_mean=0.390, reward_bound=0.196, batch=193\n",
      "6335: loss=0.194, reward_mean=0.470, reward_bound=0.206, batch=201\n",
      "6336: loss=0.186, reward_mean=0.400, reward_bound=0.229, batch=208\n",
      "6337: loss=0.185, reward_mean=0.510, reward_bound=0.231, batch=215\n",
      "6338: loss=0.188, reward_mean=0.400, reward_bound=0.254, batch=219\n",
      "6339: loss=0.187, reward_mean=0.340, reward_bound=0.254, batch=222\n",
      "6340: loss=0.191, reward_mean=0.420, reward_bound=0.282, batch=219\n",
      "6341: loss=0.189, reward_mean=0.410, reward_bound=0.314, batch=211\n",
      "6342: loss=0.190, reward_mean=0.570, reward_bound=0.314, batch=217\n",
      "6343: loss=0.191, reward_mean=0.550, reward_bound=0.308, batch=222\n",
      "6344: loss=0.188, reward_mean=0.430, reward_bound=0.349, batch=211\n",
      "6345: loss=0.189, reward_mean=0.400, reward_bound=0.206, batch=216\n",
      "6346: loss=0.191, reward_mean=0.400, reward_bound=0.331, batch=221\n",
      "6347: loss=0.191, reward_mean=0.500, reward_bound=0.349, batch=222\n",
      "6348: loss=0.190, reward_mean=0.440, reward_bound=0.292, batch=225\n",
      "6349: loss=0.190, reward_mean=0.500, reward_bound=0.356, batch=227\n",
      "6350: loss=0.190, reward_mean=0.480, reward_bound=0.387, batch=207\n",
      "6351: loss=0.189, reward_mean=0.390, reward_bound=0.249, batch=215\n",
      "6352: loss=0.189, reward_mean=0.410, reward_bound=0.254, batch=218\n",
      "6353: loss=0.187, reward_mean=0.480, reward_bound=0.314, batch=220\n",
      "6354: loss=0.187, reward_mean=0.420, reward_bound=0.349, batch=222\n",
      "6355: loss=0.188, reward_mean=0.450, reward_bound=0.387, batch=224\n",
      "6356: loss=0.189, reward_mean=0.480, reward_bound=0.422, batch=227\n",
      "6357: loss=0.197, reward_mean=0.370, reward_bound=0.430, batch=162\n",
      "6358: loss=0.196, reward_mean=0.520, reward_bound=0.109, batch=181\n",
      "6359: loss=0.202, reward_mean=0.440, reward_bound=0.109, batch=196\n",
      "6360: loss=0.196, reward_mean=0.390, reward_bound=0.135, batch=203\n",
      "6361: loss=0.193, reward_mean=0.380, reward_bound=0.150, batch=205\n",
      "6362: loss=0.189, reward_mean=0.480, reward_bound=0.167, batch=210\n",
      "6363: loss=0.193, reward_mean=0.430, reward_bound=0.185, batch=215\n",
      "6364: loss=0.191, reward_mean=0.420, reward_bound=0.210, batch=220\n",
      "6365: loss=0.190, reward_mean=0.420, reward_bound=0.247, batch=224\n",
      "6366: loss=0.185, reward_mean=0.490, reward_bound=0.254, batch=221\n",
      "6367: loss=0.194, reward_mean=0.480, reward_bound=0.282, batch=211\n",
      "6368: loss=0.194, reward_mean=0.450, reward_bound=0.167, batch=216\n",
      "6369: loss=0.189, reward_mean=0.410, reward_bound=0.254, batch=219\n",
      "6370: loss=0.187, reward_mean=0.440, reward_bound=0.239, batch=223\n",
      "6371: loss=0.194, reward_mean=0.320, reward_bound=0.314, batch=217\n",
      "6372: loss=0.196, reward_mean=0.400, reward_bound=0.267, batch=222\n",
      "6373: loss=0.190, reward_mean=0.430, reward_bound=0.292, batch=225\n",
      "6374: loss=0.192, reward_mean=0.410, reward_bound=0.321, batch=227\n",
      "6375: loss=0.191, reward_mean=0.370, reward_bound=0.342, batch=229\n",
      "6376: loss=0.191, reward_mean=0.350, reward_bound=0.349, batch=214\n",
      "6377: loss=0.189, reward_mean=0.470, reward_bound=0.229, batch=219\n",
      "6378: loss=0.189, reward_mean=0.440, reward_bound=0.282, batch=222\n",
      "6379: loss=0.192, reward_mean=0.520, reward_bound=0.387, batch=205\n",
      "6380: loss=0.190, reward_mean=0.350, reward_bound=0.185, batch=212\n",
      "6381: loss=0.192, reward_mean=0.430, reward_bound=0.236, batch=218\n",
      "6382: loss=0.194, reward_mean=0.520, reward_bound=0.254, batch=217\n",
      "6383: loss=0.191, reward_mean=0.450, reward_bound=0.314, batch=220\n",
      "6384: loss=0.189, reward_mean=0.480, reward_bound=0.274, batch=224\n",
      "6385: loss=0.188, reward_mean=0.540, reward_bound=0.282, batch=226\n",
      "6386: loss=0.188, reward_mean=0.480, reward_bound=0.331, batch=228\n",
      "6387: loss=0.190, reward_mean=0.570, reward_bound=0.349, batch=224\n",
      "6388: loss=0.189, reward_mean=0.380, reward_bound=0.314, batch=226\n",
      "6389: loss=0.190, reward_mean=0.460, reward_bound=0.368, batch=228\n",
      "6390: loss=0.189, reward_mean=0.470, reward_bound=0.353, batch=229\n",
      "6391: loss=0.194, reward_mean=0.380, reward_bound=0.387, batch=220\n",
      "6392: loss=0.196, reward_mean=0.510, reward_bound=0.274, batch=224\n",
      "6393: loss=0.195, reward_mean=0.430, reward_bound=0.314, batch=225\n",
      "6394: loss=0.193, reward_mean=0.400, reward_bound=0.321, batch=227\n",
      "6395: loss=0.191, reward_mean=0.370, reward_bound=0.349, batch=227\n",
      "6396: loss=0.190, reward_mean=0.420, reward_bound=0.380, batch=229\n",
      "6397: loss=0.192, reward_mean=0.490, reward_bound=0.387, batch=227\n",
      "6398: loss=0.197, reward_mean=0.470, reward_bound=0.430, batch=191\n",
      "6399: loss=0.197, reward_mean=0.500, reward_bound=0.206, batch=201\n",
      "6400: loss=0.195, reward_mean=0.480, reward_bound=0.150, batch=210\n",
      "6401: loss=0.196, reward_mean=0.390, reward_bound=0.229, batch=213\n",
      "6402: loss=0.195, reward_mean=0.470, reward_bound=0.271, batch=219\n",
      "6403: loss=0.192, reward_mean=0.480, reward_bound=0.282, batch=219\n",
      "6404: loss=0.191, reward_mean=0.400, reward_bound=0.314, batch=216\n",
      "6405: loss=0.192, reward_mean=0.490, reward_bound=0.314, batch=220\n",
      "6406: loss=0.193, reward_mean=0.400, reward_bound=0.282, batch=223\n",
      "6407: loss=0.195, reward_mean=0.530, reward_bound=0.349, batch=223\n",
      "6408: loss=0.197, reward_mean=0.530, reward_bound=0.349, batch=225\n",
      "6409: loss=0.197, reward_mean=0.390, reward_bound=0.314, batch=226\n",
      "6410: loss=0.196, reward_mean=0.440, reward_bound=0.387, batch=220\n",
      "6411: loss=0.194, reward_mean=0.420, reward_bound=0.376, batch=224\n",
      "6412: loss=0.196, reward_mean=0.490, reward_bound=0.387, batch=225\n",
      "6413: loss=0.199, reward_mean=0.460, reward_bound=0.430, batch=213\n",
      "6414: loss=0.201, reward_mean=0.500, reward_bound=0.282, batch=218\n",
      "6415: loss=0.201, reward_mean=0.520, reward_bound=0.349, batch=221\n",
      "6416: loss=0.201, reward_mean=0.450, reward_bound=0.387, batch=221\n",
      "6417: loss=0.198, reward_mean=0.380, reward_bound=0.314, batch=224\n",
      "6418: loss=0.198, reward_mean=0.480, reward_bound=0.314, batch=226\n",
      "6419: loss=0.199, reward_mean=0.400, reward_bound=0.349, batch=227\n",
      "6420: loss=0.198, reward_mean=0.440, reward_bound=0.387, batch=227\n",
      "6421: loss=0.197, reward_mean=0.470, reward_bound=0.314, batch=228\n",
      "6422: loss=0.199, reward_mean=0.390, reward_bound=0.430, batch=227\n",
      "6423: loss=0.199, reward_mean=0.490, reward_bound=0.469, batch=229\n",
      "6424: loss=0.199, reward_mean=0.430, reward_bound=0.360, batch=230\n",
      "6425: loss=0.201, reward_mean=0.480, reward_bound=0.406, batch=231\n",
      "6426: loss=0.196, reward_mean=0.440, reward_bound=0.478, batch=144\n",
      "6427: loss=0.187, reward_mean=0.390, reward_bound=0.097, batch=171\n",
      "6428: loss=0.184, reward_mean=0.480, reward_bound=0.098, batch=186\n",
      "6429: loss=0.186, reward_mean=0.460, reward_bound=0.099, batch=200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6430: loss=0.187, reward_mean=0.410, reward_bound=0.118, batch=210\n",
      "6431: loss=0.185, reward_mean=0.440, reward_bound=0.131, batch=217\n",
      "6432: loss=0.191, reward_mean=0.470, reward_bound=0.206, batch=212\n",
      "6433: loss=0.196, reward_mean=0.470, reward_bound=0.229, batch=215\n",
      "6434: loss=0.192, reward_mean=0.410, reward_bound=0.254, batch=212\n",
      "6435: loss=0.191, reward_mean=0.460, reward_bound=0.220, batch=218\n",
      "6436: loss=0.196, reward_mean=0.490, reward_bound=0.282, batch=210\n",
      "6437: loss=0.196, reward_mean=0.380, reward_bound=0.304, batch=217\n",
      "6438: loss=0.194, reward_mean=0.520, reward_bound=0.308, batch=222\n",
      "6439: loss=0.195, reward_mean=0.380, reward_bound=0.292, batch=225\n",
      "6440: loss=0.199, reward_mean=0.440, reward_bound=0.314, batch=213\n",
      "6441: loss=0.197, reward_mean=0.410, reward_bound=0.211, batch=219\n",
      "6442: loss=0.195, reward_mean=0.460, reward_bound=0.239, batch=223\n",
      "6443: loss=0.197, reward_mean=0.400, reward_bound=0.314, batch=220\n",
      "6444: loss=0.199, reward_mean=0.450, reward_bound=0.349, batch=204\n",
      "6445: loss=0.201, reward_mean=0.460, reward_bound=0.280, batch=213\n",
      "6446: loss=0.200, reward_mean=0.420, reward_bound=0.282, batch=217\n",
      "6447: loss=0.196, reward_mean=0.430, reward_bound=0.349, batch=218\n",
      "6448: loss=0.191, reward_mean=0.380, reward_bound=0.387, batch=188\n",
      "6449: loss=0.195, reward_mean=0.400, reward_bound=0.111, batch=201\n",
      "6450: loss=0.196, reward_mean=0.350, reward_bound=0.135, batch=209\n",
      "6451: loss=0.191, reward_mean=0.390, reward_bound=0.215, batch=216\n",
      "6452: loss=0.194, reward_mean=0.480, reward_bound=0.254, batch=219\n",
      "6453: loss=0.192, reward_mean=0.380, reward_bound=0.282, batch=217\n",
      "6454: loss=0.193, reward_mean=0.420, reward_bound=0.282, batch=221\n",
      "6455: loss=0.194, reward_mean=0.340, reward_bound=0.314, batch=222\n",
      "6456: loss=0.195, reward_mean=0.380, reward_bound=0.302, batch=225\n",
      "6457: loss=0.195, reward_mean=0.410, reward_bound=0.296, batch=227\n",
      "6458: loss=0.194, reward_mean=0.460, reward_bound=0.349, batch=221\n",
      "6459: loss=0.193, reward_mean=0.440, reward_bound=0.387, batch=212\n",
      "6460: loss=0.190, reward_mean=0.410, reward_bound=0.185, batch=217\n",
      "6461: loss=0.190, reward_mean=0.370, reward_bound=0.277, batch=222\n",
      "6462: loss=0.190, reward_mean=0.400, reward_bound=0.314, batch=223\n",
      "6463: loss=0.190, reward_mean=0.430, reward_bound=0.314, batch=225\n",
      "6464: loss=0.190, reward_mean=0.450, reward_bound=0.321, batch=227\n",
      "6465: loss=0.192, reward_mean=0.370, reward_bound=0.349, batch=225\n",
      "6466: loss=0.192, reward_mean=0.420, reward_bound=0.387, batch=220\n",
      "6467: loss=0.193, reward_mean=0.350, reward_bound=0.376, batch=224\n",
      "6468: loss=0.190, reward_mean=0.450, reward_bound=0.387, batch=226\n",
      "6469: loss=0.191, reward_mean=0.490, reward_bound=0.430, batch=184\n",
      "6470: loss=0.194, reward_mean=0.440, reward_bound=0.150, batch=198\n",
      "6471: loss=0.197, reward_mean=0.370, reward_bound=0.167, batch=207\n",
      "6472: loss=0.201, reward_mean=0.470, reward_bound=0.185, batch=211\n",
      "6473: loss=0.202, reward_mean=0.440, reward_bound=0.229, batch=217\n",
      "6474: loss=0.198, reward_mean=0.440, reward_bound=0.254, batch=215\n",
      "6475: loss=0.199, reward_mean=0.420, reward_bound=0.260, batch=220\n",
      "6476: loss=0.198, reward_mean=0.430, reward_bound=0.314, batch=210\n",
      "6477: loss=0.196, reward_mean=0.440, reward_bound=0.304, batch=217\n",
      "6478: loss=0.196, reward_mean=0.360, reward_bound=0.297, batch=222\n",
      "6479: loss=0.195, reward_mean=0.380, reward_bound=0.314, batch=224\n",
      "6480: loss=0.193, reward_mean=0.530, reward_bound=0.349, batch=215\n",
      "6481: loss=0.197, reward_mean=0.390, reward_bound=0.289, batch=220\n",
      "6482: loss=0.199, reward_mean=0.430, reward_bound=0.314, batch=221\n",
      "6483: loss=0.198, reward_mean=0.420, reward_bound=0.349, batch=222\n",
      "6484: loss=0.197, reward_mean=0.470, reward_bound=0.349, batch=224\n",
      "6485: loss=0.199, reward_mean=0.430, reward_bound=0.384, batch=227\n",
      "6486: loss=0.198, reward_mean=0.450, reward_bound=0.387, batch=212\n",
      "6487: loss=0.196, reward_mean=0.320, reward_bound=0.229, batch=217\n",
      "6488: loss=0.196, reward_mean=0.500, reward_bound=0.314, batch=221\n",
      "6489: loss=0.196, reward_mean=0.390, reward_bound=0.387, batch=218\n",
      "6490: loss=0.198, reward_mean=0.410, reward_bound=0.321, batch=222\n",
      "6491: loss=0.200, reward_mean=0.330, reward_bound=0.254, batch=224\n",
      "6492: loss=0.202, reward_mean=0.430, reward_bound=0.387, batch=224\n",
      "6493: loss=0.202, reward_mean=0.510, reward_bound=0.422, batch=227\n",
      "6494: loss=0.202, reward_mean=0.470, reward_bound=0.387, batch=228\n",
      "6495: loss=0.195, reward_mean=0.410, reward_bound=0.430, batch=211\n",
      "6496: loss=0.193, reward_mean=0.340, reward_bound=0.254, batch=217\n",
      "6497: loss=0.193, reward_mean=0.390, reward_bound=0.314, batch=218\n",
      "6498: loss=0.193, reward_mean=0.470, reward_bound=0.286, batch=222\n",
      "6499: loss=0.193, reward_mean=0.460, reward_bound=0.324, batch=225\n",
      "6500: loss=0.194, reward_mean=0.420, reward_bound=0.349, batch=223\n",
      "6501: loss=0.198, reward_mean=0.460, reward_bound=0.387, batch=222\n",
      "6502: loss=0.193, reward_mean=0.440, reward_bound=0.430, batch=221\n",
      "6503: loss=0.192, reward_mean=0.410, reward_bound=0.254, batch=224\n",
      "6504: loss=0.192, reward_mean=0.360, reward_bound=0.314, batch=226\n",
      "6505: loss=0.192, reward_mean=0.410, reward_bound=0.349, batch=227\n",
      "6506: loss=0.192, reward_mean=0.460, reward_bound=0.373, batch=229\n",
      "6507: loss=0.195, reward_mean=0.500, reward_bound=0.387, batch=228\n",
      "6508: loss=0.196, reward_mean=0.470, reward_bound=0.430, batch=228\n",
      "6509: loss=0.195, reward_mean=0.400, reward_bound=0.478, batch=230\n",
      "6510: loss=0.194, reward_mean=0.470, reward_bound=0.439, batch=231\n",
      "6511: loss=0.184, reward_mean=0.440, reward_bound=0.478, batch=186\n",
      "6512: loss=0.192, reward_mean=0.420, reward_bound=0.128, batch=200\n",
      "6513: loss=0.194, reward_mean=0.430, reward_bound=0.162, batch=210\n",
      "6514: loss=0.187, reward_mean=0.410, reward_bound=0.200, batch=217\n",
      "6515: loss=0.182, reward_mean=0.430, reward_bound=0.206, batch=221\n",
      "6516: loss=0.182, reward_mean=0.400, reward_bound=0.229, batch=218\n",
      "6517: loss=0.187, reward_mean=0.430, reward_bound=0.254, batch=221\n",
      "6518: loss=0.187, reward_mean=0.480, reward_bound=0.282, batch=218\n",
      "6519: loss=0.191, reward_mean=0.540, reward_bound=0.314, batch=214\n",
      "6520: loss=0.191, reward_mean=0.380, reward_bound=0.282, batch=219\n",
      "6521: loss=0.190, reward_mean=0.450, reward_bound=0.254, batch=222\n",
      "6522: loss=0.186, reward_mean=0.450, reward_bound=0.349, batch=220\n",
      "6523: loss=0.185, reward_mean=0.380, reward_bound=0.338, batch=224\n",
      "6524: loss=0.188, reward_mean=0.440, reward_bound=0.314, batch=226\n",
      "6525: loss=0.185, reward_mean=0.450, reward_bound=0.349, batch=224\n",
      "6526: loss=0.184, reward_mean=0.440, reward_bound=0.349, batch=226\n",
      "6527: loss=0.187, reward_mean=0.510, reward_bound=0.387, batch=214\n",
      "6528: loss=0.186, reward_mean=0.450, reward_bound=0.252, batch=220\n",
      "6529: loss=0.188, reward_mean=0.420, reward_bound=0.247, batch=224\n",
      "6530: loss=0.187, reward_mean=0.380, reward_bound=0.254, batch=223\n",
      "6531: loss=0.188, reward_mean=0.400, reward_bound=0.322, batch=226\n",
      "6532: loss=0.189, reward_mean=0.450, reward_bound=0.349, batch=226\n",
      "6533: loss=0.188, reward_mean=0.420, reward_bound=0.387, batch=226\n",
      "6534: loss=0.187, reward_mean=0.470, reward_bound=0.316, batch=228\n",
      "6535: loss=0.187, reward_mean=0.430, reward_bound=0.353, batch=229\n",
      "6536: loss=0.191, reward_mean=0.410, reward_bound=0.387, batch=229\n",
      "6537: loss=0.184, reward_mean=0.410, reward_bound=0.430, batch=208\n",
      "6538: loss=0.186, reward_mean=0.380, reward_bound=0.130, batch=215\n",
      "6539: loss=0.179, reward_mean=0.430, reward_bound=0.234, batch=220\n",
      "6540: loss=0.178, reward_mean=0.400, reward_bound=0.274, batch=224\n",
      "6541: loss=0.182, reward_mean=0.450, reward_bound=0.314, batch=225\n",
      "6542: loss=0.182, reward_mean=0.490, reward_bound=0.349, batch=222\n",
      "6543: loss=0.181, reward_mean=0.500, reward_bound=0.349, batch=224\n",
      "6544: loss=0.185, reward_mean=0.540, reward_bound=0.387, batch=223\n",
      "6545: loss=0.185, reward_mean=0.430, reward_bound=0.322, batch=226\n",
      "6546: loss=0.185, reward_mean=0.470, reward_bound=0.387, batch=227\n",
      "6547: loss=0.184, reward_mean=0.540, reward_bound=0.342, batch=229\n",
      "6548: loss=0.187, reward_mean=0.480, reward_bound=0.430, batch=222\n",
      "6549: loss=0.186, reward_mean=0.470, reward_bound=0.445, batch=225\n",
      "6550: loss=0.186, reward_mean=0.390, reward_bound=0.356, batch=227\n",
      "6551: loss=0.185, reward_mean=0.470, reward_bound=0.387, batch=228\n",
      "6552: loss=0.186, reward_mean=0.400, reward_bound=0.353, batch=229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6553: loss=0.185, reward_mean=0.440, reward_bound=0.405, batch=230\n",
      "6554: loss=0.185, reward_mean=0.400, reward_bound=0.347, batch=231\n",
      "6555: loss=0.185, reward_mean=0.520, reward_bound=0.387, batch=231\n",
      "6556: loss=0.185, reward_mean=0.500, reward_bound=0.478, batch=206\n",
      "6557: loss=0.185, reward_mean=0.370, reward_bound=0.217, batch=214\n",
      "6558: loss=0.185, reward_mean=0.430, reward_bound=0.229, batch=216\n",
      "6559: loss=0.187, reward_mean=0.520, reward_bound=0.241, batch=221\n",
      "6560: loss=0.188, reward_mean=0.420, reward_bound=0.282, batch=222\n",
      "6561: loss=0.186, reward_mean=0.420, reward_bound=0.282, batch=224\n",
      "6562: loss=0.185, reward_mean=0.520, reward_bound=0.314, batch=223\n",
      "6563: loss=0.185, reward_mean=0.520, reward_bound=0.349, batch=222\n",
      "6564: loss=0.186, reward_mean=0.520, reward_bound=0.360, batch=225\n",
      "6565: loss=0.186, reward_mean=0.530, reward_bound=0.282, batch=226\n",
      "6566: loss=0.188, reward_mean=0.410, reward_bound=0.387, batch=220\n",
      "6567: loss=0.187, reward_mean=0.470, reward_bound=0.418, batch=224\n",
      "6568: loss=0.186, reward_mean=0.410, reward_bound=0.387, batch=226\n",
      "6569: loss=0.181, reward_mean=0.440, reward_bound=0.430, batch=221\n",
      "6570: loss=0.182, reward_mean=0.460, reward_bound=0.282, batch=224\n",
      "6571: loss=0.180, reward_mean=0.440, reward_bound=0.384, batch=227\n",
      "6572: loss=0.179, reward_mean=0.420, reward_bound=0.342, batch=229\n",
      "6573: loss=0.180, reward_mean=0.440, reward_bound=0.364, batch=230\n",
      "6574: loss=0.182, reward_mean=0.480, reward_bound=0.418, batch=231\n",
      "6575: loss=0.184, reward_mean=0.450, reward_bound=0.430, batch=226\n",
      "6576: loss=0.183, reward_mean=0.450, reward_bound=0.454, batch=228\n",
      "6577: loss=0.183, reward_mean=0.460, reward_bound=0.349, batch=228\n",
      "6578: loss=0.186, reward_mean=0.490, reward_bound=0.317, batch=229\n",
      "6579: loss=0.184, reward_mean=0.470, reward_bound=0.387, batch=229\n",
      "6580: loss=0.184, reward_mean=0.470, reward_bound=0.450, batch=230\n",
      "6581: loss=0.183, reward_mean=0.310, reward_bound=0.406, batch=231\n",
      "6582: loss=0.183, reward_mean=0.460, reward_bound=0.430, batch=231\n",
      "6583: loss=0.182, reward_mean=0.460, reward_bound=0.478, batch=216\n",
      "6584: loss=0.179, reward_mean=0.530, reward_bound=0.282, batch=220\n",
      "6585: loss=0.180, reward_mean=0.370, reward_bound=0.304, batch=224\n",
      "6586: loss=0.179, reward_mean=0.420, reward_bound=0.314, batch=226\n",
      "6587: loss=0.180, reward_mean=0.510, reward_bound=0.349, batch=225\n",
      "6588: loss=0.183, reward_mean=0.480, reward_bound=0.387, batch=225\n",
      "6589: loss=0.184, reward_mean=0.400, reward_bound=0.430, batch=223\n",
      "6590: loss=0.183, reward_mean=0.440, reward_bound=0.387, batch=225\n",
      "6591: loss=0.182, reward_mean=0.530, reward_bound=0.356, batch=227\n",
      "6592: loss=0.182, reward_mean=0.380, reward_bound=0.349, batch=227\n",
      "6593: loss=0.182, reward_mean=0.430, reward_bound=0.380, batch=229\n",
      "6594: loss=0.183, reward_mean=0.400, reward_bound=0.405, batch=230\n",
      "6595: loss=0.183, reward_mean=0.380, reward_bound=0.349, batch=230\n",
      "6596: loss=0.182, reward_mean=0.420, reward_bound=0.430, batch=230\n",
      "6597: loss=0.182, reward_mean=0.420, reward_bound=0.430, batch=230\n",
      "6598: loss=0.185, reward_mean=0.490, reward_bound=0.464, batch=231\n",
      "6599: loss=0.185, reward_mean=0.520, reward_bound=0.478, batch=222\n",
      "6600: loss=0.186, reward_mean=0.380, reward_bound=0.314, batch=224\n",
      "6601: loss=0.184, reward_mean=0.360, reward_bound=0.426, batch=227\n",
      "6602: loss=0.183, reward_mean=0.400, reward_bound=0.430, batch=226\n",
      "6603: loss=0.184, reward_mean=0.450, reward_bound=0.478, batch=226\n",
      "6604: loss=0.183, reward_mean=0.440, reward_bound=0.430, batch=227\n",
      "6605: loss=0.183, reward_mean=0.460, reward_bound=0.380, batch=229\n",
      "6606: loss=0.183, reward_mean=0.430, reward_bound=0.430, batch=229\n",
      "6607: loss=0.185, reward_mean=0.490, reward_bound=0.405, batch=230\n",
      "6608: loss=0.183, reward_mean=0.380, reward_bound=0.430, batch=230\n",
      "6609: loss=0.183, reward_mean=0.440, reward_bound=0.464, batch=231\n",
      "6610: loss=0.183, reward_mean=0.420, reward_bound=0.478, batch=229\n",
      "6611: loss=0.183, reward_mean=0.500, reward_bound=0.430, batch=229\n",
      "6612: loss=0.183, reward_mean=0.340, reward_bound=0.344, batch=230\n",
      "6613: loss=0.184, reward_mean=0.430, reward_bound=0.478, batch=230\n",
      "6614: loss=0.184, reward_mean=0.400, reward_bound=0.349, batch=230\n",
      "6615: loss=0.183, reward_mean=0.490, reward_bound=0.464, batch=231\n",
      "6616: loss=0.184, reward_mean=0.380, reward_bound=0.478, batch=231\n",
      "6617: loss=0.184, reward_mean=0.520, reward_bound=0.478, batch=231\n",
      "6618: loss=0.184, reward_mean=0.510, reward_bound=0.478, batch=231\n",
      "6620: loss=0.181, reward_mean=0.460, reward_bound=0.000, batch=46\n",
      "6621: loss=0.170, reward_mean=0.430, reward_bound=0.000, batch=89\n",
      "6622: loss=0.171, reward_mean=0.400, reward_bound=0.000, batch=129\n",
      "6623: loss=0.165, reward_mean=0.370, reward_bound=0.001, batch=160\n",
      "6624: loss=0.177, reward_mean=0.450, reward_bound=0.006, batch=182\n",
      "6625: loss=0.179, reward_mean=0.430, reward_bound=0.019, batch=197\n",
      "6626: loss=0.169, reward_mean=0.480, reward_bound=0.034, batch=203\n",
      "6627: loss=0.163, reward_mean=0.490, reward_bound=0.042, batch=211\n",
      "6628: loss=0.161, reward_mean=0.510, reward_bound=0.058, batch=215\n",
      "6629: loss=0.161, reward_mean=0.360, reward_bound=0.072, batch=216\n",
      "6630: loss=0.162, reward_mean=0.480, reward_bound=0.089, batch=213\n",
      "6631: loss=0.158, reward_mean=0.450, reward_bound=0.098, batch=216\n",
      "6632: loss=0.157, reward_mean=0.440, reward_bound=0.109, batch=217\n",
      "6633: loss=0.151, reward_mean=0.450, reward_bound=0.135, batch=208\n",
      "6634: loss=0.153, reward_mean=0.350, reward_bound=0.150, batch=204\n",
      "6635: loss=0.151, reward_mean=0.510, reward_bound=0.167, batch=200\n",
      "6636: loss=0.163, reward_mean=0.440, reward_bound=0.185, batch=188\n",
      "6637: loss=0.165, reward_mean=0.590, reward_bound=0.185, batch=200\n",
      "6638: loss=0.162, reward_mean=0.430, reward_bound=0.200, batch=210\n",
      "6639: loss=0.165, reward_mean=0.450, reward_bound=0.206, batch=223\n",
      "6640: loss=0.160, reward_mean=0.500, reward_bound=0.206, batch=206\n",
      "6641: loss=0.171, reward_mean=0.550, reward_bound=0.229, batch=181\n",
      "6642: loss=0.171, reward_mean=0.450, reward_bound=0.109, batch=196\n",
      "6643: loss=0.173, reward_mean=0.460, reward_bound=0.176, batch=207\n",
      "6644: loss=0.169, reward_mean=0.460, reward_bound=0.249, batch=215\n",
      "6645: loss=0.175, reward_mean=0.520, reward_bound=0.254, batch=195\n",
      "6646: loss=0.174, reward_mean=0.420, reward_bound=0.282, batch=163\n",
      "6647: loss=0.175, reward_mean=0.590, reward_bound=0.098, batch=183\n",
      "6648: loss=0.172, reward_mean=0.460, reward_bound=0.101, batch=198\n",
      "6649: loss=0.169, reward_mean=0.460, reward_bound=0.122, batch=206\n",
      "6650: loss=0.172, reward_mean=0.450, reward_bound=0.150, batch=209\n",
      "6651: loss=0.172, reward_mean=0.350, reward_bound=0.167, batch=212\n",
      "6652: loss=0.168, reward_mean=0.540, reward_bound=0.185, batch=217\n",
      "6653: loss=0.168, reward_mean=0.540, reward_bound=0.229, batch=214\n",
      "6654: loss=0.171, reward_mean=0.500, reward_bound=0.252, batch=220\n",
      "6655: loss=0.171, reward_mean=0.450, reward_bound=0.254, batch=215\n",
      "6656: loss=0.172, reward_mean=0.460, reward_bound=0.282, batch=215\n",
      "6657: loss=0.172, reward_mean=0.440, reward_bound=0.289, batch=220\n",
      "6658: loss=0.157, reward_mean=0.460, reward_bound=0.314, batch=164\n",
      "6659: loss=0.160, reward_mean=0.550, reward_bound=0.185, batch=184\n",
      "6660: loss=0.157, reward_mean=0.420, reward_bound=0.204, batch=199\n",
      "6661: loss=0.158, reward_mean=0.490, reward_bound=0.167, batch=208\n",
      "6662: loss=0.156, reward_mean=0.550, reward_bound=0.206, batch=206\n",
      "6663: loss=0.158, reward_mean=0.410, reward_bound=0.229, batch=205\n",
      "6664: loss=0.158, reward_mean=0.470, reward_bound=0.254, batch=208\n",
      "6665: loss=0.157, reward_mean=0.350, reward_bound=0.254, batch=214\n",
      "6666: loss=0.156, reward_mean=0.420, reward_bound=0.254, batch=219\n",
      "6667: loss=0.158, reward_mean=0.420, reward_bound=0.282, batch=212\n",
      "6668: loss=0.160, reward_mean=0.430, reward_bound=0.229, batch=216\n",
      "6669: loss=0.158, reward_mean=0.450, reward_bound=0.314, batch=207\n",
      "6670: loss=0.159, reward_mean=0.360, reward_bound=0.254, batch=214\n",
      "6671: loss=0.159, reward_mean=0.420, reward_bound=0.252, batch=220\n",
      "6672: loss=0.158, reward_mean=0.470, reward_bound=0.338, batch=224\n",
      "6673: loss=0.157, reward_mean=0.480, reward_bound=0.345, batch=227\n",
      "6674: loss=0.165, reward_mean=0.520, reward_bound=0.349, batch=163\n",
      "6675: loss=0.160, reward_mean=0.350, reward_bound=0.054, batch=184\n",
      "6676: loss=0.158, reward_mean=0.530, reward_bound=0.134, batch=199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6677: loss=0.151, reward_mean=0.510, reward_bound=0.167, batch=207\n",
      "6678: loss=0.159, reward_mean=0.480, reward_bound=0.206, batch=209\n",
      "6679: loss=0.157, reward_mean=0.420, reward_bound=0.203, batch=216\n",
      "6680: loss=0.153, reward_mean=0.430, reward_bound=0.229, batch=220\n",
      "6681: loss=0.154, reward_mean=0.470, reward_bound=0.254, batch=214\n",
      "6682: loss=0.157, reward_mean=0.460, reward_bound=0.252, batch=220\n",
      "6683: loss=0.157, reward_mean=0.500, reward_bound=0.282, batch=213\n",
      "6684: loss=0.157, reward_mean=0.490, reward_bound=0.282, batch=218\n",
      "6685: loss=0.156, reward_mean=0.340, reward_bound=0.229, batch=221\n",
      "6686: loss=0.162, reward_mean=0.430, reward_bound=0.314, batch=207\n",
      "6687: loss=0.162, reward_mean=0.420, reward_bound=0.282, batch=213\n",
      "6688: loss=0.161, reward_mean=0.400, reward_bound=0.314, batch=216\n",
      "6689: loss=0.166, reward_mean=0.480, reward_bound=0.349, batch=204\n",
      "6690: loss=0.165, reward_mean=0.470, reward_bound=0.252, batch=213\n",
      "6691: loss=0.162, reward_mean=0.570, reward_bound=0.244, batch=219\n",
      "6692: loss=0.162, reward_mean=0.390, reward_bound=0.254, batch=221\n",
      "6693: loss=0.158, reward_mean=0.470, reward_bound=0.282, batch=224\n",
      "6694: loss=0.159, reward_mean=0.350, reward_bound=0.249, batch=227\n",
      "6695: loss=0.159, reward_mean=0.470, reward_bound=0.277, batch=229\n",
      "6696: loss=0.161, reward_mean=0.420, reward_bound=0.314, batch=227\n",
      "6697: loss=0.162, reward_mean=0.440, reward_bound=0.342, batch=229\n",
      "6698: loss=0.165, reward_mean=0.460, reward_bound=0.349, batch=224\n",
      "6699: loss=0.165, reward_mean=0.420, reward_bound=0.252, batch=227\n",
      "6700: loss=0.164, reward_mean=0.390, reward_bound=0.314, batch=227\n",
      "6701: loss=0.168, reward_mean=0.450, reward_bound=0.387, batch=147\n",
      "6702: loss=0.175, reward_mean=0.470, reward_bound=0.042, batch=172\n",
      "6703: loss=0.176, reward_mean=0.420, reward_bound=0.072, batch=189\n",
      "6704: loss=0.167, reward_mean=0.380, reward_bound=0.098, batch=199\n",
      "6705: loss=0.163, reward_mean=0.460, reward_bound=0.122, batch=208\n",
      "6706: loss=0.166, reward_mean=0.500, reward_bound=0.150, batch=212\n",
      "6707: loss=0.166, reward_mean=0.430, reward_bound=0.172, batch=218\n",
      "6708: loss=0.167, reward_mean=0.450, reward_bound=0.206, batch=216\n",
      "6709: loss=0.162, reward_mean=0.430, reward_bound=0.229, batch=204\n",
      "6710: loss=0.159, reward_mean=0.440, reward_bound=0.254, batch=204\n",
      "6711: loss=0.161, reward_mean=0.390, reward_bound=0.226, batch=213\n",
      "6712: loss=0.160, reward_mean=0.440, reward_bound=0.254, batch=216\n",
      "6713: loss=0.161, reward_mean=0.410, reward_bound=0.268, batch=221\n",
      "6714: loss=0.162, reward_mean=0.450, reward_bound=0.282, batch=211\n",
      "6715: loss=0.162, reward_mean=0.450, reward_bound=0.229, batch=217\n",
      "6716: loss=0.162, reward_mean=0.490, reward_bound=0.308, batch=222\n",
      "6717: loss=0.167, reward_mean=0.490, reward_bound=0.314, batch=210\n",
      "6718: loss=0.166, reward_mean=0.520, reward_bound=0.222, batch=217\n",
      "6719: loss=0.164, reward_mean=0.520, reward_bound=0.254, batch=221\n",
      "6720: loss=0.165, reward_mean=0.510, reward_bound=0.282, batch=223\n",
      "6721: loss=0.164, reward_mean=0.420, reward_bound=0.314, batch=224\n",
      "6722: loss=0.164, reward_mean=0.450, reward_bound=0.349, batch=199\n",
      "6723: loss=0.162, reward_mean=0.400, reward_bound=0.265, batch=209\n",
      "6724: loss=0.162, reward_mean=0.440, reward_bound=0.250, batch=216\n",
      "6725: loss=0.164, reward_mean=0.420, reward_bound=0.298, batch=221\n",
      "6726: loss=0.165, reward_mean=0.460, reward_bound=0.314, batch=221\n",
      "6727: loss=0.167, reward_mean=0.420, reward_bound=0.387, batch=193\n",
      "6728: loss=0.159, reward_mean=0.400, reward_bound=0.130, batch=205\n",
      "6729: loss=0.153, reward_mean=0.430, reward_bound=0.112, batch=213\n",
      "6730: loss=0.157, reward_mean=0.410, reward_bound=0.160, batch=219\n",
      "6731: loss=0.162, reward_mean=0.440, reward_bound=0.167, batch=221\n",
      "6732: loss=0.165, reward_mean=0.460, reward_bound=0.229, batch=224\n",
      "6733: loss=0.168, reward_mean=0.340, reward_bound=0.254, batch=224\n",
      "6734: loss=0.169, reward_mean=0.440, reward_bound=0.282, batch=224\n",
      "6735: loss=0.169, reward_mean=0.480, reward_bound=0.314, batch=220\n",
      "6736: loss=0.170, reward_mean=0.450, reward_bound=0.349, batch=216\n",
      "6737: loss=0.170, reward_mean=0.410, reward_bound=0.368, batch=221\n",
      "6738: loss=0.166, reward_mean=0.440, reward_bound=0.387, batch=208\n",
      "6739: loss=0.169, reward_mean=0.450, reward_bound=0.260, batch=215\n",
      "6740: loss=0.169, reward_mean=0.460, reward_bound=0.254, batch=219\n",
      "6741: loss=0.169, reward_mean=0.540, reward_bound=0.314, batch=221\n",
      "6742: loss=0.167, reward_mean=0.360, reward_bound=0.349, batch=222\n",
      "6743: loss=0.168, reward_mean=0.460, reward_bound=0.336, batch=225\n",
      "6744: loss=0.167, reward_mean=0.490, reward_bound=0.303, batch=227\n",
      "6745: loss=0.168, reward_mean=0.530, reward_bound=0.387, batch=223\n",
      "6746: loss=0.169, reward_mean=0.390, reward_bound=0.229, batch=225\n",
      "6747: loss=0.168, reward_mean=0.400, reward_bound=0.321, batch=227\n",
      "6748: loss=0.170, reward_mean=0.400, reward_bound=0.342, batch=229\n",
      "6749: loss=0.172, reward_mean=0.500, reward_bound=0.349, batch=229\n",
      "6750: loss=0.171, reward_mean=0.440, reward_bound=0.387, batch=229\n",
      "6751: loss=0.164, reward_mean=0.500, reward_bound=0.430, batch=139\n",
      "6752: loss=0.178, reward_mean=0.520, reward_bound=0.040, batch=167\n",
      "6753: loss=0.170, reward_mean=0.410, reward_bound=0.070, batch=187\n",
      "6754: loss=0.168, reward_mean=0.420, reward_bound=0.109, batch=202\n",
      "6755: loss=0.164, reward_mean=0.460, reward_bound=0.135, batch=209\n",
      "6756: loss=0.164, reward_mean=0.420, reward_bound=0.167, batch=213\n",
      "6757: loss=0.159, reward_mean=0.520, reward_bound=0.185, batch=213\n",
      "6758: loss=0.159, reward_mean=0.450, reward_bound=0.206, batch=210\n",
      "6759: loss=0.159, reward_mean=0.490, reward_bound=0.206, batch=218\n",
      "6760: loss=0.160, reward_mean=0.490, reward_bound=0.229, batch=212\n",
      "6761: loss=0.156, reward_mean=0.500, reward_bound=0.254, batch=200\n",
      "6762: loss=0.159, reward_mean=0.390, reward_bound=0.210, batch=210\n",
      "6763: loss=0.160, reward_mean=0.480, reward_bound=0.254, batch=216\n",
      "6764: loss=0.161, reward_mean=0.560, reward_bound=0.230, batch=221\n",
      "6765: loss=0.161, reward_mean=0.500, reward_bound=0.282, batch=212\n",
      "6766: loss=0.162, reward_mean=0.490, reward_bound=0.314, batch=202\n",
      "6767: loss=0.161, reward_mean=0.410, reward_bound=0.179, batch=211\n",
      "6768: loss=0.163, reward_mean=0.430, reward_bound=0.229, batch=216\n",
      "6769: loss=0.161, reward_mean=0.440, reward_bound=0.254, batch=219\n",
      "6770: loss=0.160, reward_mean=0.420, reward_bound=0.295, batch=223\n",
      "6771: loss=0.159, reward_mean=0.450, reward_bound=0.314, batch=220\n",
      "6772: loss=0.159, reward_mean=0.430, reward_bound=0.349, batch=202\n",
      "6773: loss=0.156, reward_mean=0.410, reward_bound=0.150, batch=210\n",
      "6774: loss=0.156, reward_mean=0.440, reward_bound=0.247, batch=217\n",
      "6775: loss=0.161, reward_mean=0.390, reward_bound=0.282, batch=220\n",
      "6776: loss=0.163, reward_mean=0.490, reward_bound=0.254, batch=223\n",
      "6777: loss=0.159, reward_mean=0.490, reward_bound=0.314, batch=224\n",
      "6778: loss=0.158, reward_mean=0.400, reward_bound=0.314, batch=226\n",
      "6779: loss=0.157, reward_mean=0.400, reward_bound=0.244, batch=228\n",
      "6780: loss=0.160, reward_mean=0.430, reward_bound=0.349, batch=225\n",
      "6781: loss=0.162, reward_mean=0.450, reward_bound=0.321, batch=227\n",
      "6782: loss=0.162, reward_mean=0.470, reward_bound=0.342, batch=229\n",
      "6783: loss=0.159, reward_mean=0.420, reward_bound=0.349, batch=229\n",
      "6784: loss=0.159, reward_mean=0.560, reward_bound=0.364, batch=230\n",
      "6785: loss=0.160, reward_mean=0.480, reward_bound=0.387, batch=198\n",
      "6786: loss=0.162, reward_mean=0.530, reward_bound=0.282, batch=207\n",
      "6787: loss=0.162, reward_mean=0.490, reward_bound=0.314, batch=211\n",
      "6788: loss=0.161, reward_mean=0.380, reward_bound=0.314, batch=217\n",
      "6789: loss=0.160, reward_mean=0.400, reward_bound=0.308, batch=222\n",
      "6790: loss=0.159, reward_mean=0.400, reward_bound=0.349, batch=219\n",
      "6791: loss=0.162, reward_mean=0.470, reward_bound=0.387, batch=218\n",
      "6792: loss=0.161, reward_mean=0.410, reward_bound=0.173, batch=222\n",
      "6793: loss=0.159, reward_mean=0.470, reward_bound=0.263, batch=225\n",
      "6794: loss=0.160, reward_mean=0.530, reward_bound=0.321, batch=227\n",
      "6795: loss=0.160, reward_mean=0.450, reward_bound=0.349, batch=227\n",
      "6796: loss=0.161, reward_mean=0.400, reward_bound=0.387, batch=226\n",
      "6797: loss=0.161, reward_mean=0.400, reward_bound=0.390, batch=228\n",
      "6798: loss=0.161, reward_mean=0.450, reward_bound=0.430, batch=187\n",
      "6799: loss=0.159, reward_mean=0.430, reward_bound=0.163, batch=201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6800: loss=0.165, reward_mean=0.430, reward_bound=0.185, batch=209\n",
      "6801: loss=0.155, reward_mean=0.540, reward_bound=0.254, batch=214\n",
      "6802: loss=0.155, reward_mean=0.450, reward_bound=0.282, batch=214\n",
      "6803: loss=0.156, reward_mean=0.400, reward_bound=0.206, batch=219\n",
      "6804: loss=0.155, reward_mean=0.330, reward_bound=0.229, batch=222\n",
      "6805: loss=0.159, reward_mean=0.370, reward_bound=0.236, batch=225\n",
      "6806: loss=0.160, reward_mean=0.480, reward_bound=0.314, batch=221\n",
      "6807: loss=0.160, reward_mean=0.400, reward_bound=0.314, batch=224\n",
      "6808: loss=0.159, reward_mean=0.500, reward_bound=0.314, batch=226\n",
      "6809: loss=0.165, reward_mean=0.470, reward_bound=0.349, batch=217\n",
      "6810: loss=0.162, reward_mean=0.450, reward_bound=0.254, batch=221\n",
      "6811: loss=0.163, reward_mean=0.370, reward_bound=0.254, batch=222\n",
      "6812: loss=0.165, reward_mean=0.470, reward_bound=0.324, batch=225\n",
      "6813: loss=0.164, reward_mean=0.510, reward_bound=0.321, batch=227\n",
      "6814: loss=0.168, reward_mean=0.430, reward_bound=0.380, batch=229\n",
      "6815: loss=0.168, reward_mean=0.350, reward_bound=0.343, batch=230\n",
      "6816: loss=0.169, reward_mean=0.450, reward_bound=0.387, batch=213\n",
      "6817: loss=0.169, reward_mean=0.350, reward_bound=0.261, batch=219\n",
      "6818: loss=0.170, reward_mean=0.380, reward_bound=0.282, batch=221\n",
      "6819: loss=0.167, reward_mean=0.410, reward_bound=0.314, batch=223\n",
      "6820: loss=0.167, reward_mean=0.400, reward_bound=0.314, batch=225\n",
      "6821: loss=0.166, reward_mean=0.470, reward_bound=0.321, batch=227\n",
      "6822: loss=0.167, reward_mean=0.400, reward_bound=0.349, batch=227\n",
      "6823: loss=0.166, reward_mean=0.460, reward_bound=0.314, batch=228\n",
      "6824: loss=0.168, reward_mean=0.470, reward_bound=0.387, batch=224\n",
      "6825: loss=0.165, reward_mean=0.340, reward_bound=0.204, batch=227\n",
      "6826: loss=0.169, reward_mean=0.430, reward_bound=0.342, batch=229\n",
      "6827: loss=0.168, reward_mean=0.420, reward_bound=0.387, batch=228\n",
      "6828: loss=0.165, reward_mean=0.420, reward_bound=0.430, batch=210\n",
      "6829: loss=0.166, reward_mean=0.440, reward_bound=0.200, batch=217\n",
      "6830: loss=0.170, reward_mean=0.400, reward_bound=0.229, batch=221\n",
      "6831: loss=0.171, reward_mean=0.410, reward_bound=0.282, batch=224\n",
      "6832: loss=0.175, reward_mean=0.310, reward_bound=0.311, batch=227\n",
      "6833: loss=0.171, reward_mean=0.390, reward_bound=0.314, batch=226\n",
      "6834: loss=0.167, reward_mean=0.430, reward_bound=0.349, batch=222\n",
      "6835: loss=0.165, reward_mean=0.470, reward_bound=0.387, batch=222\n",
      "6836: loss=0.165, reward_mean=0.400, reward_bound=0.387, batch=222\n",
      "6837: loss=0.165, reward_mean=0.470, reward_bound=0.387, batch=223\n",
      "6838: loss=0.164, reward_mean=0.450, reward_bound=0.314, batch=225\n",
      "6839: loss=0.166, reward_mean=0.570, reward_bound=0.430, batch=216\n",
      "6840: loss=0.166, reward_mean=0.420, reward_bound=0.298, batch=221\n",
      "6841: loss=0.169, reward_mean=0.410, reward_bound=0.314, batch=223\n",
      "6842: loss=0.171, reward_mean=0.350, reward_bound=0.271, batch=226\n",
      "6843: loss=0.170, reward_mean=0.430, reward_bound=0.254, batch=227\n",
      "6844: loss=0.169, reward_mean=0.350, reward_bound=0.342, batch=229\n",
      "6845: loss=0.167, reward_mean=0.500, reward_bound=0.349, batch=227\n",
      "6846: loss=0.165, reward_mean=0.400, reward_bound=0.387, batch=225\n",
      "6847: loss=0.163, reward_mean=0.500, reward_bound=0.356, batch=227\n",
      "6848: loss=0.163, reward_mean=0.420, reward_bound=0.387, batch=227\n",
      "6849: loss=0.164, reward_mean=0.380, reward_bound=0.380, batch=229\n",
      "6850: loss=0.166, reward_mean=0.400, reward_bound=0.430, batch=226\n",
      "6851: loss=0.166, reward_mean=0.300, reward_bound=0.430, batch=227\n",
      "6852: loss=0.163, reward_mean=0.400, reward_bound=0.478, batch=75\n",
      "6853: loss=0.167, reward_mean=0.510, reward_bound=0.006, batch=122\n",
      "6854: loss=0.152, reward_mean=0.470, reward_bound=0.014, batch=155\n",
      "6855: loss=0.146, reward_mean=0.390, reward_bound=0.038, batch=177\n",
      "6856: loss=0.156, reward_mean=0.460, reward_bound=0.057, batch=194\n",
      "6857: loss=0.163, reward_mean=0.450, reward_bound=0.072, batch=205\n",
      "6858: loss=0.159, reward_mean=0.480, reward_bound=0.098, batch=209\n",
      "6859: loss=0.165, reward_mean=0.540, reward_bound=0.122, batch=211\n",
      "6860: loss=0.160, reward_mean=0.400, reward_bound=0.135, batch=213\n",
      "6861: loss=0.163, reward_mean=0.360, reward_bound=0.150, batch=207\n",
      "6862: loss=0.158, reward_mean=0.410, reward_bound=0.167, batch=207\n",
      "6863: loss=0.158, reward_mean=0.470, reward_bound=0.182, batch=215\n",
      "6864: loss=0.153, reward_mean=0.450, reward_bound=0.185, batch=207\n",
      "6865: loss=0.151, reward_mean=0.490, reward_bound=0.206, batch=206\n",
      "6866: loss=0.141, reward_mean=0.390, reward_bound=0.229, batch=195\n",
      "6867: loss=0.140, reward_mean=0.390, reward_bound=0.229, batch=205\n",
      "6868: loss=0.142, reward_mean=0.450, reward_bound=0.234, batch=213\n",
      "6869: loss=0.140, reward_mean=0.360, reward_bound=0.178, batch=219\n",
      "6870: loss=0.148, reward_mean=0.480, reward_bound=0.254, batch=192\n",
      "6871: loss=0.145, reward_mean=0.430, reward_bound=0.213, batch=204\n",
      "6872: loss=0.143, reward_mean=0.380, reward_bound=0.183, batch=213\n",
      "6873: loss=0.144, reward_mean=0.490, reward_bound=0.206, batch=218\n",
      "6874: loss=0.144, reward_mean=0.400, reward_bound=0.254, batch=220\n",
      "6875: loss=0.141, reward_mean=0.370, reward_bound=0.282, batch=195\n",
      "6876: loss=0.144, reward_mean=0.380, reward_bound=0.175, batch=206\n",
      "6877: loss=0.144, reward_mean=0.390, reward_bound=0.168, batch=214\n",
      "6878: loss=0.143, reward_mean=0.380, reward_bound=0.206, batch=214\n",
      "6879: loss=0.141, reward_mean=0.360, reward_bound=0.226, batch=220\n",
      "6880: loss=0.141, reward_mean=0.420, reward_bound=0.229, batch=220\n",
      "6881: loss=0.139, reward_mean=0.470, reward_bound=0.254, batch=218\n",
      "6882: loss=0.143, reward_mean=0.400, reward_bound=0.314, batch=173\n",
      "6883: loss=0.136, reward_mean=0.390, reward_bound=0.098, batch=189\n",
      "6884: loss=0.140, reward_mean=0.340, reward_bound=0.083, batch=202\n",
      "6885: loss=0.148, reward_mean=0.510, reward_bound=0.135, batch=208\n",
      "6886: loss=0.144, reward_mean=0.440, reward_bound=0.185, batch=211\n",
      "6887: loss=0.144, reward_mean=0.400, reward_bound=0.167, batch=217\n",
      "6888: loss=0.146, reward_mean=0.480, reward_bound=0.229, batch=219\n",
      "6889: loss=0.146, reward_mean=0.450, reward_bound=0.254, batch=218\n",
      "6890: loss=0.144, reward_mean=0.510, reward_bound=0.282, batch=216\n",
      "6891: loss=0.143, reward_mean=0.460, reward_bound=0.298, batch=221\n",
      "6892: loss=0.147, reward_mean=0.410, reward_bound=0.314, batch=214\n",
      "6893: loss=0.145, reward_mean=0.440, reward_bound=0.345, batch=220\n",
      "6894: loss=0.150, reward_mean=0.410, reward_bound=0.349, batch=188\n",
      "6895: loss=0.152, reward_mean=0.420, reward_bound=0.150, batch=200\n",
      "6896: loss=0.153, reward_mean=0.460, reward_bound=0.206, batch=214\n",
      "6897: loss=0.148, reward_mean=0.480, reward_bound=0.206, batch=218\n",
      "6898: loss=0.152, reward_mean=0.390, reward_bound=0.231, batch=222\n",
      "6899: loss=0.147, reward_mean=0.380, reward_bound=0.254, batch=221\n",
      "6900: loss=0.148, reward_mean=0.370, reward_bound=0.282, batch=220\n",
      "6901: loss=0.149, reward_mean=0.440, reward_bound=0.229, batch=222\n",
      "6902: loss=0.154, reward_mean=0.550, reward_bound=0.314, batch=223\n",
      "6903: loss=0.154, reward_mean=0.380, reward_bound=0.335, batch=226\n",
      "6904: loss=0.157, reward_mean=0.460, reward_bound=0.349, batch=220\n",
      "6905: loss=0.159, reward_mean=0.470, reward_bound=0.314, batch=223\n",
      "6906: loss=0.158, reward_mean=0.450, reward_bound=0.372, batch=226\n",
      "6907: loss=0.157, reward_mean=0.330, reward_bound=0.387, batch=174\n",
      "6908: loss=0.155, reward_mean=0.480, reward_bound=0.098, batch=191\n",
      "6909: loss=0.159, reward_mean=0.470, reward_bound=0.150, batch=199\n",
      "6910: loss=0.155, reward_mean=0.500, reward_bound=0.185, batch=207\n",
      "6911: loss=0.153, reward_mean=0.370, reward_bound=0.202, batch=215\n",
      "6912: loss=0.155, reward_mean=0.460, reward_bound=0.206, batch=217\n",
      "6913: loss=0.154, reward_mean=0.390, reward_bound=0.198, batch=222\n",
      "6914: loss=0.150, reward_mean=0.440, reward_bound=0.236, batch=225\n",
      "6915: loss=0.155, reward_mean=0.380, reward_bound=0.254, batch=219\n",
      "6916: loss=0.156, reward_mean=0.430, reward_bound=0.282, batch=218\n",
      "6917: loss=0.155, reward_mean=0.410, reward_bound=0.254, batch=221\n",
      "6918: loss=0.159, reward_mean=0.470, reward_bound=0.314, batch=216\n",
      "6919: loss=0.157, reward_mean=0.350, reward_bound=0.349, batch=206\n",
      "6920: loss=0.159, reward_mean=0.380, reward_bound=0.207, batch=214\n",
      "6921: loss=0.156, reward_mean=0.480, reward_bound=0.314, batch=219\n",
      "6922: loss=0.156, reward_mean=0.380, reward_bound=0.328, batch=223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6923: loss=0.155, reward_mean=0.420, reward_bound=0.301, batch=226\n",
      "6924: loss=0.155, reward_mean=0.490, reward_bound=0.314, batch=226\n",
      "6925: loss=0.154, reward_mean=0.440, reward_bound=0.349, batch=225\n",
      "6926: loss=0.157, reward_mean=0.570, reward_bound=0.387, batch=212\n",
      "6927: loss=0.161, reward_mean=0.480, reward_bound=0.213, batch=218\n",
      "6928: loss=0.156, reward_mean=0.360, reward_bound=0.282, batch=221\n",
      "6929: loss=0.156, reward_mean=0.460, reward_bound=0.349, batch=223\n",
      "6930: loss=0.156, reward_mean=0.410, reward_bound=0.335, batch=226\n",
      "6931: loss=0.155, reward_mean=0.480, reward_bound=0.349, batch=227\n",
      "6932: loss=0.154, reward_mean=0.410, reward_bound=0.380, batch=229\n",
      "6933: loss=0.155, reward_mean=0.430, reward_bound=0.387, batch=223\n",
      "6934: loss=0.154, reward_mean=0.440, reward_bound=0.398, batch=226\n",
      "6935: loss=0.153, reward_mean=0.440, reward_bound=0.430, batch=149\n",
      "6936: loss=0.147, reward_mean=0.410, reward_bound=0.072, batch=173\n",
      "6937: loss=0.142, reward_mean=0.530, reward_bound=0.122, batch=189\n",
      "6938: loss=0.144, reward_mean=0.470, reward_bound=0.157, batch=202\n",
      "6939: loss=0.145, reward_mean=0.310, reward_bound=0.135, batch=210\n",
      "6940: loss=0.147, reward_mean=0.410, reward_bound=0.206, batch=218\n",
      "6941: loss=0.143, reward_mean=0.450, reward_bound=0.206, batch=220\n",
      "6942: loss=0.157, reward_mean=0.520, reward_bound=0.254, batch=213\n",
      "6943: loss=0.158, reward_mean=0.450, reward_bound=0.282, batch=206\n",
      "6944: loss=0.155, reward_mean=0.400, reward_bound=0.271, batch=214\n",
      "6945: loss=0.156, reward_mean=0.400, reward_bound=0.311, batch=220\n",
      "6946: loss=0.156, reward_mean=0.350, reward_bound=0.314, batch=205\n",
      "6947: loss=0.157, reward_mean=0.430, reward_bound=0.194, batch=213\n",
      "6948: loss=0.157, reward_mean=0.420, reward_bound=0.282, batch=218\n",
      "6949: loss=0.158, reward_mean=0.440, reward_bound=0.257, batch=222\n",
      "6950: loss=0.155, reward_mean=0.430, reward_bound=0.314, batch=222\n",
      "6951: loss=0.161, reward_mean=0.370, reward_bound=0.349, batch=206\n",
      "6952: loss=0.159, reward_mean=0.430, reward_bound=0.229, batch=212\n",
      "6953: loss=0.156, reward_mean=0.350, reward_bound=0.213, batch=218\n",
      "6954: loss=0.157, reward_mean=0.460, reward_bound=0.314, batch=217\n",
      "6955: loss=0.160, reward_mean=0.340, reward_bound=0.282, batch=221\n",
      "6956: loss=0.161, reward_mean=0.460, reward_bound=0.349, batch=220\n",
      "6957: loss=0.150, reward_mean=0.450, reward_bound=0.387, batch=197\n",
      "6958: loss=0.151, reward_mean=0.420, reward_bound=0.158, batch=208\n",
      "6959: loss=0.147, reward_mean=0.480, reward_bound=0.254, batch=213\n",
      "6960: loss=0.146, reward_mean=0.410, reward_bound=0.229, batch=218\n",
      "6961: loss=0.150, reward_mean=0.460, reward_bound=0.282, batch=218\n",
      "6962: loss=0.149, reward_mean=0.410, reward_bound=0.257, batch=222\n",
      "6963: loss=0.148, reward_mean=0.390, reward_bound=0.314, batch=220\n",
      "6964: loss=0.149, reward_mean=0.400, reward_bound=0.349, batch=220\n",
      "6965: loss=0.149, reward_mean=0.440, reward_bound=0.338, batch=224\n",
      "6966: loss=0.151, reward_mean=0.450, reward_bound=0.384, batch=227\n",
      "6967: loss=0.148, reward_mean=0.410, reward_bound=0.387, batch=218\n",
      "6968: loss=0.148, reward_mean=0.450, reward_bound=0.387, batch=221\n",
      "6969: loss=0.148, reward_mean=0.380, reward_bound=0.430, batch=185\n",
      "6970: loss=0.151, reward_mean=0.390, reward_bound=0.150, batch=196\n",
      "6971: loss=0.157, reward_mean=0.450, reward_bound=0.185, batch=206\n",
      "6972: loss=0.157, reward_mean=0.340, reward_bound=0.138, batch=214\n",
      "6973: loss=0.145, reward_mean=0.430, reward_bound=0.206, batch=212\n",
      "6974: loss=0.144, reward_mean=0.450, reward_bound=0.254, batch=214\n",
      "6975: loss=0.140, reward_mean=0.400, reward_bound=0.282, batch=215\n",
      "6976: loss=0.135, reward_mean=0.470, reward_bound=0.314, batch=218\n",
      "6977: loss=0.136, reward_mean=0.500, reward_bound=0.286, batch=222\n",
      "6978: loss=0.137, reward_mean=0.400, reward_bound=0.314, batch=224\n",
      "6979: loss=0.136, reward_mean=0.400, reward_bound=0.345, batch=227\n",
      "6980: loss=0.136, reward_mean=0.360, reward_bound=0.349, batch=220\n",
      "6981: loss=0.142, reward_mean=0.470, reward_bound=0.387, batch=211\n",
      "6982: loss=0.139, reward_mean=0.440, reward_bound=0.254, batch=217\n",
      "6983: loss=0.138, reward_mean=0.350, reward_bound=0.282, batch=219\n",
      "6984: loss=0.137, reward_mean=0.390, reward_bound=0.265, batch=223\n",
      "6985: loss=0.137, reward_mean=0.490, reward_bound=0.282, batch=223\n",
      "6986: loss=0.139, reward_mean=0.380, reward_bound=0.314, batch=221\n",
      "6987: loss=0.144, reward_mean=0.430, reward_bound=0.349, batch=218\n",
      "6988: loss=0.142, reward_mean=0.480, reward_bound=0.286, batch=222\n",
      "6989: loss=0.141, reward_mean=0.410, reward_bound=0.292, batch=225\n",
      "6990: loss=0.142, reward_mean=0.400, reward_bound=0.349, batch=226\n",
      "6991: loss=0.141, reward_mean=0.420, reward_bound=0.282, batch=227\n",
      "6992: loss=0.139, reward_mean=0.440, reward_bound=0.387, batch=225\n",
      "6993: loss=0.138, reward_mean=0.490, reward_bound=0.396, batch=227\n",
      "6994: loss=0.143, reward_mean=0.410, reward_bound=0.430, batch=205\n",
      "6995: loss=0.140, reward_mean=0.320, reward_bound=0.234, batch=213\n",
      "6996: loss=0.143, reward_mean=0.440, reward_bound=0.254, batch=218\n",
      "6997: loss=0.152, reward_mean=0.370, reward_bound=0.282, batch=219\n",
      "6998: loss=0.149, reward_mean=0.500, reward_bound=0.328, batch=223\n",
      "6999: loss=0.151, reward_mean=0.420, reward_bound=0.349, batch=221\n",
      "7000: loss=0.151, reward_mean=0.470, reward_bound=0.349, batch=224\n",
      "7001: loss=0.150, reward_mean=0.440, reward_bound=0.345, batch=227\n",
      "7002: loss=0.149, reward_mean=0.400, reward_bound=0.349, batch=228\n",
      "7003: loss=0.149, reward_mean=0.450, reward_bound=0.314, batch=228\n",
      "7004: loss=0.144, reward_mean=0.420, reward_bound=0.387, batch=222\n",
      "7005: loss=0.145, reward_mean=0.440, reward_bound=0.400, batch=225\n",
      "7006: loss=0.145, reward_mean=0.500, reward_bound=0.387, batch=226\n",
      "7007: loss=0.146, reward_mean=0.310, reward_bound=0.331, batch=228\n",
      "7008: loss=0.141, reward_mean=0.450, reward_bound=0.430, batch=219\n",
      "7009: loss=0.141, reward_mean=0.410, reward_bound=0.405, batch=223\n",
      "7010: loss=0.140, reward_mean=0.420, reward_bound=0.372, batch=226\n",
      "7011: loss=0.140, reward_mean=0.530, reward_bound=0.409, batch=228\n",
      "7012: loss=0.140, reward_mean=0.350, reward_bound=0.317, batch=229\n",
      "7013: loss=0.140, reward_mean=0.410, reward_bound=0.430, batch=227\n",
      "7014: loss=0.139, reward_mean=0.480, reward_bound=0.335, batch=229\n",
      "7015: loss=0.139, reward_mean=0.440, reward_bound=0.349, batch=229\n",
      "7016: loss=0.139, reward_mean=0.400, reward_bound=0.387, batch=229\n",
      "7017: loss=0.139, reward_mean=0.420, reward_bound=0.450, batch=230\n",
      "7018: loss=0.138, reward_mean=0.390, reward_bound=0.406, batch=231\n",
      "7019: loss=0.139, reward_mean=0.450, reward_bound=0.430, batch=230\n",
      "7020: loss=0.139, reward_mean=0.420, reward_bound=0.430, batch=230\n",
      "7021: loss=0.139, reward_mean=0.410, reward_bound=0.464, batch=231\n",
      "7022: loss=0.139, reward_mean=0.450, reward_bound=0.430, batch=231\n",
      "7023: loss=0.141, reward_mean=0.470, reward_bound=0.478, batch=148\n",
      "7024: loss=0.151, reward_mean=0.390, reward_bound=0.039, batch=173\n",
      "7025: loss=0.156, reward_mean=0.450, reward_bound=0.069, batch=191\n",
      "7026: loss=0.152, reward_mean=0.470, reward_bound=0.150, batch=199\n",
      "7027: loss=0.156, reward_mean=0.480, reward_bound=0.167, batch=207\n",
      "7028: loss=0.159, reward_mean=0.400, reward_bound=0.185, batch=206\n",
      "7029: loss=0.152, reward_mean=0.390, reward_bound=0.206, batch=212\n",
      "7030: loss=0.152, reward_mean=0.490, reward_bound=0.229, batch=212\n",
      "7031: loss=0.145, reward_mean=0.400, reward_bound=0.254, batch=208\n",
      "7032: loss=0.147, reward_mean=0.370, reward_bound=0.206, batch=214\n",
      "7033: loss=0.147, reward_mean=0.380, reward_bound=0.229, batch=217\n",
      "7034: loss=0.149, reward_mean=0.360, reward_bound=0.277, batch=222\n",
      "7035: loss=0.145, reward_mean=0.470, reward_bound=0.282, batch=211\n",
      "7036: loss=0.146, reward_mean=0.400, reward_bound=0.254, batch=217\n",
      "7037: loss=0.146, reward_mean=0.370, reward_bound=0.249, batch=222\n",
      "7038: loss=0.145, reward_mean=0.520, reward_bound=0.292, batch=225\n",
      "7039: loss=0.143, reward_mean=0.420, reward_bound=0.314, batch=214\n",
      "7040: loss=0.142, reward_mean=0.420, reward_bound=0.252, batch=220\n",
      "7041: loss=0.143, reward_mean=0.350, reward_bound=0.247, batch=224\n",
      "7042: loss=0.143, reward_mean=0.380, reward_bound=0.254, batch=226\n",
      "7043: loss=0.145, reward_mean=0.510, reward_bound=0.314, batch=227\n",
      "7044: loss=0.142, reward_mean=0.300, reward_bound=0.349, batch=202\n",
      "7045: loss=0.145, reward_mean=0.430, reward_bound=0.191, batch=211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7046: loss=0.140, reward_mean=0.410, reward_bound=0.206, batch=213\n",
      "7047: loss=0.137, reward_mean=0.420, reward_bound=0.254, batch=218\n",
      "7048: loss=0.138, reward_mean=0.480, reward_bound=0.282, batch=219\n",
      "7049: loss=0.136, reward_mean=0.380, reward_bound=0.254, batch=222\n",
      "7050: loss=0.139, reward_mean=0.420, reward_bound=0.292, batch=225\n",
      "7051: loss=0.142, reward_mean=0.510, reward_bound=0.314, batch=220\n",
      "7052: loss=0.142, reward_mean=0.370, reward_bound=0.349, batch=214\n",
      "7053: loss=0.142, reward_mean=0.400, reward_bound=0.339, batch=220\n",
      "7054: loss=0.142, reward_mean=0.440, reward_bound=0.387, batch=198\n",
      "7055: loss=0.141, reward_mean=0.360, reward_bound=0.208, batch=208\n",
      "7056: loss=0.142, reward_mean=0.480, reward_bound=0.229, batch=213\n",
      "7057: loss=0.138, reward_mean=0.370, reward_bound=0.254, batch=216\n",
      "7058: loss=0.135, reward_mean=0.550, reward_bound=0.282, batch=219\n",
      "7059: loss=0.138, reward_mean=0.330, reward_bound=0.314, batch=218\n",
      "7060: loss=0.137, reward_mean=0.480, reward_bound=0.317, batch=222\n",
      "7061: loss=0.141, reward_mean=0.460, reward_bound=0.349, batch=218\n",
      "7062: loss=0.142, reward_mean=0.420, reward_bound=0.234, batch=222\n",
      "7063: loss=0.142, reward_mean=0.450, reward_bound=0.263, batch=225\n",
      "7064: loss=0.141, reward_mean=0.410, reward_bound=0.282, batch=225\n",
      "7065: loss=0.139, reward_mean=0.400, reward_bound=0.349, batch=226\n",
      "7066: loss=0.142, reward_mean=0.450, reward_bound=0.387, batch=222\n",
      "7067: loss=0.141, reward_mean=0.430, reward_bound=0.292, batch=225\n",
      "7068: loss=0.140, reward_mean=0.390, reward_bound=0.321, batch=227\n",
      "7069: loss=0.141, reward_mean=0.510, reward_bound=0.387, batch=227\n",
      "7070: loss=0.140, reward_mean=0.510, reward_bound=0.387, batch=228\n",
      "7071: loss=0.137, reward_mean=0.430, reward_bound=0.430, batch=190\n",
      "7072: loss=0.135, reward_mean=0.470, reward_bound=0.282, batch=200\n",
      "7073: loss=0.137, reward_mean=0.450, reward_bound=0.157, batch=210\n",
      "7074: loss=0.135, reward_mean=0.420, reward_bound=0.206, batch=219\n",
      "7075: loss=0.134, reward_mean=0.450, reward_bound=0.239, batch=223\n",
      "7076: loss=0.135, reward_mean=0.470, reward_bound=0.271, batch=226\n",
      "7077: loss=0.136, reward_mean=0.360, reward_bound=0.282, batch=221\n",
      "7078: loss=0.134, reward_mean=0.410, reward_bound=0.314, batch=216\n",
      "7079: loss=0.132, reward_mean=0.350, reward_bound=0.241, batch=221\n",
      "7080: loss=0.132, reward_mean=0.490, reward_bound=0.314, batch=222\n",
      "7081: loss=0.132, reward_mean=0.460, reward_bound=0.349, batch=216\n",
      "7082: loss=0.132, reward_mean=0.470, reward_bound=0.241, batch=221\n",
      "7083: loss=0.133, reward_mean=0.430, reward_bound=0.314, batch=224\n",
      "7084: loss=0.133, reward_mean=0.380, reward_bound=0.345, batch=227\n",
      "7085: loss=0.134, reward_mean=0.530, reward_bound=0.349, batch=227\n",
      "7086: loss=0.133, reward_mean=0.410, reward_bound=0.349, batch=228\n",
      "7087: loss=0.133, reward_mean=0.400, reward_bound=0.353, batch=229\n",
      "7088: loss=0.135, reward_mean=0.490, reward_bound=0.387, batch=213\n",
      "7089: loss=0.134, reward_mean=0.530, reward_bound=0.335, batch=219\n",
      "7090: loss=0.134, reward_mean=0.430, reward_bound=0.349, batch=222\n",
      "7091: loss=0.136, reward_mean=0.380, reward_bound=0.191, batch=225\n",
      "7092: loss=0.133, reward_mean=0.470, reward_bound=0.387, batch=222\n",
      "7093: loss=0.132, reward_mean=0.430, reward_bound=0.349, batch=223\n",
      "7094: loss=0.131, reward_mean=0.420, reward_bound=0.335, batch=226\n",
      "7095: loss=0.132, reward_mean=0.490, reward_bound=0.387, batch=226\n",
      "7096: loss=0.132, reward_mean=0.470, reward_bound=0.349, batch=227\n",
      "7097: loss=0.134, reward_mean=0.500, reward_bound=0.422, batch=229\n",
      "7098: loss=0.138, reward_mean=0.490, reward_bound=0.430, batch=213\n",
      "7099: loss=0.136, reward_mean=0.360, reward_bound=0.271, batch=219\n",
      "7100: loss=0.137, reward_mean=0.430, reward_bound=0.282, batch=222\n",
      "7101: loss=0.140, reward_mean=0.400, reward_bound=0.324, batch=225\n",
      "7102: loss=0.138, reward_mean=0.460, reward_bound=0.356, batch=227\n",
      "7103: loss=0.137, reward_mean=0.400, reward_bound=0.387, batch=225\n",
      "7104: loss=0.136, reward_mean=0.430, reward_bound=0.365, batch=227\n",
      "7105: loss=0.138, reward_mean=0.490, reward_bound=0.430, batch=223\n",
      "7106: loss=0.137, reward_mean=0.470, reward_bound=0.358, batch=226\n",
      "7107: loss=0.136, reward_mean=0.490, reward_bound=0.409, batch=228\n",
      "7108: loss=0.137, reward_mean=0.410, reward_bound=0.430, batch=228\n",
      "7109: loss=0.137, reward_mean=0.400, reward_bound=0.397, batch=229\n",
      "7110: loss=0.137, reward_mean=0.400, reward_bound=0.424, batch=230\n",
      "7111: loss=0.137, reward_mean=0.440, reward_bound=0.349, batch=230\n",
      "7112: loss=0.139, reward_mean=0.460, reward_bound=0.478, batch=185\n",
      "7113: loss=0.134, reward_mean=0.440, reward_bound=0.122, batch=198\n",
      "7114: loss=0.137, reward_mean=0.510, reward_bound=0.167, batch=206\n",
      "7115: loss=0.139, reward_mean=0.510, reward_bound=0.217, batch=214\n",
      "7116: loss=0.140, reward_mean=0.430, reward_bound=0.204, batch=220\n",
      "7117: loss=0.139, reward_mean=0.360, reward_bound=0.254, batch=214\n",
      "7118: loss=0.137, reward_mean=0.470, reward_bound=0.282, batch=215\n",
      "7119: loss=0.138, reward_mean=0.480, reward_bound=0.234, batch=220\n",
      "7120: loss=0.140, reward_mean=0.360, reward_bound=0.254, batch=223\n",
      "7121: loss=0.141, reward_mean=0.380, reward_bound=0.314, batch=218\n",
      "7122: loss=0.140, reward_mean=0.420, reward_bound=0.314, batch=221\n",
      "7123: loss=0.142, reward_mean=0.480, reward_bound=0.254, batch=224\n",
      "7124: loss=0.141, reward_mean=0.430, reward_bound=0.252, batch=227\n",
      "7125: loss=0.142, reward_mean=0.480, reward_bound=0.308, batch=229\n",
      "7126: loss=0.145, reward_mean=0.430, reward_bound=0.349, batch=217\n",
      "7127: loss=0.146, reward_mean=0.390, reward_bound=0.185, batch=220\n",
      "7128: loss=0.145, reward_mean=0.430, reward_bound=0.314, batch=223\n",
      "7129: loss=0.146, reward_mean=0.410, reward_bound=0.322, batch=226\n",
      "7130: loss=0.148, reward_mean=0.440, reward_bound=0.349, batch=227\n",
      "7131: loss=0.144, reward_mean=0.510, reward_bound=0.387, batch=210\n",
      "7132: loss=0.144, reward_mean=0.420, reward_bound=0.254, batch=216\n",
      "7133: loss=0.147, reward_mean=0.430, reward_bound=0.254, batch=220\n",
      "7134: loss=0.144, reward_mean=0.390, reward_bound=0.314, batch=223\n",
      "7135: loss=0.144, reward_mean=0.450, reward_bound=0.349, batch=221\n",
      "7136: loss=0.143, reward_mean=0.420, reward_bound=0.349, batch=223\n",
      "7137: loss=0.141, reward_mean=0.470, reward_bound=0.387, batch=219\n",
      "7138: loss=0.141, reward_mean=0.460, reward_bound=0.282, batch=221\n",
      "7139: loss=0.141, reward_mean=0.440, reward_bound=0.314, batch=224\n",
      "7140: loss=0.141, reward_mean=0.380, reward_bound=0.311, batch=227\n",
      "7141: loss=0.143, reward_mean=0.490, reward_bound=0.314, batch=228\n",
      "7142: loss=0.139, reward_mean=0.440, reward_bound=0.349, batch=226\n",
      "7143: loss=0.140, reward_mean=0.440, reward_bound=0.316, batch=228\n",
      "7144: loss=0.138, reward_mean=0.440, reward_bound=0.387, batch=228\n",
      "7145: loss=0.138, reward_mean=0.460, reward_bound=0.387, batch=228\n",
      "7146: loss=0.137, reward_mean=0.400, reward_bound=0.430, batch=209\n",
      "7147: loss=0.142, reward_mean=0.490, reward_bound=0.254, batch=215\n",
      "7148: loss=0.148, reward_mean=0.430, reward_bound=0.314, batch=219\n",
      "7149: loss=0.147, reward_mean=0.360, reward_bound=0.349, batch=220\n",
      "7150: loss=0.146, reward_mean=0.410, reward_bound=0.314, batch=222\n",
      "7151: loss=0.146, reward_mean=0.470, reward_bound=0.336, batch=225\n",
      "7152: loss=0.148, reward_mean=0.490, reward_bound=0.356, batch=227\n",
      "7153: loss=0.140, reward_mean=0.400, reward_bound=0.387, batch=223\n",
      "7154: loss=0.143, reward_mean=0.380, reward_bound=0.314, batch=224\n",
      "7155: loss=0.144, reward_mean=0.440, reward_bound=0.349, batch=226\n",
      "7156: loss=0.145, reward_mean=0.380, reward_bound=0.368, batch=228\n",
      "7157: loss=0.140, reward_mean=0.500, reward_bound=0.387, batch=228\n",
      "7158: loss=0.140, reward_mean=0.470, reward_bound=0.353, batch=229\n",
      "7159: loss=0.140, reward_mean=0.510, reward_bound=0.405, batch=230\n",
      "7160: loss=0.140, reward_mean=0.390, reward_bound=0.314, batch=230\n",
      "7161: loss=0.139, reward_mean=0.490, reward_bound=0.430, batch=222\n",
      "7162: loss=0.139, reward_mean=0.440, reward_bound=0.324, batch=225\n",
      "7163: loss=0.138, reward_mean=0.530, reward_bound=0.396, batch=227\n",
      "7164: loss=0.136, reward_mean=0.450, reward_bound=0.342, batch=229\n",
      "7165: loss=0.137, reward_mean=0.380, reward_bound=0.309, batch=230\n",
      "7166: loss=0.139, reward_mean=0.480, reward_bound=0.349, batch=229\n",
      "7167: loss=0.139, reward_mean=0.460, reward_bound=0.405, batch=230\n",
      "7168: loss=0.139, reward_mean=0.420, reward_bound=0.418, batch=231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7169: loss=0.140, reward_mean=0.450, reward_bound=0.430, batch=231\n",
      "7170: loss=0.137, reward_mean=0.390, reward_bound=0.478, batch=202\n",
      "7171: loss=0.145, reward_mean=0.390, reward_bound=0.185, batch=210\n",
      "7172: loss=0.134, reward_mean=0.500, reward_bound=0.282, batch=213\n",
      "7173: loss=0.133, reward_mean=0.370, reward_bound=0.282, batch=218\n",
      "7174: loss=0.131, reward_mean=0.460, reward_bound=0.231, batch=222\n",
      "7175: loss=0.132, reward_mean=0.440, reward_bound=0.282, batch=224\n",
      "7176: loss=0.132, reward_mean=0.430, reward_bound=0.314, batch=221\n",
      "7177: loss=0.135, reward_mean=0.440, reward_bound=0.349, batch=222\n",
      "7178: loss=0.137, reward_mean=0.410, reward_bound=0.349, batch=224\n",
      "7179: loss=0.137, reward_mean=0.380, reward_bound=0.384, batch=227\n",
      "7180: loss=0.137, reward_mean=0.480, reward_bound=0.387, batch=222\n",
      "7181: loss=0.137, reward_mean=0.400, reward_bound=0.387, batch=223\n",
      "7182: loss=0.136, reward_mean=0.470, reward_bound=0.314, batch=225\n",
      "7183: loss=0.136, reward_mean=0.400, reward_bound=0.430, batch=214\n",
      "7184: loss=0.132, reward_mean=0.540, reward_bound=0.305, batch=220\n",
      "7185: loss=0.131, reward_mean=0.330, reward_bound=0.304, batch=224\n",
      "7186: loss=0.131, reward_mean=0.420, reward_bound=0.314, batch=226\n",
      "7187: loss=0.131, reward_mean=0.440, reward_bound=0.349, batch=227\n",
      "7188: loss=0.131, reward_mean=0.440, reward_bound=0.349, batch=228\n",
      "7189: loss=0.134, reward_mean=0.480, reward_bound=0.387, batch=225\n",
      "7190: loss=0.134, reward_mean=0.470, reward_bound=0.387, batch=226\n",
      "7191: loss=0.136, reward_mean=0.360, reward_bound=0.430, batch=225\n",
      "7192: loss=0.135, reward_mean=0.420, reward_bound=0.365, batch=227\n",
      "7193: loss=0.134, reward_mean=0.380, reward_bound=0.422, batch=229\n",
      "7194: loss=0.137, reward_mean=0.420, reward_bound=0.430, batch=229\n",
      "7195: loss=0.136, reward_mean=0.450, reward_bound=0.405, batch=230\n",
      "7196: loss=0.136, reward_mean=0.420, reward_bound=0.395, batch=231\n",
      "7197: loss=0.136, reward_mean=0.450, reward_bound=0.430, batch=230\n",
      "7198: loss=0.136, reward_mean=0.340, reward_bound=0.478, batch=210\n",
      "7199: loss=0.135, reward_mean=0.490, reward_bound=0.314, batch=214\n",
      "7200: loss=0.137, reward_mean=0.370, reward_bound=0.280, batch=220\n",
      "7201: loss=0.135, reward_mean=0.510, reward_bound=0.304, batch=224\n",
      "7202: loss=0.134, reward_mean=0.470, reward_bound=0.229, batch=226\n",
      "7203: loss=0.133, reward_mean=0.440, reward_bound=0.284, batch=228\n",
      "7204: loss=0.134, reward_mean=0.510, reward_bound=0.349, batch=221\n",
      "7205: loss=0.136, reward_mean=0.500, reward_bound=0.349, batch=223\n",
      "7206: loss=0.137, reward_mean=0.390, reward_bound=0.387, batch=218\n",
      "7207: loss=0.140, reward_mean=0.390, reward_bound=0.260, batch=222\n",
      "7208: loss=0.140, reward_mean=0.400, reward_bound=0.360, batch=225\n",
      "7209: loss=0.140, reward_mean=0.390, reward_bound=0.329, batch=227\n",
      "7210: loss=0.139, reward_mean=0.440, reward_bound=0.342, batch=229\n",
      "7211: loss=0.137, reward_mean=0.400, reward_bound=0.387, batch=225\n",
      "7212: loss=0.138, reward_mean=0.360, reward_bound=0.430, batch=213\n",
      "7213: loss=0.138, reward_mean=0.530, reward_bound=0.384, batch=219\n",
      "7214: loss=0.136, reward_mean=0.470, reward_bound=0.254, batch=221\n",
      "7215: loss=0.135, reward_mean=0.430, reward_bound=0.314, batch=224\n",
      "7216: loss=0.137, reward_mean=0.420, reward_bound=0.349, batch=225\n",
      "7217: loss=0.136, reward_mean=0.400, reward_bound=0.387, batch=225\n",
      "7218: loss=0.137, reward_mean=0.510, reward_bound=0.314, batch=226\n",
      "7219: loss=0.136, reward_mean=0.410, reward_bound=0.387, batch=227\n",
      "7220: loss=0.136, reward_mean=0.390, reward_bound=0.430, batch=223\n",
      "7221: loss=0.137, reward_mean=0.470, reward_bound=0.459, batch=226\n",
      "7222: loss=0.137, reward_mean=0.390, reward_bound=0.316, batch=228\n",
      "7223: loss=0.139, reward_mean=0.450, reward_bound=0.353, batch=229\n",
      "7224: loss=0.140, reward_mean=0.400, reward_bound=0.343, batch=230\n",
      "7225: loss=0.139, reward_mean=0.390, reward_bound=0.430, batch=230\n",
      "7226: loss=0.137, reward_mean=0.410, reward_bound=0.478, batch=219\n",
      "7227: loss=0.138, reward_mean=0.510, reward_bound=0.314, batch=222\n",
      "7228: loss=0.136, reward_mean=0.490, reward_bound=0.360, batch=225\n",
      "7229: loss=0.140, reward_mean=0.550, reward_bound=0.387, batch=225\n",
      "7230: loss=0.140, reward_mean=0.380, reward_bound=0.289, batch=227\n",
      "7231: loss=0.140, reward_mean=0.530, reward_bound=0.342, batch=229\n",
      "7232: loss=0.143, reward_mean=0.320, reward_bound=0.387, batch=229\n",
      "7233: loss=0.140, reward_mean=0.360, reward_bound=0.430, batch=226\n",
      "7234: loss=0.138, reward_mean=0.410, reward_bound=0.478, batch=222\n",
      "7235: loss=0.137, reward_mean=0.410, reward_bound=0.400, batch=225\n",
      "7236: loss=0.135, reward_mean=0.380, reward_bound=0.396, batch=227\n",
      "7237: loss=0.139, reward_mean=0.470, reward_bound=0.430, batch=226\n",
      "7238: loss=0.138, reward_mean=0.420, reward_bound=0.316, batch=228\n",
      "7239: loss=0.139, reward_mean=0.390, reward_bound=0.387, batch=227\n",
      "7240: loss=0.139, reward_mean=0.430, reward_bound=0.430, batch=226\n",
      "7241: loss=0.139, reward_mean=0.470, reward_bound=0.454, batch=228\n",
      "7242: loss=0.140, reward_mean=0.460, reward_bound=0.392, batch=229\n",
      "7243: loss=0.140, reward_mean=0.440, reward_bound=0.387, batch=229\n",
      "7244: loss=0.140, reward_mean=0.440, reward_bound=0.478, batch=231\n",
      "7245: loss=0.140, reward_mean=0.420, reward_bound=0.430, batch=231\n",
      "7246: loss=0.140, reward_mean=0.400, reward_bound=0.430, batch=231\n",
      "7247: loss=0.140, reward_mean=0.350, reward_bound=0.478, batch=226\n",
      "7248: loss=0.142, reward_mean=0.390, reward_bound=0.268, batch=228\n",
      "7249: loss=0.141, reward_mean=0.420, reward_bound=0.392, batch=229\n",
      "7250: loss=0.140, reward_mean=0.370, reward_bound=0.381, batch=230\n",
      "7251: loss=0.139, reward_mean=0.370, reward_bound=0.430, batch=230\n",
      "7252: loss=0.141, reward_mean=0.430, reward_bound=0.451, batch=231\n",
      "7253: loss=0.141, reward_mean=0.430, reward_bound=0.478, batch=231\n",
      "7254: loss=0.141, reward_mean=0.500, reward_bound=0.387, batch=231\n",
      "7255: loss=0.141, reward_mean=0.460, reward_bound=0.430, batch=231\n",
      "7256: loss=0.141, reward_mean=0.420, reward_bound=0.387, batch=231\n",
      "7258: loss=0.154, reward_mean=0.470, reward_bound=0.000, batch=47\n",
      "7259: loss=0.150, reward_mean=0.450, reward_bound=0.000, batch=92\n",
      "7260: loss=0.157, reward_mean=0.360, reward_bound=0.000, batch=128\n",
      "7261: loss=0.151, reward_mean=0.510, reward_bound=0.007, batch=159\n",
      "7262: loss=0.152, reward_mean=0.480, reward_bound=0.016, batch=179\n",
      "7263: loss=0.159, reward_mean=0.380, reward_bound=0.029, batch=195\n",
      "7264: loss=0.158, reward_mean=0.370, reward_bound=0.042, batch=205\n",
      "7265: loss=0.162, reward_mean=0.390, reward_bound=0.065, batch=205\n",
      "7266: loss=0.159, reward_mean=0.450, reward_bound=0.080, batch=208\n",
      "7267: loss=0.160, reward_mean=0.390, reward_bound=0.098, batch=203\n",
      "7268: loss=0.155, reward_mean=0.490, reward_bound=0.109, batch=201\n",
      "7269: loss=0.159, reward_mean=0.450, reward_bound=0.122, batch=199\n",
      "7270: loss=0.159, reward_mean=0.410, reward_bound=0.135, batch=191\n",
      "7271: loss=0.153, reward_mean=0.510, reward_bound=0.150, batch=187\n",
      "7272: loss=0.158, reward_mean=0.470, reward_bound=0.167, batch=193\n",
      "7273: loss=0.159, reward_mean=0.410, reward_bound=0.185, batch=196\n",
      "7274: loss=0.158, reward_mean=0.440, reward_bound=0.167, batch=206\n",
      "7275: loss=0.157, reward_mean=0.500, reward_bound=0.206, batch=199\n",
      "7276: loss=0.160, reward_mean=0.370, reward_bound=0.215, batch=209\n",
      "7277: loss=0.159, reward_mean=0.530, reward_bound=0.229, batch=189\n",
      "7278: loss=0.158, reward_mean=0.490, reward_bound=0.127, batch=202\n",
      "7279: loss=0.153, reward_mean=0.460, reward_bound=0.167, batch=210\n",
      "7280: loss=0.154, reward_mean=0.430, reward_bound=0.206, batch=221\n",
      "7281: loss=0.154, reward_mean=0.420, reward_bound=0.206, batch=222\n",
      "7282: loss=0.154, reward_mean=0.390, reward_bound=0.229, batch=221\n",
      "7283: loss=0.150, reward_mean=0.440, reward_bound=0.254, batch=203\n",
      "7284: loss=0.150, reward_mean=0.440, reward_bound=0.206, batch=211\n",
      "7285: loss=0.143, reward_mean=0.430, reward_bound=0.282, batch=166\n",
      "7286: loss=0.154, reward_mean=0.490, reward_bound=0.094, batch=186\n",
      "7287: loss=0.150, reward_mean=0.470, reward_bound=0.151, batch=200\n",
      "7288: loss=0.147, reward_mean=0.460, reward_bound=0.185, batch=206\n",
      "7289: loss=0.146, reward_mean=0.440, reward_bound=0.185, batch=213\n",
      "7290: loss=0.148, reward_mean=0.320, reward_bound=0.185, batch=218\n",
      "7291: loss=0.145, reward_mean=0.450, reward_bound=0.229, batch=214\n",
      "7292: loss=0.144, reward_mean=0.420, reward_bound=0.254, batch=212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7293: loss=0.147, reward_mean=0.330, reward_bound=0.282, batch=210\n",
      "7294: loss=0.149, reward_mean=0.430, reward_bound=0.194, batch=217\n",
      "7295: loss=0.148, reward_mean=0.380, reward_bound=0.229, batch=220\n",
      "7296: loss=0.148, reward_mean=0.370, reward_bound=0.304, batch=224\n",
      "7297: loss=0.149, reward_mean=0.400, reward_bound=0.314, batch=176\n",
      "7298: loss=0.153, reward_mean=0.460, reward_bound=0.128, batch=193\n",
      "7299: loss=0.152, reward_mean=0.450, reward_bound=0.135, batch=203\n",
      "7300: loss=0.147, reward_mean=0.450, reward_bound=0.185, batch=207\n",
      "7301: loss=0.142, reward_mean=0.500, reward_bound=0.229, batch=214\n",
      "7302: loss=0.144, reward_mean=0.390, reward_bound=0.254, batch=209\n",
      "7303: loss=0.146, reward_mean=0.520, reward_bound=0.282, batch=203\n",
      "7304: loss=0.145, reward_mean=0.410, reward_bound=0.229, batch=210\n",
      "7305: loss=0.145, reward_mean=0.420, reward_bound=0.167, batch=216\n",
      "7306: loss=0.145, reward_mean=0.420, reward_bound=0.241, batch=221\n",
      "7307: loss=0.145, reward_mean=0.440, reward_bound=0.282, batch=220\n",
      "7308: loss=0.143, reward_mean=0.370, reward_bound=0.314, batch=210\n",
      "7309: loss=0.143, reward_mean=0.400, reward_bound=0.254, batch=215\n",
      "7310: loss=0.144, reward_mean=0.530, reward_bound=0.206, batch=219\n",
      "7311: loss=0.142, reward_mean=0.460, reward_bound=0.239, batch=223\n",
      "7312: loss=0.144, reward_mean=0.510, reward_bound=0.271, batch=226\n",
      "7313: loss=0.145, reward_mean=0.520, reward_bound=0.298, batch=228\n",
      "7314: loss=0.144, reward_mean=0.370, reward_bound=0.314, batch=226\n",
      "7315: loss=0.144, reward_mean=0.440, reward_bound=0.314, batch=227\n",
      "7316: loss=0.153, reward_mean=0.440, reward_bound=0.349, batch=174\n",
      "7317: loss=0.152, reward_mean=0.450, reward_bound=0.080, batch=191\n",
      "7318: loss=0.148, reward_mean=0.380, reward_bound=0.109, batch=203\n",
      "7319: loss=0.156, reward_mean=0.510, reward_bound=0.185, batch=211\n",
      "7320: loss=0.153, reward_mean=0.490, reward_bound=0.229, batch=213\n",
      "7321: loss=0.152, reward_mean=0.430, reward_bound=0.206, batch=218\n",
      "7322: loss=0.150, reward_mean=0.380, reward_bound=0.254, batch=216\n",
      "7323: loss=0.154, reward_mean=0.440, reward_bound=0.282, batch=207\n",
      "7324: loss=0.154, reward_mean=0.350, reward_bound=0.254, batch=213\n",
      "7325: loss=0.159, reward_mean=0.410, reward_bound=0.271, batch=219\n",
      "7326: loss=0.152, reward_mean=0.430, reward_bound=0.314, batch=213\n",
      "7327: loss=0.155, reward_mean=0.530, reward_bound=0.335, batch=219\n",
      "7328: loss=0.154, reward_mean=0.530, reward_bound=0.349, batch=211\n",
      "7329: loss=0.152, reward_mean=0.430, reward_bound=0.229, batch=216\n",
      "7330: loss=0.152, reward_mean=0.430, reward_bound=0.241, batch=221\n",
      "7331: loss=0.153, reward_mean=0.410, reward_bound=0.254, batch=224\n",
      "7332: loss=0.152, reward_mean=0.390, reward_bound=0.280, batch=227\n",
      "7333: loss=0.154, reward_mean=0.500, reward_bound=0.282, batch=227\n",
      "7334: loss=0.153, reward_mean=0.390, reward_bound=0.314, batch=226\n",
      "7335: loss=0.154, reward_mean=0.450, reward_bound=0.349, batch=224\n",
      "7336: loss=0.164, reward_mean=0.430, reward_bound=0.387, batch=144\n",
      "7337: loss=0.157, reward_mean=0.380, reward_bound=0.030, batch=171\n",
      "7338: loss=0.164, reward_mean=0.460, reward_bound=0.080, batch=189\n",
      "7339: loss=0.170, reward_mean=0.520, reward_bound=0.135, batch=199\n",
      "7340: loss=0.166, reward_mean=0.450, reward_bound=0.150, batch=202\n",
      "7341: loss=0.162, reward_mean=0.450, reward_bound=0.167, batch=209\n",
      "7342: loss=0.160, reward_mean=0.400, reward_bound=0.185, batch=210\n",
      "7343: loss=0.163, reward_mean=0.420, reward_bound=0.229, batch=211\n",
      "7344: loss=0.161, reward_mean=0.450, reward_bound=0.206, batch=217\n",
      "7345: loss=0.161, reward_mean=0.430, reward_bound=0.229, batch=220\n",
      "7346: loss=0.163, reward_mean=0.470, reward_bound=0.254, batch=213\n",
      "7347: loss=0.161, reward_mean=0.470, reward_bound=0.220, batch=219\n",
      "7348: loss=0.162, reward_mean=0.420, reward_bound=0.254, batch=221\n",
      "7349: loss=0.163, reward_mean=0.440, reward_bound=0.282, batch=216\n",
      "7350: loss=0.164, reward_mean=0.390, reward_bound=0.206, batch=220\n",
      "7351: loss=0.167, reward_mean=0.440, reward_bound=0.274, batch=224\n",
      "7352: loss=0.166, reward_mean=0.520, reward_bound=0.314, batch=213\n",
      "7353: loss=0.165, reward_mean=0.390, reward_bound=0.282, batch=217\n",
      "7354: loss=0.158, reward_mean=0.440, reward_bound=0.349, batch=197\n",
      "7355: loss=0.159, reward_mean=0.380, reward_bound=0.147, batch=208\n",
      "7356: loss=0.156, reward_mean=0.420, reward_bound=0.208, batch=215\n",
      "7357: loss=0.154, reward_mean=0.400, reward_bound=0.229, batch=217\n",
      "7358: loss=0.153, reward_mean=0.420, reward_bound=0.254, batch=220\n",
      "7359: loss=0.155, reward_mean=0.480, reward_bound=0.266, batch=224\n",
      "7360: loss=0.155, reward_mean=0.390, reward_bound=0.282, batch=224\n",
      "7361: loss=0.157, reward_mean=0.420, reward_bound=0.282, batch=226\n",
      "7362: loss=0.152, reward_mean=0.450, reward_bound=0.314, batch=223\n",
      "7363: loss=0.156, reward_mean=0.430, reward_bound=0.349, batch=219\n",
      "7364: loss=0.158, reward_mean=0.410, reward_bound=0.292, batch=223\n",
      "7365: loss=0.157, reward_mean=0.420, reward_bound=0.349, batch=224\n",
      "7366: loss=0.154, reward_mean=0.380, reward_bound=0.387, batch=201\n",
      "7367: loss=0.154, reward_mean=0.410, reward_bound=0.185, batch=210\n",
      "7368: loss=0.153, reward_mean=0.540, reward_bound=0.229, batch=214\n",
      "7369: loss=0.154, reward_mean=0.440, reward_bound=0.254, batch=217\n",
      "7370: loss=0.155, reward_mean=0.460, reward_bound=0.249, batch=222\n",
      "7371: loss=0.154, reward_mean=0.440, reward_bound=0.282, batch=224\n",
      "7372: loss=0.151, reward_mean=0.400, reward_bound=0.314, batch=218\n",
      "7373: loss=0.153, reward_mean=0.430, reward_bound=0.349, batch=217\n",
      "7374: loss=0.156, reward_mean=0.460, reward_bound=0.349, batch=219\n",
      "7375: loss=0.154, reward_mean=0.450, reward_bound=0.387, batch=210\n",
      "7376: loss=0.154, reward_mean=0.440, reward_bound=0.282, batch=216\n",
      "7377: loss=0.158, reward_mean=0.430, reward_bound=0.314, batch=220\n",
      "7378: loss=0.158, reward_mean=0.420, reward_bound=0.304, batch=224\n",
      "7379: loss=0.155, reward_mean=0.590, reward_bound=0.349, batch=219\n",
      "7380: loss=0.153, reward_mean=0.450, reward_bound=0.364, batch=223\n",
      "7381: loss=0.156, reward_mean=0.410, reward_bound=0.387, batch=222\n",
      "7382: loss=0.155, reward_mean=0.470, reward_bound=0.349, batch=224\n",
      "7383: loss=0.154, reward_mean=0.490, reward_bound=0.387, batch=226\n",
      "7384: loss=0.167, reward_mean=0.470, reward_bound=0.430, batch=123\n",
      "7385: loss=0.165, reward_mean=0.430, reward_bound=0.026, batch=156\n",
      "7386: loss=0.175, reward_mean=0.490, reward_bound=0.040, batch=179\n",
      "7387: loss=0.177, reward_mean=0.420, reward_bound=0.072, batch=192\n",
      "7388: loss=0.179, reward_mean=0.470, reward_bound=0.109, batch=201\n",
      "7389: loss=0.176, reward_mean=0.430, reward_bound=0.122, batch=203\n",
      "7390: loss=0.176, reward_mean=0.400, reward_bound=0.135, batch=210\n",
      "7391: loss=0.168, reward_mean=0.390, reward_bound=0.150, batch=213\n",
      "7392: loss=0.165, reward_mean=0.400, reward_bound=0.167, batch=217\n",
      "7393: loss=0.169, reward_mean=0.460, reward_bound=0.185, batch=219\n",
      "7394: loss=0.162, reward_mean=0.550, reward_bound=0.206, batch=213\n",
      "7395: loss=0.155, reward_mean=0.410, reward_bound=0.229, batch=216\n",
      "7396: loss=0.157, reward_mean=0.440, reward_bound=0.254, batch=208\n",
      "7397: loss=0.156, reward_mean=0.440, reward_bound=0.208, batch=215\n",
      "7398: loss=0.154, reward_mean=0.450, reward_bound=0.282, batch=212\n",
      "7399: loss=0.158, reward_mean=0.440, reward_bound=0.314, batch=193\n",
      "7400: loss=0.159, reward_mean=0.550, reward_bound=0.206, batch=204\n",
      "7401: loss=0.160, reward_mean=0.520, reward_bound=0.229, batch=210\n",
      "7402: loss=0.160, reward_mean=0.450, reward_bound=0.247, batch=217\n",
      "7403: loss=0.162, reward_mean=0.510, reward_bound=0.282, batch=217\n",
      "7404: loss=0.162, reward_mean=0.430, reward_bound=0.229, batch=221\n",
      "7405: loss=0.158, reward_mean=0.450, reward_bound=0.314, batch=216\n",
      "7406: loss=0.160, reward_mean=0.530, reward_bound=0.314, batch=220\n",
      "7407: loss=0.161, reward_mean=0.530, reward_bound=0.349, batch=197\n",
      "7408: loss=0.161, reward_mean=0.370, reward_bound=0.163, batch=208\n",
      "7409: loss=0.161, reward_mean=0.500, reward_bound=0.208, batch=215\n",
      "7410: loss=0.158, reward_mean=0.490, reward_bound=0.254, batch=217\n",
      "7411: loss=0.162, reward_mean=0.440, reward_bound=0.282, batch=221\n",
      "7412: loss=0.165, reward_mean=0.510, reward_bound=0.314, batch=222\n",
      "7413: loss=0.164, reward_mean=0.410, reward_bound=0.349, batch=219\n",
      "7414: loss=0.166, reward_mean=0.510, reward_bound=0.254, batch=222\n",
      "7415: loss=0.166, reward_mean=0.380, reward_bound=0.349, batch=223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7416: loss=0.166, reward_mean=0.480, reward_bound=0.387, batch=185\n",
      "7417: loss=0.164, reward_mean=0.390, reward_bound=0.115, batch=199\n",
      "7418: loss=0.158, reward_mean=0.620, reward_bound=0.265, batch=209\n",
      "7419: loss=0.158, reward_mean=0.520, reward_bound=0.254, batch=215\n",
      "7420: loss=0.159, reward_mean=0.350, reward_bound=0.260, batch=220\n",
      "7421: loss=0.161, reward_mean=0.370, reward_bound=0.282, batch=220\n",
      "7422: loss=0.164, reward_mean=0.440, reward_bound=0.314, batch=209\n",
      "7423: loss=0.165, reward_mean=0.470, reward_bound=0.314, batch=215\n",
      "7424: loss=0.166, reward_mean=0.510, reward_bound=0.349, batch=211\n",
      "7425: loss=0.165, reward_mean=0.510, reward_bound=0.282, batch=215\n",
      "7426: loss=0.165, reward_mean=0.430, reward_bound=0.314, batch=219\n",
      "7427: loss=0.165, reward_mean=0.450, reward_bound=0.254, batch=222\n",
      "7428: loss=0.165, reward_mean=0.430, reward_bound=0.282, batch=222\n",
      "7429: loss=0.166, reward_mean=0.470, reward_bound=0.324, batch=225\n",
      "7430: loss=0.163, reward_mean=0.450, reward_bound=0.387, batch=213\n",
      "7431: loss=0.162, reward_mean=0.410, reward_bound=0.254, batch=217\n",
      "7432: loss=0.160, reward_mean=0.520, reward_bound=0.297, batch=222\n",
      "7433: loss=0.161, reward_mean=0.440, reward_bound=0.314, batch=221\n",
      "7434: loss=0.166, reward_mean=0.430, reward_bound=0.349, batch=221\n",
      "7435: loss=0.165, reward_mean=0.390, reward_bound=0.314, batch=224\n",
      "7436: loss=0.166, reward_mean=0.430, reward_bound=0.349, batch=223\n",
      "7437: loss=0.164, reward_mean=0.430, reward_bound=0.387, batch=222\n",
      "7438: loss=0.164, reward_mean=0.520, reward_bound=0.292, batch=225\n",
      "7439: loss=0.164, reward_mean=0.450, reward_bound=0.321, batch=227\n",
      "7440: loss=0.163, reward_mean=0.340, reward_bound=0.342, batch=229\n",
      "7441: loss=0.163, reward_mean=0.380, reward_bound=0.349, batch=229\n",
      "7442: loss=0.163, reward_mean=0.440, reward_bound=0.405, batch=230\n",
      "7443: loss=0.162, reward_mean=0.390, reward_bound=0.418, batch=231\n",
      "7444: loss=0.167, reward_mean=0.390, reward_bound=0.430, batch=186\n",
      "7445: loss=0.160, reward_mean=0.380, reward_bound=0.167, batch=199\n",
      "7446: loss=0.162, reward_mean=0.480, reward_bound=0.185, batch=205\n",
      "7447: loss=0.161, reward_mean=0.460, reward_bound=0.149, batch=213\n",
      "7448: loss=0.162, reward_mean=0.500, reward_bound=0.206, batch=216\n",
      "7449: loss=0.161, reward_mean=0.440, reward_bound=0.229, batch=220\n",
      "7450: loss=0.163, reward_mean=0.460, reward_bound=0.254, batch=221\n",
      "7451: loss=0.167, reward_mean=0.440, reward_bound=0.282, batch=220\n",
      "7452: loss=0.167, reward_mean=0.440, reward_bound=0.304, batch=224\n",
      "7453: loss=0.169, reward_mean=0.450, reward_bound=0.314, batch=218\n",
      "7454: loss=0.169, reward_mean=0.500, reward_bound=0.349, batch=212\n",
      "7455: loss=0.167, reward_mean=0.450, reward_bound=0.254, batch=217\n",
      "7456: loss=0.166, reward_mean=0.440, reward_bound=0.314, batch=220\n",
      "7457: loss=0.167, reward_mean=0.470, reward_bound=0.282, batch=223\n",
      "7458: loss=0.167, reward_mean=0.490, reward_bound=0.335, batch=226\n",
      "7459: loss=0.167, reward_mean=0.460, reward_bound=0.282, batch=227\n",
      "7460: loss=0.165, reward_mean=0.450, reward_bound=0.349, batch=227\n",
      "7461: loss=0.166, reward_mean=0.470, reward_bound=0.380, batch=229\n",
      "7462: loss=0.167, reward_mean=0.420, reward_bound=0.387, batch=221\n",
      "7463: loss=0.167, reward_mean=0.470, reward_bound=0.314, batch=224\n",
      "7464: loss=0.166, reward_mean=0.550, reward_bound=0.384, batch=227\n",
      "7465: loss=0.166, reward_mean=0.430, reward_bound=0.387, batch=225\n",
      "7466: loss=0.163, reward_mean=0.380, reward_bound=0.430, batch=204\n",
      "7467: loss=0.162, reward_mean=0.390, reward_bound=0.165, batch=213\n",
      "7468: loss=0.162, reward_mean=0.530, reward_bound=0.244, batch=219\n",
      "7469: loss=0.166, reward_mean=0.390, reward_bound=0.314, batch=220\n",
      "7470: loss=0.165, reward_mean=0.440, reward_bound=0.349, batch=218\n",
      "7471: loss=0.165, reward_mean=0.400, reward_bound=0.314, batch=220\n",
      "7472: loss=0.163, reward_mean=0.390, reward_bound=0.282, batch=223\n",
      "7473: loss=0.164, reward_mean=0.490, reward_bound=0.349, batch=224\n",
      "7474: loss=0.164, reward_mean=0.400, reward_bound=0.387, batch=222\n",
      "7475: loss=0.163, reward_mean=0.510, reward_bound=0.349, batch=223\n",
      "7476: loss=0.166, reward_mean=0.490, reward_bound=0.413, batch=226\n",
      "7477: loss=0.166, reward_mean=0.410, reward_bound=0.390, batch=228\n",
      "7478: loss=0.166, reward_mean=0.440, reward_bound=0.357, batch=229\n",
      "7479: loss=0.160, reward_mean=0.400, reward_bound=0.430, batch=217\n",
      "7480: loss=0.161, reward_mean=0.480, reward_bound=0.229, batch=221\n",
      "7481: loss=0.162, reward_mean=0.500, reward_bound=0.314, batch=222\n",
      "7482: loss=0.164, reward_mean=0.360, reward_bound=0.324, batch=225\n",
      "7483: loss=0.164, reward_mean=0.500, reward_bound=0.321, batch=227\n",
      "7484: loss=0.163, reward_mean=0.450, reward_bound=0.380, batch=229\n",
      "7485: loss=0.162, reward_mean=0.450, reward_bound=0.430, batch=227\n",
      "7486: loss=0.162, reward_mean=0.510, reward_bound=0.349, batch=228\n",
      "7487: loss=0.162, reward_mean=0.530, reward_bound=0.357, batch=229\n",
      "7488: loss=0.162, reward_mean=0.500, reward_bound=0.430, batch=229\n",
      "7489: loss=0.165, reward_mean=0.460, reward_bound=0.478, batch=232\n",
      "7490: loss=0.158, reward_mean=0.500, reward_bound=0.478, batch=88\n",
      "7491: loss=0.159, reward_mean=0.370, reward_bound=0.000, batch=125\n",
      "7492: loss=0.163, reward_mean=0.430, reward_bound=0.011, batch=157\n",
      "7493: loss=0.158, reward_mean=0.510, reward_bound=0.042, batch=178\n",
      "7494: loss=0.152, reward_mean=0.380, reward_bound=0.065, batch=190\n",
      "7495: loss=0.144, reward_mean=0.520, reward_bound=0.086, batch=203\n",
      "7496: loss=0.144, reward_mean=0.400, reward_bound=0.098, batch=206\n",
      "7497: loss=0.147, reward_mean=0.440, reward_bound=0.109, batch=213\n",
      "7498: loss=0.152, reward_mean=0.440, reward_bound=0.135, batch=211\n",
      "7499: loss=0.152, reward_mean=0.350, reward_bound=0.150, batch=207\n",
      "7500: loss=0.151, reward_mean=0.470, reward_bound=0.167, batch=206\n",
      "7501: loss=0.153, reward_mean=0.520, reward_bound=0.185, batch=211\n",
      "7502: loss=0.152, reward_mean=0.410, reward_bound=0.185, batch=216\n",
      "7503: loss=0.153, reward_mean=0.410, reward_bound=0.206, batch=208\n",
      "7504: loss=0.155, reward_mean=0.470, reward_bound=0.229, batch=197\n",
      "7505: loss=0.156, reward_mean=0.410, reward_bound=0.107, batch=208\n",
      "7506: loss=0.154, reward_mean=0.480, reward_bound=0.187, batch=215\n",
      "7507: loss=0.158, reward_mean=0.500, reward_bound=0.254, batch=200\n",
      "7508: loss=0.157, reward_mean=0.410, reward_bound=0.167, batch=209\n",
      "7509: loss=0.159, reward_mean=0.360, reward_bound=0.194, batch=216\n",
      "7510: loss=0.161, reward_mean=0.380, reward_bound=0.254, batch=219\n",
      "7511: loss=0.168, reward_mean=0.440, reward_bound=0.282, batch=200\n",
      "7512: loss=0.169, reward_mean=0.340, reward_bound=0.142, batch=210\n",
      "7513: loss=0.165, reward_mean=0.560, reward_bound=0.185, batch=216\n",
      "7514: loss=0.166, reward_mean=0.470, reward_bound=0.241, batch=221\n",
      "7515: loss=0.167, reward_mean=0.440, reward_bound=0.282, batch=223\n",
      "7516: loss=0.174, reward_mean=0.540, reward_bound=0.314, batch=204\n",
      "7517: loss=0.174, reward_mean=0.450, reward_bound=0.229, batch=212\n",
      "7518: loss=0.173, reward_mean=0.480, reward_bound=0.206, batch=218\n",
      "7519: loss=0.174, reward_mean=0.380, reward_bound=0.282, batch=219\n",
      "7520: loss=0.175, reward_mean=0.540, reward_bound=0.314, batch=219\n",
      "7521: loss=0.175, reward_mean=0.380, reward_bound=0.314, batch=222\n",
      "7522: loss=0.169, reward_mean=0.390, reward_bound=0.349, batch=187\n",
      "7523: loss=0.170, reward_mean=0.410, reward_bound=0.192, batch=201\n",
      "7524: loss=0.169, reward_mean=0.380, reward_bound=0.122, batch=209\n",
      "7525: loss=0.168, reward_mean=0.410, reward_bound=0.164, batch=216\n",
      "7526: loss=0.171, reward_mean=0.470, reward_bound=0.206, batch=218\n",
      "7527: loss=0.170, reward_mean=0.340, reward_bound=0.229, batch=219\n",
      "7528: loss=0.171, reward_mean=0.510, reward_bound=0.239, batch=223\n",
      "7529: loss=0.169, reward_mean=0.500, reward_bound=0.282, batch=221\n",
      "7530: loss=0.173, reward_mean=0.440, reward_bound=0.314, batch=216\n",
      "7531: loss=0.179, reward_mean=0.380, reward_bound=0.268, batch=221\n",
      "7532: loss=0.175, reward_mean=0.420, reward_bound=0.349, batch=215\n",
      "7533: loss=0.174, reward_mean=0.360, reward_bound=0.254, batch=218\n",
      "7534: loss=0.173, reward_mean=0.400, reward_bound=0.314, batch=221\n",
      "7535: loss=0.174, reward_mean=0.420, reward_bound=0.349, batch=222\n",
      "7536: loss=0.173, reward_mean=0.460, reward_bound=0.349, batch=224\n",
      "7537: loss=0.163, reward_mean=0.410, reward_bound=0.387, batch=177\n",
      "7538: loss=0.166, reward_mean=0.500, reward_bound=0.150, batch=192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7539: loss=0.169, reward_mean=0.420, reward_bound=0.145, batch=204\n",
      "7540: loss=0.170, reward_mean=0.460, reward_bound=0.226, batch=213\n",
      "7541: loss=0.167, reward_mean=0.360, reward_bound=0.229, batch=211\n",
      "7542: loss=0.167, reward_mean=0.390, reward_bound=0.254, batch=215\n",
      "7543: loss=0.166, reward_mean=0.440, reward_bound=0.282, batch=212\n",
      "7544: loss=0.166, reward_mean=0.400, reward_bound=0.263, batch=218\n",
      "7545: loss=0.169, reward_mean=0.460, reward_bound=0.314, batch=211\n",
      "7546: loss=0.169, reward_mean=0.400, reward_bound=0.314, batch=217\n",
      "7547: loss=0.166, reward_mean=0.440, reward_bound=0.349, batch=212\n",
      "7548: loss=0.168, reward_mean=0.420, reward_bound=0.314, batch=216\n",
      "7549: loss=0.170, reward_mean=0.430, reward_bound=0.314, batch=218\n",
      "7550: loss=0.171, reward_mean=0.420, reward_bound=0.282, batch=221\n",
      "7551: loss=0.171, reward_mean=0.490, reward_bound=0.349, batch=221\n",
      "7552: loss=0.173, reward_mean=0.430, reward_bound=0.387, batch=210\n",
      "7553: loss=0.172, reward_mean=0.480, reward_bound=0.296, batch=217\n",
      "7554: loss=0.171, reward_mean=0.480, reward_bound=0.308, batch=222\n",
      "7555: loss=0.174, reward_mean=0.430, reward_bound=0.349, batch=221\n",
      "7556: loss=0.174, reward_mean=0.470, reward_bound=0.282, batch=224\n",
      "7557: loss=0.173, reward_mean=0.410, reward_bound=0.349, batch=225\n",
      "7558: loss=0.172, reward_mean=0.470, reward_bound=0.387, batch=221\n",
      "7559: loss=0.174, reward_mean=0.460, reward_bound=0.387, batch=224\n",
      "7560: loss=0.174, reward_mean=0.490, reward_bound=0.349, batch=226\n",
      "7561: loss=0.175, reward_mean=0.400, reward_bound=0.409, batch=228\n",
      "7562: loss=0.165, reward_mean=0.430, reward_bound=0.430, batch=154\n",
      "7563: loss=0.165, reward_mean=0.430, reward_bound=0.063, batch=178\n",
      "7564: loss=0.168, reward_mean=0.450, reward_bound=0.081, batch=194\n",
      "7565: loss=0.162, reward_mean=0.360, reward_bound=0.122, batch=204\n",
      "7566: loss=0.163, reward_mean=0.430, reward_bound=0.135, batch=210\n",
      "7567: loss=0.165, reward_mean=0.420, reward_bound=0.150, batch=215\n",
      "7568: loss=0.166, reward_mean=0.430, reward_bound=0.170, batch=220\n",
      "7569: loss=0.161, reward_mean=0.400, reward_bound=0.185, batch=219\n",
      "7570: loss=0.162, reward_mean=0.370, reward_bound=0.206, batch=219\n",
      "7571: loss=0.162, reward_mean=0.330, reward_bound=0.206, batch=221\n",
      "7572: loss=0.164, reward_mean=0.470, reward_bound=0.229, batch=214\n",
      "7573: loss=0.163, reward_mean=0.450, reward_bound=0.226, batch=220\n",
      "7574: loss=0.162, reward_mean=0.470, reward_bound=0.254, batch=214\n",
      "7575: loss=0.161, reward_mean=0.410, reward_bound=0.280, batch=220\n",
      "7576: loss=0.163, reward_mean=0.380, reward_bound=0.282, batch=210\n",
      "7577: loss=0.162, reward_mean=0.330, reward_bound=0.282, batch=216\n",
      "7578: loss=0.162, reward_mean=0.500, reward_bound=0.268, batch=221\n",
      "7579: loss=0.163, reward_mean=0.400, reward_bound=0.282, batch=223\n",
      "7580: loss=0.166, reward_mean=0.450, reward_bound=0.314, batch=210\n",
      "7581: loss=0.165, reward_mean=0.430, reward_bound=0.240, batch=217\n",
      "7582: loss=0.168, reward_mean=0.480, reward_bound=0.254, batch=219\n",
      "7583: loss=0.164, reward_mean=0.400, reward_bound=0.282, batch=218\n",
      "7584: loss=0.165, reward_mean=0.420, reward_bound=0.260, batch=222\n",
      "7585: loss=0.164, reward_mean=0.350, reward_bound=0.314, batch=221\n",
      "7586: loss=0.164, reward_mean=0.390, reward_bound=0.282, batch=222\n",
      "7587: loss=0.165, reward_mean=0.470, reward_bound=0.349, batch=206\n",
      "7588: loss=0.167, reward_mean=0.410, reward_bound=0.282, batch=212\n",
      "7589: loss=0.168, reward_mean=0.520, reward_bound=0.314, batch=215\n",
      "7590: loss=0.170, reward_mean=0.450, reward_bound=0.234, batch=220\n",
      "7591: loss=0.169, reward_mean=0.440, reward_bound=0.304, batch=224\n",
      "7592: loss=0.171, reward_mean=0.400, reward_bound=0.282, batch=226\n",
      "7593: loss=0.172, reward_mean=0.390, reward_bound=0.314, batch=225\n",
      "7594: loss=0.167, reward_mean=0.400, reward_bound=0.349, batch=220\n",
      "7595: loss=0.166, reward_mean=0.440, reward_bound=0.314, batch=223\n",
      "7596: loss=0.165, reward_mean=0.430, reward_bound=0.372, batch=226\n",
      "7597: loss=0.167, reward_mean=0.440, reward_bound=0.387, batch=206\n",
      "7598: loss=0.168, reward_mean=0.390, reward_bound=0.176, batch=214\n",
      "7599: loss=0.169, reward_mean=0.370, reward_bound=0.185, batch=218\n",
      "7600: loss=0.166, reward_mean=0.440, reward_bound=0.254, batch=216\n",
      "7601: loss=0.166, reward_mean=0.400, reward_bound=0.314, batch=220\n",
      "7602: loss=0.169, reward_mean=0.410, reward_bound=0.349, batch=220\n",
      "7603: loss=0.171, reward_mean=0.460, reward_bound=0.387, batch=219\n",
      "7604: loss=0.171, reward_mean=0.420, reward_bound=0.364, batch=223\n",
      "7605: loss=0.170, reward_mean=0.370, reward_bound=0.324, batch=226\n",
      "7606: loss=0.169, reward_mean=0.520, reward_bound=0.387, batch=225\n",
      "7607: loss=0.170, reward_mean=0.410, reward_bound=0.349, batch=225\n",
      "7608: loss=0.167, reward_mean=0.460, reward_bound=0.430, batch=201\n",
      "7609: loss=0.171, reward_mean=0.420, reward_bound=0.206, batch=210\n",
      "7610: loss=0.167, reward_mean=0.370, reward_bound=0.254, batch=214\n",
      "7611: loss=0.171, reward_mean=0.370, reward_bound=0.254, batch=219\n",
      "7612: loss=0.175, reward_mean=0.420, reward_bound=0.282, batch=217\n",
      "7613: loss=0.176, reward_mean=0.370, reward_bound=0.277, batch=222\n",
      "7614: loss=0.175, reward_mean=0.410, reward_bound=0.314, batch=221\n",
      "7615: loss=0.176, reward_mean=0.480, reward_bound=0.349, batch=220\n",
      "7616: loss=0.175, reward_mean=0.410, reward_bound=0.304, batch=224\n",
      "7617: loss=0.178, reward_mean=0.420, reward_bound=0.349, batch=224\n",
      "7618: loss=0.177, reward_mean=0.430, reward_bound=0.311, batch=227\n",
      "7619: loss=0.177, reward_mean=0.430, reward_bound=0.349, batch=228\n",
      "7620: loss=0.174, reward_mean=0.360, reward_bound=0.387, batch=221\n",
      "7621: loss=0.175, reward_mean=0.460, reward_bound=0.387, batch=224\n",
      "7622: loss=0.177, reward_mean=0.380, reward_bound=0.387, batch=226\n",
      "7623: loss=0.178, reward_mean=0.350, reward_bound=0.351, batch=228\n",
      "7624: loss=0.177, reward_mean=0.450, reward_bound=0.392, batch=229\n",
      "7625: loss=0.175, reward_mean=0.360, reward_bound=0.430, batch=217\n",
      "7626: loss=0.173, reward_mean=0.420, reward_bound=0.342, batch=222\n",
      "7627: loss=0.172, reward_mean=0.440, reward_bound=0.292, batch=225\n",
      "7628: loss=0.174, reward_mean=0.430, reward_bound=0.321, batch=227\n",
      "7629: loss=0.175, reward_mean=0.440, reward_bound=0.349, batch=228\n",
      "7630: loss=0.174, reward_mean=0.350, reward_bound=0.392, batch=229\n",
      "7631: loss=0.174, reward_mean=0.380, reward_bound=0.405, batch=230\n",
      "7632: loss=0.173, reward_mean=0.370, reward_bound=0.430, batch=225\n",
      "7633: loss=0.175, reward_mean=0.410, reward_bound=0.356, batch=227\n",
      "7634: loss=0.173, reward_mean=0.350, reward_bound=0.387, batch=228\n",
      "7635: loss=0.173, reward_mean=0.490, reward_bound=0.349, batch=228\n",
      "7636: loss=0.172, reward_mean=0.390, reward_bound=0.357, batch=229\n",
      "7637: loss=0.172, reward_mean=0.380, reward_bound=0.405, batch=230\n",
      "7638: loss=0.173, reward_mean=0.360, reward_bound=0.406, batch=231\n",
      "7639: loss=0.172, reward_mean=0.440, reward_bound=0.430, batch=229\n",
      "7640: loss=0.173, reward_mean=0.360, reward_bound=0.405, batch=230\n",
      "7641: loss=0.172, reward_mean=0.360, reward_bound=0.376, batch=231\n",
      "7642: loss=0.172, reward_mean=0.300, reward_bound=0.430, batch=230\n",
      "7643: loss=0.172, reward_mean=0.370, reward_bound=0.349, batch=230\n",
      "7644: loss=0.172, reward_mean=0.400, reward_bound=0.430, batch=230\n",
      "7645: loss=0.173, reward_mean=0.370, reward_bound=0.451, batch=231\n",
      "7646: loss=0.173, reward_mean=0.310, reward_bound=0.430, batch=231\n",
      "7647: loss=0.171, reward_mean=0.400, reward_bound=0.478, batch=146\n",
      "7648: loss=0.174, reward_mean=0.460, reward_bound=0.050, batch=172\n",
      "7649: loss=0.182, reward_mean=0.280, reward_bound=0.040, batch=190\n",
      "7650: loss=0.172, reward_mean=0.400, reward_bound=0.089, batch=202\n",
      "7651: loss=0.169, reward_mean=0.370, reward_bound=0.109, batch=210\n",
      "7652: loss=0.170, reward_mean=0.410, reward_bound=0.150, batch=213\n",
      "7653: loss=0.171, reward_mean=0.420, reward_bound=0.178, batch=219\n",
      "7654: loss=0.168, reward_mean=0.440, reward_bound=0.185, batch=219\n",
      "7655: loss=0.165, reward_mean=0.380, reward_bound=0.206, batch=222\n",
      "7656: loss=0.162, reward_mean=0.370, reward_bound=0.254, batch=210\n",
      "7657: loss=0.166, reward_mean=0.410, reward_bound=0.247, batch=217\n",
      "7658: loss=0.165, reward_mean=0.340, reward_bound=0.277, batch=222\n",
      "7659: loss=0.169, reward_mean=0.440, reward_bound=0.282, batch=215\n",
      "7660: loss=0.169, reward_mean=0.340, reward_bound=0.234, batch=220\n",
      "7661: loss=0.173, reward_mean=0.450, reward_bound=0.314, batch=210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7662: loss=0.174, reward_mean=0.440, reward_bound=0.274, batch=217\n",
      "7663: loss=0.175, reward_mean=0.530, reward_bound=0.277, batch=222\n",
      "7664: loss=0.172, reward_mean=0.440, reward_bound=0.292, batch=225\n",
      "7665: loss=0.173, reward_mean=0.450, reward_bound=0.349, batch=204\n",
      "7666: loss=0.171, reward_mean=0.400, reward_bound=0.183, batch=213\n",
      "7667: loss=0.173, reward_mean=0.440, reward_bound=0.206, batch=218\n",
      "7668: loss=0.176, reward_mean=0.470, reward_bound=0.254, batch=217\n",
      "7669: loss=0.171, reward_mean=0.460, reward_bound=0.282, batch=216\n",
      "7670: loss=0.170, reward_mean=0.410, reward_bound=0.314, batch=218\n",
      "7671: loss=0.170, reward_mean=0.440, reward_bound=0.260, batch=222\n",
      "7672: loss=0.173, reward_mean=0.410, reward_bound=0.314, batch=222\n",
      "7673: loss=0.171, reward_mean=0.430, reward_bound=0.263, batch=225\n",
      "7674: loss=0.170, reward_mean=0.470, reward_bound=0.349, batch=221\n",
      "7675: loss=0.170, reward_mean=0.440, reward_bound=0.349, batch=224\n",
      "7676: loss=0.170, reward_mean=0.400, reward_bound=0.345, batch=227\n",
      "7677: loss=0.170, reward_mean=0.350, reward_bound=0.314, batch=228\n",
      "7678: loss=0.170, reward_mean=0.420, reward_bound=0.349, batch=228\n",
      "7679: loss=0.169, reward_mean=0.420, reward_bound=0.387, batch=206\n",
      "7680: loss=0.170, reward_mean=0.480, reward_bound=0.206, batch=212\n",
      "7681: loss=0.170, reward_mean=0.470, reward_bound=0.236, batch=218\n",
      "7682: loss=0.169, reward_mean=0.340, reward_bound=0.257, batch=222\n",
      "7683: loss=0.167, reward_mean=0.400, reward_bound=0.282, batch=222\n",
      "7684: loss=0.172, reward_mean=0.550, reward_bound=0.314, batch=223\n",
      "7685: loss=0.172, reward_mean=0.460, reward_bound=0.349, batch=224\n",
      "7686: loss=0.172, reward_mean=0.400, reward_bound=0.384, batch=227\n",
      "7687: loss=0.173, reward_mean=0.350, reward_bound=0.387, batch=221\n",
      "7688: loss=0.171, reward_mean=0.420, reward_bound=0.229, batch=224\n",
      "7689: loss=0.172, reward_mean=0.300, reward_bound=0.311, batch=227\n",
      "7690: loss=0.173, reward_mean=0.450, reward_bound=0.349, batch=226\n",
      "7691: loss=0.173, reward_mean=0.390, reward_bound=0.229, batch=227\n",
      "7692: loss=0.174, reward_mean=0.460, reward_bound=0.380, batch=229\n",
      "7693: loss=0.171, reward_mean=0.470, reward_bound=0.430, batch=192\n",
      "7694: loss=0.170, reward_mean=0.380, reward_bound=0.083, batch=204\n",
      "7695: loss=0.168, reward_mean=0.390, reward_bound=0.183, batch=213\n",
      "7696: loss=0.167, reward_mean=0.450, reward_bound=0.198, batch=219\n",
      "7697: loss=0.165, reward_mean=0.380, reward_bound=0.229, batch=220\n",
      "7698: loss=0.166, reward_mean=0.490, reward_bound=0.247, batch=224\n",
      "7699: loss=0.168, reward_mean=0.370, reward_bound=0.282, batch=218\n",
      "7700: loss=0.167, reward_mean=0.430, reward_bound=0.314, batch=211\n",
      "7701: loss=0.167, reward_mean=0.420, reward_bound=0.314, batch=217\n",
      "7702: loss=0.168, reward_mean=0.460, reward_bound=0.297, batch=222\n",
      "7703: loss=0.169, reward_mean=0.400, reward_bound=0.349, batch=216\n",
      "7704: loss=0.169, reward_mean=0.560, reward_bound=0.349, batch=220\n",
      "7705: loss=0.168, reward_mean=0.420, reward_bound=0.356, batch=224\n",
      "7706: loss=0.171, reward_mean=0.390, reward_bound=0.349, batch=226\n",
      "7707: loss=0.167, reward_mean=0.450, reward_bound=0.387, batch=215\n",
      "7708: loss=0.166, reward_mean=0.570, reward_bound=0.356, batch=220\n",
      "7709: loss=0.167, reward_mean=0.390, reward_bound=0.376, batch=224\n",
      "7710: loss=0.167, reward_mean=0.500, reward_bound=0.384, batch=227\n",
      "7711: loss=0.170, reward_mean=0.420, reward_bound=0.430, batch=212\n",
      "7712: loss=0.167, reward_mean=0.370, reward_bound=0.254, batch=217\n",
      "7713: loss=0.170, reward_mean=0.400, reward_bound=0.277, batch=222\n",
      "7714: loss=0.169, reward_mean=0.480, reward_bound=0.282, batch=222\n",
      "7715: loss=0.173, reward_mean=0.490, reward_bound=0.314, batch=223\n",
      "7716: loss=0.174, reward_mean=0.280, reward_bound=0.322, batch=226\n",
      "7717: loss=0.170, reward_mean=0.470, reward_bound=0.349, batch=225\n",
      "7718: loss=0.172, reward_mean=0.440, reward_bound=0.329, batch=227\n",
      "7719: loss=0.170, reward_mean=0.430, reward_bound=0.387, batch=223\n",
      "7720: loss=0.170, reward_mean=0.410, reward_bound=0.271, batch=226\n",
      "7721: loss=0.168, reward_mean=0.410, reward_bound=0.331, batch=228\n",
      "7722: loss=0.168, reward_mean=0.470, reward_bound=0.349, batch=228\n",
      "7723: loss=0.168, reward_mean=0.260, reward_bound=0.392, batch=229\n",
      "7724: loss=0.167, reward_mean=0.430, reward_bound=0.405, batch=230\n",
      "7725: loss=0.167, reward_mean=0.380, reward_bound=0.387, batch=230\n",
      "7726: loss=0.167, reward_mean=0.390, reward_bound=0.387, batch=230\n",
      "7727: loss=0.169, reward_mean=0.410, reward_bound=0.430, batch=225\n",
      "7728: loss=0.169, reward_mean=0.430, reward_bound=0.430, batch=226\n",
      "7729: loss=0.169, reward_mean=0.470, reward_bound=0.430, batch=227\n",
      "7730: loss=0.168, reward_mean=0.450, reward_bound=0.387, batch=228\n",
      "7731: loss=0.168, reward_mean=0.390, reward_bound=0.357, batch=229\n",
      "7732: loss=0.168, reward_mean=0.440, reward_bound=0.405, batch=230\n",
      "7733: loss=0.168, reward_mean=0.450, reward_bound=0.418, batch=231\n",
      "7734: loss=0.168, reward_mean=0.450, reward_bound=0.349, batch=231\n",
      "7735: loss=0.170, reward_mean=0.520, reward_bound=0.430, batch=231\n",
      "7736: loss=0.170, reward_mean=0.510, reward_bound=0.387, batch=231\n",
      "7737: loss=0.169, reward_mean=0.390, reward_bound=0.478, batch=180\n",
      "7738: loss=0.168, reward_mean=0.390, reward_bound=0.138, batch=196\n",
      "7739: loss=0.168, reward_mean=0.450, reward_bound=0.176, batch=207\n",
      "7740: loss=0.168, reward_mean=0.370, reward_bound=0.185, batch=213\n",
      "7741: loss=0.167, reward_mean=0.450, reward_bound=0.229, batch=216\n",
      "7742: loss=0.173, reward_mean=0.220, reward_bound=0.254, batch=217\n",
      "7743: loss=0.174, reward_mean=0.310, reward_bound=0.277, batch=222\n",
      "7744: loss=0.177, reward_mean=0.470, reward_bound=0.282, batch=222\n",
      "7745: loss=0.178, reward_mean=0.400, reward_bound=0.314, batch=220\n",
      "7746: loss=0.182, reward_mean=0.450, reward_bound=0.338, batch=224\n",
      "7747: loss=0.182, reward_mean=0.470, reward_bound=0.345, batch=227\n",
      "7748: loss=0.173, reward_mean=0.450, reward_bound=0.349, batch=214\n",
      "7749: loss=0.177, reward_mean=0.380, reward_bound=0.280, batch=220\n",
      "7750: loss=0.174, reward_mean=0.510, reward_bound=0.314, batch=222\n",
      "7751: loss=0.174, reward_mean=0.400, reward_bound=0.360, batch=225\n",
      "7752: loss=0.174, reward_mean=0.380, reward_bound=0.356, batch=227\n",
      "7753: loss=0.173, reward_mean=0.380, reward_bound=0.277, batch=229\n",
      "7754: loss=0.169, reward_mean=0.410, reward_bound=0.387, batch=216\n",
      "7755: loss=0.176, reward_mean=0.300, reward_bound=0.186, batch=221\n",
      "7756: loss=0.167, reward_mean=0.500, reward_bound=0.349, batch=222\n",
      "7757: loss=0.166, reward_mean=0.390, reward_bound=0.360, batch=225\n",
      "7758: loss=0.167, reward_mean=0.360, reward_bound=0.314, batch=226\n",
      "7759: loss=0.166, reward_mean=0.540, reward_bound=0.387, batch=226\n",
      "7760: loss=0.165, reward_mean=0.400, reward_bound=0.368, batch=228\n",
      "7761: loss=0.166, reward_mean=0.490, reward_bound=0.430, batch=206\n",
      "7762: loss=0.164, reward_mean=0.380, reward_bound=0.196, batch=214\n",
      "7763: loss=0.166, reward_mean=0.400, reward_bound=0.206, batch=219\n",
      "7764: loss=0.166, reward_mean=0.380, reward_bound=0.254, batch=222\n",
      "7765: loss=0.166, reward_mean=0.350, reward_bound=0.282, batch=224\n",
      "7766: loss=0.165, reward_mean=0.350, reward_bound=0.311, batch=227\n",
      "7767: loss=0.166, reward_mean=0.410, reward_bound=0.314, batch=224\n",
      "7768: loss=0.167, reward_mean=0.390, reward_bound=0.349, batch=222\n",
      "7769: loss=0.168, reward_mean=0.440, reward_bound=0.360, batch=225\n",
      "7770: loss=0.167, reward_mean=0.440, reward_bound=0.349, batch=226\n",
      "7771: loss=0.167, reward_mean=0.320, reward_bound=0.368, batch=228\n",
      "7772: loss=0.167, reward_mean=0.390, reward_bound=0.387, batch=223\n",
      "7773: loss=0.167, reward_mean=0.360, reward_bound=0.358, batch=226\n",
      "7774: loss=0.168, reward_mean=0.390, reward_bound=0.351, batch=228\n",
      "7775: loss=0.167, reward_mean=0.490, reward_bound=0.349, batch=228\n",
      "7776: loss=0.167, reward_mean=0.450, reward_bound=0.353, batch=229\n",
      "7777: loss=0.165, reward_mean=0.440, reward_bound=0.387, batch=229\n",
      "7778: loss=0.165, reward_mean=0.410, reward_bound=0.430, batch=223\n",
      "7779: loss=0.164, reward_mean=0.320, reward_bound=0.372, batch=226\n",
      "7780: loss=0.164, reward_mean=0.430, reward_bound=0.454, batch=228\n",
      "7781: loss=0.165, reward_mean=0.460, reward_bound=0.478, batch=232\n",
      "7782: loss=0.165, reward_mean=0.400, reward_bound=0.478, batch=195\n",
      "7783: loss=0.172, reward_mean=0.460, reward_bound=0.229, batch=204\n",
      "7784: loss=0.172, reward_mean=0.420, reward_bound=0.226, batch=213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7785: loss=0.172, reward_mean=0.500, reward_bound=0.282, batch=215\n",
      "7786: loss=0.171, reward_mean=0.460, reward_bound=0.314, batch=214\n",
      "7787: loss=0.171, reward_mean=0.400, reward_bound=0.314, batch=219\n",
      "7788: loss=0.172, reward_mean=0.340, reward_bound=0.314, batch=222\n",
      "7789: loss=0.169, reward_mean=0.470, reward_bound=0.349, batch=222\n",
      "7790: loss=0.169, reward_mean=0.450, reward_bound=0.360, batch=225\n",
      "7791: loss=0.169, reward_mean=0.410, reward_bound=0.314, batch=226\n",
      "7792: loss=0.170, reward_mean=0.400, reward_bound=0.387, batch=216\n",
      "7793: loss=0.169, reward_mean=0.320, reward_bound=0.241, batch=221\n",
      "7794: loss=0.169, reward_mean=0.450, reward_bound=0.282, batch=224\n",
      "7795: loss=0.168, reward_mean=0.340, reward_bound=0.345, batch=227\n",
      "7796: loss=0.172, reward_mean=0.440, reward_bound=0.349, batch=228\n",
      "7797: loss=0.172, reward_mean=0.420, reward_bound=0.321, batch=229\n",
      "7798: loss=0.171, reward_mean=0.470, reward_bound=0.405, batch=230\n",
      "7799: loss=0.171, reward_mean=0.390, reward_bound=0.406, batch=231\n",
      "7800: loss=0.172, reward_mean=0.400, reward_bound=0.430, batch=212\n",
      "7801: loss=0.174, reward_mean=0.430, reward_bound=0.254, batch=217\n",
      "7802: loss=0.173, reward_mean=0.440, reward_bound=0.277, batch=222\n",
      "7803: loss=0.174, reward_mean=0.370, reward_bound=0.292, batch=225\n",
      "7804: loss=0.175, reward_mean=0.340, reward_bound=0.314, batch=225\n",
      "7805: loss=0.174, reward_mean=0.450, reward_bound=0.321, batch=227\n",
      "7806: loss=0.171, reward_mean=0.380, reward_bound=0.349, batch=227\n",
      "7807: loss=0.174, reward_mean=0.360, reward_bound=0.387, batch=226\n",
      "7808: loss=0.173, reward_mean=0.420, reward_bound=0.430, batch=222\n",
      "7809: loss=0.174, reward_mean=0.420, reward_bound=0.373, batch=225\n",
      "7810: loss=0.173, reward_mean=0.430, reward_bound=0.396, batch=227\n",
      "7811: loss=0.173, reward_mean=0.380, reward_bound=0.349, batch=228\n",
      "7812: loss=0.173, reward_mean=0.390, reward_bound=0.387, batch=228\n",
      "7813: loss=0.173, reward_mean=0.400, reward_bound=0.430, batch=226\n",
      "7814: loss=0.171, reward_mean=0.360, reward_bound=0.478, batch=207\n",
      "7815: loss=0.172, reward_mean=0.460, reward_bound=0.245, batch=215\n",
      "7816: loss=0.174, reward_mean=0.390, reward_bound=0.254, batch=216\n",
      "7817: loss=0.174, reward_mean=0.470, reward_bound=0.298, batch=221\n",
      "7818: loss=0.176, reward_mean=0.400, reward_bound=0.314, batch=224\n",
      "7819: loss=0.176, reward_mean=0.380, reward_bound=0.345, batch=227\n",
      "7820: loss=0.178, reward_mean=0.420, reward_bound=0.349, batch=224\n",
      "7821: loss=0.175, reward_mean=0.430, reward_bound=0.387, batch=221\n",
      "7822: loss=0.173, reward_mean=0.380, reward_bound=0.430, batch=220\n",
      "7823: loss=0.172, reward_mean=0.440, reward_bound=0.282, batch=223\n",
      "7824: loss=0.171, reward_mean=0.410, reward_bound=0.335, batch=226\n",
      "7825: loss=0.170, reward_mean=0.380, reward_bound=0.331, batch=228\n",
      "7826: loss=0.173, reward_mean=0.450, reward_bound=0.349, batch=228\n",
      "7827: loss=0.173, reward_mean=0.420, reward_bound=0.430, batch=226\n",
      "7828: loss=0.172, reward_mean=0.370, reward_bound=0.409, batch=228\n",
      "7829: loss=0.172, reward_mean=0.390, reward_bound=0.392, batch=229\n",
      "7830: loss=0.171, reward_mean=0.330, reward_bound=0.364, batch=230\n",
      "7831: loss=0.171, reward_mean=0.430, reward_bound=0.418, batch=231\n",
      "7832: loss=0.172, reward_mean=0.300, reward_bound=0.430, batch=228\n",
      "7833: loss=0.173, reward_mean=0.450, reward_bound=0.397, batch=229\n",
      "7834: loss=0.172, reward_mean=0.550, reward_bound=0.478, batch=231\n",
      "7835: loss=0.169, reward_mean=0.400, reward_bound=0.478, batch=220\n",
      "7836: loss=0.167, reward_mean=0.430, reward_bound=0.338, batch=224\n",
      "7837: loss=0.167, reward_mean=0.430, reward_bound=0.311, batch=227\n",
      "7838: loss=0.167, reward_mean=0.480, reward_bound=0.342, batch=229\n",
      "7839: loss=0.168, reward_mean=0.340, reward_bound=0.349, batch=228\n",
      "7840: loss=0.169, reward_mean=0.310, reward_bound=0.353, batch=229\n",
      "7841: loss=0.168, reward_mean=0.440, reward_bound=0.450, batch=230\n",
      "7842: loss=0.168, reward_mean=0.370, reward_bound=0.478, batch=224\n",
      "7843: loss=0.168, reward_mean=0.360, reward_bound=0.229, batch=226\n",
      "7844: loss=0.168, reward_mean=0.400, reward_bound=0.387, batch=226\n",
      "7845: loss=0.168, reward_mean=0.360, reward_bound=0.430, batch=227\n",
      "7846: loss=0.168, reward_mean=0.410, reward_bound=0.282, batch=228\n",
      "7847: loss=0.167, reward_mean=0.340, reward_bound=0.478, batch=231\n",
      "7848: loss=0.167, reward_mean=0.530, reward_bound=0.430, batch=231\n",
      "7849: loss=0.167, reward_mean=0.420, reward_bound=0.478, batch=228\n",
      "7850: loss=0.167, reward_mean=0.370, reward_bound=0.362, batch=229\n",
      "7851: loss=0.167, reward_mean=0.410, reward_bound=0.450, batch=230\n",
      "7852: loss=0.169, reward_mean=0.400, reward_bound=0.478, batch=230\n",
      "7853: loss=0.170, reward_mean=0.340, reward_bound=0.464, batch=231\n",
      "7854: loss=0.170, reward_mean=0.410, reward_bound=0.430, batch=231\n",
      "7855: loss=0.170, reward_mean=0.430, reward_bound=0.349, batch=231\n",
      "7856: loss=0.168, reward_mean=0.370, reward_bound=0.478, batch=231\n",
      "7858: loss=0.168, reward_mean=0.420, reward_bound=0.000, batch=42\n",
      "7859: loss=0.173, reward_mean=0.400, reward_bound=0.000, batch=82\n",
      "7860: loss=0.177, reward_mean=0.350, reward_bound=0.000, batch=117\n",
      "7861: loss=0.184, reward_mean=0.440, reward_bound=0.002, batch=152\n",
      "7862: loss=0.184, reward_mean=0.480, reward_bound=0.016, batch=174\n",
      "7863: loss=0.184, reward_mean=0.400, reward_bound=0.031, batch=189\n",
      "7864: loss=0.182, reward_mean=0.400, reward_bound=0.047, batch=196\n",
      "7865: loss=0.185, reward_mean=0.470, reward_bound=0.072, batch=199\n",
      "7866: loss=0.181, reward_mean=0.500, reward_bound=0.089, batch=197\n",
      "7867: loss=0.180, reward_mean=0.380, reward_bound=0.098, batch=206\n",
      "7868: loss=0.177, reward_mean=0.440, reward_bound=0.109, batch=210\n",
      "7869: loss=0.175, reward_mean=0.490, reward_bound=0.131, batch=217\n",
      "7870: loss=0.175, reward_mean=0.440, reward_bound=0.135, batch=217\n",
      "7871: loss=0.174, reward_mean=0.350, reward_bound=0.150, batch=208\n",
      "7872: loss=0.168, reward_mean=0.370, reward_bound=0.167, batch=188\n",
      "7873: loss=0.165, reward_mean=0.470, reward_bound=0.185, batch=177\n",
      "7874: loss=0.160, reward_mean=0.420, reward_bound=0.147, batch=194\n",
      "7875: loss=0.161, reward_mean=0.450, reward_bound=0.150, batch=205\n",
      "7876: loss=0.160, reward_mean=0.540, reward_bound=0.185, batch=208\n",
      "7877: loss=0.159, reward_mean=0.380, reward_bound=0.206, batch=189\n",
      "7878: loss=0.160, reward_mean=0.490, reward_bound=0.157, batch=202\n",
      "7879: loss=0.158, reward_mean=0.340, reward_bound=0.167, batch=210\n",
      "7880: loss=0.159, reward_mean=0.450, reward_bound=0.229, batch=190\n",
      "7881: loss=0.157, reward_mean=0.490, reward_bound=0.185, batch=202\n",
      "7882: loss=0.158, reward_mean=0.410, reward_bound=0.213, batch=211\n",
      "7883: loss=0.157, reward_mean=0.350, reward_bound=0.167, batch=217\n",
      "7884: loss=0.157, reward_mean=0.370, reward_bound=0.224, batch=222\n",
      "7885: loss=0.159, reward_mean=0.490, reward_bound=0.254, batch=197\n",
      "7886: loss=0.157, reward_mean=0.440, reward_bound=0.254, batch=206\n",
      "7887: loss=0.158, reward_mean=0.370, reward_bound=0.256, batch=214\n",
      "7888: loss=0.163, reward_mean=0.460, reward_bound=0.282, batch=173\n",
      "7889: loss=0.162, reward_mean=0.440, reward_bound=0.098, batch=190\n",
      "7890: loss=0.161, reward_mean=0.420, reward_bound=0.185, batch=199\n",
      "7891: loss=0.165, reward_mean=0.460, reward_bound=0.206, batch=204\n",
      "7892: loss=0.163, reward_mean=0.420, reward_bound=0.226, batch=213\n",
      "7893: loss=0.166, reward_mean=0.510, reward_bound=0.229, batch=213\n",
      "7894: loss=0.166, reward_mean=0.410, reward_bound=0.254, batch=212\n",
      "7895: loss=0.166, reward_mean=0.490, reward_bound=0.220, batch=218\n",
      "7896: loss=0.166, reward_mean=0.410, reward_bound=0.231, batch=222\n",
      "7897: loss=0.163, reward_mean=0.390, reward_bound=0.282, batch=218\n",
      "7898: loss=0.168, reward_mean=0.390, reward_bound=0.314, batch=186\n",
      "7899: loss=0.165, reward_mean=0.430, reward_bound=0.167, batch=197\n",
      "7900: loss=0.165, reward_mean=0.340, reward_bound=0.202, batch=208\n",
      "7901: loss=0.169, reward_mean=0.500, reward_bound=0.254, batch=205\n",
      "7902: loss=0.167, reward_mean=0.340, reward_bound=0.150, batch=211\n",
      "7903: loss=0.169, reward_mean=0.410, reward_bound=0.229, batch=215\n",
      "7904: loss=0.170, reward_mean=0.420, reward_bound=0.206, batch=219\n",
      "7905: loss=0.166, reward_mean=0.370, reward_bound=0.254, batch=222\n",
      "7906: loss=0.168, reward_mean=0.340, reward_bound=0.282, batch=222\n",
      "7907: loss=0.167, reward_mean=0.430, reward_bound=0.314, batch=218\n",
      "7908: loss=0.167, reward_mean=0.430, reward_bound=0.317, batch=222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7909: loss=0.160, reward_mean=0.420, reward_bound=0.349, batch=157\n",
      "7910: loss=0.161, reward_mean=0.450, reward_bound=0.037, batch=180\n",
      "7911: loss=0.169, reward_mean=0.300, reward_bound=0.041, batch=196\n",
      "7912: loss=0.162, reward_mean=0.420, reward_bound=0.068, batch=207\n",
      "7913: loss=0.161, reward_mean=0.450, reward_bound=0.132, batch=215\n",
      "7914: loss=0.161, reward_mean=0.400, reward_bound=0.138, batch=220\n",
      "7915: loss=0.159, reward_mean=0.380, reward_bound=0.167, batch=221\n",
      "7916: loss=0.156, reward_mean=0.370, reward_bound=0.185, batch=220\n",
      "7917: loss=0.159, reward_mean=0.420, reward_bound=0.206, batch=231\n",
      "7918: loss=0.163, reward_mean=0.470, reward_bound=0.206, batch=229\n",
      "7919: loss=0.163, reward_mean=0.470, reward_bound=0.229, batch=228\n",
      "7920: loss=0.159, reward_mean=0.370, reward_bound=0.254, batch=220\n",
      "7921: loss=0.165, reward_mean=0.410, reward_bound=0.282, batch=212\n",
      "7922: loss=0.166, reward_mean=0.370, reward_bound=0.314, batch=205\n",
      "7923: loss=0.167, reward_mean=0.440, reward_bound=0.289, batch=213\n",
      "7924: loss=0.170, reward_mean=0.390, reward_bound=0.254, batch=218\n",
      "7925: loss=0.170, reward_mean=0.400, reward_bound=0.257, batch=222\n",
      "7926: loss=0.164, reward_mean=0.340, reward_bound=0.314, batch=219\n",
      "7927: loss=0.165, reward_mean=0.450, reward_bound=0.349, batch=203\n",
      "7928: loss=0.169, reward_mean=0.420, reward_bound=0.301, batch=212\n",
      "7929: loss=0.167, reward_mean=0.350, reward_bound=0.314, batch=216\n",
      "7930: loss=0.166, reward_mean=0.420, reward_bound=0.349, batch=220\n",
      "7931: loss=0.167, reward_mean=0.400, reward_bound=0.314, batch=223\n",
      "7932: loss=0.165, reward_mean=0.480, reward_bound=0.349, batch=225\n",
      "7933: loss=0.165, reward_mean=0.470, reward_bound=0.356, batch=227\n",
      "7934: loss=0.166, reward_mean=0.410, reward_bound=0.314, batch=228\n",
      "7935: loss=0.166, reward_mean=0.390, reward_bound=0.353, batch=229\n",
      "7936: loss=0.168, reward_mean=0.360, reward_bound=0.387, batch=151\n",
      "7937: loss=0.171, reward_mean=0.460, reward_bound=0.047, batch=174\n",
      "7938: loss=0.170, reward_mean=0.460, reward_bound=0.098, batch=191\n",
      "7939: loss=0.170, reward_mean=0.420, reward_bound=0.150, batch=202\n",
      "7940: loss=0.167, reward_mean=0.420, reward_bound=0.167, batch=205\n",
      "7941: loss=0.167, reward_mean=0.410, reward_bound=0.206, batch=208\n",
      "7942: loss=0.166, reward_mean=0.380, reward_bound=0.208, batch=215\n",
      "7943: loss=0.165, reward_mean=0.510, reward_bound=0.229, batch=210\n",
      "7944: loss=0.163, reward_mean=0.420, reward_bound=0.254, batch=212\n",
      "7945: loss=0.162, reward_mean=0.470, reward_bound=0.254, batch=217\n",
      "7946: loss=0.164, reward_mean=0.470, reward_bound=0.282, batch=206\n",
      "7947: loss=0.165, reward_mean=0.480, reward_bound=0.298, batch=214\n",
      "7948: loss=0.163, reward_mean=0.410, reward_bound=0.305, batch=220\n",
      "7949: loss=0.166, reward_mean=0.430, reward_bound=0.314, batch=206\n",
      "7950: loss=0.163, reward_mean=0.360, reward_bound=0.196, batch=214\n",
      "7951: loss=0.174, reward_mean=0.400, reward_bound=0.229, batch=215\n",
      "7952: loss=0.169, reward_mean=0.420, reward_bound=0.260, batch=220\n",
      "7953: loss=0.168, reward_mean=0.450, reward_bound=0.282, batch=223\n",
      "7954: loss=0.169, reward_mean=0.420, reward_bound=0.314, batch=224\n",
      "7955: loss=0.169, reward_mean=0.410, reward_bound=0.345, batch=227\n",
      "7956: loss=0.169, reward_mean=0.420, reward_bound=0.349, batch=214\n",
      "7957: loss=0.169, reward_mean=0.450, reward_bound=0.254, batch=219\n",
      "7958: loss=0.169, reward_mean=0.470, reward_bound=0.314, batch=221\n",
      "7959: loss=0.169, reward_mean=0.410, reward_bound=0.387, batch=197\n",
      "7960: loss=0.169, reward_mean=0.450, reward_bound=0.185, batch=207\n",
      "7961: loss=0.170, reward_mean=0.440, reward_bound=0.229, batch=213\n",
      "7962: loss=0.170, reward_mean=0.410, reward_bound=0.244, batch=219\n",
      "7963: loss=0.168, reward_mean=0.400, reward_bound=0.282, batch=217\n",
      "7964: loss=0.170, reward_mean=0.420, reward_bound=0.277, batch=222\n",
      "7965: loss=0.168, reward_mean=0.380, reward_bound=0.314, batch=221\n",
      "7966: loss=0.169, reward_mean=0.440, reward_bound=0.349, batch=223\n",
      "7967: loss=0.169, reward_mean=0.380, reward_bound=0.301, batch=226\n",
      "7968: loss=0.168, reward_mean=0.380, reward_bound=0.387, batch=219\n",
      "7969: loss=0.168, reward_mean=0.360, reward_bound=0.349, batch=221\n",
      "7970: loss=0.168, reward_mean=0.470, reward_bound=0.387, batch=222\n",
      "7971: loss=0.168, reward_mean=0.420, reward_bound=0.387, batch=224\n",
      "7972: loss=0.168, reward_mean=0.430, reward_bound=0.384, batch=227\n",
      "7973: loss=0.168, reward_mean=0.470, reward_bound=0.387, batch=228\n",
      "7974: loss=0.179, reward_mean=0.430, reward_bound=0.430, batch=117\n",
      "7975: loss=0.186, reward_mean=0.350, reward_bound=0.000, batch=152\n",
      "7976: loss=0.173, reward_mean=0.460, reward_bound=0.032, batch=176\n",
      "7977: loss=0.178, reward_mean=0.360, reward_bound=0.052, batch=191\n",
      "7978: loss=0.178, reward_mean=0.350, reward_bound=0.089, batch=198\n",
      "7979: loss=0.171, reward_mean=0.400, reward_bound=0.109, batch=200\n",
      "7980: loss=0.167, reward_mean=0.420, reward_bound=0.135, batch=204\n",
      "7981: loss=0.172, reward_mean=0.440, reward_bound=0.167, batch=207\n",
      "7982: loss=0.169, reward_mean=0.430, reward_bound=0.185, batch=204\n",
      "7983: loss=0.169, reward_mean=0.470, reward_bound=0.206, batch=205\n",
      "7984: loss=0.168, reward_mean=0.370, reward_bound=0.206, batch=212\n",
      "7985: loss=0.170, reward_mean=0.430, reward_bound=0.229, batch=211\n",
      "7986: loss=0.170, reward_mean=0.400, reward_bound=0.254, batch=210\n",
      "7987: loss=0.168, reward_mean=0.490, reward_bound=0.222, batch=217\n",
      "7988: loss=0.171, reward_mean=0.440, reward_bound=0.282, batch=201\n",
      "7989: loss=0.171, reward_mean=0.430, reward_bound=0.150, batch=209\n",
      "7990: loss=0.172, reward_mean=0.420, reward_bound=0.254, batch=215\n",
      "7991: loss=0.169, reward_mean=0.480, reward_bound=0.282, batch=218\n",
      "7992: loss=0.169, reward_mean=0.390, reward_bound=0.260, batch=222\n",
      "7993: loss=0.174, reward_mean=0.450, reward_bound=0.314, batch=203\n",
      "7994: loss=0.173, reward_mean=0.420, reward_bound=0.271, batch=212\n",
      "7995: loss=0.171, reward_mean=0.420, reward_bound=0.314, batch=214\n",
      "7996: loss=0.170, reward_mean=0.500, reward_bound=0.254, batch=218\n",
      "7997: loss=0.170, reward_mean=0.320, reward_bound=0.286, batch=222\n",
      "7998: loss=0.172, reward_mean=0.390, reward_bound=0.314, batch=222\n",
      "7999: loss=0.168, reward_mean=0.350, reward_bound=0.349, batch=192\n",
      "8000: loss=0.168, reward_mean=0.330, reward_bound=0.140, batch=204\n",
      "8001: loss=0.168, reward_mean=0.390, reward_bound=0.206, batch=209\n",
      "8002: loss=0.165, reward_mean=0.460, reward_bound=0.282, batch=214\n",
      "8003: loss=0.165, reward_mean=0.480, reward_bound=0.314, batch=217\n",
      "8004: loss=0.166, reward_mean=0.410, reward_bound=0.224, batch=222\n",
      "8005: loss=0.165, reward_mean=0.350, reward_bound=0.292, batch=225\n",
      "8006: loss=0.167, reward_mean=0.450, reward_bound=0.289, batch=227\n",
      "8007: loss=0.167, reward_mean=0.420, reward_bound=0.314, batch=227\n",
      "8008: loss=0.166, reward_mean=0.390, reward_bound=0.349, batch=220\n",
      "8009: loss=0.167, reward_mean=0.480, reward_bound=0.349, batch=223\n",
      "8010: loss=0.166, reward_mean=0.400, reward_bound=0.301, batch=226\n",
      "8011: loss=0.167, reward_mean=0.450, reward_bound=0.349, batch=226\n",
      "8012: loss=0.172, reward_mean=0.390, reward_bound=0.387, batch=184\n",
      "8013: loss=0.169, reward_mean=0.370, reward_bound=0.185, batch=198\n",
      "8014: loss=0.169, reward_mean=0.410, reward_bound=0.206, batch=205\n",
      "8015: loss=0.171, reward_mean=0.400, reward_bound=0.229, batch=209\n",
      "8016: loss=0.172, reward_mean=0.350, reward_bound=0.239, batch=216\n",
      "8017: loss=0.169, reward_mean=0.440, reward_bound=0.254, batch=220\n",
      "8018: loss=0.168, reward_mean=0.400, reward_bound=0.282, batch=215\n",
      "8019: loss=0.170, reward_mean=0.380, reward_bound=0.254, batch=218\n",
      "8020: loss=0.168, reward_mean=0.370, reward_bound=0.208, batch=222\n",
      "8021: loss=0.169, reward_mean=0.380, reward_bound=0.314, batch=220\n",
      "8022: loss=0.169, reward_mean=0.330, reward_bound=0.254, batch=221\n",
      "8023: loss=0.170, reward_mean=0.520, reward_bound=0.314, batch=223\n",
      "8024: loss=0.171, reward_mean=0.350, reward_bound=0.349, batch=208\n",
      "8025: loss=0.168, reward_mean=0.390, reward_bound=0.211, batch=215\n",
      "8026: loss=0.170, reward_mean=0.390, reward_bound=0.260, batch=220\n",
      "8027: loss=0.173, reward_mean=0.320, reward_bound=0.282, batch=218\n",
      "8028: loss=0.175, reward_mean=0.350, reward_bound=0.286, batch=222\n",
      "8029: loss=0.173, reward_mean=0.380, reward_bound=0.314, batch=221\n",
      "8030: loss=0.174, reward_mean=0.410, reward_bound=0.314, batch=224\n",
      "8031: loss=0.174, reward_mean=0.410, reward_bound=0.349, batch=225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8032: loss=0.174, reward_mean=0.380, reward_bound=0.387, batch=213\n",
      "8033: loss=0.173, reward_mean=0.370, reward_bound=0.271, batch=219\n",
      "8034: loss=0.174, reward_mean=0.490, reward_bound=0.265, batch=223\n",
      "8035: loss=0.173, reward_mean=0.350, reward_bound=0.282, batch=224\n",
      "8036: loss=0.173, reward_mean=0.370, reward_bound=0.314, batch=226\n",
      "8037: loss=0.173, reward_mean=0.440, reward_bound=0.349, batch=226\n",
      "8038: loss=0.173, reward_mean=0.430, reward_bound=0.387, batch=223\n",
      "8039: loss=0.172, reward_mean=0.320, reward_bound=0.314, batch=225\n",
      "8040: loss=0.172, reward_mean=0.490, reward_bound=0.314, batch=225\n",
      "8041: loss=0.172, reward_mean=0.390, reward_bound=0.314, batch=226\n",
      "8042: loss=0.166, reward_mean=0.480, reward_bound=0.430, batch=173\n",
      "8043: loss=0.168, reward_mean=0.440, reward_bound=0.144, batch=191\n",
      "8044: loss=0.172, reward_mean=0.390, reward_bound=0.150, batch=201\n",
      "8045: loss=0.176, reward_mean=0.350, reward_bound=0.167, batch=209\n",
      "8046: loss=0.172, reward_mean=0.420, reward_bound=0.185, batch=215\n",
      "8047: loss=0.171, reward_mean=0.440, reward_bound=0.206, batch=216\n",
      "8048: loss=0.172, reward_mean=0.370, reward_bound=0.229, batch=217\n",
      "8049: loss=0.172, reward_mean=0.390, reward_bound=0.185, batch=221\n",
      "8050: loss=0.169, reward_mean=0.360, reward_bound=0.254, batch=216\n",
      "8051: loss=0.166, reward_mean=0.420, reward_bound=0.282, batch=215\n",
      "8052: loss=0.166, reward_mean=0.470, reward_bound=0.314, batch=208\n",
      "8053: loss=0.164, reward_mean=0.440, reward_bound=0.231, batch=215\n",
      "8054: loss=0.165, reward_mean=0.370, reward_bound=0.254, batch=219\n",
      "8055: loss=0.164, reward_mean=0.420, reward_bound=0.282, batch=222\n",
      "8056: loss=0.160, reward_mean=0.400, reward_bound=0.349, batch=213\n",
      "8057: loss=0.158, reward_mean=0.450, reward_bound=0.301, batch=219\n",
      "8058: loss=0.159, reward_mean=0.400, reward_bound=0.314, batch=221\n",
      "8059: loss=0.160, reward_mean=0.350, reward_bound=0.282, batch=223\n",
      "8060: loss=0.160, reward_mean=0.500, reward_bound=0.335, batch=226\n",
      "8061: loss=0.160, reward_mean=0.360, reward_bound=0.349, batch=225\n",
      "8062: loss=0.160, reward_mean=0.420, reward_bound=0.321, batch=227\n",
      "8063: loss=0.159, reward_mean=0.390, reward_bound=0.349, batch=228\n",
      "8064: loss=0.159, reward_mean=0.460, reward_bound=0.353, batch=229\n",
      "8065: loss=0.159, reward_mean=0.330, reward_bound=0.387, batch=212\n",
      "8066: loss=0.161, reward_mean=0.360, reward_bound=0.292, batch=218\n",
      "8067: loss=0.160, reward_mean=0.380, reward_bound=0.314, batch=221\n",
      "8068: loss=0.161, reward_mean=0.370, reward_bound=0.229, batch=224\n",
      "8069: loss=0.159, reward_mean=0.440, reward_bound=0.311, batch=227\n",
      "8070: loss=0.159, reward_mean=0.430, reward_bound=0.349, batch=225\n",
      "8071: loss=0.157, reward_mean=0.390, reward_bound=0.387, batch=224\n",
      "8072: loss=0.156, reward_mean=0.460, reward_bound=0.384, batch=227\n",
      "8073: loss=0.157, reward_mean=0.410, reward_bound=0.380, batch=229\n",
      "8074: loss=0.156, reward_mean=0.430, reward_bound=0.387, batch=229\n",
      "8075: loss=0.159, reward_mean=0.440, reward_bound=0.430, batch=206\n",
      "8076: loss=0.158, reward_mean=0.300, reward_bound=0.229, batch=213\n",
      "8077: loss=0.158, reward_mean=0.340, reward_bound=0.220, batch=219\n",
      "8078: loss=0.158, reward_mean=0.420, reward_bound=0.282, batch=222\n",
      "8079: loss=0.159, reward_mean=0.340, reward_bound=0.314, batch=220\n",
      "8080: loss=0.158, reward_mean=0.490, reward_bound=0.314, batch=223\n",
      "8081: loss=0.159, reward_mean=0.440, reward_bound=0.349, batch=219\n",
      "8082: loss=0.159, reward_mean=0.370, reward_bound=0.343, batch=223\n",
      "8083: loss=0.158, reward_mean=0.440, reward_bound=0.387, batch=216\n",
      "8084: loss=0.157, reward_mean=0.370, reward_bound=0.331, batch=221\n",
      "8085: loss=0.158, reward_mean=0.460, reward_bound=0.349, batch=221\n",
      "8086: loss=0.158, reward_mean=0.410, reward_bound=0.387, batch=222\n",
      "8087: loss=0.157, reward_mean=0.480, reward_bound=0.360, batch=225\n",
      "8088: loss=0.157, reward_mean=0.430, reward_bound=0.329, batch=227\n",
      "8089: loss=0.156, reward_mean=0.500, reward_bound=0.422, batch=229\n",
      "8090: loss=0.156, reward_mean=0.330, reward_bound=0.405, batch=230\n",
      "8091: loss=0.156, reward_mean=0.420, reward_bound=0.418, batch=231\n",
      "8092: loss=0.157, reward_mean=0.320, reward_bound=0.430, batch=221\n",
      "8093: loss=0.157, reward_mean=0.370, reward_bound=0.282, batch=224\n",
      "8094: loss=0.156, reward_mean=0.360, reward_bound=0.314, batch=226\n",
      "8095: loss=0.155, reward_mean=0.490, reward_bound=0.409, batch=228\n",
      "8096: loss=0.155, reward_mean=0.390, reward_bound=0.357, batch=229\n",
      "8097: loss=0.154, reward_mean=0.440, reward_bound=0.328, batch=230\n",
      "8098: loss=0.155, reward_mean=0.460, reward_bound=0.430, batch=229\n",
      "8099: loss=0.155, reward_mean=0.410, reward_bound=0.424, batch=230\n",
      "8100: loss=0.157, reward_mean=0.410, reward_bound=0.478, batch=110\n",
      "8101: loss=0.158, reward_mean=0.440, reward_bound=0.015, batch=147\n",
      "8102: loss=0.164, reward_mean=0.410, reward_bound=0.028, batch=171\n",
      "8103: loss=0.162, reward_mean=0.430, reward_bound=0.058, batch=187\n",
      "8104: loss=0.167, reward_mean=0.450, reward_bound=0.080, batch=200\n",
      "8105: loss=0.162, reward_mean=0.430, reward_bound=0.106, batch=210\n",
      "8106: loss=0.164, reward_mean=0.380, reward_bound=0.122, batch=211\n",
      "8107: loss=0.161, reward_mean=0.430, reward_bound=0.135, batch=216\n",
      "8108: loss=0.156, reward_mean=0.440, reward_bound=0.150, batch=217\n",
      "8109: loss=0.162, reward_mean=0.430, reward_bound=0.167, batch=214\n",
      "8110: loss=0.158, reward_mean=0.330, reward_bound=0.185, batch=216\n",
      "8111: loss=0.160, reward_mean=0.320, reward_bound=0.206, batch=210\n",
      "8112: loss=0.157, reward_mean=0.410, reward_bound=0.206, batch=218\n",
      "8113: loss=0.157, reward_mean=0.410, reward_bound=0.229, batch=204\n",
      "8114: loss=0.156, reward_mean=0.380, reward_bound=0.249, batch=213\n",
      "8115: loss=0.154, reward_mean=0.440, reward_bound=0.254, batch=202\n",
      "8116: loss=0.157, reward_mean=0.410, reward_bound=0.263, batch=211\n",
      "8117: loss=0.159, reward_mean=0.370, reward_bound=0.282, batch=187\n",
      "8118: loss=0.156, reward_mean=0.510, reward_bound=0.249, batch=201\n",
      "8119: loss=0.153, reward_mean=0.470, reward_bound=0.206, batch=210\n",
      "8120: loss=0.153, reward_mean=0.400, reward_bound=0.240, batch=217\n",
      "8121: loss=0.153, reward_mean=0.480, reward_bound=0.282, batch=218\n",
      "8122: loss=0.155, reward_mean=0.430, reward_bound=0.314, batch=195\n",
      "8123: loss=0.159, reward_mean=0.490, reward_bound=0.229, batch=204\n",
      "8124: loss=0.159, reward_mean=0.430, reward_bound=0.167, batch=211\n",
      "8125: loss=0.159, reward_mean=0.330, reward_bound=0.185, batch=216\n",
      "8126: loss=0.157, reward_mean=0.560, reward_bound=0.254, batch=218\n",
      "8127: loss=0.156, reward_mean=0.350, reward_bound=0.282, batch=213\n",
      "8128: loss=0.159, reward_mean=0.360, reward_bound=0.282, batch=218\n",
      "8129: loss=0.157, reward_mean=0.440, reward_bound=0.314, batch=218\n",
      "8130: loss=0.156, reward_mean=0.390, reward_bound=0.317, batch=222\n",
      "8131: loss=0.154, reward_mean=0.420, reward_bound=0.292, batch=225\n",
      "8132: loss=0.154, reward_mean=0.400, reward_bound=0.321, batch=227\n",
      "8133: loss=0.152, reward_mean=0.460, reward_bound=0.349, batch=203\n",
      "8134: loss=0.154, reward_mean=0.410, reward_bound=0.220, batch=212\n",
      "8135: loss=0.155, reward_mean=0.420, reward_bound=0.282, batch=215\n",
      "8136: loss=0.154, reward_mean=0.390, reward_bound=0.282, batch=219\n",
      "8137: loss=0.153, reward_mean=0.450, reward_bound=0.314, batch=218\n",
      "8138: loss=0.153, reward_mean=0.490, reward_bound=0.349, batch=220\n",
      "8139: loss=0.152, reward_mean=0.380, reward_bound=0.349, batch=223\n",
      "8140: loss=0.151, reward_mean=0.440, reward_bound=0.372, batch=226\n",
      "8141: loss=0.151, reward_mean=0.460, reward_bound=0.368, batch=228\n",
      "8142: loss=0.157, reward_mean=0.360, reward_bound=0.387, batch=186\n",
      "8143: loss=0.157, reward_mean=0.420, reward_bound=0.158, batch=200\n",
      "8144: loss=0.158, reward_mean=0.440, reward_bound=0.167, batch=209\n",
      "8145: loss=0.164, reward_mean=0.440, reward_bound=0.185, batch=215\n",
      "8146: loss=0.159, reward_mean=0.450, reward_bound=0.229, batch=219\n",
      "8147: loss=0.154, reward_mean=0.400, reward_bound=0.254, batch=215\n",
      "8148: loss=0.153, reward_mean=0.400, reward_bound=0.282, batch=214\n",
      "8149: loss=0.156, reward_mean=0.450, reward_bound=0.314, batch=214\n",
      "8150: loss=0.158, reward_mean=0.440, reward_bound=0.282, batch=219\n",
      "8151: loss=0.156, reward_mean=0.440, reward_bound=0.328, batch=223\n",
      "8152: loss=0.156, reward_mean=0.450, reward_bound=0.322, batch=226\n",
      "8153: loss=0.155, reward_mean=0.340, reward_bound=0.349, batch=213\n",
      "8154: loss=0.154, reward_mean=0.400, reward_bound=0.349, batch=218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8155: loss=0.154, reward_mean=0.460, reward_bound=0.314, batch=221\n",
      "8156: loss=0.153, reward_mean=0.430, reward_bound=0.314, batch=224\n",
      "8157: loss=0.154, reward_mean=0.400, reward_bound=0.387, batch=210\n",
      "8158: loss=0.154, reward_mean=0.410, reward_bound=0.254, batch=216\n",
      "8159: loss=0.155, reward_mean=0.340, reward_bound=0.282, batch=220\n",
      "8160: loss=0.156, reward_mean=0.390, reward_bound=0.329, batch=224\n",
      "8161: loss=0.157, reward_mean=0.390, reward_bound=0.349, batch=224\n",
      "8162: loss=0.157, reward_mean=0.380, reward_bound=0.384, batch=227\n",
      "8163: loss=0.154, reward_mean=0.490, reward_bound=0.387, batch=222\n",
      "8164: loss=0.154, reward_mean=0.440, reward_bound=0.400, batch=225\n",
      "8165: loss=0.153, reward_mean=0.500, reward_bound=0.430, batch=180\n",
      "8166: loss=0.151, reward_mean=0.390, reward_bound=0.135, batch=193\n",
      "8167: loss=0.151, reward_mean=0.440, reward_bound=0.167, batch=203\n",
      "8168: loss=0.154, reward_mean=0.450, reward_bound=0.229, batch=210\n",
      "8169: loss=0.154, reward_mean=0.450, reward_bound=0.222, batch=217\n",
      "8170: loss=0.154, reward_mean=0.420, reward_bound=0.254, batch=218\n",
      "8171: loss=0.154, reward_mean=0.400, reward_bound=0.286, batch=222\n",
      "8172: loss=0.154, reward_mean=0.460, reward_bound=0.314, batch=222\n",
      "8173: loss=0.154, reward_mean=0.350, reward_bound=0.324, batch=225\n",
      "8174: loss=0.153, reward_mean=0.430, reward_bound=0.321, batch=227\n",
      "8175: loss=0.152, reward_mean=0.430, reward_bound=0.349, batch=214\n",
      "8176: loss=0.151, reward_mean=0.390, reward_bound=0.311, batch=220\n",
      "8177: loss=0.152, reward_mean=0.370, reward_bound=0.296, batch=224\n",
      "8178: loss=0.151, reward_mean=0.340, reward_bound=0.314, batch=225\n",
      "8179: loss=0.151, reward_mean=0.440, reward_bound=0.349, batch=223\n",
      "8180: loss=0.151, reward_mean=0.470, reward_bound=0.372, batch=226\n",
      "8181: loss=0.152, reward_mean=0.450, reward_bound=0.387, batch=214\n",
      "8182: loss=0.153, reward_mean=0.320, reward_bound=0.206, batch=219\n",
      "8183: loss=0.153, reward_mean=0.400, reward_bound=0.349, batch=222\n",
      "8184: loss=0.154, reward_mean=0.510, reward_bound=0.387, batch=222\n",
      "8185: loss=0.155, reward_mean=0.380, reward_bound=0.387, batch=224\n",
      "8186: loss=0.155, reward_mean=0.400, reward_bound=0.384, batch=227\n",
      "8187: loss=0.155, reward_mean=0.470, reward_bound=0.430, batch=204\n",
      "8188: loss=0.157, reward_mean=0.440, reward_bound=0.252, batch=213\n",
      "8189: loss=0.159, reward_mean=0.500, reward_bound=0.314, batch=216\n",
      "8190: loss=0.157, reward_mean=0.340, reward_bound=0.314, batch=219\n",
      "8191: loss=0.156, reward_mean=0.430, reward_bound=0.295, batch=223\n",
      "8192: loss=0.157, reward_mean=0.420, reward_bound=0.349, batch=219\n",
      "8193: loss=0.157, reward_mean=0.320, reward_bound=0.349, batch=222\n",
      "8194: loss=0.157, reward_mean=0.390, reward_bound=0.324, batch=225\n",
      "8195: loss=0.153, reward_mean=0.340, reward_bound=0.387, batch=220\n",
      "8196: loss=0.153, reward_mean=0.410, reward_bound=0.376, batch=224\n",
      "8197: loss=0.153, reward_mean=0.320, reward_bound=0.426, batch=227\n",
      "8198: loss=0.152, reward_mean=0.410, reward_bound=0.422, batch=229\n",
      "8199: loss=0.155, reward_mean=0.340, reward_bound=0.430, batch=216\n",
      "8200: loss=0.155, reward_mean=0.440, reward_bound=0.368, batch=221\n",
      "8201: loss=0.154, reward_mean=0.350, reward_bound=0.387, batch=221\n",
      "8202: loss=0.154, reward_mean=0.390, reward_bound=0.430, batch=220\n",
      "8203: loss=0.153, reward_mean=0.300, reward_bound=0.259, batch=224\n",
      "8204: loss=0.153, reward_mean=0.440, reward_bound=0.314, batch=226\n",
      "8205: loss=0.154, reward_mean=0.500, reward_bound=0.349, batch=226\n",
      "8206: loss=0.154, reward_mean=0.400, reward_bound=0.282, batch=227\n",
      "8207: loss=0.154, reward_mean=0.460, reward_bound=0.349, batch=228\n",
      "8208: loss=0.154, reward_mean=0.360, reward_bound=0.392, batch=229\n",
      "8209: loss=0.153, reward_mean=0.370, reward_bound=0.364, batch=230\n",
      "8210: loss=0.153, reward_mean=0.340, reward_bound=0.365, batch=231\n",
      "8211: loss=0.153, reward_mean=0.370, reward_bound=0.387, batch=231\n",
      "8212: loss=0.153, reward_mean=0.400, reward_bound=0.430, batch=226\n",
      "8213: loss=0.153, reward_mean=0.370, reward_bound=0.314, batch=227\n",
      "8214: loss=0.152, reward_mean=0.510, reward_bound=0.414, batch=229\n",
      "8215: loss=0.152, reward_mean=0.510, reward_bound=0.405, batch=230\n",
      "8216: loss=0.152, reward_mean=0.440, reward_bound=0.406, batch=231\n",
      "8217: loss=0.154, reward_mean=0.470, reward_bound=0.430, batch=230\n",
      "8218: loss=0.157, reward_mean=0.360, reward_bound=0.464, batch=231\n",
      "8219: loss=0.154, reward_mean=0.400, reward_bound=0.478, batch=166\n",
      "8220: loss=0.159, reward_mean=0.470, reward_bound=0.104, batch=186\n",
      "8221: loss=0.154, reward_mean=0.370, reward_bound=0.122, batch=198\n",
      "8222: loss=0.153, reward_mean=0.420, reward_bound=0.135, batch=205\n",
      "8223: loss=0.150, reward_mean=0.300, reward_bound=0.150, batch=212\n",
      "8224: loss=0.152, reward_mean=0.380, reward_bound=0.167, batch=215\n",
      "8225: loss=0.151, reward_mean=0.340, reward_bound=0.185, batch=219\n",
      "8226: loss=0.153, reward_mean=0.510, reward_bound=0.229, batch=222\n",
      "8227: loss=0.153, reward_mean=0.430, reward_bound=0.254, batch=222\n",
      "8228: loss=0.151, reward_mean=0.360, reward_bound=0.282, batch=216\n",
      "8229: loss=0.149, reward_mean=0.370, reward_bound=0.196, batch=221\n",
      "8230: loss=0.150, reward_mean=0.530, reward_bound=0.282, batch=222\n",
      "8231: loss=0.149, reward_mean=0.480, reward_bound=0.314, batch=215\n",
      "8232: loss=0.149, reward_mean=0.400, reward_bound=0.260, batch=220\n",
      "8233: loss=0.148, reward_mean=0.380, reward_bound=0.274, batch=224\n",
      "8234: loss=0.148, reward_mean=0.480, reward_bound=0.282, batch=226\n",
      "8235: loss=0.149, reward_mean=0.340, reward_bound=0.314, batch=224\n",
      "8236: loss=0.155, reward_mean=0.530, reward_bound=0.349, batch=218\n",
      "8237: loss=0.153, reward_mean=0.400, reward_bound=0.289, batch=222\n",
      "8238: loss=0.154, reward_mean=0.460, reward_bound=0.360, batch=225\n",
      "8239: loss=0.151, reward_mean=0.420, reward_bound=0.387, batch=211\n",
      "8240: loss=0.150, reward_mean=0.430, reward_bound=0.206, batch=217\n",
      "8241: loss=0.150, reward_mean=0.470, reward_bound=0.314, batch=219\n",
      "8242: loss=0.149, reward_mean=0.460, reward_bound=0.324, batch=223\n",
      "8243: loss=0.149, reward_mean=0.430, reward_bound=0.261, batch=226\n",
      "8244: loss=0.150, reward_mean=0.490, reward_bound=0.298, batch=228\n",
      "8245: loss=0.151, reward_mean=0.330, reward_bound=0.387, batch=224\n",
      "8246: loss=0.154, reward_mean=0.400, reward_bound=0.430, batch=193\n",
      "8247: loss=0.150, reward_mean=0.520, reward_bound=0.271, batch=205\n",
      "8248: loss=0.151, reward_mean=0.320, reward_bound=0.206, batch=212\n",
      "8249: loss=0.150, reward_mean=0.390, reward_bound=0.229, batch=217\n",
      "8250: loss=0.150, reward_mean=0.460, reward_bound=0.206, batch=221\n",
      "8251: loss=0.150, reward_mean=0.380, reward_bound=0.254, batch=222\n",
      "8252: loss=0.151, reward_mean=0.340, reward_bound=0.282, batch=218\n",
      "8253: loss=0.150, reward_mean=0.370, reward_bound=0.314, batch=217\n",
      "8254: loss=0.150, reward_mean=0.500, reward_bound=0.308, batch=222\n",
      "8255: loss=0.150, reward_mean=0.370, reward_bound=0.254, batch=223\n",
      "8256: loss=0.151, reward_mean=0.440, reward_bound=0.314, batch=225\n",
      "8257: loss=0.151, reward_mean=0.410, reward_bound=0.349, batch=222\n",
      "8258: loss=0.153, reward_mean=0.490, reward_bound=0.387, batch=221\n",
      "8259: loss=0.152, reward_mean=0.390, reward_bound=0.349, batch=224\n",
      "8260: loss=0.151, reward_mean=0.410, reward_bound=0.384, batch=227\n",
      "8261: loss=0.154, reward_mean=0.450, reward_bound=0.430, batch=213\n",
      "8262: loss=0.153, reward_mean=0.470, reward_bound=0.314, batch=218\n",
      "8263: loss=0.154, reward_mean=0.440, reward_bound=0.349, batch=221\n",
      "8264: loss=0.153, reward_mean=0.430, reward_bound=0.349, batch=223\n",
      "8265: loss=0.153, reward_mean=0.520, reward_bound=0.349, batch=225\n",
      "8266: loss=0.152, reward_mean=0.430, reward_bound=0.387, batch=223\n",
      "8267: loss=0.152, reward_mean=0.450, reward_bound=0.430, batch=224\n",
      "8268: loss=0.153, reward_mean=0.340, reward_bound=0.422, batch=227\n",
      "8269: loss=0.155, reward_mean=0.430, reward_bound=0.422, batch=229\n",
      "8270: loss=0.155, reward_mean=0.390, reward_bound=0.430, batch=228\n",
      "8271: loss=0.155, reward_mean=0.440, reward_bound=0.387, batch=228\n",
      "8272: loss=0.155, reward_mean=0.400, reward_bound=0.430, batch=228\n",
      "8273: loss=0.154, reward_mean=0.470, reward_bound=0.478, batch=230\n",
      "8274: loss=0.154, reward_mean=0.330, reward_bound=0.376, batch=231\n",
      "8275: loss=0.154, reward_mean=0.470, reward_bound=0.387, batch=231\n",
      "8276: loss=0.157, reward_mean=0.350, reward_bound=0.478, batch=196\n",
      "8277: loss=0.162, reward_mean=0.400, reward_bound=0.196, batch=207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8278: loss=0.159, reward_mean=0.480, reward_bound=0.206, batch=213\n",
      "8279: loss=0.161, reward_mean=0.390, reward_bound=0.206, batch=218\n",
      "8280: loss=0.165, reward_mean=0.410, reward_bound=0.254, batch=220\n",
      "8281: loss=0.162, reward_mean=0.390, reward_bound=0.282, batch=223\n",
      "8282: loss=0.162, reward_mean=0.430, reward_bound=0.314, batch=223\n",
      "8283: loss=0.156, reward_mean=0.520, reward_bound=0.349, batch=212\n",
      "8284: loss=0.162, reward_mean=0.480, reward_bound=0.206, batch=222\n",
      "8285: loss=0.161, reward_mean=0.480, reward_bound=0.206, batch=229\n",
      "8286: loss=0.154, reward_mean=0.420, reward_bound=0.239, batch=230\n",
      "8287: loss=0.155, reward_mean=0.330, reward_bound=0.282, batch=229\n",
      "8288: loss=0.158, reward_mean=0.470, reward_bound=0.314, batch=227\n",
      "8289: loss=0.159, reward_mean=0.380, reward_bound=0.249, batch=229\n",
      "8290: loss=0.161, reward_mean=0.410, reward_bound=0.282, batch=229\n",
      "8291: loss=0.161, reward_mean=0.440, reward_bound=0.349, batch=228\n",
      "8292: loss=0.161, reward_mean=0.430, reward_bound=0.387, batch=222\n",
      "8293: loss=0.160, reward_mean=0.350, reward_bound=0.349, batch=223\n",
      "8294: loss=0.158, reward_mean=0.390, reward_bound=0.430, batch=210\n",
      "8295: loss=0.158, reward_mean=0.390, reward_bound=0.282, batch=215\n",
      "8296: loss=0.156, reward_mean=0.520, reward_bound=0.229, batch=219\n",
      "8297: loss=0.155, reward_mean=0.410, reward_bound=0.250, batch=223\n",
      "8298: loss=0.156, reward_mean=0.410, reward_bound=0.301, batch=226\n",
      "8299: loss=0.154, reward_mean=0.410, reward_bound=0.314, batch=226\n",
      "8300: loss=0.155, reward_mean=0.480, reward_bound=0.349, batch=225\n",
      "8301: loss=0.155, reward_mean=0.520, reward_bound=0.396, batch=227\n",
      "8302: loss=0.157, reward_mean=0.480, reward_bound=0.422, batch=229\n",
      "8303: loss=0.158, reward_mean=0.480, reward_bound=0.430, batch=220\n",
      "8304: loss=0.158, reward_mean=0.400, reward_bound=0.282, batch=223\n",
      "8305: loss=0.160, reward_mean=0.440, reward_bound=0.349, batch=225\n",
      "8306: loss=0.157, reward_mean=0.450, reward_bound=0.396, batch=227\n",
      "8307: loss=0.157, reward_mean=0.430, reward_bound=0.349, batch=228\n",
      "8308: loss=0.158, reward_mean=0.470, reward_bound=0.478, batch=230\n",
      "8309: loss=0.157, reward_mean=0.390, reward_bound=0.338, batch=231\n",
      "8310: loss=0.159, reward_mean=0.350, reward_bound=0.478, batch=211\n",
      "8311: loss=0.159, reward_mean=0.400, reward_bound=0.314, batch=217\n",
      "8312: loss=0.159, reward_mean=0.410, reward_bound=0.349, batch=217\n",
      "8313: loss=0.159, reward_mean=0.420, reward_bound=0.380, batch=222\n",
      "8314: loss=0.160, reward_mean=0.520, reward_bound=0.349, batch=224\n",
      "8315: loss=0.160, reward_mean=0.400, reward_bound=0.314, batch=226\n",
      "8316: loss=0.159, reward_mean=0.400, reward_bound=0.387, batch=221\n",
      "8317: loss=0.158, reward_mean=0.400, reward_bound=0.349, batch=223\n",
      "8318: loss=0.157, reward_mean=0.440, reward_bound=0.322, batch=226\n",
      "8319: loss=0.157, reward_mean=0.350, reward_bound=0.387, batch=226\n",
      "8320: loss=0.157, reward_mean=0.490, reward_bound=0.387, batch=227\n",
      "8321: loss=0.157, reward_mean=0.430, reward_bound=0.430, batch=226\n",
      "8322: loss=0.157, reward_mean=0.410, reward_bound=0.409, batch=228\n",
      "8323: loss=0.157, reward_mean=0.360, reward_bound=0.387, batch=228\n",
      "8324: loss=0.157, reward_mean=0.440, reward_bound=0.392, batch=229\n",
      "8325: loss=0.157, reward_mean=0.410, reward_bound=0.343, batch=230\n",
      "8326: loss=0.158, reward_mean=0.360, reward_bound=0.464, batch=231\n",
      "8327: loss=0.158, reward_mean=0.470, reward_bound=0.314, batch=231\n",
      "8328: loss=0.158, reward_mean=0.390, reward_bound=0.478, batch=219\n",
      "8329: loss=0.157, reward_mean=0.430, reward_bound=0.314, batch=222\n",
      "8330: loss=0.158, reward_mean=0.490, reward_bound=0.387, batch=222\n",
      "8331: loss=0.158, reward_mean=0.470, reward_bound=0.400, batch=225\n",
      "8332: loss=0.157, reward_mean=0.390, reward_bound=0.387, batch=226\n",
      "8333: loss=0.158, reward_mean=0.340, reward_bound=0.430, batch=222\n",
      "8334: loss=0.158, reward_mean=0.410, reward_bound=0.387, batch=224\n",
      "8335: loss=0.157, reward_mean=0.410, reward_bound=0.384, batch=227\n",
      "8336: loss=0.157, reward_mean=0.460, reward_bound=0.314, batch=228\n",
      "8337: loss=0.157, reward_mean=0.430, reward_bound=0.353, batch=229\n",
      "8338: loss=0.156, reward_mean=0.330, reward_bound=0.328, batch=230\n",
      "8339: loss=0.157, reward_mean=0.440, reward_bound=0.349, batch=229\n",
      "8340: loss=0.157, reward_mean=0.440, reward_bound=0.405, batch=230\n",
      "8341: loss=0.156, reward_mean=0.370, reward_bound=0.418, batch=231\n",
      "8342: loss=0.158, reward_mean=0.500, reward_bound=0.430, batch=226\n",
      "8343: loss=0.158, reward_mean=0.420, reward_bound=0.390, batch=228\n",
      "8344: loss=0.157, reward_mean=0.420, reward_bound=0.478, batch=233\n",
      "8345: loss=0.156, reward_mean=0.540, reward_bound=0.478, batch=227\n",
      "8346: loss=0.156, reward_mean=0.370, reward_bound=0.478, batch=227\n",
      "8347: loss=0.156, reward_mean=0.400, reward_bound=0.521, batch=229\n",
      "8348: loss=0.155, reward_mean=0.520, reward_bound=0.381, batch=230\n",
      "8349: loss=0.156, reward_mean=0.480, reward_bound=0.430, batch=229\n",
      "8350: loss=0.156, reward_mean=0.450, reward_bound=0.471, batch=230\n",
      "8351: loss=0.156, reward_mean=0.530, reward_bound=0.501, batch=231\n",
      "8352: loss=0.156, reward_mean=0.360, reward_bound=0.430, batch=231\n",
      "8354: loss=0.163, reward_mean=0.470, reward_bound=0.000, batch=47\n",
      "8355: loss=0.165, reward_mean=0.270, reward_bound=0.000, batch=74\n",
      "8356: loss=0.165, reward_mean=0.410, reward_bound=0.000, batch=115\n",
      "8357: loss=0.163, reward_mean=0.360, reward_bound=0.000, batch=150\n",
      "8358: loss=0.160, reward_mean=0.480, reward_bound=0.006, batch=173\n",
      "8359: loss=0.158, reward_mean=0.440, reward_bound=0.013, batch=190\n",
      "8360: loss=0.158, reward_mean=0.410, reward_bound=0.028, batch=202\n",
      "8361: loss=0.162, reward_mean=0.440, reward_bound=0.042, batch=206\n",
      "8362: loss=0.158, reward_mean=0.460, reward_bound=0.061, batch=214\n",
      "8363: loss=0.155, reward_mean=0.310, reward_bound=0.065, batch=214\n",
      "8364: loss=0.152, reward_mean=0.450, reward_bound=0.080, batch=208\n",
      "8365: loss=0.154, reward_mean=0.390, reward_bound=0.089, batch=211\n",
      "8366: loss=0.149, reward_mean=0.380, reward_bound=0.109, batch=198\n",
      "8367: loss=0.146, reward_mean=0.520, reward_bound=0.122, batch=194\n",
      "8368: loss=0.143, reward_mean=0.430, reward_bound=0.135, batch=202\n",
      "8369: loss=0.146, reward_mean=0.490, reward_bound=0.150, batch=199\n",
      "8370: loss=0.147, reward_mean=0.450, reward_bound=0.167, batch=191\n",
      "8371: loss=0.139, reward_mean=0.360, reward_bound=0.185, batch=185\n",
      "8372: loss=0.139, reward_mean=0.510, reward_bound=0.161, batch=199\n",
      "8373: loss=0.140, reward_mean=0.520, reward_bound=0.185, batch=208\n",
      "8374: loss=0.141, reward_mean=0.400, reward_bound=0.185, batch=214\n",
      "8375: loss=0.141, reward_mean=0.450, reward_bound=0.206, batch=203\n",
      "8376: loss=0.139, reward_mean=0.530, reward_bound=0.229, batch=180\n",
      "8377: loss=0.138, reward_mean=0.500, reward_bound=0.200, batch=196\n",
      "8378: loss=0.138, reward_mean=0.440, reward_bound=0.206, batch=205\n",
      "8379: loss=0.139, reward_mean=0.410, reward_bound=0.229, batch=204\n",
      "8380: loss=0.141, reward_mean=0.490, reward_bound=0.254, batch=187\n",
      "8381: loss=0.142, reward_mean=0.490, reward_bound=0.182, batch=201\n",
      "8382: loss=0.145, reward_mean=0.420, reward_bound=0.167, batch=210\n",
      "8383: loss=0.143, reward_mean=0.420, reward_bound=0.185, batch=213\n",
      "8384: loss=0.143, reward_mean=0.430, reward_bound=0.206, batch=217\n",
      "8385: loss=0.142, reward_mean=0.390, reward_bound=0.224, batch=222\n",
      "8386: loss=0.140, reward_mean=0.400, reward_bound=0.229, batch=224\n",
      "8387: loss=0.140, reward_mean=0.400, reward_bound=0.280, batch=227\n",
      "8388: loss=0.143, reward_mean=0.420, reward_bound=0.282, batch=180\n",
      "8389: loss=0.144, reward_mean=0.420, reward_bound=0.180, batch=196\n",
      "8390: loss=0.142, reward_mean=0.430, reward_bound=0.206, batch=206\n",
      "8391: loss=0.143, reward_mean=0.440, reward_bound=0.229, batch=211\n",
      "8392: loss=0.144, reward_mean=0.390, reward_bound=0.254, batch=217\n",
      "8393: loss=0.145, reward_mean=0.320, reward_bound=0.282, batch=218\n",
      "8394: loss=0.145, reward_mean=0.520, reward_bound=0.257, batch=222\n",
      "8395: loss=0.139, reward_mean=0.460, reward_bound=0.314, batch=170\n",
      "8396: loss=0.137, reward_mean=0.390, reward_bound=0.135, batch=189\n",
      "8397: loss=0.138, reward_mean=0.480, reward_bound=0.157, batch=202\n",
      "8398: loss=0.144, reward_mean=0.410, reward_bound=0.185, batch=208\n",
      "8399: loss=0.141, reward_mean=0.470, reward_bound=0.206, batch=210\n",
      "8400: loss=0.140, reward_mean=0.440, reward_bound=0.247, batch=217\n",
      "8401: loss=0.141, reward_mean=0.450, reward_bound=0.249, batch=222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8402: loss=0.140, reward_mean=0.410, reward_bound=0.254, batch=217\n",
      "8403: loss=0.135, reward_mean=0.470, reward_bound=0.282, batch=213\n",
      "8404: loss=0.133, reward_mean=0.480, reward_bound=0.314, batch=208\n",
      "8405: loss=0.134, reward_mean=0.430, reward_bound=0.257, batch=215\n",
      "8406: loss=0.135, reward_mean=0.420, reward_bound=0.282, batch=219\n",
      "8407: loss=0.135, reward_mean=0.430, reward_bound=0.314, batch=221\n",
      "8408: loss=0.132, reward_mean=0.350, reward_bound=0.349, batch=167\n",
      "8409: loss=0.133, reward_mean=0.420, reward_bound=0.089, batch=189\n",
      "8410: loss=0.133, reward_mean=0.490, reward_bound=0.122, batch=200\n",
      "8411: loss=0.128, reward_mean=0.420, reward_bound=0.162, batch=210\n",
      "8412: loss=0.134, reward_mean=0.350, reward_bound=0.167, batch=214\n",
      "8413: loss=0.132, reward_mean=0.490, reward_bound=0.206, batch=216\n",
      "8414: loss=0.132, reward_mean=0.490, reward_bound=0.217, batch=221\n",
      "8415: loss=0.130, reward_mean=0.440, reward_bound=0.229, batch=219\n",
      "8416: loss=0.128, reward_mean=0.500, reward_bound=0.282, batch=214\n",
      "8417: loss=0.127, reward_mean=0.470, reward_bound=0.204, batch=220\n",
      "8418: loss=0.128, reward_mean=0.490, reward_bound=0.282, batch=223\n",
      "8419: loss=0.128, reward_mean=0.480, reward_bound=0.282, batch=225\n",
      "8420: loss=0.129, reward_mean=0.450, reward_bound=0.314, batch=216\n",
      "8421: loss=0.130, reward_mean=0.430, reward_bound=0.331, batch=221\n",
      "8422: loss=0.130, reward_mean=0.430, reward_bound=0.349, batch=206\n",
      "8423: loss=0.130, reward_mean=0.410, reward_bound=0.241, batch=214\n",
      "8424: loss=0.130, reward_mean=0.490, reward_bound=0.254, batch=218\n",
      "8425: loss=0.130, reward_mean=0.390, reward_bound=0.282, batch=220\n",
      "8426: loss=0.129, reward_mean=0.470, reward_bound=0.314, batch=223\n",
      "8427: loss=0.128, reward_mean=0.510, reward_bound=0.244, batch=226\n",
      "8428: loss=0.128, reward_mean=0.470, reward_bound=0.254, batch=227\n",
      "8429: loss=0.128, reward_mean=0.390, reward_bound=0.335, batch=229\n",
      "8430: loss=0.130, reward_mean=0.430, reward_bound=0.349, batch=224\n",
      "8431: loss=0.131, reward_mean=0.330, reward_bound=0.229, batch=226\n",
      "8432: loss=0.128, reward_mean=0.520, reward_bound=0.387, batch=148\n",
      "8433: loss=0.130, reward_mean=0.440, reward_bound=0.080, batch=170\n",
      "8434: loss=0.130, reward_mean=0.460, reward_bound=0.070, batch=189\n",
      "8435: loss=0.134, reward_mean=0.390, reward_bound=0.083, batch=202\n",
      "8436: loss=0.133, reward_mean=0.400, reward_bound=0.109, batch=210\n",
      "8437: loss=0.125, reward_mean=0.480, reward_bound=0.135, batch=215\n",
      "8438: loss=0.126, reward_mean=0.300, reward_bound=0.150, batch=215\n",
      "8439: loss=0.121, reward_mean=0.390, reward_bound=0.185, batch=212\n",
      "8440: loss=0.124, reward_mean=0.360, reward_bound=0.206, batch=224\n",
      "8441: loss=0.125, reward_mean=0.360, reward_bound=0.206, batch=222\n",
      "8442: loss=0.127, reward_mean=0.470, reward_bound=0.229, batch=220\n",
      "8443: loss=0.129, reward_mean=0.490, reward_bound=0.254, batch=213\n",
      "8444: loss=0.130, reward_mean=0.470, reward_bound=0.282, batch=208\n",
      "8445: loss=0.129, reward_mean=0.470, reward_bound=0.257, batch=215\n",
      "8446: loss=0.132, reward_mean=0.370, reward_bound=0.282, batch=218\n",
      "8447: loss=0.132, reward_mean=0.480, reward_bound=0.286, batch=222\n",
      "8448: loss=0.132, reward_mean=0.360, reward_bound=0.314, batch=216\n",
      "8449: loss=0.132, reward_mean=0.480, reward_bound=0.206, batch=220\n",
      "8450: loss=0.132, reward_mean=0.440, reward_bound=0.314, batch=222\n",
      "8451: loss=0.132, reward_mean=0.410, reward_bound=0.324, batch=225\n",
      "8452: loss=0.129, reward_mean=0.480, reward_bound=0.349, batch=214\n",
      "8453: loss=0.130, reward_mean=0.420, reward_bound=0.280, batch=220\n",
      "8454: loss=0.128, reward_mean=0.460, reward_bound=0.338, batch=224\n",
      "8455: loss=0.129, reward_mean=0.380, reward_bound=0.349, batch=223\n",
      "8456: loss=0.130, reward_mean=0.470, reward_bound=0.387, batch=212\n",
      "8457: loss=0.130, reward_mean=0.440, reward_bound=0.314, batch=217\n",
      "8458: loss=0.130, reward_mean=0.470, reward_bound=0.277, batch=222\n",
      "8459: loss=0.130, reward_mean=0.370, reward_bound=0.292, batch=225\n",
      "8460: loss=0.131, reward_mean=0.390, reward_bound=0.260, batch=227\n",
      "8461: loss=0.132, reward_mean=0.400, reward_bound=0.282, batch=228\n",
      "8462: loss=0.130, reward_mean=0.360, reward_bound=0.387, batch=222\n",
      "8463: loss=0.130, reward_mean=0.410, reward_bound=0.282, batch=223\n",
      "8464: loss=0.130, reward_mean=0.490, reward_bound=0.349, batch=225\n",
      "8465: loss=0.130, reward_mean=0.420, reward_bound=0.387, batch=226\n",
      "8466: loss=0.131, reward_mean=0.420, reward_bound=0.368, batch=228\n",
      "8467: loss=0.130, reward_mean=0.520, reward_bound=0.387, batch=227\n",
      "8468: loss=0.131, reward_mean=0.420, reward_bound=0.430, batch=125\n",
      "8469: loss=0.121, reward_mean=0.390, reward_bound=0.006, batch=157\n",
      "8470: loss=0.133, reward_mean=0.500, reward_bound=0.057, batch=180\n",
      "8471: loss=0.135, reward_mean=0.370, reward_bound=0.065, batch=194\n",
      "8472: loss=0.131, reward_mean=0.350, reward_bound=0.089, batch=203\n",
      "8473: loss=0.136, reward_mean=0.460, reward_bound=0.122, batch=199\n",
      "8474: loss=0.142, reward_mean=0.450, reward_bound=0.150, batch=207\n",
      "8475: loss=0.138, reward_mean=0.410, reward_bound=0.182, batch=215\n",
      "8476: loss=0.139, reward_mean=0.460, reward_bound=0.185, batch=216\n",
      "8477: loss=0.140, reward_mean=0.440, reward_bound=0.206, batch=214\n",
      "8478: loss=0.139, reward_mean=0.470, reward_bound=0.229, batch=209\n",
      "8479: loss=0.138, reward_mean=0.410, reward_bound=0.206, batch=215\n",
      "8480: loss=0.139, reward_mean=0.480, reward_bound=0.254, batch=210\n",
      "8481: loss=0.138, reward_mean=0.400, reward_bound=0.206, batch=218\n",
      "8482: loss=0.136, reward_mean=0.420, reward_bound=0.229, batch=220\n",
      "8483: loss=0.136, reward_mean=0.370, reward_bound=0.274, batch=224\n",
      "8484: loss=0.134, reward_mean=0.430, reward_bound=0.282, batch=205\n",
      "8485: loss=0.134, reward_mean=0.460, reward_bound=0.234, batch=213\n",
      "8486: loss=0.135, reward_mean=0.400, reward_bound=0.227, batch=219\n",
      "8487: loss=0.135, reward_mean=0.410, reward_bound=0.282, batch=222\n",
      "8488: loss=0.136, reward_mean=0.450, reward_bound=0.314, batch=210\n",
      "8489: loss=0.136, reward_mean=0.530, reward_bound=0.282, batch=215\n",
      "8490: loss=0.134, reward_mean=0.470, reward_bound=0.260, batch=220\n",
      "8491: loss=0.134, reward_mean=0.310, reward_bound=0.314, batch=222\n",
      "8492: loss=0.132, reward_mean=0.430, reward_bound=0.349, batch=191\n",
      "8493: loss=0.133, reward_mean=0.480, reward_bound=0.229, batch=203\n",
      "8494: loss=0.131, reward_mean=0.370, reward_bound=0.178, batch=212\n",
      "8495: loss=0.133, reward_mean=0.510, reward_bound=0.254, batch=215\n",
      "8496: loss=0.133, reward_mean=0.400, reward_bound=0.260, batch=220\n",
      "8497: loss=0.137, reward_mean=0.480, reward_bound=0.304, batch=224\n",
      "8498: loss=0.134, reward_mean=0.420, reward_bound=0.314, batch=216\n",
      "8499: loss=0.133, reward_mean=0.420, reward_bound=0.331, batch=221\n",
      "8500: loss=0.135, reward_mean=0.470, reward_bound=0.349, batch=218\n",
      "8501: loss=0.134, reward_mean=0.500, reward_bound=0.254, batch=221\n",
      "8502: loss=0.131, reward_mean=0.390, reward_bound=0.387, batch=194\n",
      "8503: loss=0.135, reward_mean=0.450, reward_bound=0.282, batch=203\n",
      "8504: loss=0.133, reward_mean=0.410, reward_bound=0.282, batch=211\n",
      "8505: loss=0.134, reward_mean=0.470, reward_bound=0.282, batch=217\n",
      "8506: loss=0.134, reward_mean=0.400, reward_bound=0.272, batch=222\n",
      "8507: loss=0.135, reward_mean=0.420, reward_bound=0.292, batch=225\n",
      "8508: loss=0.134, reward_mean=0.400, reward_bound=0.321, batch=227\n",
      "8509: loss=0.134, reward_mean=0.540, reward_bound=0.349, batch=226\n",
      "8510: loss=0.133, reward_mean=0.480, reward_bound=0.387, batch=217\n",
      "8511: loss=0.133, reward_mean=0.410, reward_bound=0.277, batch=222\n",
      "8512: loss=0.133, reward_mean=0.440, reward_bound=0.360, batch=225\n",
      "8513: loss=0.129, reward_mean=0.420, reward_bound=0.430, batch=179\n",
      "8514: loss=0.124, reward_mean=0.410, reward_bound=0.127, batch=195\n",
      "8515: loss=0.131, reward_mean=0.450, reward_bound=0.167, batch=204\n",
      "8516: loss=0.135, reward_mean=0.460, reward_bound=0.206, batch=210\n",
      "8517: loss=0.134, reward_mean=0.490, reward_bound=0.229, batch=214\n",
      "8518: loss=0.132, reward_mean=0.450, reward_bound=0.224, batch=220\n",
      "8519: loss=0.134, reward_mean=0.450, reward_bound=0.247, batch=224\n",
      "8520: loss=0.133, reward_mean=0.450, reward_bound=0.254, batch=219\n",
      "8521: loss=0.128, reward_mean=0.460, reward_bound=0.282, batch=215\n",
      "8522: loss=0.127, reward_mean=0.350, reward_bound=0.216, batch=220\n",
      "8523: loss=0.127, reward_mean=0.340, reward_bound=0.282, batch=221\n",
      "8524: loss=0.127, reward_mean=0.440, reward_bound=0.282, batch=224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8525: loss=0.127, reward_mean=0.410, reward_bound=0.282, batch=225\n",
      "8526: loss=0.126, reward_mean=0.500, reward_bound=0.314, batch=223\n",
      "8527: loss=0.127, reward_mean=0.410, reward_bound=0.349, batch=219\n",
      "8528: loss=0.128, reward_mean=0.420, reward_bound=0.387, batch=209\n",
      "8529: loss=0.127, reward_mean=0.460, reward_bound=0.328, batch=216\n",
      "8530: loss=0.127, reward_mean=0.410, reward_bound=0.298, batch=221\n",
      "8531: loss=0.127, reward_mean=0.390, reward_bound=0.314, batch=223\n",
      "8532: loss=0.128, reward_mean=0.410, reward_bound=0.349, batch=222\n",
      "8533: loss=0.128, reward_mean=0.380, reward_bound=0.360, batch=225\n",
      "8534: loss=0.128, reward_mean=0.380, reward_bound=0.260, batch=227\n",
      "8535: loss=0.129, reward_mean=0.480, reward_bound=0.308, batch=229\n",
      "8536: loss=0.128, reward_mean=0.370, reward_bound=0.387, batch=220\n",
      "8537: loss=0.127, reward_mean=0.360, reward_bound=0.240, batch=224\n",
      "8538: loss=0.127, reward_mean=0.410, reward_bound=0.280, batch=227\n",
      "8539: loss=0.128, reward_mean=0.460, reward_bound=0.342, batch=229\n",
      "8540: loss=0.128, reward_mean=0.480, reward_bound=0.349, batch=228\n",
      "8541: loss=0.128, reward_mean=0.510, reward_bound=0.392, batch=229\n",
      "8542: loss=0.129, reward_mean=0.490, reward_bound=0.430, batch=206\n",
      "8543: loss=0.129, reward_mean=0.510, reward_bound=0.241, batch=214\n",
      "8544: loss=0.129, reward_mean=0.570, reward_bound=0.314, batch=217\n",
      "8545: loss=0.129, reward_mean=0.320, reward_bound=0.308, batch=222\n",
      "8546: loss=0.128, reward_mean=0.380, reward_bound=0.140, batch=225\n",
      "8547: loss=0.127, reward_mean=0.460, reward_bound=0.321, batch=227\n",
      "8548: loss=0.127, reward_mean=0.320, reward_bound=0.308, batch=229\n",
      "8549: loss=0.129, reward_mean=0.400, reward_bound=0.349, batch=221\n",
      "8550: loss=0.128, reward_mean=0.360, reward_bound=0.282, batch=224\n",
      "8551: loss=0.129, reward_mean=0.470, reward_bound=0.345, batch=227\n",
      "8552: loss=0.129, reward_mean=0.350, reward_bound=0.349, batch=227\n",
      "8553: loss=0.130, reward_mean=0.440, reward_bound=0.387, batch=223\n",
      "8554: loss=0.129, reward_mean=0.410, reward_bound=0.398, batch=226\n",
      "8555: loss=0.128, reward_mean=0.460, reward_bound=0.430, batch=218\n",
      "8556: loss=0.127, reward_mean=0.420, reward_bound=0.286, batch=222\n",
      "8557: loss=0.127, reward_mean=0.390, reward_bound=0.272, batch=225\n",
      "8558: loss=0.127, reward_mean=0.380, reward_bound=0.314, batch=225\n",
      "8559: loss=0.127, reward_mean=0.410, reward_bound=0.349, batch=225\n",
      "8560: loss=0.127, reward_mean=0.410, reward_bound=0.387, batch=226\n",
      "8561: loss=0.128, reward_mean=0.440, reward_bound=0.430, batch=223\n",
      "8562: loss=0.128, reward_mean=0.480, reward_bound=0.413, batch=226\n",
      "8563: loss=0.128, reward_mean=0.460, reward_bound=0.430, batch=227\n",
      "8564: loss=0.127, reward_mean=0.380, reward_bound=0.314, batch=228\n",
      "8565: loss=0.128, reward_mean=0.420, reward_bound=0.430, batch=228\n",
      "8566: loss=0.128, reward_mean=0.460, reward_bound=0.478, batch=230\n",
      "8567: loss=0.116, reward_mean=0.420, reward_bound=0.478, batch=82\n",
      "8568: loss=0.120, reward_mean=0.450, reward_bound=0.000, batch=127\n",
      "8569: loss=0.115, reward_mean=0.530, reward_bound=0.022, batch=159\n",
      "8570: loss=0.121, reward_mean=0.490, reward_bound=0.038, batch=178\n",
      "8571: loss=0.127, reward_mean=0.540, reward_bound=0.058, batch=193\n",
      "8572: loss=0.129, reward_mean=0.440, reward_bound=0.089, batch=199\n",
      "8573: loss=0.125, reward_mean=0.440, reward_bound=0.098, batch=203\n",
      "8574: loss=0.126, reward_mean=0.430, reward_bound=0.109, batch=208\n",
      "8575: loss=0.129, reward_mean=0.470, reward_bound=0.123, batch=215\n",
      "8576: loss=0.130, reward_mean=0.370, reward_bound=0.150, batch=202\n",
      "8577: loss=0.127, reward_mean=0.430, reward_bound=0.167, batch=204\n",
      "8578: loss=0.125, reward_mean=0.470, reward_bound=0.185, batch=203\n",
      "8579: loss=0.124, reward_mean=0.470, reward_bound=0.206, batch=196\n",
      "8580: loss=0.120, reward_mean=0.430, reward_bound=0.136, batch=207\n",
      "8581: loss=0.125, reward_mean=0.430, reward_bound=0.206, batch=214\n",
      "8582: loss=0.123, reward_mean=0.540, reward_bound=0.229, batch=206\n",
      "8583: loss=0.121, reward_mean=0.480, reward_bound=0.217, batch=214\n",
      "8584: loss=0.122, reward_mean=0.400, reward_bound=0.226, batch=220\n",
      "8585: loss=0.124, reward_mean=0.400, reward_bound=0.254, batch=206\n",
      "8586: loss=0.119, reward_mean=0.460, reward_bound=0.282, batch=180\n",
      "8587: loss=0.125, reward_mean=0.380, reward_bound=0.096, batch=196\n",
      "8588: loss=0.120, reward_mean=0.520, reward_bound=0.143, batch=207\n",
      "8589: loss=0.120, reward_mean=0.450, reward_bound=0.167, batch=214\n",
      "8590: loss=0.118, reward_mean=0.410, reward_bound=0.185, batch=218\n",
      "8591: loss=0.120, reward_mean=0.510, reward_bound=0.229, batch=215\n",
      "8592: loss=0.118, reward_mean=0.490, reward_bound=0.254, batch=217\n",
      "8593: loss=0.115, reward_mean=0.410, reward_bound=0.282, batch=216\n",
      "8594: loss=0.116, reward_mean=0.500, reward_bound=0.314, batch=186\n",
      "8595: loss=0.116, reward_mean=0.400, reward_bound=0.158, batch=200\n",
      "8596: loss=0.114, reward_mean=0.390, reward_bound=0.185, batch=207\n",
      "8597: loss=0.115, reward_mean=0.410, reward_bound=0.229, batch=214\n",
      "8598: loss=0.116, reward_mean=0.320, reward_bound=0.226, batch=220\n",
      "8599: loss=0.114, reward_mean=0.370, reward_bound=0.222, batch=224\n",
      "8600: loss=0.117, reward_mean=0.390, reward_bound=0.254, batch=225\n",
      "8601: loss=0.118, reward_mean=0.500, reward_bound=0.282, batch=224\n",
      "8602: loss=0.118, reward_mean=0.480, reward_bound=0.280, batch=227\n",
      "8603: loss=0.115, reward_mean=0.330, reward_bound=0.314, batch=222\n",
      "8604: loss=0.115, reward_mean=0.470, reward_bound=0.314, batch=224\n",
      "8605: loss=0.116, reward_mean=0.390, reward_bound=0.345, batch=227\n",
      "8606: loss=0.118, reward_mean=0.390, reward_bound=0.349, batch=188\n",
      "8607: loss=0.116, reward_mean=0.470, reward_bound=0.231, batch=201\n",
      "8608: loss=0.118, reward_mean=0.420, reward_bound=0.185, batch=209\n",
      "8609: loss=0.117, reward_mean=0.380, reward_bound=0.206, batch=214\n",
      "8610: loss=0.117, reward_mean=0.400, reward_bound=0.204, batch=220\n",
      "8611: loss=0.116, reward_mean=0.450, reward_bound=0.254, batch=220\n",
      "8612: loss=0.119, reward_mean=0.520, reward_bound=0.304, batch=224\n",
      "8613: loss=0.119, reward_mean=0.490, reward_bound=0.314, batch=215\n",
      "8614: loss=0.118, reward_mean=0.510, reward_bound=0.349, batch=209\n",
      "8615: loss=0.118, reward_mean=0.420, reward_bound=0.314, batch=213\n",
      "8616: loss=0.119, reward_mean=0.440, reward_bound=0.282, batch=218\n",
      "8617: loss=0.118, reward_mean=0.540, reward_bound=0.286, batch=222\n",
      "8618: loss=0.119, reward_mean=0.400, reward_bound=0.191, batch=225\n",
      "8619: loss=0.117, reward_mean=0.390, reward_bound=0.314, batch=224\n",
      "8620: loss=0.117, reward_mean=0.420, reward_bound=0.311, batch=227\n",
      "8621: loss=0.118, reward_mean=0.360, reward_bound=0.314, batch=228\n",
      "8622: loss=0.119, reward_mean=0.440, reward_bound=0.349, batch=223\n",
      "8623: loss=0.119, reward_mean=0.470, reward_bound=0.372, batch=226\n",
      "8624: loss=0.120, reward_mean=0.450, reward_bound=0.387, batch=174\n",
      "8625: loss=0.116, reward_mean=0.420, reward_bound=0.122, batch=191\n",
      "8626: loss=0.115, reward_mean=0.400, reward_bound=0.135, batch=201\n",
      "8627: loss=0.117, reward_mean=0.450, reward_bound=0.167, batch=210\n",
      "8628: loss=0.118, reward_mean=0.410, reward_bound=0.185, batch=214\n",
      "8629: loss=0.120, reward_mean=0.460, reward_bound=0.206, batch=217\n",
      "8630: loss=0.122, reward_mean=0.380, reward_bound=0.229, batch=220\n",
      "8631: loss=0.124, reward_mean=0.430, reward_bound=0.254, batch=219\n",
      "8632: loss=0.121, reward_mean=0.510, reward_bound=0.282, batch=214\n",
      "8633: loss=0.122, reward_mean=0.390, reward_bound=0.229, batch=218\n",
      "8634: loss=0.121, reward_mean=0.420, reward_bound=0.314, batch=214\n",
      "8635: loss=0.122, reward_mean=0.420, reward_bound=0.282, batch=219\n",
      "8636: loss=0.121, reward_mean=0.460, reward_bound=0.328, batch=223\n",
      "8637: loss=0.119, reward_mean=0.430, reward_bound=0.349, batch=210\n",
      "8638: loss=0.120, reward_mean=0.560, reward_bound=0.304, batch=217\n",
      "8639: loss=0.119, reward_mean=0.580, reward_bound=0.342, batch=222\n",
      "8640: loss=0.119, reward_mean=0.480, reward_bound=0.324, batch=225\n",
      "8641: loss=0.118, reward_mean=0.410, reward_bound=0.349, batch=220\n",
      "8642: loss=0.118, reward_mean=0.490, reward_bound=0.329, batch=224\n",
      "8643: loss=0.119, reward_mean=0.320, reward_bound=0.282, batch=226\n",
      "8644: loss=0.119, reward_mean=0.380, reward_bound=0.349, batch=226\n",
      "8645: loss=0.119, reward_mean=0.390, reward_bound=0.368, batch=228\n",
      "8646: loss=0.119, reward_mean=0.470, reward_bound=0.387, batch=212\n",
      "8647: loss=0.120, reward_mean=0.460, reward_bound=0.302, batch=218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8648: loss=0.121, reward_mean=0.350, reward_bound=0.257, batch=222\n",
      "8649: loss=0.119, reward_mean=0.450, reward_bound=0.349, batch=222\n",
      "8650: loss=0.119, reward_mean=0.490, reward_bound=0.387, batch=221\n",
      "8651: loss=0.119, reward_mean=0.380, reward_bound=0.387, batch=223\n",
      "8652: loss=0.120, reward_mean=0.370, reward_bound=0.301, batch=226\n",
      "8653: loss=0.119, reward_mean=0.480, reward_bound=0.349, batch=226\n",
      "8654: loss=0.119, reward_mean=0.500, reward_bound=0.368, batch=228\n",
      "8655: loss=0.120, reward_mean=0.460, reward_bound=0.392, batch=229\n",
      "8656: loss=0.119, reward_mean=0.480, reward_bound=0.430, batch=153\n",
      "8657: loss=0.120, reward_mean=0.470, reward_bound=0.080, batch=176\n",
      "8658: loss=0.114, reward_mean=0.420, reward_bound=0.104, batch=193\n",
      "8659: loss=0.115, reward_mean=0.410, reward_bound=0.122, batch=204\n",
      "8660: loss=0.112, reward_mean=0.440, reward_bound=0.150, batch=210\n",
      "8661: loss=0.112, reward_mean=0.390, reward_bound=0.185, batch=210\n",
      "8662: loss=0.114, reward_mean=0.420, reward_bound=0.206, batch=219\n",
      "8663: loss=0.116, reward_mean=0.450, reward_bound=0.229, batch=217\n",
      "8664: loss=0.116, reward_mean=0.460, reward_bound=0.254, batch=218\n",
      "8665: loss=0.118, reward_mean=0.430, reward_bound=0.282, batch=210\n",
      "8666: loss=0.120, reward_mean=0.410, reward_bound=0.206, batch=218\n",
      "8667: loss=0.119, reward_mean=0.430, reward_bound=0.254, batch=221\n",
      "8668: loss=0.119, reward_mean=0.510, reward_bound=0.314, batch=205\n",
      "8669: loss=0.120, reward_mean=0.500, reward_bound=0.229, batch=211\n",
      "8670: loss=0.119, reward_mean=0.410, reward_bound=0.254, batch=217\n",
      "8671: loss=0.124, reward_mean=0.480, reward_bound=0.249, batch=222\n",
      "8672: loss=0.123, reward_mean=0.470, reward_bound=0.292, batch=225\n",
      "8673: loss=0.121, reward_mean=0.460, reward_bound=0.321, batch=227\n",
      "8674: loss=0.126, reward_mean=0.480, reward_bound=0.349, batch=205\n",
      "8675: loss=0.123, reward_mean=0.510, reward_bound=0.185, batch=212\n",
      "8676: loss=0.124, reward_mean=0.430, reward_bound=0.220, batch=218\n",
      "8677: loss=0.125, reward_mean=0.500, reward_bound=0.282, batch=217\n",
      "8678: loss=0.127, reward_mean=0.520, reward_bound=0.314, batch=219\n",
      "8679: loss=0.125, reward_mean=0.460, reward_bound=0.349, batch=221\n",
      "8680: loss=0.125, reward_mean=0.410, reward_bound=0.349, batch=224\n",
      "8681: loss=0.125, reward_mean=0.360, reward_bound=0.349, batch=226\n",
      "8682: loss=0.122, reward_mean=0.500, reward_bound=0.387, batch=206\n",
      "8683: loss=0.122, reward_mean=0.430, reward_bound=0.282, batch=212\n",
      "8684: loss=0.122, reward_mean=0.520, reward_bound=0.349, batch=213\n",
      "8685: loss=0.122, reward_mean=0.530, reward_bound=0.282, batch=218\n",
      "8686: loss=0.122, reward_mean=0.370, reward_bound=0.353, batch=222\n",
      "8687: loss=0.122, reward_mean=0.440, reward_bound=0.387, batch=223\n",
      "8688: loss=0.121, reward_mean=0.420, reward_bound=0.349, batch=224\n",
      "8689: loss=0.121, reward_mean=0.410, reward_bound=0.384, batch=227\n",
      "8690: loss=0.122, reward_mean=0.400, reward_bound=0.380, batch=229\n",
      "8691: loss=0.121, reward_mean=0.440, reward_bound=0.387, batch=226\n",
      "8692: loss=0.118, reward_mean=0.460, reward_bound=0.430, batch=191\n",
      "8693: loss=0.118, reward_mean=0.360, reward_bound=0.206, batch=203\n",
      "8694: loss=0.117, reward_mean=0.420, reward_bound=0.229, batch=211\n",
      "8695: loss=0.117, reward_mean=0.400, reward_bound=0.229, batch=215\n",
      "8696: loss=0.118, reward_mean=0.440, reward_bound=0.254, batch=218\n",
      "8697: loss=0.117, reward_mean=0.390, reward_bound=0.282, batch=215\n",
      "8698: loss=0.116, reward_mean=0.460, reward_bound=0.314, batch=217\n",
      "8699: loss=0.116, reward_mean=0.410, reward_bound=0.229, batch=221\n",
      "8700: loss=0.117, reward_mean=0.410, reward_bound=0.349, batch=212\n",
      "8701: loss=0.117, reward_mean=0.490, reward_bound=0.263, batch=218\n",
      "8702: loss=0.117, reward_mean=0.480, reward_bound=0.314, batch=221\n",
      "8703: loss=0.117, reward_mean=0.400, reward_bound=0.349, batch=224\n",
      "8704: loss=0.117, reward_mean=0.460, reward_bound=0.384, batch=227\n",
      "8705: loss=0.118, reward_mean=0.400, reward_bound=0.380, batch=229\n",
      "8706: loss=0.120, reward_mean=0.420, reward_bound=0.387, batch=216\n",
      "8707: loss=0.119, reward_mean=0.480, reward_bound=0.372, batch=221\n",
      "8708: loss=0.120, reward_mean=0.430, reward_bound=0.314, batch=224\n",
      "8709: loss=0.119, reward_mean=0.440, reward_bound=0.349, batch=226\n",
      "8710: loss=0.119, reward_mean=0.360, reward_bound=0.368, batch=228\n",
      "8711: loss=0.118, reward_mean=0.470, reward_bound=0.392, batch=229\n",
      "8712: loss=0.118, reward_mean=0.400, reward_bound=0.343, batch=230\n",
      "8713: loss=0.118, reward_mean=0.530, reward_bound=0.430, batch=204\n",
      "8714: loss=0.119, reward_mean=0.350, reward_bound=0.254, batch=211\n",
      "8715: loss=0.118, reward_mean=0.410, reward_bound=0.254, batch=216\n",
      "8716: loss=0.118, reward_mean=0.430, reward_bound=0.282, batch=217\n",
      "8717: loss=0.118, reward_mean=0.440, reward_bound=0.342, batch=222\n",
      "8718: loss=0.117, reward_mean=0.530, reward_bound=0.349, batch=219\n",
      "8719: loss=0.117, reward_mean=0.590, reward_bound=0.278, batch=223\n",
      "8720: loss=0.118, reward_mean=0.510, reward_bound=0.314, batch=225\n",
      "8721: loss=0.117, reward_mean=0.380, reward_bound=0.356, batch=227\n",
      "8722: loss=0.117, reward_mean=0.440, reward_bound=0.349, batch=228\n",
      "8723: loss=0.119, reward_mean=0.500, reward_bound=0.387, batch=222\n",
      "8724: loss=0.119, reward_mean=0.480, reward_bound=0.314, batch=225\n",
      "8725: loss=0.119, reward_mean=0.470, reward_bound=0.387, batch=224\n",
      "8726: loss=0.119, reward_mean=0.440, reward_bound=0.387, batch=224\n",
      "8727: loss=0.120, reward_mean=0.550, reward_bound=0.384, batch=227\n",
      "8728: loss=0.119, reward_mean=0.440, reward_bound=0.422, batch=229\n",
      "8729: loss=0.119, reward_mean=0.430, reward_bound=0.430, batch=217\n",
      "8730: loss=0.118, reward_mean=0.410, reward_bound=0.249, batch=222\n",
      "8731: loss=0.119, reward_mean=0.490, reward_bound=0.282, batch=224\n",
      "8732: loss=0.119, reward_mean=0.440, reward_bound=0.384, batch=227\n",
      "8733: loss=0.119, reward_mean=0.440, reward_bound=0.387, batch=225\n",
      "8734: loss=0.119, reward_mean=0.570, reward_bound=0.356, batch=227\n",
      "8735: loss=0.119, reward_mean=0.510, reward_bound=0.430, batch=225\n",
      "8736: loss=0.120, reward_mean=0.480, reward_bound=0.321, batch=227\n",
      "8737: loss=0.120, reward_mean=0.530, reward_bound=0.342, batch=229\n",
      "8738: loss=0.118, reward_mean=0.460, reward_bound=0.387, batch=228\n",
      "8739: loss=0.118, reward_mean=0.470, reward_bound=0.478, batch=230\n",
      "8740: loss=0.118, reward_mean=0.380, reward_bound=0.418, batch=231\n",
      "8741: loss=0.118, reward_mean=0.390, reward_bound=0.430, batch=230\n",
      "8742: loss=0.118, reward_mean=0.410, reward_bound=0.376, batch=231\n",
      "8743: loss=0.114, reward_mean=0.490, reward_bound=0.478, batch=147\n",
      "8744: loss=0.116, reward_mean=0.390, reward_bound=0.051, batch=173\n",
      "8745: loss=0.110, reward_mean=0.410, reward_bound=0.062, batch=191\n",
      "8746: loss=0.111, reward_mean=0.410, reward_bound=0.089, batch=201\n",
      "8747: loss=0.112, reward_mean=0.460, reward_bound=0.122, batch=210\n",
      "8748: loss=0.106, reward_mean=0.490, reward_bound=0.167, batch=213\n",
      "8749: loss=0.111, reward_mean=0.450, reward_bound=0.185, batch=214\n",
      "8750: loss=0.114, reward_mean=0.500, reward_bound=0.206, batch=212\n",
      "8751: loss=0.113, reward_mean=0.440, reward_bound=0.229, batch=208\n",
      "8752: loss=0.113, reward_mean=0.460, reward_bound=0.231, batch=215\n",
      "8753: loss=0.114, reward_mean=0.480, reward_bound=0.254, batch=206\n",
      "8754: loss=0.114, reward_mean=0.420, reward_bound=0.254, batch=211\n",
      "8755: loss=0.115, reward_mean=0.500, reward_bound=0.254, batch=217\n",
      "8756: loss=0.116, reward_mean=0.420, reward_bound=0.277, batch=222\n",
      "8757: loss=0.114, reward_mean=0.420, reward_bound=0.282, batch=213\n",
      "8758: loss=0.114, reward_mean=0.480, reward_bound=0.244, batch=219\n",
      "8759: loss=0.113, reward_mean=0.510, reward_bound=0.295, batch=223\n",
      "8760: loss=0.113, reward_mean=0.440, reward_bound=0.314, batch=201\n",
      "8761: loss=0.113, reward_mean=0.380, reward_bound=0.254, batch=210\n",
      "8762: loss=0.114, reward_mean=0.470, reward_bound=0.274, batch=217\n",
      "8763: loss=0.114, reward_mean=0.430, reward_bound=0.308, batch=222\n",
      "8764: loss=0.116, reward_mean=0.480, reward_bound=0.314, batch=223\n",
      "8765: loss=0.117, reward_mean=0.410, reward_bound=0.335, batch=226\n",
      "8766: loss=0.116, reward_mean=0.390, reward_bound=0.349, batch=204\n",
      "8767: loss=0.114, reward_mean=0.480, reward_bound=0.226, batch=213\n",
      "8768: loss=0.116, reward_mean=0.500, reward_bound=0.244, batch=219\n",
      "8769: loss=0.115, reward_mean=0.360, reward_bound=0.265, batch=223\n",
      "8770: loss=0.114, reward_mean=0.510, reward_bound=0.314, batch=221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8771: loss=0.114, reward_mean=0.410, reward_bound=0.282, batch=224\n",
      "8772: loss=0.113, reward_mean=0.370, reward_bound=0.349, batch=224\n",
      "8773: loss=0.113, reward_mean=0.440, reward_bound=0.387, batch=198\n",
      "8774: loss=0.115, reward_mean=0.450, reward_bound=0.152, batch=208\n",
      "8775: loss=0.110, reward_mean=0.430, reward_bound=0.187, batch=215\n",
      "8776: loss=0.112, reward_mean=0.510, reward_bound=0.254, batch=218\n",
      "8777: loss=0.114, reward_mean=0.400, reward_bound=0.231, batch=222\n",
      "8778: loss=0.114, reward_mean=0.420, reward_bound=0.254, batch=223\n",
      "8779: loss=0.114, reward_mean=0.470, reward_bound=0.282, batch=222\n",
      "8780: loss=0.113, reward_mean=0.410, reward_bound=0.314, batch=219\n",
      "8781: loss=0.113, reward_mean=0.400, reward_bound=0.349, batch=218\n",
      "8782: loss=0.113, reward_mean=0.480, reward_bound=0.282, batch=221\n",
      "8783: loss=0.113, reward_mean=0.400, reward_bound=0.314, batch=224\n",
      "8784: loss=0.112, reward_mean=0.510, reward_bound=0.311, batch=227\n",
      "8785: loss=0.112, reward_mean=0.430, reward_bound=0.349, batch=226\n",
      "8786: loss=0.113, reward_mean=0.510, reward_bound=0.387, batch=216\n",
      "8787: loss=0.113, reward_mean=0.510, reward_bound=0.351, batch=221\n",
      "8788: loss=0.113, reward_mean=0.460, reward_bound=0.387, batch=222\n",
      "8789: loss=0.113, reward_mean=0.400, reward_bound=0.314, batch=224\n",
      "8790: loss=0.113, reward_mean=0.440, reward_bound=0.282, batch=225\n",
      "8791: loss=0.113, reward_mean=0.430, reward_bound=0.396, batch=227\n",
      "8792: loss=0.115, reward_mean=0.460, reward_bound=0.430, batch=195\n",
      "8793: loss=0.114, reward_mean=0.370, reward_bound=0.134, batch=206\n",
      "8794: loss=0.115, reward_mean=0.450, reward_bound=0.229, batch=213\n",
      "8795: loss=0.118, reward_mean=0.570, reward_bound=0.254, batch=218\n",
      "8796: loss=0.118, reward_mean=0.400, reward_bound=0.282, batch=221\n",
      "8797: loss=0.117, reward_mean=0.400, reward_bound=0.314, batch=219\n",
      "8798: loss=0.117, reward_mean=0.440, reward_bound=0.328, batch=223\n",
      "8799: loss=0.116, reward_mean=0.500, reward_bound=0.349, batch=218\n",
      "8800: loss=0.116, reward_mean=0.420, reward_bound=0.314, batch=220\n",
      "8801: loss=0.116, reward_mean=0.500, reward_bound=0.338, batch=224\n",
      "8802: loss=0.115, reward_mean=0.490, reward_bound=0.349, batch=226\n",
      "8803: loss=0.115, reward_mean=0.350, reward_bound=0.351, batch=228\n",
      "8804: loss=0.115, reward_mean=0.520, reward_bound=0.321, batch=229\n",
      "8805: loss=0.113, reward_mean=0.430, reward_bound=0.387, batch=224\n",
      "8806: loss=0.115, reward_mean=0.400, reward_bound=0.345, batch=227\n",
      "8807: loss=0.115, reward_mean=0.410, reward_bound=0.314, batch=228\n",
      "8808: loss=0.113, reward_mean=0.460, reward_bound=0.392, batch=229\n",
      "8809: loss=0.113, reward_mean=0.500, reward_bound=0.430, batch=215\n",
      "8810: loss=0.114, reward_mean=0.470, reward_bound=0.349, batch=218\n",
      "8811: loss=0.113, reward_mean=0.410, reward_bound=0.314, batch=221\n",
      "8812: loss=0.114, reward_mean=0.530, reward_bound=0.387, batch=222\n",
      "8813: loss=0.114, reward_mean=0.490, reward_bound=0.400, batch=225\n",
      "8814: loss=0.114, reward_mean=0.440, reward_bound=0.356, batch=227\n",
      "8815: loss=0.114, reward_mean=0.410, reward_bound=0.422, batch=229\n",
      "8816: loss=0.114, reward_mean=0.460, reward_bound=0.405, batch=230\n",
      "8817: loss=0.114, reward_mean=0.470, reward_bound=0.387, batch=230\n",
      "8818: loss=0.113, reward_mean=0.430, reward_bound=0.430, batch=227\n",
      "8819: loss=0.112, reward_mean=0.420, reward_bound=0.478, batch=182\n",
      "8820: loss=0.111, reward_mean=0.540, reward_bound=0.229, batch=193\n",
      "8821: loss=0.108, reward_mean=0.460, reward_bound=0.109, batch=203\n",
      "8822: loss=0.115, reward_mean=0.500, reward_bound=0.171, batch=212\n",
      "8823: loss=0.114, reward_mean=0.450, reward_bound=0.206, batch=224\n",
      "8824: loss=0.109, reward_mean=0.540, reward_bound=0.206, batch=226\n",
      "8825: loss=0.109, reward_mean=0.460, reward_bound=0.254, batch=221\n",
      "8826: loss=0.109, reward_mean=0.470, reward_bound=0.254, batch=224\n",
      "8827: loss=0.109, reward_mean=0.390, reward_bound=0.282, batch=220\n",
      "8828: loss=0.109, reward_mean=0.470, reward_bound=0.304, batch=224\n",
      "8829: loss=0.110, reward_mean=0.450, reward_bound=0.314, batch=217\n",
      "8830: loss=0.110, reward_mean=0.500, reward_bound=0.308, batch=222\n",
      "8831: loss=0.110, reward_mean=0.460, reward_bound=0.314, batch=224\n",
      "8832: loss=0.111, reward_mean=0.450, reward_bound=0.349, batch=221\n",
      "8833: loss=0.112, reward_mean=0.450, reward_bound=0.314, batch=224\n",
      "8834: loss=0.114, reward_mean=0.510, reward_bound=0.387, batch=211\n",
      "8835: loss=0.114, reward_mean=0.440, reward_bound=0.314, batch=216\n",
      "8836: loss=0.116, reward_mean=0.480, reward_bound=0.331, batch=221\n",
      "8837: loss=0.116, reward_mean=0.530, reward_bound=0.349, batch=221\n",
      "8838: loss=0.114, reward_mean=0.410, reward_bound=0.387, batch=217\n",
      "8839: loss=0.115, reward_mean=0.360, reward_bound=0.277, batch=222\n",
      "8840: loss=0.117, reward_mean=0.440, reward_bound=0.292, batch=225\n",
      "8841: loss=0.116, reward_mean=0.440, reward_bound=0.321, batch=227\n",
      "8842: loss=0.114, reward_mean=0.410, reward_bound=0.380, batch=229\n",
      "8843: loss=0.115, reward_mean=0.450, reward_bound=0.387, batch=228\n",
      "8844: loss=0.113, reward_mean=0.520, reward_bound=0.430, batch=208\n",
      "8845: loss=0.114, reward_mean=0.450, reward_bound=0.282, batch=214\n",
      "8846: loss=0.113, reward_mean=0.480, reward_bound=0.254, batch=219\n",
      "8847: loss=0.115, reward_mean=0.450, reward_bound=0.295, batch=223\n",
      "8848: loss=0.115, reward_mean=0.510, reward_bound=0.314, batch=225\n",
      "8849: loss=0.115, reward_mean=0.430, reward_bound=0.349, batch=224\n",
      "8850: loss=0.114, reward_mean=0.440, reward_bound=0.349, batch=226\n",
      "8851: loss=0.114, reward_mean=0.440, reward_bound=0.387, batch=223\n",
      "8852: loss=0.114, reward_mean=0.480, reward_bound=0.387, batch=225\n",
      "8853: loss=0.114, reward_mean=0.350, reward_bound=0.356, batch=227\n",
      "8854: loss=0.113, reward_mean=0.440, reward_bound=0.430, batch=221\n",
      "8855: loss=0.114, reward_mean=0.430, reward_bound=0.349, batch=224\n",
      "8856: loss=0.114, reward_mean=0.500, reward_bound=0.384, batch=227\n",
      "8857: loss=0.114, reward_mean=0.490, reward_bound=0.380, batch=229\n",
      "8858: loss=0.114, reward_mean=0.410, reward_bound=0.343, batch=230\n",
      "8859: loss=0.113, reward_mean=0.340, reward_bound=0.387, batch=230\n",
      "8860: loss=0.113, reward_mean=0.360, reward_bound=0.430, batch=227\n",
      "8861: loss=0.113, reward_mean=0.430, reward_bound=0.469, batch=229\n",
      "8862: loss=0.113, reward_mean=0.360, reward_bound=0.387, batch=229\n",
      "8863: loss=0.113, reward_mean=0.420, reward_bound=0.364, batch=230\n",
      "8864: loss=0.113, reward_mean=0.440, reward_bound=0.376, batch=231\n",
      "8865: loss=0.113, reward_mean=0.380, reward_bound=0.387, batch=231\n",
      "8866: loss=0.112, reward_mean=0.410, reward_bound=0.478, batch=207\n",
      "8867: loss=0.113, reward_mean=0.420, reward_bound=0.342, batch=215\n",
      "8868: loss=0.113, reward_mean=0.510, reward_bound=0.321, batch=220\n",
      "8869: loss=0.114, reward_mean=0.430, reward_bound=0.314, batch=223\n",
      "8870: loss=0.113, reward_mean=0.390, reward_bound=0.349, batch=224\n",
      "8871: loss=0.113, reward_mean=0.420, reward_bound=0.387, batch=222\n",
      "8872: loss=0.113, reward_mean=0.440, reward_bound=0.302, batch=225\n",
      "8873: loss=0.113, reward_mean=0.480, reward_bound=0.396, batch=227\n",
      "8874: loss=0.113, reward_mean=0.500, reward_bound=0.380, batch=229\n",
      "8875: loss=0.113, reward_mean=0.430, reward_bound=0.343, batch=230\n",
      "8876: loss=0.114, reward_mean=0.480, reward_bound=0.430, batch=217\n",
      "8877: loss=0.113, reward_mean=0.400, reward_bound=0.249, batch=222\n",
      "8878: loss=0.114, reward_mean=0.400, reward_bound=0.324, batch=225\n",
      "8879: loss=0.113, reward_mean=0.420, reward_bound=0.387, batch=225\n",
      "8880: loss=0.113, reward_mean=0.450, reward_bound=0.282, batch=226\n",
      "8881: loss=0.113, reward_mean=0.350, reward_bound=0.368, batch=228\n",
      "8882: loss=0.112, reward_mean=0.460, reward_bound=0.387, batch=228\n",
      "8883: loss=0.113, reward_mean=0.520, reward_bound=0.430, batch=224\n",
      "8884: loss=0.114, reward_mean=0.430, reward_bound=0.380, batch=227\n",
      "8885: loss=0.113, reward_mean=0.470, reward_bound=0.380, batch=229\n",
      "8886: loss=0.114, reward_mean=0.460, reward_bound=0.430, batch=229\n",
      "8887: loss=0.114, reward_mean=0.440, reward_bound=0.450, batch=230\n",
      "8888: loss=0.114, reward_mean=0.460, reward_bound=0.418, batch=231\n",
      "8889: loss=0.112, reward_mean=0.480, reward_bound=0.478, batch=219\n",
      "8890: loss=0.111, reward_mean=0.500, reward_bound=0.349, batch=222\n",
      "8891: loss=0.112, reward_mean=0.420, reward_bound=0.387, batch=223\n",
      "8892: loss=0.112, reward_mean=0.560, reward_bound=0.430, batch=225\n",
      "8893: loss=0.111, reward_mean=0.380, reward_bound=0.227, batch=227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8894: loss=0.112, reward_mean=0.450, reward_bound=0.380, batch=229\n",
      "8895: loss=0.112, reward_mean=0.380, reward_bound=0.387, batch=229\n",
      "8896: loss=0.112, reward_mean=0.470, reward_bound=0.430, batch=228\n",
      "8897: loss=0.113, reward_mean=0.420, reward_bound=0.478, batch=231\n",
      "8898: loss=0.112, reward_mean=0.500, reward_bound=0.478, batch=227\n",
      "8899: loss=0.112, reward_mean=0.450, reward_bound=0.422, batch=229\n",
      "8900: loss=0.112, reward_mean=0.380, reward_bound=0.450, batch=230\n",
      "8901: loss=0.112, reward_mean=0.440, reward_bound=0.430, batch=230\n",
      "8902: loss=0.112, reward_mean=0.450, reward_bound=0.439, batch=231\n",
      "8903: loss=0.112, reward_mean=0.540, reward_bound=0.349, batch=231\n",
      "8904: loss=0.112, reward_mean=0.480, reward_bound=0.478, batch=231\n",
      "8905: loss=0.112, reward_mean=0.370, reward_bound=0.282, batch=231\n",
      "8906: loss=0.112, reward_mean=0.390, reward_bound=0.430, batch=231\n",
      "8908: loss=0.105, reward_mean=0.410, reward_bound=0.000, batch=41\n",
      "8909: loss=0.101, reward_mean=0.440, reward_bound=0.000, batch=85\n",
      "8910: loss=0.102, reward_mean=0.450, reward_bound=0.000, batch=129\n",
      "8911: loss=0.115, reward_mean=0.470, reward_bound=0.004, batch=160\n",
      "8912: loss=0.122, reward_mean=0.470, reward_bound=0.013, batch=181\n",
      "8913: loss=0.118, reward_mean=0.490, reward_bound=0.028, batch=194\n",
      "8914: loss=0.113, reward_mean=0.440, reward_bound=0.042, batch=199\n",
      "8915: loss=0.119, reward_mean=0.410, reward_bound=0.052, batch=205\n",
      "8916: loss=0.126, reward_mean=0.540, reward_bound=0.080, batch=212\n",
      "8917: loss=0.124, reward_mean=0.380, reward_bound=0.089, batch=216\n",
      "8918: loss=0.123, reward_mean=0.410, reward_bound=0.098, batch=219\n",
      "8919: loss=0.123, reward_mean=0.450, reward_bound=0.122, batch=215\n",
      "8920: loss=0.123, reward_mean=0.420, reward_bound=0.150, batch=200\n",
      "8921: loss=0.119, reward_mean=0.430, reward_bound=0.167, batch=198\n",
      "8922: loss=0.115, reward_mean=0.470, reward_bound=0.185, batch=192\n",
      "8923: loss=0.114, reward_mean=0.420, reward_bound=0.155, batch=204\n",
      "8924: loss=0.114, reward_mean=0.420, reward_bound=0.185, batch=212\n",
      "8925: loss=0.114, reward_mean=0.460, reward_bound=0.206, batch=222\n",
      "8926: loss=0.113, reward_mean=0.490, reward_bound=0.206, batch=239\n",
      "8927: loss=0.111, reward_mean=0.480, reward_bound=0.206, batch=219\n",
      "8928: loss=0.109, reward_mean=0.560, reward_bound=0.229, batch=199\n",
      "8929: loss=0.109, reward_mean=0.460, reward_bound=0.150, batch=208\n",
      "8930: loss=0.111, reward_mean=0.440, reward_bound=0.254, batch=171\n",
      "8931: loss=0.111, reward_mean=0.360, reward_bound=0.072, batch=189\n",
      "8932: loss=0.109, reward_mean=0.460, reward_bound=0.135, batch=201\n",
      "8933: loss=0.106, reward_mean=0.420, reward_bound=0.150, batch=210\n",
      "8934: loss=0.106, reward_mean=0.450, reward_bound=0.185, batch=210\n",
      "8935: loss=0.108, reward_mean=0.400, reward_bound=0.185, batch=216\n",
      "8936: loss=0.106, reward_mean=0.470, reward_bound=0.229, batch=219\n",
      "8937: loss=0.109, reward_mean=0.530, reward_bound=0.254, batch=214\n",
      "8938: loss=0.116, reward_mean=0.450, reward_bound=0.282, batch=175\n",
      "8939: loss=0.112, reward_mean=0.490, reward_bound=0.124, batch=192\n",
      "8940: loss=0.112, reward_mean=0.450, reward_bound=0.140, batch=204\n",
      "8941: loss=0.111, reward_mean=0.430, reward_bound=0.150, batch=212\n",
      "8942: loss=0.112, reward_mean=0.370, reward_bound=0.206, batch=222\n",
      "8943: loss=0.111, reward_mean=0.420, reward_bound=0.206, batch=230\n",
      "8944: loss=0.113, reward_mean=0.430, reward_bound=0.229, batch=230\n",
      "8945: loss=0.114, reward_mean=0.420, reward_bound=0.254, batch=229\n",
      "8946: loss=0.114, reward_mean=0.460, reward_bound=0.282, batch=222\n",
      "8947: loss=0.114, reward_mean=0.550, reward_bound=0.314, batch=174\n",
      "8948: loss=0.111, reward_mean=0.420, reward_bound=0.106, batch=192\n",
      "8949: loss=0.112, reward_mean=0.400, reward_bound=0.155, batch=204\n",
      "8950: loss=0.116, reward_mean=0.560, reward_bound=0.206, batch=211\n",
      "8951: loss=0.116, reward_mean=0.480, reward_bound=0.229, batch=210\n",
      "8952: loss=0.116, reward_mean=0.530, reward_bound=0.247, batch=217\n",
      "8953: loss=0.115, reward_mean=0.480, reward_bound=0.277, batch=222\n",
      "8954: loss=0.113, reward_mean=0.490, reward_bound=0.282, batch=217\n",
      "8955: loss=0.115, reward_mean=0.490, reward_bound=0.314, batch=210\n",
      "8956: loss=0.115, reward_mean=0.480, reward_bound=0.274, batch=217\n",
      "8957: loss=0.114, reward_mean=0.460, reward_bound=0.282, batch=220\n",
      "8958: loss=0.111, reward_mean=0.440, reward_bound=0.349, batch=163\n",
      "8959: loss=0.109, reward_mean=0.480, reward_bound=0.122, batch=182\n",
      "8960: loss=0.107, reward_mean=0.380, reward_bound=0.098, batch=196\n",
      "8961: loss=0.111, reward_mean=0.510, reward_bound=0.167, batch=205\n",
      "8962: loss=0.110, reward_mean=0.350, reward_bound=0.185, batch=209\n",
      "8963: loss=0.112, reward_mean=0.520, reward_bound=0.206, batch=206\n",
      "8964: loss=0.115, reward_mean=0.480, reward_bound=0.229, batch=208\n",
      "8965: loss=0.116, reward_mean=0.430, reward_bound=0.229, batch=214\n",
      "8966: loss=0.115, reward_mean=0.420, reward_bound=0.254, batch=212\n",
      "8967: loss=0.115, reward_mean=0.370, reward_bound=0.263, batch=218\n",
      "8968: loss=0.115, reward_mean=0.520, reward_bound=0.282, batch=217\n",
      "8969: loss=0.115, reward_mean=0.460, reward_bound=0.277, batch=222\n",
      "8970: loss=0.116, reward_mean=0.390, reward_bound=0.292, batch=225\n",
      "8971: loss=0.114, reward_mean=0.400, reward_bound=0.314, batch=218\n",
      "8972: loss=0.114, reward_mean=0.400, reward_bound=0.211, batch=222\n",
      "8973: loss=0.113, reward_mean=0.440, reward_bound=0.282, batch=224\n",
      "8974: loss=0.113, reward_mean=0.410, reward_bound=0.345, batch=227\n",
      "8975: loss=0.113, reward_mean=0.380, reward_bound=0.342, batch=229\n",
      "8976: loss=0.112, reward_mean=0.400, reward_bound=0.349, batch=216\n",
      "8977: loss=0.113, reward_mean=0.440, reward_bound=0.282, batch=220\n",
      "8978: loss=0.111, reward_mean=0.460, reward_bound=0.314, batch=222\n",
      "8979: loss=0.112, reward_mean=0.490, reward_bound=0.349, batch=221\n",
      "8980: loss=0.111, reward_mean=0.440, reward_bound=0.314, batch=223\n",
      "8981: loss=0.111, reward_mean=0.450, reward_bound=0.301, batch=226\n",
      "8982: loss=0.112, reward_mean=0.430, reward_bound=0.349, batch=225\n",
      "8983: loss=0.112, reward_mean=0.430, reward_bound=0.356, batch=227\n",
      "8984: loss=0.107, reward_mean=0.500, reward_bound=0.387, batch=146\n",
      "8985: loss=0.114, reward_mean=0.440, reward_bound=0.050, batch=172\n",
      "8986: loss=0.108, reward_mean=0.440, reward_bound=0.067, batch=190\n",
      "8987: loss=0.106, reward_mean=0.520, reward_bound=0.122, batch=200\n",
      "8988: loss=0.108, reward_mean=0.540, reward_bound=0.135, batch=209\n",
      "8989: loss=0.109, reward_mean=0.430, reward_bound=0.157, batch=216\n",
      "8990: loss=0.105, reward_mean=0.360, reward_bound=0.167, batch=212\n",
      "8991: loss=0.101, reward_mean=0.380, reward_bound=0.185, batch=207\n",
      "8992: loss=0.102, reward_mean=0.450, reward_bound=0.202, batch=215\n",
      "8993: loss=0.109, reward_mean=0.530, reward_bound=0.206, batch=219\n",
      "8994: loss=0.108, reward_mean=0.460, reward_bound=0.215, batch=223\n",
      "8995: loss=0.109, reward_mean=0.470, reward_bound=0.229, batch=224\n",
      "8996: loss=0.105, reward_mean=0.500, reward_bound=0.254, batch=216\n",
      "8997: loss=0.104, reward_mean=0.350, reward_bound=0.282, batch=208\n",
      "8998: loss=0.102, reward_mean=0.330, reward_bound=0.137, batch=215\n",
      "8999: loss=0.104, reward_mean=0.470, reward_bound=0.210, batch=220\n",
      "9000: loss=0.107, reward_mean=0.540, reward_bound=0.254, batch=222\n",
      "9001: loss=0.106, reward_mean=0.500, reward_bound=0.282, batch=224\n",
      "9002: loss=0.106, reward_mean=0.370, reward_bound=0.249, batch=227\n",
      "9003: loss=0.110, reward_mean=0.430, reward_bound=0.314, batch=206\n",
      "9004: loss=0.113, reward_mean=0.450, reward_bound=0.268, batch=214\n",
      "9005: loss=0.114, reward_mean=0.480, reward_bound=0.280, batch=220\n",
      "9006: loss=0.112, reward_mean=0.460, reward_bound=0.338, batch=224\n",
      "9007: loss=0.109, reward_mean=0.450, reward_bound=0.349, batch=208\n",
      "9008: loss=0.108, reward_mean=0.460, reward_bound=0.138, batch=215\n",
      "9009: loss=0.110, reward_mean=0.390, reward_bound=0.234, batch=220\n",
      "9010: loss=0.110, reward_mean=0.470, reward_bound=0.282, batch=222\n",
      "9011: loss=0.110, reward_mean=0.420, reward_bound=0.314, batch=224\n",
      "9012: loss=0.110, reward_mean=0.500, reward_bound=0.349, batch=221\n",
      "9013: loss=0.110, reward_mean=0.400, reward_bound=0.282, batch=223\n",
      "9014: loss=0.110, reward_mean=0.570, reward_bound=0.372, batch=226\n",
      "9015: loss=0.109, reward_mean=0.610, reward_bound=0.387, batch=205\n",
      "9016: loss=0.110, reward_mean=0.400, reward_bound=0.254, batch=212\n",
      "9017: loss=0.109, reward_mean=0.460, reward_bound=0.263, batch=218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9018: loss=0.108, reward_mean=0.430, reward_bound=0.257, batch=222\n",
      "9019: loss=0.110, reward_mean=0.470, reward_bound=0.349, batch=219\n",
      "9020: loss=0.109, reward_mean=0.480, reward_bound=0.282, batch=222\n",
      "9021: loss=0.110, reward_mean=0.460, reward_bound=0.349, batch=224\n",
      "9022: loss=0.111, reward_mean=0.440, reward_bound=0.387, batch=224\n",
      "9023: loss=0.112, reward_mean=0.540, reward_bound=0.345, batch=227\n",
      "9024: loss=0.112, reward_mean=0.370, reward_bound=0.380, batch=229\n",
      "9025: loss=0.111, reward_mean=0.510, reward_bound=0.387, batch=228\n",
      "9026: loss=0.112, reward_mean=0.420, reward_bound=0.430, batch=118\n",
      "9027: loss=0.097, reward_mean=0.410, reward_bound=0.010, batch=152\n",
      "9028: loss=0.108, reward_mean=0.470, reward_bound=0.026, batch=176\n",
      "9029: loss=0.109, reward_mean=0.520, reward_bound=0.061, batch=193\n",
      "9030: loss=0.116, reward_mean=0.380, reward_bound=0.080, batch=204\n",
      "9031: loss=0.115, reward_mean=0.450, reward_bound=0.120, batch=213\n",
      "9032: loss=0.115, reward_mean=0.420, reward_bound=0.122, batch=217\n",
      "9033: loss=0.119, reward_mean=0.440, reward_bound=0.150, batch=214\n",
      "9034: loss=0.118, reward_mean=0.430, reward_bound=0.164, batch=220\n",
      "9035: loss=0.117, reward_mean=0.460, reward_bound=0.185, batch=214\n",
      "9036: loss=0.119, reward_mean=0.470, reward_bound=0.206, batch=203\n",
      "9037: loss=0.115, reward_mean=0.410, reward_bound=0.229, batch=200\n",
      "9038: loss=0.116, reward_mean=0.380, reward_bound=0.254, batch=195\n",
      "9039: loss=0.117, reward_mean=0.500, reward_bound=0.189, batch=206\n",
      "9040: loss=0.114, reward_mean=0.390, reward_bound=0.241, batch=214\n",
      "9041: loss=0.114, reward_mean=0.420, reward_bound=0.249, batch=220\n",
      "9042: loss=0.115, reward_mean=0.420, reward_bound=0.254, batch=220\n",
      "9043: loss=0.119, reward_mean=0.430, reward_bound=0.282, batch=202\n",
      "9044: loss=0.119, reward_mean=0.410, reward_bound=0.245, batch=211\n",
      "9045: loss=0.118, reward_mean=0.390, reward_bound=0.254, batch=216\n",
      "9046: loss=0.118, reward_mean=0.460, reward_bound=0.282, batch=218\n",
      "9047: loss=0.118, reward_mean=0.460, reward_bound=0.282, batch=221\n",
      "9048: loss=0.118, reward_mean=0.510, reward_bound=0.314, batch=199\n",
      "9049: loss=0.114, reward_mean=0.430, reward_bound=0.167, batch=208\n",
      "9050: loss=0.114, reward_mean=0.410, reward_bound=0.187, batch=215\n",
      "9051: loss=0.116, reward_mean=0.400, reward_bound=0.229, batch=218\n",
      "9052: loss=0.118, reward_mean=0.420, reward_bound=0.254, batch=220\n",
      "9053: loss=0.117, reward_mean=0.360, reward_bound=0.282, batch=222\n",
      "9054: loss=0.117, reward_mean=0.390, reward_bound=0.314, batch=223\n",
      "9055: loss=0.118, reward_mean=0.420, reward_bound=0.335, batch=226\n",
      "9056: loss=0.119, reward_mean=0.430, reward_bound=0.349, batch=213\n",
      "9057: loss=0.119, reward_mean=0.410, reward_bound=0.229, batch=218\n",
      "9058: loss=0.118, reward_mean=0.390, reward_bound=0.314, batch=220\n",
      "9059: loss=0.118, reward_mean=0.340, reward_bound=0.349, batch=219\n",
      "9060: loss=0.118, reward_mean=0.470, reward_bound=0.343, batch=223\n",
      "9061: loss=0.117, reward_mean=0.460, reward_bound=0.301, batch=226\n",
      "9062: loss=0.117, reward_mean=0.430, reward_bound=0.314, batch=226\n",
      "9063: loss=0.117, reward_mean=0.400, reward_bound=0.331, batch=228\n",
      "9064: loss=0.113, reward_mean=0.360, reward_bound=0.387, batch=199\n",
      "9065: loss=0.114, reward_mean=0.340, reward_bound=0.135, batch=208\n",
      "9066: loss=0.114, reward_mean=0.490, reward_bound=0.211, batch=215\n",
      "9067: loss=0.112, reward_mean=0.450, reward_bound=0.282, batch=218\n",
      "9068: loss=0.112, reward_mean=0.460, reward_bound=0.314, batch=221\n",
      "9069: loss=0.113, reward_mean=0.450, reward_bound=0.349, batch=218\n",
      "9070: loss=0.113, reward_mean=0.360, reward_bound=0.187, batch=222\n",
      "9071: loss=0.114, reward_mean=0.420, reward_bound=0.349, batch=224\n",
      "9072: loss=0.114, reward_mean=0.400, reward_bound=0.384, batch=227\n",
      "9073: loss=0.114, reward_mean=0.500, reward_bound=0.366, batch=229\n",
      "9074: loss=0.116, reward_mean=0.440, reward_bound=0.387, batch=222\n",
      "9075: loss=0.116, reward_mean=0.430, reward_bound=0.349, batch=224\n",
      "9076: loss=0.114, reward_mean=0.420, reward_bound=0.345, batch=227\n",
      "9077: loss=0.115, reward_mean=0.460, reward_bound=0.387, batch=228\n",
      "9078: loss=0.115, reward_mean=0.370, reward_bound=0.286, batch=229\n",
      "9079: loss=0.115, reward_mean=0.450, reward_bound=0.387, batch=229\n",
      "9080: loss=0.115, reward_mean=0.520, reward_bound=0.430, batch=181\n",
      "9081: loss=0.114, reward_mean=0.410, reward_bound=0.167, batch=196\n",
      "9082: loss=0.114, reward_mean=0.340, reward_bound=0.135, batch=203\n",
      "9083: loss=0.112, reward_mean=0.400, reward_bound=0.160, batch=212\n",
      "9084: loss=0.115, reward_mean=0.450, reward_bound=0.206, batch=220\n",
      "9085: loss=0.113, reward_mean=0.440, reward_bound=0.206, batch=228\n",
      "9086: loss=0.118, reward_mean=0.450, reward_bound=0.229, batch=228\n",
      "9087: loss=0.116, reward_mean=0.470, reward_bound=0.282, batch=225\n",
      "9088: loss=0.116, reward_mean=0.510, reward_bound=0.314, batch=223\n",
      "9089: loss=0.114, reward_mean=0.420, reward_bound=0.349, batch=208\n",
      "9090: loss=0.114, reward_mean=0.480, reward_bound=0.282, batch=214\n",
      "9091: loss=0.113, reward_mean=0.440, reward_bound=0.387, batch=203\n",
      "9092: loss=0.112, reward_mean=0.480, reward_bound=0.271, batch=212\n",
      "9093: loss=0.110, reward_mean=0.410, reward_bound=0.263, batch=218\n",
      "9094: loss=0.112, reward_mean=0.460, reward_bound=0.286, batch=222\n",
      "9095: loss=0.112, reward_mean=0.410, reward_bound=0.314, batch=218\n",
      "9096: loss=0.112, reward_mean=0.430, reward_bound=0.349, batch=218\n",
      "9097: loss=0.111, reward_mean=0.470, reward_bound=0.260, batch=222\n",
      "9098: loss=0.109, reward_mean=0.450, reward_bound=0.263, batch=225\n",
      "9099: loss=0.111, reward_mean=0.400, reward_bound=0.314, batch=226\n",
      "9100: loss=0.111, reward_mean=0.510, reward_bound=0.349, batch=226\n",
      "9101: loss=0.112, reward_mean=0.360, reward_bound=0.387, batch=221\n",
      "9102: loss=0.111, reward_mean=0.490, reward_bound=0.282, batch=224\n",
      "9103: loss=0.111, reward_mean=0.480, reward_bound=0.314, batch=226\n",
      "9104: loss=0.111, reward_mean=0.480, reward_bound=0.349, batch=226\n",
      "9105: loss=0.111, reward_mean=0.450, reward_bound=0.349, batch=226\n",
      "9106: loss=0.111, reward_mean=0.420, reward_bound=0.387, batch=226\n",
      "9107: loss=0.111, reward_mean=0.420, reward_bound=0.314, batch=227\n",
      "9108: loss=0.112, reward_mean=0.450, reward_bound=0.422, batch=229\n",
      "9109: loss=0.115, reward_mean=0.450, reward_bound=0.430, batch=204\n",
      "9110: loss=0.115, reward_mean=0.500, reward_bound=0.314, batch=209\n",
      "9111: loss=0.115, reward_mean=0.470, reward_bound=0.328, batch=216\n",
      "9112: loss=0.115, reward_mean=0.400, reward_bound=0.282, batch=220\n",
      "9113: loss=0.114, reward_mean=0.510, reward_bound=0.338, batch=224\n",
      "9114: loss=0.114, reward_mean=0.400, reward_bound=0.349, batch=222\n",
      "9115: loss=0.115, reward_mean=0.540, reward_bound=0.387, batch=220\n",
      "9116: loss=0.115, reward_mean=0.400, reward_bound=0.349, batch=222\n",
      "9117: loss=0.116, reward_mean=0.390, reward_bound=0.324, batch=225\n",
      "9118: loss=0.114, reward_mean=0.390, reward_bound=0.387, batch=223\n",
      "9119: loss=0.114, reward_mean=0.470, reward_bound=0.358, batch=226\n",
      "9120: loss=0.116, reward_mean=0.400, reward_bound=0.387, batch=227\n",
      "9121: loss=0.117, reward_mean=0.470, reward_bound=0.277, batch=229\n",
      "9122: loss=0.115, reward_mean=0.450, reward_bound=0.405, batch=230\n",
      "9123: loss=0.117, reward_mean=0.480, reward_bound=0.430, batch=221\n",
      "9124: loss=0.117, reward_mean=0.460, reward_bound=0.387, batch=224\n",
      "9125: loss=0.117, reward_mean=0.450, reward_bound=0.254, batch=226\n",
      "9126: loss=0.116, reward_mean=0.470, reward_bound=0.349, batch=227\n",
      "9127: loss=0.116, reward_mean=0.380, reward_bound=0.308, batch=229\n",
      "9128: loss=0.116, reward_mean=0.480, reward_bound=0.387, batch=228\n",
      "9129: loss=0.117, reward_mean=0.410, reward_bound=0.430, batch=227\n",
      "9130: loss=0.117, reward_mean=0.480, reward_bound=0.414, batch=229\n",
      "9131: loss=0.117, reward_mean=0.350, reward_bound=0.430, batch=229\n",
      "9132: loss=0.117, reward_mean=0.380, reward_bound=0.364, batch=230\n",
      "9133: loss=0.117, reward_mean=0.480, reward_bound=0.365, batch=231\n",
      "9134: loss=0.108, reward_mean=0.440, reward_bound=0.478, batch=98\n",
      "9135: loss=0.120, reward_mean=0.530, reward_bound=0.028, batch=137\n",
      "9136: loss=0.116, reward_mean=0.470, reward_bound=0.034, batch=162\n",
      "9137: loss=0.113, reward_mean=0.560, reward_bound=0.065, batch=181\n",
      "9138: loss=0.115, reward_mean=0.440, reward_bound=0.080, batch=195\n",
      "9139: loss=0.113, reward_mean=0.380, reward_bound=0.109, batch=208\n",
      "9140: loss=0.115, reward_mean=0.570, reward_bound=0.135, batch=208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9141: loss=0.117, reward_mean=0.350, reward_bound=0.150, batch=213\n",
      "9142: loss=0.117, reward_mean=0.500, reward_bound=0.167, batch=215\n",
      "9143: loss=0.123, reward_mean=0.400, reward_bound=0.185, batch=212\n",
      "9144: loss=0.123, reward_mean=0.420, reward_bound=0.206, batch=224\n",
      "9145: loss=0.124, reward_mean=0.510, reward_bound=0.206, batch=215\n",
      "9146: loss=0.125, reward_mean=0.540, reward_bound=0.229, batch=204\n",
      "9147: loss=0.122, reward_mean=0.450, reward_bound=0.183, batch=213\n",
      "9148: loss=0.120, reward_mean=0.460, reward_bound=0.254, batch=202\n",
      "9149: loss=0.121, reward_mean=0.480, reward_bound=0.245, batch=211\n",
      "9150: loss=0.120, reward_mean=0.410, reward_bound=0.254, batch=217\n",
      "9151: loss=0.113, reward_mean=0.490, reward_bound=0.282, batch=199\n",
      "9152: loss=0.112, reward_mean=0.500, reward_bound=0.215, batch=209\n",
      "9153: loss=0.112, reward_mean=0.370, reward_bound=0.215, batch=216\n",
      "9154: loss=0.115, reward_mean=0.460, reward_bound=0.229, batch=219\n",
      "9155: loss=0.114, reward_mean=0.460, reward_bound=0.254, batch=219\n",
      "9156: loss=0.111, reward_mean=0.570, reward_bound=0.314, batch=197\n",
      "9157: loss=0.115, reward_mean=0.480, reward_bound=0.229, batch=205\n",
      "9158: loss=0.113, reward_mean=0.460, reward_bound=0.234, batch=213\n",
      "9159: loss=0.112, reward_mean=0.400, reward_bound=0.271, batch=219\n",
      "9160: loss=0.112, reward_mean=0.420, reward_bound=0.282, batch=219\n",
      "9161: loss=0.112, reward_mean=0.350, reward_bound=0.314, batch=217\n",
      "9162: loss=0.112, reward_mean=0.430, reward_bound=0.349, batch=183\n",
      "9163: loss=0.111, reward_mean=0.420, reward_bound=0.167, batch=195\n",
      "9164: loss=0.109, reward_mean=0.450, reward_bound=0.206, batch=200\n",
      "9165: loss=0.109, reward_mean=0.430, reward_bound=0.247, batch=210\n",
      "9166: loss=0.108, reward_mean=0.470, reward_bound=0.247, batch=217\n",
      "9167: loss=0.108, reward_mean=0.420, reward_bound=0.254, batch=219\n",
      "9168: loss=0.110, reward_mean=0.480, reward_bound=0.282, batch=220\n",
      "9169: loss=0.111, reward_mean=0.430, reward_bound=0.314, batch=219\n",
      "9170: loss=0.112, reward_mean=0.400, reward_bound=0.282, batch=222\n",
      "9171: loss=0.112, reward_mean=0.510, reward_bound=0.349, batch=211\n",
      "9172: loss=0.110, reward_mean=0.400, reward_bound=0.282, batch=217\n",
      "9173: loss=0.111, reward_mean=0.440, reward_bound=0.314, batch=219\n",
      "9174: loss=0.110, reward_mean=0.400, reward_bound=0.282, batch=222\n",
      "9175: loss=0.111, reward_mean=0.470, reward_bound=0.349, batch=222\n",
      "9176: loss=0.111, reward_mean=0.410, reward_bound=0.282, batch=224\n",
      "9177: loss=0.110, reward_mean=0.370, reward_bound=0.349, batch=225\n",
      "9178: loss=0.104, reward_mean=0.480, reward_bound=0.387, batch=192\n",
      "9179: loss=0.105, reward_mean=0.460, reward_bound=0.185, batch=200\n",
      "9180: loss=0.107, reward_mean=0.440, reward_bound=0.200, batch=210\n",
      "9181: loss=0.108, reward_mean=0.520, reward_bound=0.206, batch=219\n",
      "9182: loss=0.107, reward_mean=0.480, reward_bound=0.215, batch=223\n",
      "9183: loss=0.106, reward_mean=0.500, reward_bound=0.229, batch=223\n",
      "9184: loss=0.106, reward_mean=0.370, reward_bound=0.254, batch=221\n",
      "9185: loss=0.103, reward_mean=0.550, reward_bound=0.282, batch=219\n",
      "9186: loss=0.102, reward_mean=0.510, reward_bound=0.314, batch=216\n",
      "9187: loss=0.104, reward_mean=0.460, reward_bound=0.298, batch=221\n",
      "9188: loss=0.103, reward_mean=0.460, reward_bound=0.314, batch=222\n",
      "9189: loss=0.100, reward_mean=0.500, reward_bound=0.349, batch=219\n",
      "9190: loss=0.099, reward_mean=0.400, reward_bound=0.364, batch=223\n",
      "9191: loss=0.101, reward_mean=0.400, reward_bound=0.387, batch=216\n",
      "9192: loss=0.100, reward_mean=0.540, reward_bound=0.349, batch=219\n",
      "9193: loss=0.099, reward_mean=0.380, reward_bound=0.349, batch=221\n",
      "9194: loss=0.099, reward_mean=0.460, reward_bound=0.314, batch=224\n",
      "9195: loss=0.099, reward_mean=0.470, reward_bound=0.342, batch=227\n",
      "9196: loss=0.100, reward_mean=0.430, reward_bound=0.380, batch=229\n",
      "9197: loss=0.101, reward_mean=0.410, reward_bound=0.387, batch=226\n",
      "9198: loss=0.100, reward_mean=0.400, reward_bound=0.356, batch=228\n",
      "9199: loss=0.106, reward_mean=0.510, reward_bound=0.430, batch=173\n",
      "9200: loss=0.101, reward_mean=0.510, reward_bound=0.135, batch=190\n",
      "9201: loss=0.110, reward_mean=0.420, reward_bound=0.162, batch=203\n",
      "9202: loss=0.107, reward_mean=0.420, reward_bound=0.185, batch=207\n",
      "9203: loss=0.111, reward_mean=0.480, reward_bound=0.206, batch=212\n",
      "9204: loss=0.109, reward_mean=0.460, reward_bound=0.185, batch=218\n",
      "9205: loss=0.106, reward_mean=0.400, reward_bound=0.229, batch=215\n",
      "9206: loss=0.106, reward_mean=0.420, reward_bound=0.254, batch=216\n",
      "9207: loss=0.106, reward_mean=0.420, reward_bound=0.254, batch=220\n",
      "9208: loss=0.108, reward_mean=0.480, reward_bound=0.282, batch=216\n",
      "9209: loss=0.105, reward_mean=0.530, reward_bound=0.314, batch=212\n",
      "9210: loss=0.105, reward_mean=0.490, reward_bound=0.314, batch=215\n",
      "9211: loss=0.106, reward_mean=0.450, reward_bound=0.314, batch=219\n",
      "9212: loss=0.106, reward_mean=0.430, reward_bound=0.349, batch=209\n",
      "9213: loss=0.108, reward_mean=0.390, reward_bound=0.194, batch=216\n",
      "9214: loss=0.105, reward_mean=0.420, reward_bound=0.206, batch=220\n",
      "9215: loss=0.108, reward_mean=0.540, reward_bound=0.282, batch=223\n",
      "9216: loss=0.108, reward_mean=0.500, reward_bound=0.314, batch=225\n",
      "9217: loss=0.107, reward_mean=0.470, reward_bound=0.349, batch=223\n",
      "9218: loss=0.106, reward_mean=0.430, reward_bound=0.387, batch=202\n",
      "9219: loss=0.104, reward_mean=0.390, reward_bound=0.155, batch=211\n",
      "9220: loss=0.106, reward_mean=0.430, reward_bound=0.185, batch=217\n",
      "9221: loss=0.107, reward_mean=0.400, reward_bound=0.229, batch=221\n",
      "9222: loss=0.108, reward_mean=0.530, reward_bound=0.254, batch=224\n",
      "9223: loss=0.107, reward_mean=0.440, reward_bound=0.282, batch=223\n",
      "9224: loss=0.108, reward_mean=0.390, reward_bound=0.314, batch=221\n",
      "9225: loss=0.107, reward_mean=0.480, reward_bound=0.349, batch=220\n",
      "9226: loss=0.108, reward_mean=0.520, reward_bound=0.387, batch=214\n",
      "9227: loss=0.108, reward_mean=0.430, reward_bound=0.308, batch=220\n",
      "9228: loss=0.108, reward_mean=0.440, reward_bound=0.314, batch=223\n",
      "9229: loss=0.109, reward_mean=0.450, reward_bound=0.349, batch=224\n",
      "9230: loss=0.110, reward_mean=0.380, reward_bound=0.305, batch=227\n",
      "9231: loss=0.109, reward_mean=0.450, reward_bound=0.349, batch=227\n",
      "9232: loss=0.108, reward_mean=0.440, reward_bound=0.387, batch=220\n",
      "9233: loss=0.109, reward_mean=0.480, reward_bound=0.304, batch=224\n",
      "9234: loss=0.110, reward_mean=0.410, reward_bound=0.252, batch=227\n",
      "9235: loss=0.109, reward_mean=0.480, reward_bound=0.308, batch=229\n",
      "9236: loss=0.108, reward_mean=0.460, reward_bound=0.349, batch=228\n",
      "9237: loss=0.109, reward_mean=0.520, reward_bound=0.353, batch=229\n",
      "9238: loss=0.107, reward_mean=0.420, reward_bound=0.387, batch=225\n",
      "9239: loss=0.110, reward_mean=0.500, reward_bound=0.430, batch=199\n",
      "9240: loss=0.109, reward_mean=0.330, reward_bound=0.203, batch=209\n",
      "9241: loss=0.113, reward_mean=0.380, reward_bound=0.167, batch=214\n",
      "9242: loss=0.110, reward_mean=0.420, reward_bound=0.206, batch=217\n",
      "9243: loss=0.112, reward_mean=0.490, reward_bound=0.229, batch=219\n",
      "9244: loss=0.109, reward_mean=0.320, reward_bound=0.254, batch=222\n",
      "9245: loss=0.110, reward_mean=0.460, reward_bound=0.282, batch=222\n",
      "9246: loss=0.110, reward_mean=0.480, reward_bound=0.314, batch=223\n",
      "9247: loss=0.110, reward_mean=0.380, reward_bound=0.349, batch=220\n",
      "9248: loss=0.111, reward_mean=0.380, reward_bound=0.314, batch=222\n",
      "9249: loss=0.111, reward_mean=0.570, reward_bound=0.360, batch=225\n",
      "9250: loss=0.111, reward_mean=0.410, reward_bound=0.387, batch=214\n",
      "9251: loss=0.110, reward_mean=0.450, reward_bound=0.277, batch=220\n",
      "9252: loss=0.109, reward_mean=0.470, reward_bound=0.304, batch=224\n",
      "9253: loss=0.111, reward_mean=0.350, reward_bound=0.314, batch=224\n",
      "9254: loss=0.109, reward_mean=0.520, reward_bound=0.349, batch=222\n",
      "9255: loss=0.109, reward_mean=0.270, reward_bound=0.245, batch=225\n",
      "9256: loss=0.110, reward_mean=0.550, reward_bound=0.314, batch=226\n",
      "9257: loss=0.110, reward_mean=0.440, reward_bound=0.314, batch=227\n",
      "9258: loss=0.109, reward_mean=0.470, reward_bound=0.349, batch=228\n",
      "9259: loss=0.109, reward_mean=0.530, reward_bound=0.387, batch=227\n",
      "9260: loss=0.109, reward_mean=0.480, reward_bound=0.342, batch=229\n",
      "9261: loss=0.110, reward_mean=0.480, reward_bound=0.349, batch=229\n",
      "9262: loss=0.109, reward_mean=0.440, reward_bound=0.387, batch=228\n",
      "9263: loss=0.109, reward_mean=0.500, reward_bound=0.392, batch=229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9264: loss=0.109, reward_mean=0.380, reward_bound=0.430, batch=220\n",
      "9265: loss=0.109, reward_mean=0.350, reward_bound=0.376, batch=224\n",
      "9266: loss=0.109, reward_mean=0.490, reward_bound=0.387, batch=225\n",
      "9267: loss=0.109, reward_mean=0.520, reward_bound=0.396, batch=227\n",
      "9268: loss=0.109, reward_mean=0.410, reward_bound=0.430, batch=225\n",
      "9269: loss=0.107, reward_mean=0.450, reward_bound=0.478, batch=151\n",
      "9270: loss=0.102, reward_mean=0.420, reward_bound=0.038, batch=175\n",
      "9271: loss=0.101, reward_mean=0.500, reward_bound=0.101, batch=192\n",
      "9272: loss=0.104, reward_mean=0.410, reward_bound=0.135, batch=203\n",
      "9273: loss=0.109, reward_mean=0.570, reward_bound=0.150, batch=211\n",
      "9274: loss=0.107, reward_mean=0.420, reward_bound=0.185, batch=211\n",
      "9275: loss=0.113, reward_mean=0.490, reward_bound=0.206, batch=216\n",
      "9276: loss=0.112, reward_mean=0.400, reward_bound=0.229, batch=209\n",
      "9277: loss=0.111, reward_mean=0.470, reward_bound=0.254, batch=202\n",
      "9278: loss=0.110, reward_mean=0.440, reward_bound=0.191, batch=211\n",
      "9279: loss=0.114, reward_mean=0.420, reward_bound=0.229, batch=216\n",
      "9280: loss=0.113, reward_mean=0.490, reward_bound=0.254, batch=219\n",
      "9281: loss=0.113, reward_mean=0.340, reward_bound=0.282, batch=212\n",
      "9282: loss=0.108, reward_mean=0.470, reward_bound=0.314, batch=208\n",
      "9283: loss=0.109, reward_mean=0.450, reward_bound=0.208, batch=215\n",
      "9284: loss=0.108, reward_mean=0.490, reward_bound=0.314, batch=218\n",
      "9285: loss=0.106, reward_mean=0.590, reward_bound=0.349, batch=206\n",
      "9286: loss=0.107, reward_mean=0.360, reward_bound=0.176, batch=214\n",
      "9287: loss=0.106, reward_mean=0.380, reward_bound=0.229, batch=219\n",
      "9288: loss=0.107, reward_mean=0.460, reward_bound=0.254, batch=222\n",
      "9289: loss=0.104, reward_mean=0.450, reward_bound=0.292, batch=225\n",
      "9290: loss=0.105, reward_mean=0.440, reward_bound=0.314, batch=221\n",
      "9291: loss=0.107, reward_mean=0.460, reward_bound=0.349, batch=221\n",
      "9292: loss=0.107, reward_mean=0.440, reward_bound=0.349, batch=224\n",
      "9293: loss=0.105, reward_mean=0.410, reward_bound=0.387, batch=201\n",
      "9294: loss=0.105, reward_mean=0.410, reward_bound=0.185, batch=210\n",
      "9295: loss=0.106, reward_mean=0.460, reward_bound=0.282, batch=214\n",
      "9296: loss=0.107, reward_mean=0.390, reward_bound=0.254, batch=219\n",
      "9297: loss=0.108, reward_mean=0.460, reward_bound=0.215, batch=223\n",
      "9298: loss=0.110, reward_mean=0.390, reward_bound=0.282, batch=224\n",
      "9299: loss=0.108, reward_mean=0.480, reward_bound=0.314, batch=222\n",
      "9300: loss=0.109, reward_mean=0.510, reward_bound=0.302, batch=225\n",
      "9301: loss=0.109, reward_mean=0.360, reward_bound=0.314, batch=226\n",
      "9302: loss=0.108, reward_mean=0.400, reward_bound=0.349, batch=218\n",
      "9303: loss=0.108, reward_mean=0.490, reward_bound=0.349, batch=221\n",
      "9304: loss=0.106, reward_mean=0.460, reward_bound=0.387, batch=211\n",
      "9305: loss=0.105, reward_mean=0.450, reward_bound=0.282, batch=216\n",
      "9306: loss=0.104, reward_mean=0.570, reward_bound=0.298, batch=221\n",
      "9307: loss=0.103, reward_mean=0.390, reward_bound=0.229, batch=224\n",
      "9308: loss=0.105, reward_mean=0.470, reward_bound=0.314, batch=226\n",
      "9309: loss=0.105, reward_mean=0.430, reward_bound=0.316, batch=228\n",
      "9310: loss=0.103, reward_mean=0.440, reward_bound=0.349, batch=228\n",
      "9311: loss=0.105, reward_mean=0.410, reward_bound=0.387, batch=219\n",
      "9312: loss=0.105, reward_mean=0.400, reward_bound=0.295, batch=223\n",
      "9313: loss=0.106, reward_mean=0.440, reward_bound=0.335, batch=226\n",
      "9314: loss=0.105, reward_mean=0.420, reward_bound=0.387, batch=226\n",
      "9315: loss=0.105, reward_mean=0.520, reward_bound=0.335, batch=228\n",
      "9316: loss=0.104, reward_mean=0.470, reward_bound=0.321, batch=229\n",
      "9317: loss=0.105, reward_mean=0.430, reward_bound=0.387, batch=229\n",
      "9318: loss=0.106, reward_mean=0.400, reward_bound=0.430, batch=187\n",
      "9319: loss=0.106, reward_mean=0.400, reward_bound=0.132, batch=201\n",
      "9320: loss=0.103, reward_mean=0.470, reward_bound=0.135, batch=209\n",
      "9321: loss=0.104, reward_mean=0.520, reward_bound=0.185, batch=214\n",
      "9322: loss=0.103, reward_mean=0.380, reward_bound=0.229, batch=213\n",
      "9323: loss=0.103, reward_mean=0.510, reward_bound=0.254, batch=218\n",
      "9324: loss=0.105, reward_mean=0.430, reward_bound=0.282, batch=218\n",
      "9325: loss=0.105, reward_mean=0.440, reward_bound=0.260, batch=222\n",
      "9326: loss=0.104, reward_mean=0.450, reward_bound=0.314, batch=219\n",
      "9327: loss=0.106, reward_mean=0.450, reward_bound=0.349, batch=212\n",
      "9328: loss=0.106, reward_mean=0.390, reward_bound=0.314, batch=216\n",
      "9329: loss=0.107, reward_mean=0.460, reward_bound=0.368, batch=221\n",
      "9330: loss=0.107, reward_mean=0.450, reward_bound=0.314, batch=223\n",
      "9331: loss=0.110, reward_mean=0.520, reward_bound=0.387, batch=212\n",
      "9332: loss=0.109, reward_mean=0.430, reward_bound=0.282, batch=216\n",
      "9333: loss=0.111, reward_mean=0.410, reward_bound=0.230, batch=221\n",
      "9334: loss=0.111, reward_mean=0.480, reward_bound=0.314, batch=223\n",
      "9335: loss=0.112, reward_mean=0.450, reward_bound=0.335, batch=226\n",
      "9336: loss=0.113, reward_mean=0.370, reward_bound=0.316, batch=228\n",
      "9337: loss=0.112, reward_mean=0.410, reward_bound=0.349, batch=224\n",
      "9338: loss=0.111, reward_mean=0.400, reward_bound=0.384, batch=227\n",
      "9339: loss=0.111, reward_mean=0.420, reward_bound=0.349, batch=228\n",
      "9340: loss=0.111, reward_mean=0.480, reward_bound=0.314, batch=228\n",
      "9341: loss=0.111, reward_mean=0.440, reward_bound=0.349, batch=228\n",
      "9342: loss=0.109, reward_mean=0.500, reward_bound=0.387, batch=224\n",
      "9343: loss=0.108, reward_mean=0.320, reward_bound=0.380, batch=227\n",
      "9344: loss=0.108, reward_mean=0.460, reward_bound=0.387, batch=227\n",
      "9345: loss=0.108, reward_mean=0.450, reward_bound=0.422, batch=229\n",
      "9346: loss=0.107, reward_mean=0.450, reward_bound=0.430, batch=208\n",
      "9347: loss=0.107, reward_mean=0.520, reward_bound=0.254, batch=214\n",
      "9348: loss=0.106, reward_mean=0.520, reward_bound=0.254, batch=218\n",
      "9349: loss=0.108, reward_mean=0.460, reward_bound=0.282, batch=219\n",
      "9350: loss=0.107, reward_mean=0.400, reward_bound=0.295, batch=223\n",
      "9351: loss=0.107, reward_mean=0.390, reward_bound=0.314, batch=225\n",
      "9352: loss=0.107, reward_mean=0.380, reward_bound=0.387, batch=221\n",
      "9353: loss=0.108, reward_mean=0.390, reward_bound=0.282, batch=224\n",
      "9354: loss=0.108, reward_mean=0.340, reward_bound=0.345, batch=227\n",
      "9355: loss=0.108, reward_mean=0.410, reward_bound=0.349, batch=227\n",
      "9356: loss=0.108, reward_mean=0.430, reward_bound=0.422, batch=229\n",
      "9357: loss=0.108, reward_mean=0.500, reward_bound=0.430, batch=222\n",
      "9358: loss=0.108, reward_mean=0.440, reward_bound=0.400, batch=225\n",
      "9359: loss=0.108, reward_mean=0.390, reward_bound=0.396, batch=227\n",
      "9360: loss=0.109, reward_mean=0.450, reward_bound=0.430, batch=227\n",
      "9361: loss=0.109, reward_mean=0.490, reward_bound=0.469, batch=229\n",
      "9362: loss=0.109, reward_mean=0.390, reward_bound=0.450, batch=230\n",
      "9363: loss=0.110, reward_mean=0.410, reward_bound=0.478, batch=188\n",
      "9364: loss=0.113, reward_mean=0.390, reward_bound=0.112, batch=201\n",
      "9365: loss=0.111, reward_mean=0.560, reward_bound=0.254, batch=210\n",
      "9366: loss=0.109, reward_mean=0.500, reward_bound=0.282, batch=213\n",
      "9367: loss=0.109, reward_mean=0.380, reward_bound=0.235, batch=219\n",
      "9368: loss=0.108, reward_mean=0.420, reward_bound=0.265, batch=223\n",
      "9369: loss=0.113, reward_mean=0.470, reward_bound=0.314, batch=219\n",
      "9370: loss=0.111, reward_mean=0.470, reward_bound=0.349, batch=216\n",
      "9371: loss=0.110, reward_mean=0.390, reward_bound=0.316, batch=221\n",
      "9372: loss=0.111, reward_mean=0.420, reward_bound=0.349, batch=224\n",
      "9373: loss=0.111, reward_mean=0.370, reward_bound=0.282, batch=226\n",
      "9374: loss=0.111, reward_mean=0.530, reward_bound=0.349, batch=227\n",
      "9375: loss=0.109, reward_mean=0.460, reward_bound=0.387, batch=218\n",
      "9376: loss=0.110, reward_mean=0.450, reward_bound=0.430, batch=210\n",
      "9377: loss=0.110, reward_mean=0.470, reward_bound=0.304, batch=217\n",
      "9378: loss=0.111, reward_mean=0.330, reward_bound=0.220, batch=222\n",
      "9379: loss=0.110, reward_mean=0.460, reward_bound=0.292, batch=225\n",
      "9380: loss=0.114, reward_mean=0.460, reward_bound=0.314, batch=226\n",
      "9381: loss=0.111, reward_mean=0.480, reward_bound=0.349, batch=227\n",
      "9382: loss=0.111, reward_mean=0.470, reward_bound=0.373, batch=229\n",
      "9383: loss=0.111, reward_mean=0.460, reward_bound=0.387, batch=222\n",
      "9384: loss=0.111, reward_mean=0.500, reward_bound=0.387, batch=224\n",
      "9385: loss=0.112, reward_mean=0.450, reward_bound=0.345, batch=227\n",
      "9386: loss=0.110, reward_mean=0.580, reward_bound=0.349, batch=228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9387: loss=0.111, reward_mean=0.460, reward_bound=0.293, batch=229\n",
      "9388: loss=0.111, reward_mean=0.510, reward_bound=0.430, batch=217\n",
      "9389: loss=0.110, reward_mean=0.530, reward_bound=0.380, batch=222\n",
      "9390: loss=0.110, reward_mean=0.530, reward_bound=0.349, batch=224\n",
      "9391: loss=0.110, reward_mean=0.430, reward_bound=0.387, batch=223\n",
      "9392: loss=0.110, reward_mean=0.480, reward_bound=0.349, batch=225\n",
      "9393: loss=0.110, reward_mean=0.290, reward_bound=0.356, batch=227\n",
      "9394: loss=0.110, reward_mean=0.450, reward_bound=0.373, batch=229\n",
      "9395: loss=0.110, reward_mean=0.450, reward_bound=0.387, batch=228\n",
      "9396: loss=0.110, reward_mean=0.360, reward_bound=0.353, batch=229\n",
      "9397: loss=0.110, reward_mean=0.390, reward_bound=0.430, batch=224\n",
      "9398: loss=0.110, reward_mean=0.490, reward_bound=0.387, batch=226\n",
      "9399: loss=0.110, reward_mean=0.450, reward_bound=0.368, batch=228\n",
      "9400: loss=0.109, reward_mean=0.450, reward_bound=0.397, batch=229\n",
      "9401: loss=0.109, reward_mean=0.470, reward_bound=0.478, batch=231\n",
      "9402: loss=0.110, reward_mean=0.410, reward_bound=0.478, batch=210\n",
      "9403: loss=0.110, reward_mean=0.370, reward_bound=0.274, batch=217\n",
      "9404: loss=0.110, reward_mean=0.410, reward_bound=0.282, batch=221\n",
      "9405: loss=0.110, reward_mean=0.400, reward_bound=0.349, batch=221\n",
      "9406: loss=0.111, reward_mean=0.470, reward_bound=0.349, batch=224\n",
      "9407: loss=0.112, reward_mean=0.470, reward_bound=0.387, batch=226\n",
      "9408: loss=0.111, reward_mean=0.440, reward_bound=0.430, batch=219\n",
      "9409: loss=0.111, reward_mean=0.460, reward_bound=0.278, batch=223\n",
      "9410: loss=0.111, reward_mean=0.430, reward_bound=0.335, batch=226\n",
      "9411: loss=0.112, reward_mean=0.550, reward_bound=0.349, batch=224\n",
      "9412: loss=0.112, reward_mean=0.450, reward_bound=0.387, batch=225\n",
      "9413: loss=0.112, reward_mean=0.500, reward_bound=0.430, batch=225\n",
      "9414: loss=0.112, reward_mean=0.350, reward_bound=0.349, batch=225\n",
      "9415: loss=0.110, reward_mean=0.430, reward_bound=0.478, batch=214\n",
      "9416: loss=0.111, reward_mean=0.450, reward_bound=0.311, batch=220\n",
      "9417: loss=0.113, reward_mean=0.360, reward_bound=0.338, batch=224\n",
      "9418: loss=0.112, reward_mean=0.430, reward_bound=0.345, batch=227\n",
      "9419: loss=0.113, reward_mean=0.310, reward_bound=0.308, batch=229\n",
      "9420: loss=0.109, reward_mean=0.490, reward_bound=0.349, batch=228\n",
      "9421: loss=0.110, reward_mean=0.430, reward_bound=0.387, batch=225\n",
      "9422: loss=0.111, reward_mean=0.360, reward_bound=0.260, batch=227\n",
      "9423: loss=0.110, reward_mean=0.430, reward_bound=0.342, batch=229\n",
      "9424: loss=0.110, reward_mean=0.380, reward_bound=0.364, batch=230\n",
      "9425: loss=0.109, reward_mean=0.460, reward_bound=0.387, batch=229\n",
      "9426: loss=0.109, reward_mean=0.500, reward_bound=0.430, batch=225\n",
      "9427: loss=0.109, reward_mean=0.360, reward_bound=0.396, batch=227\n",
      "9428: loss=0.109, reward_mean=0.360, reward_bound=0.387, batch=228\n",
      "9429: loss=0.109, reward_mean=0.400, reward_bound=0.435, batch=229\n",
      "9430: loss=0.109, reward_mean=0.360, reward_bound=0.405, batch=230\n",
      "9431: loss=0.109, reward_mean=0.410, reward_bound=0.464, batch=231\n",
      "9432: loss=0.109, reward_mean=0.410, reward_bound=0.387, batch=231\n",
      "9433: loss=0.110, reward_mean=0.400, reward_bound=0.478, batch=224\n",
      "9434: loss=0.111, reward_mean=0.370, reward_bound=0.387, batch=226\n",
      "9435: loss=0.111, reward_mean=0.410, reward_bound=0.430, batch=227\n",
      "9436: loss=0.111, reward_mean=0.520, reward_bound=0.460, batch=229\n",
      "9437: loss=0.111, reward_mean=0.490, reward_bound=0.380, batch=230\n",
      "9438: loss=0.111, reward_mean=0.500, reward_bound=0.478, batch=228\n",
      "9439: loss=0.110, reward_mean=0.410, reward_bound=0.362, batch=229\n",
      "9440: loss=0.110, reward_mean=0.450, reward_bound=0.401, batch=230\n",
      "9441: loss=0.110, reward_mean=0.450, reward_bound=0.439, batch=231\n",
      "9442: loss=0.110, reward_mean=0.400, reward_bound=0.430, batch=231\n",
      "9443: loss=0.110, reward_mean=0.500, reward_bound=0.387, batch=231\n",
      "9444: loss=0.110, reward_mean=0.430, reward_bound=0.349, batch=231\n",
      "9445: loss=0.110, reward_mean=0.440, reward_bound=0.430, batch=231\n",
      "9446: loss=0.110, reward_mean=0.460, reward_bound=0.387, batch=231\n",
      "9447: loss=0.110, reward_mean=0.410, reward_bound=0.349, batch=231\n",
      "9448: loss=0.110, reward_mean=0.400, reward_bound=0.478, batch=229\n",
      "9449: loss=0.110, reward_mean=0.410, reward_bound=0.387, batch=229\n",
      "9450: loss=0.110, reward_mean=0.410, reward_bound=0.450, batch=230\n",
      "9451: loss=0.110, reward_mean=0.500, reward_bound=0.478, batch=229\n",
      "9453: loss=0.099, reward_mean=0.500, reward_bound=0.000, batch=50\n",
      "9454: loss=0.101, reward_mean=0.390, reward_bound=0.000, batch=89\n",
      "9455: loss=0.104, reward_mean=0.450, reward_bound=0.000, batch=132\n",
      "9456: loss=0.112, reward_mean=0.490, reward_bound=0.005, batch=160\n",
      "9457: loss=0.111, reward_mean=0.370, reward_bound=0.011, batch=182\n",
      "9458: loss=0.107, reward_mean=0.470, reward_bound=0.025, batch=195\n",
      "9459: loss=0.112, reward_mean=0.450, reward_bound=0.042, batch=200\n",
      "9460: loss=0.115, reward_mean=0.460, reward_bound=0.052, batch=206\n",
      "9461: loss=0.117, reward_mean=0.440, reward_bound=0.072, batch=210\n",
      "9462: loss=0.120, reward_mean=0.500, reward_bound=0.089, batch=212\n",
      "9463: loss=0.121, reward_mean=0.400, reward_bound=0.098, batch=215\n",
      "9464: loss=0.123, reward_mean=0.450, reward_bound=0.109, batch=235\n",
      "9465: loss=0.122, reward_mean=0.400, reward_bound=0.109, batch=249\n",
      "9466: loss=0.116, reward_mean=0.420, reward_bound=0.109, batch=238\n",
      "9467: loss=0.111, reward_mean=0.400, reward_bound=0.122, batch=231\n",
      "9468: loss=0.110, reward_mean=0.490, reward_bound=0.135, batch=227\n",
      "9469: loss=0.103, reward_mean=0.400, reward_bound=0.150, batch=209\n",
      "9470: loss=0.105, reward_mean=0.440, reward_bound=0.157, batch=216\n",
      "9471: loss=0.101, reward_mean=0.380, reward_bound=0.167, batch=203\n",
      "9472: loss=0.102, reward_mean=0.400, reward_bound=0.139, batch=212\n",
      "9473: loss=0.098, reward_mean=0.510, reward_bound=0.185, batch=209\n",
      "9474: loss=0.098, reward_mean=0.410, reward_bound=0.206, batch=195\n",
      "9475: loss=0.097, reward_mean=0.440, reward_bound=0.167, batch=205\n",
      "9476: loss=0.099, reward_mean=0.440, reward_bound=0.229, batch=178\n",
      "9477: loss=0.095, reward_mean=0.400, reward_bound=0.043, batch=194\n",
      "9478: loss=0.099, reward_mean=0.440, reward_bound=0.108, batch=206\n",
      "9479: loss=0.102, reward_mean=0.440, reward_bound=0.135, batch=212\n",
      "9480: loss=0.102, reward_mean=0.400, reward_bound=0.155, batch=218\n",
      "9481: loss=0.102, reward_mean=0.480, reward_bound=0.206, batch=218\n",
      "9482: loss=0.101, reward_mean=0.440, reward_bound=0.231, batch=222\n",
      "9483: loss=0.104, reward_mean=0.490, reward_bound=0.254, batch=183\n",
      "9484: loss=0.105, reward_mean=0.450, reward_bound=0.109, batch=197\n",
      "9485: loss=0.103, reward_mean=0.460, reward_bound=0.122, batch=206\n",
      "9486: loss=0.104, reward_mean=0.340, reward_bound=0.150, batch=211\n",
      "9487: loss=0.103, reward_mean=0.310, reward_bound=0.185, batch=217\n",
      "9488: loss=0.101, reward_mean=0.440, reward_bound=0.206, batch=221\n",
      "9489: loss=0.102, reward_mean=0.460, reward_bound=0.254, batch=219\n",
      "9490: loss=0.104, reward_mean=0.370, reward_bound=0.282, batch=181\n",
      "9491: loss=0.104, reward_mean=0.460, reward_bound=0.185, batch=196\n",
      "9492: loss=0.101, reward_mean=0.410, reward_bound=0.196, batch=207\n",
      "9493: loss=0.105, reward_mean=0.510, reward_bound=0.249, batch=215\n",
      "9494: loss=0.106, reward_mean=0.500, reward_bound=0.254, batch=208\n",
      "9495: loss=0.106, reward_mean=0.390, reward_bound=0.208, batch=215\n",
      "9496: loss=0.107, reward_mean=0.460, reward_bound=0.234, batch=220\n",
      "9497: loss=0.108, reward_mean=0.450, reward_bound=0.274, batch=224\n",
      "9498: loss=0.109, reward_mean=0.400, reward_bound=0.282, batch=219\n",
      "9499: loss=0.108, reward_mean=0.480, reward_bound=0.314, batch=168\n",
      "9500: loss=0.121, reward_mean=0.440, reward_bound=0.053, batch=187\n",
      "9501: loss=0.112, reward_mean=0.520, reward_bound=0.109, batch=202\n",
      "9502: loss=0.114, reward_mean=0.400, reward_bound=0.113, batch=211\n",
      "9503: loss=0.112, reward_mean=0.430, reward_bound=0.167, batch=216\n",
      "9504: loss=0.110, reward_mean=0.440, reward_bound=0.206, batch=215\n",
      "9505: loss=0.111, reward_mean=0.480, reward_bound=0.229, batch=218\n",
      "9506: loss=0.111, reward_mean=0.460, reward_bound=0.254, batch=218\n",
      "9507: loss=0.111, reward_mean=0.380, reward_bound=0.282, batch=214\n",
      "9508: loss=0.112, reward_mean=0.480, reward_bound=0.311, batch=220\n",
      "9509: loss=0.110, reward_mean=0.460, reward_bound=0.314, batch=214\n",
      "9510: loss=0.110, reward_mean=0.390, reward_bound=0.282, batch=219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9511: loss=0.111, reward_mean=0.440, reward_bound=0.295, batch=223\n",
      "9512: loss=0.111, reward_mean=0.330, reward_bound=0.301, batch=226\n",
      "9513: loss=0.111, reward_mean=0.410, reward_bound=0.314, batch=225\n",
      "9514: loss=0.107, reward_mean=0.470, reward_bound=0.349, batch=154\n",
      "9515: loss=0.105, reward_mean=0.410, reward_bound=0.065, batch=176\n",
      "9516: loss=0.106, reward_mean=0.510, reward_bound=0.104, batch=193\n",
      "9517: loss=0.107, reward_mean=0.420, reward_bound=0.135, batch=202\n",
      "9518: loss=0.108, reward_mean=0.500, reward_bound=0.150, batch=209\n",
      "9519: loss=0.106, reward_mean=0.490, reward_bound=0.185, batch=211\n",
      "9520: loss=0.111, reward_mean=0.450, reward_bound=0.229, batch=212\n",
      "9521: loss=0.113, reward_mean=0.390, reward_bound=0.254, batch=205\n",
      "9522: loss=0.113, reward_mean=0.450, reward_bound=0.260, batch=213\n",
      "9523: loss=0.111, reward_mean=0.380, reward_bound=0.229, batch=218\n",
      "9524: loss=0.112, reward_mean=0.400, reward_bound=0.282, batch=210\n",
      "9525: loss=0.115, reward_mean=0.440, reward_bound=0.247, batch=217\n",
      "9526: loss=0.116, reward_mean=0.460, reward_bound=0.277, batch=222\n",
      "9527: loss=0.113, reward_mean=0.530, reward_bound=0.282, batch=222\n",
      "9528: loss=0.109, reward_mean=0.400, reward_bound=0.314, batch=207\n",
      "9529: loss=0.108, reward_mean=0.410, reward_bound=0.198, batch=215\n",
      "9530: loss=0.108, reward_mean=0.450, reward_bound=0.254, batch=219\n",
      "9531: loss=0.109, reward_mean=0.470, reward_bound=0.349, batch=209\n",
      "9532: loss=0.109, reward_mean=0.420, reward_bound=0.295, batch=216\n",
      "9533: loss=0.108, reward_mean=0.480, reward_bound=0.368, batch=221\n",
      "9534: loss=0.107, reward_mean=0.350, reward_bound=0.282, batch=224\n",
      "9535: loss=0.101, reward_mean=0.420, reward_bound=0.387, batch=147\n",
      "9536: loss=0.094, reward_mean=0.350, reward_bound=0.027, batch=173\n",
      "9537: loss=0.099, reward_mean=0.450, reward_bound=0.098, batch=187\n",
      "9538: loss=0.097, reward_mean=0.460, reward_bound=0.119, batch=201\n",
      "9539: loss=0.098, reward_mean=0.490, reward_bound=0.135, batch=208\n",
      "9540: loss=0.092, reward_mean=0.550, reward_bound=0.150, batch=214\n",
      "9541: loss=0.091, reward_mean=0.330, reward_bound=0.167, batch=217\n",
      "9542: loss=0.093, reward_mean=0.510, reward_bound=0.206, batch=216\n",
      "9543: loss=0.092, reward_mean=0.450, reward_bound=0.229, batch=216\n",
      "9544: loss=0.097, reward_mean=0.360, reward_bound=0.254, batch=208\n",
      "9545: loss=0.095, reward_mean=0.500, reward_bound=0.282, batch=208\n",
      "9546: loss=0.095, reward_mean=0.390, reward_bound=0.171, batch=215\n",
      "9547: loss=0.094, reward_mean=0.470, reward_bound=0.229, batch=217\n",
      "9548: loss=0.093, reward_mean=0.330, reward_bound=0.224, batch=222\n",
      "9549: loss=0.094, reward_mean=0.510, reward_bound=0.254, batch=223\n",
      "9550: loss=0.094, reward_mean=0.380, reward_bound=0.301, batch=226\n",
      "9551: loss=0.097, reward_mean=0.390, reward_bound=0.314, batch=217\n",
      "9552: loss=0.098, reward_mean=0.460, reward_bound=0.314, batch=220\n",
      "9553: loss=0.097, reward_mean=0.410, reward_bound=0.338, batch=224\n",
      "9554: loss=0.100, reward_mean=0.550, reward_bound=0.349, batch=205\n",
      "9555: loss=0.102, reward_mean=0.430, reward_bound=0.210, batch=213\n",
      "9556: loss=0.101, reward_mean=0.460, reward_bound=0.244, batch=219\n",
      "9557: loss=0.102, reward_mean=0.550, reward_bound=0.282, batch=221\n",
      "9558: loss=0.103, reward_mean=0.530, reward_bound=0.314, batch=221\n",
      "9559: loss=0.103, reward_mean=0.470, reward_bound=0.314, batch=224\n",
      "9560: loss=0.102, reward_mean=0.490, reward_bound=0.349, batch=223\n",
      "9561: loss=0.103, reward_mean=0.400, reward_bound=0.387, batch=196\n",
      "9562: loss=0.105, reward_mean=0.370, reward_bound=0.185, batch=206\n",
      "9563: loss=0.104, reward_mean=0.410, reward_bound=0.196, batch=214\n",
      "9564: loss=0.110, reward_mean=0.460, reward_bound=0.254, batch=217\n",
      "9565: loss=0.119, reward_mean=0.410, reward_bound=0.308, batch=222\n",
      "9566: loss=0.119, reward_mean=0.380, reward_bound=0.314, batch=223\n",
      "9567: loss=0.111, reward_mean=0.420, reward_bound=0.349, batch=219\n",
      "9568: loss=0.110, reward_mean=0.370, reward_bound=0.328, batch=223\n",
      "9569: loss=0.111, reward_mean=0.380, reward_bound=0.335, batch=226\n",
      "9570: loss=0.111, reward_mean=0.430, reward_bound=0.368, batch=228\n",
      "9571: loss=0.109, reward_mean=0.350, reward_bound=0.387, batch=222\n",
      "9572: loss=0.108, reward_mean=0.420, reward_bound=0.324, batch=225\n",
      "9573: loss=0.108, reward_mean=0.440, reward_bound=0.356, batch=227\n",
      "9574: loss=0.108, reward_mean=0.410, reward_bound=0.335, batch=229\n",
      "9575: loss=0.109, reward_mean=0.490, reward_bound=0.364, batch=230\n",
      "9576: loss=0.108, reward_mean=0.390, reward_bound=0.387, batch=230\n",
      "9577: loss=0.113, reward_mean=0.370, reward_bound=0.430, batch=127\n",
      "9578: loss=0.094, reward_mean=0.450, reward_bound=0.022, batch=159\n",
      "9579: loss=0.103, reward_mean=0.510, reward_bound=0.065, batch=180\n",
      "9580: loss=0.102, reward_mean=0.410, reward_bound=0.072, batch=195\n",
      "9581: loss=0.093, reward_mean=0.490, reward_bound=0.098, batch=204\n",
      "9582: loss=0.098, reward_mean=0.450, reward_bound=0.122, batch=211\n",
      "9583: loss=0.102, reward_mean=0.490, reward_bound=0.150, batch=206\n",
      "9584: loss=0.103, reward_mean=0.410, reward_bound=0.167, batch=208\n",
      "9585: loss=0.108, reward_mean=0.480, reward_bound=0.185, batch=213\n",
      "9586: loss=0.106, reward_mean=0.480, reward_bound=0.198, batch=219\n",
      "9587: loss=0.108, reward_mean=0.450, reward_bound=0.206, batch=217\n",
      "9588: loss=0.113, reward_mean=0.480, reward_bound=0.229, batch=208\n",
      "9589: loss=0.106, reward_mean=0.520, reward_bound=0.254, batch=206\n",
      "9590: loss=0.103, reward_mean=0.410, reward_bound=0.282, batch=202\n",
      "9591: loss=0.102, reward_mean=0.490, reward_bound=0.206, batch=212\n",
      "9592: loss=0.103, reward_mean=0.490, reward_bound=0.213, batch=218\n",
      "9593: loss=0.105, reward_mean=0.460, reward_bound=0.286, batch=222\n",
      "9594: loss=0.109, reward_mean=0.450, reward_bound=0.314, batch=200\n",
      "9595: loss=0.109, reward_mean=0.560, reward_bound=0.247, batch=210\n",
      "9596: loss=0.108, reward_mean=0.410, reward_bound=0.254, batch=216\n",
      "9597: loss=0.108, reward_mean=0.420, reward_bound=0.282, batch=215\n",
      "9598: loss=0.108, reward_mean=0.370, reward_bound=0.210, batch=220\n",
      "9599: loss=0.108, reward_mean=0.530, reward_bound=0.304, batch=224\n",
      "9600: loss=0.107, reward_mean=0.410, reward_bound=0.305, batch=227\n",
      "9601: loss=0.107, reward_mean=0.450, reward_bound=0.314, batch=225\n",
      "9602: loss=0.111, reward_mean=0.410, reward_bound=0.349, batch=200\n",
      "9603: loss=0.112, reward_mean=0.450, reward_bound=0.274, batch=210\n",
      "9604: loss=0.112, reward_mean=0.380, reward_bound=0.266, batch=217\n",
      "9605: loss=0.111, reward_mean=0.490, reward_bound=0.308, batch=222\n",
      "9606: loss=0.111, reward_mean=0.570, reward_bound=0.292, batch=225\n",
      "9607: loss=0.111, reward_mean=0.490, reward_bound=0.314, batch=224\n",
      "9608: loss=0.111, reward_mean=0.450, reward_bound=0.345, batch=227\n",
      "9609: loss=0.111, reward_mean=0.460, reward_bound=0.349, batch=220\n",
      "9610: loss=0.112, reward_mean=0.410, reward_bound=0.314, batch=223\n",
      "9611: loss=0.108, reward_mean=0.370, reward_bound=0.387, batch=194\n",
      "9612: loss=0.111, reward_mean=0.410, reward_bound=0.185, batch=205\n",
      "9613: loss=0.109, reward_mean=0.400, reward_bound=0.206, batch=209\n",
      "9614: loss=0.109, reward_mean=0.480, reward_bound=0.215, batch=216\n",
      "9615: loss=0.109, reward_mean=0.450, reward_bound=0.254, batch=220\n",
      "9616: loss=0.113, reward_mean=0.420, reward_bound=0.282, batch=221\n",
      "9617: loss=0.110, reward_mean=0.360, reward_bound=0.314, batch=220\n",
      "9618: loss=0.110, reward_mean=0.360, reward_bound=0.338, batch=224\n",
      "9619: loss=0.109, reward_mean=0.460, reward_bound=0.314, batch=226\n",
      "9620: loss=0.108, reward_mean=0.450, reward_bound=0.349, batch=219\n",
      "9621: loss=0.109, reward_mean=0.440, reward_bound=0.387, batch=211\n",
      "9622: loss=0.109, reward_mean=0.460, reward_bound=0.254, batch=216\n",
      "9623: loss=0.109, reward_mean=0.500, reward_bound=0.298, batch=221\n",
      "9624: loss=0.109, reward_mean=0.370, reward_bound=0.229, batch=223\n",
      "9625: loss=0.108, reward_mean=0.360, reward_bound=0.314, batch=222\n",
      "9626: loss=0.109, reward_mean=0.430, reward_bound=0.349, batch=221\n",
      "9627: loss=0.109, reward_mean=0.390, reward_bound=0.229, batch=224\n",
      "9628: loss=0.110, reward_mean=0.520, reward_bound=0.384, batch=227\n",
      "9629: loss=0.109, reward_mean=0.520, reward_bound=0.387, batch=225\n",
      "9630: loss=0.109, reward_mean=0.420, reward_bound=0.356, batch=227\n",
      "9631: loss=0.109, reward_mean=0.430, reward_bound=0.387, batch=228\n",
      "9632: loss=0.108, reward_mean=0.400, reward_bound=0.430, batch=185\n",
      "9633: loss=0.109, reward_mean=0.440, reward_bound=0.167, batch=197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9634: loss=0.111, reward_mean=0.450, reward_bound=0.206, batch=206\n",
      "9635: loss=0.110, reward_mean=0.510, reward_bound=0.229, batch=212\n",
      "9636: loss=0.112, reward_mean=0.400, reward_bound=0.254, batch=215\n",
      "9637: loss=0.111, reward_mean=0.470, reward_bound=0.260, batch=220\n",
      "9638: loss=0.111, reward_mean=0.470, reward_bound=0.282, batch=220\n",
      "9639: loss=0.111, reward_mean=0.520, reward_bound=0.314, batch=221\n",
      "9640: loss=0.113, reward_mean=0.530, reward_bound=0.282, batch=224\n",
      "9641: loss=0.112, reward_mean=0.460, reward_bound=0.314, batch=225\n",
      "9642: loss=0.107, reward_mean=0.420, reward_bound=0.349, batch=215\n",
      "9643: loss=0.107, reward_mean=0.500, reward_bound=0.234, batch=220\n",
      "9644: loss=0.107, reward_mean=0.440, reward_bound=0.338, batch=224\n",
      "9645: loss=0.108, reward_mean=0.430, reward_bound=0.349, batch=226\n",
      "9646: loss=0.108, reward_mean=0.480, reward_bound=0.387, batch=216\n",
      "9647: loss=0.109, reward_mean=0.440, reward_bound=0.351, batch=221\n",
      "9648: loss=0.109, reward_mean=0.490, reward_bound=0.349, batch=222\n",
      "9649: loss=0.109, reward_mean=0.520, reward_bound=0.387, batch=221\n",
      "9650: loss=0.109, reward_mean=0.440, reward_bound=0.387, batch=224\n",
      "9651: loss=0.108, reward_mean=0.470, reward_bound=0.426, batch=227\n",
      "9652: loss=0.109, reward_mean=0.470, reward_bound=0.373, batch=229\n",
      "9653: loss=0.109, reward_mean=0.420, reward_bound=0.364, batch=230\n",
      "9654: loss=0.107, reward_mean=0.420, reward_bound=0.430, batch=206\n",
      "9655: loss=0.106, reward_mean=0.490, reward_bound=0.196, batch=214\n",
      "9656: loss=0.109, reward_mean=0.400, reward_bound=0.226, batch=220\n",
      "9657: loss=0.109, reward_mean=0.560, reward_bound=0.247, batch=224\n",
      "9658: loss=0.109, reward_mean=0.450, reward_bound=0.254, batch=223\n",
      "9659: loss=0.111, reward_mean=0.520, reward_bound=0.314, batch=224\n",
      "9660: loss=0.111, reward_mean=0.440, reward_bound=0.349, batch=220\n",
      "9661: loss=0.110, reward_mean=0.480, reward_bound=0.387, batch=221\n",
      "9662: loss=0.110, reward_mean=0.510, reward_bound=0.349, batch=224\n",
      "9663: loss=0.110, reward_mean=0.400, reward_bound=0.345, batch=227\n",
      "9664: loss=0.110, reward_mean=0.450, reward_bound=0.349, batch=228\n",
      "9665: loss=0.108, reward_mean=0.440, reward_bound=0.430, batch=216\n",
      "9666: loss=0.109, reward_mean=0.370, reward_bound=0.308, batch=221\n",
      "9667: loss=0.108, reward_mean=0.460, reward_bound=0.314, batch=224\n",
      "9668: loss=0.108, reward_mean=0.470, reward_bound=0.384, batch=227\n",
      "9669: loss=0.108, reward_mean=0.420, reward_bound=0.387, batch=226\n",
      "9670: loss=0.108, reward_mean=0.470, reward_bound=0.387, batch=227\n",
      "9671: loss=0.109, reward_mean=0.470, reward_bound=0.422, batch=229\n",
      "9672: loss=0.109, reward_mean=0.510, reward_bound=0.405, batch=230\n",
      "9673: loss=0.109, reward_mean=0.440, reward_bound=0.406, batch=231\n",
      "9674: loss=0.109, reward_mean=0.390, reward_bound=0.387, batch=231\n",
      "9675: loss=0.107, reward_mean=0.470, reward_bound=0.430, batch=221\n",
      "9676: loss=0.109, reward_mean=0.450, reward_bound=0.282, batch=224\n",
      "9677: loss=0.109, reward_mean=0.470, reward_bound=0.384, batch=227\n",
      "9678: loss=0.108, reward_mean=0.460, reward_bound=0.387, batch=228\n",
      "9679: loss=0.108, reward_mean=0.440, reward_bound=0.357, batch=229\n",
      "9680: loss=0.107, reward_mean=0.460, reward_bound=0.430, batch=227\n",
      "9681: loss=0.108, reward_mean=0.500, reward_bound=0.380, batch=229\n",
      "9682: loss=0.107, reward_mean=0.560, reward_bound=0.405, batch=230\n",
      "9683: loss=0.107, reward_mean=0.540, reward_bound=0.464, batch=231\n",
      "9684: loss=0.094, reward_mean=0.560, reward_bound=0.478, batch=89\n",
      "9685: loss=0.106, reward_mean=0.490, reward_bound=0.022, batch=132\n",
      "9686: loss=0.099, reward_mean=0.500, reward_bound=0.031, batch=161\n",
      "9687: loss=0.103, reward_mean=0.430, reward_bound=0.042, batch=179\n",
      "9688: loss=0.105, reward_mean=0.470, reward_bound=0.058, batch=192\n",
      "9689: loss=0.103, reward_mean=0.390, reward_bound=0.080, batch=199\n",
      "9690: loss=0.107, reward_mean=0.480, reward_bound=0.109, batch=201\n",
      "9691: loss=0.109, reward_mean=0.560, reward_bound=0.135, batch=202\n",
      "9692: loss=0.109, reward_mean=0.350, reward_bound=0.150, batch=208\n",
      "9693: loss=0.112, reward_mean=0.390, reward_bound=0.167, batch=208\n",
      "9694: loss=0.114, reward_mean=0.470, reward_bound=0.185, batch=202\n",
      "9695: loss=0.117, reward_mean=0.450, reward_bound=0.206, batch=219\n",
      "9696: loss=0.117, reward_mean=0.520, reward_bound=0.206, batch=216\n",
      "9697: loss=0.115, reward_mean=0.450, reward_bound=0.229, batch=207\n",
      "9698: loss=0.116, reward_mean=0.470, reward_bound=0.254, batch=193\n",
      "9699: loss=0.115, reward_mean=0.440, reward_bound=0.244, batch=205\n",
      "9700: loss=0.113, reward_mean=0.400, reward_bound=0.229, batch=212\n",
      "9701: loss=0.111, reward_mean=0.460, reward_bound=0.254, batch=215\n",
      "9702: loss=0.105, reward_mean=0.410, reward_bound=0.282, batch=198\n",
      "9703: loss=0.103, reward_mean=0.450, reward_bound=0.282, batch=207\n",
      "9704: loss=0.104, reward_mean=0.410, reward_bound=0.302, batch=215\n",
      "9705: loss=0.101, reward_mean=0.510, reward_bound=0.314, batch=193\n",
      "9706: loss=0.100, reward_mean=0.490, reward_bound=0.206, batch=204\n",
      "9707: loss=0.099, reward_mean=0.540, reward_bound=0.252, batch=213\n",
      "9708: loss=0.097, reward_mean=0.390, reward_bound=0.271, batch=219\n",
      "9709: loss=0.100, reward_mean=0.420, reward_bound=0.314, batch=215\n",
      "9710: loss=0.097, reward_mean=0.490, reward_bound=0.349, batch=182\n",
      "9711: loss=0.094, reward_mean=0.450, reward_bound=0.140, batch=197\n",
      "9712: loss=0.099, reward_mean=0.480, reward_bound=0.167, batch=207\n",
      "9713: loss=0.097, reward_mean=0.510, reward_bound=0.185, batch=214\n",
      "9714: loss=0.096, reward_mean=0.400, reward_bound=0.229, batch=218\n",
      "9715: loss=0.095, reward_mean=0.450, reward_bound=0.257, batch=222\n",
      "9716: loss=0.096, reward_mean=0.420, reward_bound=0.282, batch=217\n",
      "9717: loss=0.097, reward_mean=0.430, reward_bound=0.314, batch=214\n",
      "9718: loss=0.098, reward_mean=0.460, reward_bound=0.314, batch=217\n",
      "9719: loss=0.099, reward_mean=0.460, reward_bound=0.229, batch=221\n",
      "9720: loss=0.099, reward_mean=0.450, reward_bound=0.349, batch=215\n",
      "9721: loss=0.100, reward_mean=0.480, reward_bound=0.349, batch=219\n",
      "9722: loss=0.099, reward_mean=0.470, reward_bound=0.349, batch=222\n",
      "9723: loss=0.094, reward_mean=0.480, reward_bound=0.387, batch=166\n",
      "9724: loss=0.095, reward_mean=0.440, reward_bound=0.115, batch=186\n",
      "9725: loss=0.095, reward_mean=0.440, reward_bound=0.104, batch=200\n",
      "9726: loss=0.096, reward_mean=0.460, reward_bound=0.135, batch=207\n",
      "9727: loss=0.094, reward_mean=0.580, reward_bound=0.185, batch=214\n",
      "9728: loss=0.096, reward_mean=0.430, reward_bound=0.226, batch=220\n",
      "9729: loss=0.095, reward_mean=0.420, reward_bound=0.216, batch=224\n",
      "9730: loss=0.092, reward_mean=0.380, reward_bound=0.229, batch=225\n",
      "9731: loss=0.095, reward_mean=0.390, reward_bound=0.254, batch=219\n",
      "9732: loss=0.097, reward_mean=0.450, reward_bound=0.282, batch=212\n",
      "9733: loss=0.096, reward_mean=0.410, reward_bound=0.263, batch=218\n",
      "9734: loss=0.097, reward_mean=0.370, reward_bound=0.314, batch=207\n",
      "9735: loss=0.095, reward_mean=0.400, reward_bound=0.314, batch=213\n",
      "9736: loss=0.096, reward_mean=0.350, reward_bound=0.220, batch=219\n",
      "9737: loss=0.098, reward_mean=0.490, reward_bound=0.314, batch=221\n",
      "9738: loss=0.099, reward_mean=0.320, reward_bound=0.349, batch=210\n",
      "9739: loss=0.099, reward_mean=0.510, reward_bound=0.185, batch=216\n",
      "9740: loss=0.100, reward_mean=0.390, reward_bound=0.230, batch=221\n",
      "9741: loss=0.100, reward_mean=0.300, reward_bound=0.282, batch=224\n",
      "9742: loss=0.101, reward_mean=0.430, reward_bound=0.314, batch=226\n",
      "9743: loss=0.100, reward_mean=0.350, reward_bound=0.349, batch=225\n",
      "9744: loss=0.095, reward_mean=0.390, reward_bound=0.387, batch=206\n",
      "9745: loss=0.093, reward_mean=0.400, reward_bound=0.229, batch=213\n",
      "9746: loss=0.093, reward_mean=0.440, reward_bound=0.290, batch=219\n",
      "9747: loss=0.093, reward_mean=0.410, reward_bound=0.265, batch=223\n",
      "9748: loss=0.095, reward_mean=0.420, reward_bound=0.314, batch=223\n",
      "9749: loss=0.095, reward_mean=0.510, reward_bound=0.349, batch=223\n",
      "9750: loss=0.096, reward_mean=0.480, reward_bound=0.335, batch=226\n",
      "9751: loss=0.099, reward_mean=0.420, reward_bound=0.368, batch=228\n",
      "9752: loss=0.097, reward_mean=0.330, reward_bound=0.387, batch=217\n",
      "9753: loss=0.095, reward_mean=0.420, reward_bound=0.282, batch=221\n",
      "9754: loss=0.096, reward_mean=0.510, reward_bound=0.314, batch=224\n",
      "9755: loss=0.096, reward_mean=0.460, reward_bound=0.282, batch=225\n",
      "9756: loss=0.097, reward_mean=0.470, reward_bound=0.349, batch=226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9757: loss=0.095, reward_mean=0.430, reward_bound=0.387, batch=226\n",
      "9758: loss=0.095, reward_mean=0.480, reward_bound=0.351, batch=228\n",
      "9759: loss=0.096, reward_mean=0.480, reward_bound=0.387, batch=228\n",
      "9760: loss=0.095, reward_mean=0.380, reward_bound=0.325, batch=229\n",
      "9761: loss=0.095, reward_mean=0.400, reward_bound=0.309, batch=230\n",
      "9762: loss=0.095, reward_mean=0.470, reward_bound=0.418, batch=231\n",
      "9763: loss=0.095, reward_mean=0.450, reward_bound=0.387, batch=231\n",
      "9764: loss=0.095, reward_mean=0.420, reward_bound=0.387, batch=231\n",
      "9765: loss=0.101, reward_mean=0.460, reward_bound=0.430, batch=169\n",
      "9766: loss=0.096, reward_mean=0.380, reward_bound=0.049, batch=188\n",
      "9767: loss=0.098, reward_mean=0.390, reward_bound=0.080, batch=200\n",
      "9768: loss=0.096, reward_mean=0.440, reward_bound=0.122, batch=207\n",
      "9769: loss=0.094, reward_mean=0.490, reward_bound=0.147, batch=215\n",
      "9770: loss=0.097, reward_mean=0.460, reward_bound=0.167, batch=218\n",
      "9771: loss=0.095, reward_mean=0.500, reward_bound=0.185, batch=218\n",
      "9772: loss=0.097, reward_mean=0.490, reward_bound=0.229, batch=219\n",
      "9773: loss=0.098, reward_mean=0.410, reward_bound=0.282, batch=209\n",
      "9774: loss=0.101, reward_mean=0.520, reward_bound=0.295, batch=216\n",
      "9775: loss=0.104, reward_mean=0.450, reward_bound=0.314, batch=216\n",
      "9776: loss=0.104, reward_mean=0.420, reward_bound=0.314, batch=220\n",
      "9777: loss=0.099, reward_mean=0.470, reward_bound=0.349, batch=208\n",
      "9778: loss=0.099, reward_mean=0.470, reward_bound=0.254, batch=212\n",
      "9779: loss=0.098, reward_mean=0.470, reward_bound=0.263, batch=218\n",
      "9780: loss=0.098, reward_mean=0.450, reward_bound=0.286, batch=222\n",
      "9781: loss=0.099, reward_mean=0.410, reward_bound=0.292, batch=225\n",
      "9782: loss=0.101, reward_mean=0.490, reward_bound=0.349, batch=222\n",
      "9783: loss=0.101, reward_mean=0.460, reward_bound=0.349, batch=224\n",
      "9784: loss=0.102, reward_mean=0.450, reward_bound=0.387, batch=206\n",
      "9785: loss=0.100, reward_mean=0.500, reward_bound=0.256, batch=214\n",
      "9786: loss=0.102, reward_mean=0.470, reward_bound=0.282, batch=218\n",
      "9787: loss=0.101, reward_mean=0.480, reward_bound=0.314, batch=218\n",
      "9788: loss=0.102, reward_mean=0.470, reward_bound=0.392, batch=222\n",
      "9789: loss=0.103, reward_mean=0.420, reward_bound=0.282, batch=224\n",
      "9790: loss=0.102, reward_mean=0.460, reward_bound=0.387, batch=226\n",
      "9791: loss=0.102, reward_mean=0.510, reward_bound=0.430, batch=200\n",
      "9792: loss=0.103, reward_mean=0.430, reward_bound=0.185, batch=209\n",
      "9793: loss=0.103, reward_mean=0.440, reward_bound=0.229, batch=214\n",
      "9794: loss=0.102, reward_mean=0.420, reward_bound=0.252, batch=220\n",
      "9795: loss=0.101, reward_mean=0.490, reward_bound=0.254, batch=221\n",
      "9796: loss=0.102, reward_mean=0.430, reward_bound=0.314, batch=221\n",
      "9797: loss=0.102, reward_mean=0.370, reward_bound=0.314, batch=224\n",
      "9798: loss=0.102, reward_mean=0.480, reward_bound=0.349, batch=222\n",
      "9799: loss=0.105, reward_mean=0.470, reward_bound=0.387, batch=213\n",
      "9800: loss=0.104, reward_mean=0.460, reward_bound=0.301, batch=219\n",
      "9801: loss=0.105, reward_mean=0.460, reward_bound=0.282, batch=222\n",
      "9802: loss=0.107, reward_mean=0.440, reward_bound=0.314, batch=224\n",
      "9803: loss=0.109, reward_mean=0.530, reward_bound=0.314, batch=226\n",
      "9804: loss=0.106, reward_mean=0.530, reward_bound=0.349, batch=224\n",
      "9805: loss=0.108, reward_mean=0.450, reward_bound=0.342, batch=227\n",
      "9806: loss=0.106, reward_mean=0.450, reward_bound=0.349, batch=228\n",
      "9807: loss=0.107, reward_mean=0.540, reward_bound=0.387, batch=227\n",
      "9808: loss=0.106, reward_mean=0.440, reward_bound=0.430, batch=223\n",
      "9809: loss=0.106, reward_mean=0.480, reward_bound=0.301, batch=226\n",
      "9810: loss=0.108, reward_mean=0.400, reward_bound=0.298, batch=228\n",
      "9811: loss=0.107, reward_mean=0.500, reward_bound=0.349, batch=228\n",
      "9812: loss=0.107, reward_mean=0.400, reward_bound=0.387, batch=228\n",
      "9813: loss=0.106, reward_mean=0.520, reward_bound=0.430, batch=226\n",
      "9814: loss=0.106, reward_mean=0.390, reward_bound=0.349, batch=227\n",
      "9815: loss=0.107, reward_mean=0.390, reward_bound=0.380, batch=229\n",
      "9816: loss=0.107, reward_mean=0.340, reward_bound=0.282, batch=229\n",
      "9817: loss=0.106, reward_mean=0.470, reward_bound=0.405, batch=230\n",
      "9818: loss=0.106, reward_mean=0.400, reward_bound=0.430, batch=230\n",
      "9819: loss=0.106, reward_mean=0.540, reward_bound=0.418, batch=231\n",
      "9820: loss=0.106, reward_mean=0.370, reward_bound=0.430, batch=231\n",
      "9821: loss=0.104, reward_mean=0.450, reward_bound=0.478, batch=134\n",
      "9822: loss=0.094, reward_mean=0.500, reward_bound=0.065, batch=163\n",
      "9823: loss=0.093, reward_mean=0.480, reward_bound=0.072, batch=183\n",
      "9824: loss=0.098, reward_mean=0.460, reward_bound=0.077, batch=198\n",
      "9825: loss=0.104, reward_mean=0.480, reward_bound=0.109, batch=203\n",
      "9826: loss=0.107, reward_mean=0.420, reward_bound=0.135, batch=210\n",
      "9827: loss=0.106, reward_mean=0.460, reward_bound=0.150, batch=215\n",
      "9828: loss=0.106, reward_mean=0.430, reward_bound=0.185, batch=211\n",
      "9829: loss=0.112, reward_mean=0.410, reward_bound=0.206, batch=208\n",
      "9830: loss=0.111, reward_mean=0.450, reward_bound=0.169, batch=215\n",
      "9831: loss=0.112, reward_mean=0.360, reward_bound=0.206, batch=217\n",
      "9832: loss=0.111, reward_mean=0.440, reward_bound=0.185, batch=221\n",
      "9833: loss=0.111, reward_mean=0.400, reward_bound=0.229, batch=218\n",
      "9834: loss=0.112, reward_mean=0.420, reward_bound=0.254, batch=211\n",
      "9835: loss=0.111, reward_mean=0.420, reward_bound=0.229, batch=216\n",
      "9836: loss=0.112, reward_mean=0.380, reward_bound=0.254, batch=220\n",
      "9837: loss=0.109, reward_mean=0.530, reward_bound=0.282, batch=200\n",
      "9838: loss=0.108, reward_mean=0.420, reward_bound=0.229, batch=209\n",
      "9839: loss=0.107, reward_mean=0.510, reward_bound=0.265, batch=216\n",
      "9840: loss=0.107, reward_mean=0.450, reward_bound=0.282, batch=219\n",
      "9841: loss=0.107, reward_mean=0.440, reward_bound=0.282, batch=222\n",
      "9842: loss=0.108, reward_mean=0.450, reward_bound=0.314, batch=206\n",
      "9843: loss=0.107, reward_mean=0.470, reward_bound=0.196, batch=214\n",
      "9844: loss=0.105, reward_mean=0.470, reward_bound=0.280, batch=220\n",
      "9845: loss=0.106, reward_mean=0.500, reward_bound=0.282, batch=222\n",
      "9846: loss=0.101, reward_mean=0.450, reward_bound=0.349, batch=197\n",
      "9847: loss=0.101, reward_mean=0.350, reward_bound=0.185, batch=207\n",
      "9848: loss=0.103, reward_mean=0.420, reward_bound=0.224, batch=215\n",
      "9849: loss=0.103, reward_mean=0.440, reward_bound=0.229, batch=214\n",
      "9850: loss=0.102, reward_mean=0.360, reward_bound=0.229, batch=218\n",
      "9851: loss=0.099, reward_mean=0.470, reward_bound=0.257, batch=222\n",
      "9852: loss=0.098, reward_mean=0.410, reward_bound=0.292, batch=225\n",
      "9853: loss=0.097, reward_mean=0.480, reward_bound=0.289, batch=227\n",
      "9854: loss=0.100, reward_mean=0.480, reward_bound=0.314, batch=225\n",
      "9855: loss=0.101, reward_mean=0.390, reward_bound=0.349, batch=218\n",
      "9856: loss=0.102, reward_mean=0.530, reward_bound=0.387, batch=193\n",
      "9857: loss=0.102, reward_mean=0.450, reward_bound=0.206, batch=203\n",
      "9858: loss=0.102, reward_mean=0.420, reward_bound=0.220, batch=212\n",
      "9859: loss=0.108, reward_mean=0.450, reward_bound=0.254, batch=216\n",
      "9860: loss=0.105, reward_mean=0.400, reward_bound=0.282, batch=216\n",
      "9861: loss=0.105, reward_mean=0.470, reward_bound=0.298, batch=221\n",
      "9862: loss=0.103, reward_mean=0.390, reward_bound=0.314, batch=216\n",
      "9863: loss=0.104, reward_mean=0.330, reward_bound=0.301, batch=221\n",
      "9864: loss=0.103, reward_mean=0.530, reward_bound=0.349, batch=210\n",
      "9865: loss=0.104, reward_mean=0.340, reward_bound=0.206, batch=219\n",
      "9866: loss=0.103, reward_mean=0.450, reward_bound=0.215, batch=223\n",
      "9867: loss=0.105, reward_mean=0.420, reward_bound=0.282, batch=223\n",
      "9868: loss=0.105, reward_mean=0.490, reward_bound=0.372, batch=226\n",
      "9869: loss=0.106, reward_mean=0.430, reward_bound=0.387, batch=214\n",
      "9870: loss=0.107, reward_mean=0.410, reward_bound=0.280, batch=220\n",
      "9871: loss=0.105, reward_mean=0.410, reward_bound=0.282, batch=223\n",
      "9872: loss=0.105, reward_mean=0.590, reward_bound=0.349, batch=222\n",
      "9873: loss=0.104, reward_mean=0.470, reward_bound=0.324, batch=225\n",
      "9874: loss=0.104, reward_mean=0.470, reward_bound=0.349, batch=225\n",
      "9875: loss=0.105, reward_mean=0.420, reward_bound=0.387, batch=221\n",
      "9876: loss=0.106, reward_mean=0.410, reward_bound=0.349, batch=223\n",
      "9877: loss=0.105, reward_mean=0.510, reward_bound=0.314, batch=225\n",
      "9878: loss=0.105, reward_mean=0.520, reward_bound=0.356, batch=227\n",
      "9879: loss=0.106, reward_mean=0.430, reward_bound=0.380, batch=229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9880: loss=0.105, reward_mean=0.420, reward_bound=0.387, batch=229\n",
      "9881: loss=0.106, reward_mean=0.530, reward_bound=0.430, batch=192\n",
      "9882: loss=0.105, reward_mean=0.500, reward_bound=0.167, batch=203\n",
      "9883: loss=0.105, reward_mean=0.530, reward_bound=0.198, batch=212\n",
      "9884: loss=0.108, reward_mean=0.500, reward_bound=0.254, batch=215\n",
      "9885: loss=0.107, reward_mean=0.420, reward_bound=0.282, batch=213\n",
      "9886: loss=0.106, reward_mean=0.480, reward_bound=0.314, batch=214\n",
      "9887: loss=0.105, reward_mean=0.400, reward_bound=0.183, batch=220\n",
      "9888: loss=0.105, reward_mean=0.510, reward_bound=0.314, batch=223\n",
      "9889: loss=0.107, reward_mean=0.460, reward_bound=0.349, batch=215\n",
      "9890: loss=0.107, reward_mean=0.500, reward_bound=0.356, batch=220\n",
      "9891: loss=0.113, reward_mean=0.420, reward_bound=0.365, batch=224\n",
      "9892: loss=0.107, reward_mean=0.480, reward_bound=0.387, batch=213\n",
      "9893: loss=0.105, reward_mean=0.530, reward_bound=0.290, batch=219\n",
      "9894: loss=0.105, reward_mean=0.450, reward_bound=0.295, batch=223\n",
      "9895: loss=0.108, reward_mean=0.430, reward_bound=0.349, batch=220\n",
      "9896: loss=0.108, reward_mean=0.510, reward_bound=0.349, batch=223\n",
      "9897: loss=0.108, reward_mean=0.460, reward_bound=0.358, batch=226\n",
      "9898: loss=0.107, reward_mean=0.460, reward_bound=0.298, batch=228\n",
      "9899: loss=0.107, reward_mean=0.400, reward_bound=0.317, batch=229\n",
      "9900: loss=0.107, reward_mean=0.370, reward_bound=0.364, batch=230\n",
      "9901: loss=0.107, reward_mean=0.510, reward_bound=0.387, batch=229\n",
      "9902: loss=0.107, reward_mean=0.430, reward_bound=0.430, batch=213\n",
      "9903: loss=0.106, reward_mean=0.450, reward_bound=0.206, batch=218\n",
      "9904: loss=0.107, reward_mean=0.570, reward_bound=0.314, batch=220\n",
      "9905: loss=0.107, reward_mean=0.480, reward_bound=0.281, batch=224\n",
      "9906: loss=0.108, reward_mean=0.460, reward_bound=0.311, batch=227\n",
      "9907: loss=0.106, reward_mean=0.450, reward_bound=0.349, batch=225\n",
      "9908: loss=0.108, reward_mean=0.510, reward_bound=0.387, batch=223\n",
      "9909: loss=0.108, reward_mean=0.380, reward_bound=0.314, batch=225\n",
      "9910: loss=0.107, reward_mean=0.510, reward_bound=0.349, batch=226\n",
      "9911: loss=0.109, reward_mean=0.400, reward_bound=0.387, batch=227\n",
      "9912: loss=0.108, reward_mean=0.350, reward_bound=0.342, batch=229\n",
      "9913: loss=0.108, reward_mean=0.490, reward_bound=0.387, batch=228\n",
      "9914: loss=0.109, reward_mean=0.560, reward_bound=0.392, batch=229\n",
      "9915: loss=0.106, reward_mean=0.470, reward_bound=0.430, batch=226\n",
      "9916: loss=0.107, reward_mean=0.440, reward_bound=0.372, batch=228\n",
      "9917: loss=0.107, reward_mean=0.480, reward_bound=0.387, batch=228\n",
      "9918: loss=0.106, reward_mean=0.470, reward_bound=0.317, batch=229\n",
      "9919: loss=0.107, reward_mean=0.430, reward_bound=0.430, batch=228\n",
      "9920: loss=0.106, reward_mean=0.440, reward_bound=0.478, batch=230\n",
      "9921: loss=0.106, reward_mean=0.440, reward_bound=0.376, batch=231\n",
      "9922: loss=0.103, reward_mean=0.440, reward_bound=0.478, batch=180\n",
      "9923: loss=0.101, reward_mean=0.470, reward_bound=0.118, batch=196\n",
      "9924: loss=0.103, reward_mean=0.420, reward_bound=0.176, batch=207\n",
      "9925: loss=0.099, reward_mean=0.490, reward_bound=0.206, batch=214\n",
      "9926: loss=0.096, reward_mean=0.460, reward_bound=0.229, batch=219\n",
      "9927: loss=0.100, reward_mean=0.410, reward_bound=0.254, batch=220\n",
      "9928: loss=0.100, reward_mean=0.480, reward_bound=0.282, batch=216\n",
      "9929: loss=0.103, reward_mean=0.500, reward_bound=0.314, batch=210\n",
      "9930: loss=0.105, reward_mean=0.330, reward_bound=0.247, batch=217\n",
      "9931: loss=0.104, reward_mean=0.500, reward_bound=0.349, batch=220\n",
      "9932: loss=0.104, reward_mean=0.420, reward_bound=0.282, batch=222\n",
      "9933: loss=0.105, reward_mean=0.430, reward_bound=0.282, batch=224\n",
      "9934: loss=0.104, reward_mean=0.440, reward_bound=0.349, batch=225\n",
      "9935: loss=0.101, reward_mean=0.460, reward_bound=0.387, batch=209\n",
      "9936: loss=0.101, reward_mean=0.540, reward_bound=0.282, batch=215\n",
      "9937: loss=0.103, reward_mean=0.490, reward_bound=0.296, batch=220\n",
      "9938: loss=0.104, reward_mean=0.500, reward_bound=0.376, batch=224\n",
      "9939: loss=0.102, reward_mean=0.520, reward_bound=0.345, batch=227\n",
      "9940: loss=0.102, reward_mean=0.360, reward_bound=0.387, batch=221\n",
      "9941: loss=0.101, reward_mean=0.510, reward_bound=0.349, batch=224\n",
      "9942: loss=0.101, reward_mean=0.430, reward_bound=0.349, batch=226\n",
      "9943: loss=0.101, reward_mean=0.420, reward_bound=0.368, batch=228\n",
      "9944: loss=0.101, reward_mean=0.460, reward_bound=0.387, batch=226\n",
      "9945: loss=0.101, reward_mean=0.450, reward_bound=0.409, batch=228\n",
      "9946: loss=0.101, reward_mean=0.490, reward_bound=0.387, batch=228\n",
      "9947: loss=0.101, reward_mean=0.430, reward_bound=0.353, batch=229\n",
      "9948: loss=0.102, reward_mean=0.460, reward_bound=0.405, batch=230\n",
      "9949: loss=0.102, reward_mean=0.450, reward_bound=0.430, batch=205\n",
      "9950: loss=0.106, reward_mean=0.410, reward_bound=0.189, batch=213\n",
      "9951: loss=0.108, reward_mean=0.440, reward_bound=0.271, batch=219\n",
      "9952: loss=0.108, reward_mean=0.370, reward_bound=0.237, batch=223\n",
      "9953: loss=0.104, reward_mean=0.480, reward_bound=0.282, batch=224\n",
      "9954: loss=0.107, reward_mean=0.490, reward_bound=0.349, batch=221\n",
      "9955: loss=0.105, reward_mean=0.420, reward_bound=0.387, batch=215\n",
      "9956: loss=0.105, reward_mean=0.430, reward_bound=0.296, batch=220\n",
      "9957: loss=0.104, reward_mean=0.350, reward_bound=0.254, batch=223\n",
      "9958: loss=0.105, reward_mean=0.380, reward_bound=0.282, batch=225\n",
      "9959: loss=0.104, reward_mean=0.460, reward_bound=0.349, batch=226\n",
      "9960: loss=0.104, reward_mean=0.410, reward_bound=0.321, batch=228\n",
      "9961: loss=0.105, reward_mean=0.490, reward_bound=0.353, batch=229\n",
      "9962: loss=0.104, reward_mean=0.440, reward_bound=0.387, batch=227\n",
      "9963: loss=0.104, reward_mean=0.430, reward_bound=0.282, batch=228\n",
      "9964: loss=0.104, reward_mean=0.450, reward_bound=0.325, batch=229\n",
      "9965: loss=0.105, reward_mean=0.460, reward_bound=0.405, batch=230\n",
      "9966: loss=0.103, reward_mean=0.440, reward_bound=0.430, batch=223\n",
      "9967: loss=0.103, reward_mean=0.510, reward_bound=0.314, batch=225\n",
      "9968: loss=0.105, reward_mean=0.410, reward_bound=0.329, batch=227\n",
      "9969: loss=0.103, reward_mean=0.430, reward_bound=0.387, batch=228\n",
      "9970: loss=0.104, reward_mean=0.360, reward_bound=0.430, batch=225\n",
      "9971: loss=0.103, reward_mean=0.480, reward_bound=0.356, batch=227\n",
      "9972: loss=0.106, reward_mean=0.450, reward_bound=0.422, batch=229\n",
      "9973: loss=0.104, reward_mean=0.490, reward_bound=0.430, batch=229\n",
      "9974: loss=0.104, reward_mean=0.310, reward_bound=0.424, batch=230\n",
      "9975: loss=0.104, reward_mean=0.460, reward_bound=0.314, batch=230\n",
      "9976: loss=0.104, reward_mean=0.410, reward_bound=0.430, batch=230\n",
      "9977: loss=0.105, reward_mean=0.480, reward_bound=0.478, batch=198\n",
      "9978: loss=0.106, reward_mean=0.480, reward_bound=0.206, batch=207\n",
      "9979: loss=0.105, reward_mean=0.510, reward_bound=0.206, batch=214\n",
      "9980: loss=0.106, reward_mean=0.420, reward_bound=0.252, batch=220\n",
      "9981: loss=0.106, reward_mean=0.430, reward_bound=0.254, batch=223\n",
      "9982: loss=0.102, reward_mean=0.440, reward_bound=0.314, batch=221\n",
      "9983: loss=0.103, reward_mean=0.400, reward_bound=0.254, batch=223\n",
      "9984: loss=0.103, reward_mean=0.490, reward_bound=0.335, batch=226\n",
      "9985: loss=0.103, reward_mean=0.350, reward_bound=0.349, batch=225\n",
      "9986: loss=0.105, reward_mean=0.440, reward_bound=0.387, batch=215\n",
      "9987: loss=0.106, reward_mean=0.430, reward_bound=0.365, batch=220\n",
      "9988: loss=0.107, reward_mean=0.450, reward_bound=0.365, batch=224\n",
      "9989: loss=0.106, reward_mean=0.380, reward_bound=0.387, batch=226\n",
      "9990: loss=0.106, reward_mean=0.540, reward_bound=0.409, batch=228\n",
      "9991: loss=0.107, reward_mean=0.420, reward_bound=0.392, batch=229\n",
      "9992: loss=0.107, reward_mean=0.430, reward_bound=0.381, batch=230\n",
      "9993: loss=0.108, reward_mean=0.450, reward_bound=0.430, batch=220\n",
      "9994: loss=0.107, reward_mean=0.410, reward_bound=0.365, batch=224\n",
      "9995: loss=0.108, reward_mean=0.460, reward_bound=0.387, batch=226\n",
      "9996: loss=0.108, reward_mean=0.410, reward_bound=0.331, batch=228\n",
      "9997: loss=0.109, reward_mean=0.440, reward_bound=0.392, batch=229\n",
      "9998: loss=0.109, reward_mean=0.540, reward_bound=0.349, batch=229\n",
      "9999: loss=0.109, reward_mean=0.520, reward_bound=0.450, batch=230\n",
      "10000: loss=0.109, reward_mean=0.420, reward_bound=0.451, batch=231\n",
      "10001: loss=0.109, reward_mean=0.400, reward_bound=0.430, batch=231\n",
      "10002: loss=0.109, reward_mean=0.490, reward_bound=0.430, batch=231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10003: loss=0.107, reward_mean=0.440, reward_bound=0.478, batch=216\n",
      "10004: loss=0.106, reward_mean=0.420, reward_bound=0.284, batch=221\n",
      "10005: loss=0.106, reward_mean=0.330, reward_bound=0.314, batch=224\n",
      "10006: loss=0.108, reward_mean=0.460, reward_bound=0.311, batch=227\n",
      "10007: loss=0.107, reward_mean=0.420, reward_bound=0.342, batch=229\n",
      "10008: loss=0.106, reward_mean=0.480, reward_bound=0.349, batch=227\n",
      "10009: loss=0.107, reward_mean=0.520, reward_bound=0.387, batch=226\n",
      "10010: loss=0.107, reward_mean=0.390, reward_bound=0.430, batch=224\n",
      "10011: loss=0.106, reward_mean=0.350, reward_bound=0.345, batch=227\n",
      "10012: loss=0.108, reward_mean=0.450, reward_bound=0.387, batch=226\n",
      "10013: loss=0.108, reward_mean=0.450, reward_bound=0.430, batch=227\n",
      "10014: loss=0.108, reward_mean=0.460, reward_bound=0.478, batch=225\n",
      "10015: loss=0.109, reward_mean=0.410, reward_bound=0.440, batch=227\n",
      "10016: loss=0.109, reward_mean=0.390, reward_bound=0.460, batch=229\n",
      "10017: loss=0.109, reward_mean=0.430, reward_bound=0.478, batch=231\n",
      "10018: loss=0.108, reward_mean=0.360, reward_bound=0.478, batch=226\n",
      "10019: loss=0.108, reward_mean=0.420, reward_bound=0.387, batch=227\n",
      "10020: loss=0.109, reward_mean=0.400, reward_bound=0.430, batch=228\n",
      "10021: loss=0.109, reward_mean=0.410, reward_bound=0.478, batch=230\n",
      "10022: loss=0.109, reward_mean=0.510, reward_bound=0.478, batch=228\n",
      "10023: loss=0.109, reward_mean=0.460, reward_bound=0.349, batch=228\n",
      "10024: loss=0.108, reward_mean=0.430, reward_bound=0.392, batch=229\n",
      "10025: loss=0.109, reward_mean=0.450, reward_bound=0.381, batch=230\n",
      "10026: loss=0.110, reward_mean=0.430, reward_bound=0.464, batch=231\n",
      "10027: loss=0.108, reward_mean=0.540, reward_bound=0.478, batch=231\n",
      "10028: loss=0.108, reward_mean=0.480, reward_bound=0.478, batch=231\n",
      "10030: loss=0.098, reward_mean=0.440, reward_bound=0.000, batch=44\n",
      "10031: loss=0.096, reward_mean=0.450, reward_bound=0.000, batch=89\n",
      "10032: loss=0.095, reward_mean=0.390, reward_bound=0.000, batch=128\n",
      "10033: loss=0.095, reward_mean=0.340, reward_bound=0.000, batch=159\n",
      "10034: loss=0.095, reward_mean=0.400, reward_bound=0.005, batch=179\n",
      "10035: loss=0.096, reward_mean=0.460, reward_bound=0.015, batch=196\n",
      "10036: loss=0.100, reward_mean=0.460, reward_bound=0.031, batch=203\n",
      "10037: loss=0.094, reward_mean=0.480, reward_bound=0.052, batch=209\n",
      "10038: loss=0.101, reward_mean=0.440, reward_bound=0.072, batch=213\n",
      "10039: loss=0.104, reward_mean=0.320, reward_bound=0.080, batch=218\n",
      "10040: loss=0.106, reward_mean=0.490, reward_bound=0.089, batch=221\n",
      "10041: loss=0.106, reward_mean=0.460, reward_bound=0.109, batch=206\n",
      "10042: loss=0.110, reward_mean=0.480, reward_bound=0.122, batch=207\n",
      "10043: loss=0.112, reward_mean=0.520, reward_bound=0.150, batch=193\n",
      "10044: loss=0.111, reward_mean=0.450, reward_bound=0.160, batch=205\n",
      "10045: loss=0.108, reward_mean=0.520, reward_bound=0.167, batch=200\n",
      "10046: loss=0.107, reward_mean=0.420, reward_bound=0.185, batch=189\n",
      "10047: loss=0.104, reward_mean=0.490, reward_bound=0.206, batch=166\n",
      "10048: loss=0.099, reward_mean=0.460, reward_bound=0.104, batch=186\n",
      "10049: loss=0.098, reward_mean=0.470, reward_bound=0.122, batch=199\n",
      "10050: loss=0.101, reward_mean=0.470, reward_bound=0.150, batch=208\n",
      "10051: loss=0.100, reward_mean=0.390, reward_bound=0.167, batch=212\n",
      "10052: loss=0.104, reward_mean=0.460, reward_bound=0.185, batch=212\n",
      "10053: loss=0.105, reward_mean=0.460, reward_bound=0.206, batch=221\n",
      "10054: loss=0.101, reward_mean=0.440, reward_bound=0.206, batch=224\n",
      "10055: loss=0.100, reward_mean=0.420, reward_bound=0.229, batch=203\n",
      "10056: loss=0.100, reward_mean=0.410, reward_bound=0.211, batch=212\n",
      "10057: loss=0.099, reward_mean=0.480, reward_bound=0.254, batch=177\n",
      "10058: loss=0.098, reward_mean=0.420, reward_bound=0.109, batch=195\n",
      "10059: loss=0.097, reward_mean=0.350, reward_bound=0.150, batch=205\n",
      "10060: loss=0.097, reward_mean=0.400, reward_bound=0.167, batch=212\n",
      "10061: loss=0.100, reward_mean=0.480, reward_bound=0.185, batch=217\n",
      "10062: loss=0.099, reward_mean=0.330, reward_bound=0.206, batch=220\n",
      "10063: loss=0.101, reward_mean=0.420, reward_bound=0.229, batch=222\n",
      "10064: loss=0.099, reward_mean=0.460, reward_bound=0.254, batch=222\n",
      "10065: loss=0.097, reward_mean=0.320, reward_bound=0.282, batch=173\n",
      "10066: loss=0.096, reward_mean=0.510, reward_bound=0.105, batch=191\n",
      "10067: loss=0.097, reward_mean=0.480, reward_bound=0.135, batch=202\n",
      "10068: loss=0.099, reward_mean=0.440, reward_bound=0.172, batch=211\n",
      "10069: loss=0.095, reward_mean=0.330, reward_bound=0.185, batch=214\n",
      "10070: loss=0.093, reward_mean=0.470, reward_bound=0.206, batch=216\n",
      "10071: loss=0.091, reward_mean=0.410, reward_bound=0.217, batch=221\n",
      "10072: loss=0.090, reward_mean=0.480, reward_bound=0.254, batch=219\n",
      "10073: loss=0.089, reward_mean=0.520, reward_bound=0.265, batch=223\n",
      "10074: loss=0.092, reward_mean=0.440, reward_bound=0.282, batch=215\n",
      "10075: loss=0.091, reward_mean=0.470, reward_bound=0.289, batch=220\n",
      "10076: loss=0.091, reward_mean=0.440, reward_bound=0.304, batch=224\n",
      "10077: loss=0.085, reward_mean=0.510, reward_bound=0.314, batch=180\n",
      "10078: loss=0.089, reward_mean=0.470, reward_bound=0.122, batch=193\n",
      "10079: loss=0.085, reward_mean=0.400, reward_bound=0.105, batch=205\n",
      "10080: loss=0.086, reward_mean=0.490, reward_bound=0.138, batch=213\n",
      "10081: loss=0.085, reward_mean=0.380, reward_bound=0.167, batch=218\n",
      "10082: loss=0.084, reward_mean=0.530, reward_bound=0.229, batch=217\n",
      "10083: loss=0.084, reward_mean=0.390, reward_bound=0.254, batch=219\n",
      "10084: loss=0.084, reward_mean=0.460, reward_bound=0.254, batch=222\n",
      "10085: loss=0.085, reward_mean=0.470, reward_bound=0.282, batch=220\n",
      "10086: loss=0.084, reward_mean=0.440, reward_bound=0.314, batch=215\n",
      "10087: loss=0.084, reward_mean=0.420, reward_bound=0.282, batch=219\n",
      "10088: loss=0.082, reward_mean=0.470, reward_bound=0.349, batch=157\n",
      "10089: loss=0.078, reward_mean=0.450, reward_bound=0.098, batch=179\n",
      "10090: loss=0.074, reward_mean=0.410, reward_bound=0.075, batch=195\n",
      "10091: loss=0.078, reward_mean=0.500, reward_bound=0.135, batch=202\n",
      "10092: loss=0.075, reward_mean=0.480, reward_bound=0.150, batch=210\n",
      "10093: loss=0.078, reward_mean=0.490, reward_bound=0.167, batch=215\n",
      "10094: loss=0.079, reward_mean=0.470, reward_bound=0.206, batch=216\n",
      "10095: loss=0.080, reward_mean=0.520, reward_bound=0.254, batch=215\n",
      "10096: loss=0.081, reward_mean=0.510, reward_bound=0.282, batch=207\n",
      "10097: loss=0.085, reward_mean=0.510, reward_bound=0.302, batch=215\n",
      "10098: loss=0.087, reward_mean=0.490, reward_bound=0.314, batch=206\n",
      "10099: loss=0.089, reward_mean=0.430, reward_bound=0.282, batch=213\n",
      "10100: loss=0.093, reward_mean=0.430, reward_bound=0.314, batch=217\n",
      "10101: loss=0.092, reward_mean=0.510, reward_bound=0.349, batch=205\n",
      "10102: loss=0.090, reward_mean=0.370, reward_bound=0.229, batch=212\n",
      "10103: loss=0.091, reward_mean=0.450, reward_bound=0.236, batch=218\n",
      "10104: loss=0.091, reward_mean=0.520, reward_bound=0.254, batch=219\n",
      "10105: loss=0.091, reward_mean=0.450, reward_bound=0.254, batch=222\n",
      "10106: loss=0.089, reward_mean=0.400, reward_bound=0.282, batch=223\n",
      "10107: loss=0.090, reward_mean=0.400, reward_bound=0.314, batch=222\n",
      "10108: loss=0.090, reward_mean=0.440, reward_bound=0.349, batch=223\n",
      "10109: loss=0.086, reward_mean=0.430, reward_bound=0.387, batch=141\n",
      "10110: loss=0.076, reward_mean=0.410, reward_bound=0.065, batch=166\n",
      "10111: loss=0.077, reward_mean=0.500, reward_bound=0.080, batch=184\n",
      "10112: loss=0.082, reward_mean=0.600, reward_bound=0.122, batch=197\n",
      "10113: loss=0.083, reward_mean=0.480, reward_bound=0.150, batch=204\n",
      "10114: loss=0.086, reward_mean=0.410, reward_bound=0.167, batch=207\n",
      "10115: loss=0.086, reward_mean=0.490, reward_bound=0.185, batch=213\n",
      "10116: loss=0.087, reward_mean=0.440, reward_bound=0.220, batch=219\n",
      "10117: loss=0.086, reward_mean=0.550, reward_bound=0.203, batch=223\n",
      "10118: loss=0.084, reward_mean=0.480, reward_bound=0.229, batch=210\n",
      "10119: loss=0.086, reward_mean=0.380, reward_bound=0.254, batch=207\n",
      "10120: loss=0.088, reward_mean=0.460, reward_bound=0.277, batch=215\n",
      "10121: loss=0.083, reward_mean=0.450, reward_bound=0.282, batch=210\n",
      "10122: loss=0.083, reward_mean=0.400, reward_bound=0.185, batch=215\n",
      "10123: loss=0.082, reward_mean=0.520, reward_bound=0.229, batch=219\n",
      "10124: loss=0.083, reward_mean=0.430, reward_bound=0.314, batch=208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10125: loss=0.086, reward_mean=0.500, reward_bound=0.257, batch=215\n",
      "10126: loss=0.087, reward_mean=0.520, reward_bound=0.282, batch=218\n",
      "10127: loss=0.088, reward_mean=0.510, reward_bound=0.282, batch=221\n",
      "10128: loss=0.086, reward_mean=0.520, reward_bound=0.314, batch=221\n",
      "10129: loss=0.084, reward_mean=0.400, reward_bound=0.349, batch=202\n",
      "10130: loss=0.083, reward_mean=0.340, reward_bound=0.150, batch=209\n",
      "10131: loss=0.084, reward_mean=0.470, reward_bound=0.229, batch=212\n",
      "10132: loss=0.085, reward_mean=0.440, reward_bound=0.282, batch=216\n",
      "10133: loss=0.086, reward_mean=0.340, reward_bound=0.241, batch=221\n",
      "10134: loss=0.085, reward_mean=0.480, reward_bound=0.314, batch=220\n",
      "10135: loss=0.084, reward_mean=0.500, reward_bound=0.349, batch=219\n",
      "10136: loss=0.084, reward_mean=0.420, reward_bound=0.203, batch=223\n",
      "10137: loss=0.086, reward_mean=0.460, reward_bound=0.271, batch=226\n",
      "10138: loss=0.086, reward_mean=0.370, reward_bound=0.254, batch=227\n",
      "10139: loss=0.085, reward_mean=0.350, reward_bound=0.282, batch=228\n",
      "10140: loss=0.086, reward_mean=0.360, reward_bound=0.314, batch=227\n",
      "10141: loss=0.084, reward_mean=0.480, reward_bound=0.349, batch=227\n",
      "10142: loss=0.088, reward_mean=0.510, reward_bound=0.387, batch=198\n",
      "10143: loss=0.088, reward_mean=0.390, reward_bound=0.171, batch=208\n",
      "10144: loss=0.086, reward_mean=0.430, reward_bound=0.257, batch=215\n",
      "10145: loss=0.089, reward_mean=0.490, reward_bound=0.282, batch=218\n",
      "10146: loss=0.090, reward_mean=0.560, reward_bound=0.349, batch=218\n",
      "10147: loss=0.091, reward_mean=0.440, reward_bound=0.286, batch=222\n",
      "10148: loss=0.091, reward_mean=0.400, reward_bound=0.292, batch=225\n",
      "10149: loss=0.091, reward_mean=0.510, reward_bound=0.314, batch=225\n",
      "10150: loss=0.091, reward_mean=0.490, reward_bound=0.349, batch=226\n",
      "10151: loss=0.088, reward_mean=0.380, reward_bound=0.387, batch=214\n",
      "10152: loss=0.089, reward_mean=0.440, reward_bound=0.311, batch=220\n",
      "10153: loss=0.088, reward_mean=0.400, reward_bound=0.274, batch=224\n",
      "10154: loss=0.091, reward_mean=0.430, reward_bound=0.311, batch=227\n",
      "10155: loss=0.090, reward_mean=0.410, reward_bound=0.314, batch=228\n",
      "10156: loss=0.088, reward_mean=0.450, reward_bound=0.387, batch=220\n",
      "10157: loss=0.088, reward_mean=0.530, reward_bound=0.387, batch=221\n",
      "10158: loss=0.090, reward_mean=0.460, reward_bound=0.314, batch=223\n",
      "10159: loss=0.090, reward_mean=0.410, reward_bound=0.372, batch=226\n",
      "10160: loss=0.089, reward_mean=0.410, reward_bound=0.331, batch=228\n",
      "10161: loss=0.090, reward_mean=0.550, reward_bound=0.353, batch=229\n",
      "10162: loss=0.090, reward_mean=0.480, reward_bound=0.349, batch=229\n",
      "10163: loss=0.089, reward_mean=0.490, reward_bound=0.387, batch=228\n",
      "10164: loss=0.084, reward_mean=0.510, reward_bound=0.430, batch=128\n",
      "10165: loss=0.074, reward_mean=0.410, reward_bound=0.023, batch=159\n",
      "10166: loss=0.083, reward_mean=0.430, reward_bound=0.047, batch=180\n",
      "10167: loss=0.091, reward_mean=0.490, reward_bound=0.058, batch=195\n",
      "10168: loss=0.097, reward_mean=0.370, reward_bound=0.072, batch=205\n",
      "10169: loss=0.099, reward_mean=0.390, reward_bound=0.098, batch=210\n",
      "10170: loss=0.097, reward_mean=0.460, reward_bound=0.122, batch=215\n",
      "10171: loss=0.098, reward_mean=0.410, reward_bound=0.150, batch=215\n",
      "10172: loss=0.095, reward_mean=0.460, reward_bound=0.185, batch=216\n",
      "10173: loss=0.089, reward_mean=0.420, reward_bound=0.206, batch=204\n",
      "10174: loss=0.093, reward_mean=0.500, reward_bound=0.229, batch=204\n",
      "10175: loss=0.093, reward_mean=0.500, reward_bound=0.254, batch=202\n",
      "10176: loss=0.092, reward_mean=0.450, reward_bound=0.229, batch=209\n",
      "10177: loss=0.091, reward_mean=0.440, reward_bound=0.265, batch=216\n",
      "10178: loss=0.092, reward_mean=0.420, reward_bound=0.230, batch=221\n",
      "10179: loss=0.087, reward_mean=0.410, reward_bound=0.282, batch=204\n",
      "10180: loss=0.085, reward_mean=0.530, reward_bound=0.206, batch=211\n",
      "10181: loss=0.084, reward_mean=0.410, reward_bound=0.206, batch=217\n",
      "10182: loss=0.085, reward_mean=0.390, reward_bound=0.254, batch=218\n",
      "10183: loss=0.085, reward_mean=0.390, reward_bound=0.231, batch=222\n",
      "10184: loss=0.085, reward_mean=0.470, reward_bound=0.263, batch=225\n",
      "10185: loss=0.087, reward_mean=0.460, reward_bound=0.314, batch=206\n",
      "10186: loss=0.088, reward_mean=0.340, reward_bound=0.136, batch=214\n",
      "10187: loss=0.090, reward_mean=0.430, reward_bound=0.226, batch=220\n",
      "10188: loss=0.086, reward_mean=0.370, reward_bound=0.254, batch=220\n",
      "10189: loss=0.085, reward_mean=0.490, reward_bound=0.274, batch=224\n",
      "10190: loss=0.086, reward_mean=0.480, reward_bound=0.314, batch=224\n",
      "10191: loss=0.085, reward_mean=0.370, reward_bound=0.342, batch=227\n",
      "10192: loss=0.086, reward_mean=0.390, reward_bound=0.349, batch=202\n",
      "10193: loss=0.086, reward_mean=0.480, reward_bound=0.213, batch=211\n",
      "10194: loss=0.086, reward_mean=0.430, reward_bound=0.206, batch=217\n",
      "10195: loss=0.088, reward_mean=0.440, reward_bound=0.249, batch=222\n",
      "10196: loss=0.085, reward_mean=0.410, reward_bound=0.254, batch=221\n",
      "10197: loss=0.083, reward_mean=0.430, reward_bound=0.282, batch=222\n",
      "10198: loss=0.087, reward_mean=0.460, reward_bound=0.314, batch=220\n",
      "10199: loss=0.086, reward_mean=0.570, reward_bound=0.349, batch=219\n",
      "10200: loss=0.085, reward_mean=0.390, reward_bound=0.314, batch=221\n",
      "10201: loss=0.085, reward_mean=0.410, reward_bound=0.314, batch=223\n",
      "10202: loss=0.086, reward_mean=0.440, reward_bound=0.372, batch=226\n",
      "10203: loss=0.083, reward_mean=0.520, reward_bound=0.387, batch=198\n",
      "10204: loss=0.083, reward_mean=0.480, reward_bound=0.254, batch=207\n",
      "10205: loss=0.082, reward_mean=0.480, reward_bound=0.282, batch=211\n",
      "10206: loss=0.084, reward_mean=0.410, reward_bound=0.282, batch=216\n",
      "10207: loss=0.087, reward_mean=0.410, reward_bound=0.314, batch=213\n",
      "10208: loss=0.085, reward_mean=0.470, reward_bound=0.271, batch=219\n",
      "10209: loss=0.084, reward_mean=0.510, reward_bound=0.349, batch=216\n",
      "10210: loss=0.085, reward_mean=0.340, reward_bound=0.196, batch=221\n",
      "10211: loss=0.086, reward_mean=0.480, reward_bound=0.282, batch=222\n",
      "10212: loss=0.085, reward_mean=0.470, reward_bound=0.349, batch=224\n",
      "10213: loss=0.083, reward_mean=0.500, reward_bound=0.387, batch=220\n",
      "10214: loss=0.083, reward_mean=0.540, reward_bound=0.376, batch=224\n",
      "10215: loss=0.083, reward_mean=0.390, reward_bound=0.280, batch=227\n",
      "10216: loss=0.084, reward_mean=0.390, reward_bound=0.342, batch=229\n",
      "10217: loss=0.083, reward_mean=0.490, reward_bound=0.349, batch=228\n",
      "10218: loss=0.083, reward_mean=0.430, reward_bound=0.387, batch=226\n",
      "10219: loss=0.084, reward_mean=0.420, reward_bound=0.387, batch=227\n",
      "10220: loss=0.084, reward_mean=0.560, reward_bound=0.422, batch=229\n",
      "10221: loss=0.084, reward_mean=0.420, reward_bound=0.360, batch=230\n",
      "10222: loss=0.082, reward_mean=0.460, reward_bound=0.430, batch=187\n",
      "10223: loss=0.085, reward_mean=0.450, reward_bound=0.229, batch=199\n",
      "10224: loss=0.085, reward_mean=0.430, reward_bound=0.185, batch=206\n",
      "10225: loss=0.084, reward_mean=0.440, reward_bound=0.254, batch=212\n",
      "10226: loss=0.084, reward_mean=0.490, reward_bound=0.314, batch=213\n",
      "10227: loss=0.087, reward_mean=0.360, reward_bound=0.271, batch=219\n",
      "10228: loss=0.085, reward_mean=0.480, reward_bound=0.328, batch=223\n",
      "10229: loss=0.083, reward_mean=0.500, reward_bound=0.349, batch=215\n",
      "10230: loss=0.083, reward_mean=0.440, reward_bound=0.321, batch=220\n",
      "10231: loss=0.083, reward_mean=0.480, reward_bound=0.338, batch=224\n",
      "10232: loss=0.083, reward_mean=0.460, reward_bound=0.349, batch=222\n",
      "10233: loss=0.082, reward_mean=0.480, reward_bound=0.314, batch=224\n",
      "10234: loss=0.082, reward_mean=0.400, reward_bound=0.314, batch=225\n",
      "10235: loss=0.083, reward_mean=0.400, reward_bound=0.387, batch=214\n",
      "10236: loss=0.082, reward_mean=0.490, reward_bound=0.282, batch=219\n",
      "10237: loss=0.082, reward_mean=0.490, reward_bound=0.314, batch=222\n",
      "10238: loss=0.082, reward_mean=0.470, reward_bound=0.360, batch=225\n",
      "10239: loss=0.081, reward_mean=0.470, reward_bound=0.396, batch=227\n",
      "10240: loss=0.081, reward_mean=0.440, reward_bound=0.282, batch=228\n",
      "10241: loss=0.081, reward_mean=0.610, reward_bound=0.392, batch=229\n",
      "10242: loss=0.081, reward_mean=0.320, reward_bound=0.314, batch=229\n",
      "10243: loss=0.083, reward_mean=0.480, reward_bound=0.430, batch=211\n",
      "10244: loss=0.083, reward_mean=0.440, reward_bound=0.229, batch=217\n",
      "10245: loss=0.082, reward_mean=0.470, reward_bound=0.314, batch=220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10246: loss=0.082, reward_mean=0.510, reward_bound=0.376, batch=224\n",
      "10247: loss=0.083, reward_mean=0.420, reward_bound=0.387, batch=223\n",
      "10248: loss=0.084, reward_mean=0.390, reward_bound=0.360, batch=226\n",
      "10249: loss=0.084, reward_mean=0.540, reward_bound=0.316, batch=228\n",
      "10250: loss=0.085, reward_mean=0.480, reward_bound=0.353, batch=229\n",
      "10251: loss=0.085, reward_mean=0.440, reward_bound=0.405, batch=230\n",
      "10252: loss=0.083, reward_mean=0.520, reward_bound=0.430, batch=223\n",
      "10253: loss=0.082, reward_mean=0.490, reward_bound=0.290, batch=226\n",
      "10254: loss=0.084, reward_mean=0.410, reward_bound=0.387, batch=227\n",
      "10255: loss=0.083, reward_mean=0.460, reward_bound=0.430, batch=228\n",
      "10256: loss=0.083, reward_mean=0.440, reward_bound=0.362, batch=229\n",
      "10257: loss=0.084, reward_mean=0.590, reward_bound=0.478, batch=232\n",
      "10258: loss=0.082, reward_mean=0.500, reward_bound=0.478, batch=93\n",
      "10259: loss=0.077, reward_mean=0.430, reward_bound=0.003, batch=135\n",
      "10260: loss=0.077, reward_mean=0.490, reward_bound=0.026, batch=164\n",
      "10261: loss=0.080, reward_mean=0.550, reward_bound=0.064, batch=185\n",
      "10262: loss=0.083, reward_mean=0.430, reward_bound=0.080, batch=192\n",
      "10263: loss=0.082, reward_mean=0.450, reward_bound=0.098, batch=201\n",
      "10264: loss=0.082, reward_mean=0.420, reward_bound=0.109, batch=208\n",
      "10265: loss=0.088, reward_mean=0.440, reward_bound=0.135, batch=202\n",
      "10266: loss=0.091, reward_mean=0.440, reward_bound=0.150, batch=207\n",
      "10267: loss=0.092, reward_mean=0.410, reward_bound=0.167, batch=204\n",
      "10268: loss=0.086, reward_mean=0.480, reward_bound=0.185, batch=205\n",
      "10269: loss=0.088, reward_mean=0.500, reward_bound=0.206, batch=197\n",
      "10270: loss=0.085, reward_mean=0.350, reward_bound=0.122, batch=205\n",
      "10271: loss=0.088, reward_mean=0.430, reward_bound=0.185, batch=212\n",
      "10272: loss=0.083, reward_mean=0.390, reward_bound=0.229, batch=204\n",
      "10273: loss=0.083, reward_mean=0.470, reward_bound=0.229, batch=212\n",
      "10274: loss=0.083, reward_mean=0.420, reward_bound=0.254, batch=199\n",
      "10275: loss=0.086, reward_mean=0.500, reward_bound=0.254, batch=208\n",
      "10276: loss=0.084, reward_mean=0.430, reward_bound=0.254, batch=214\n",
      "10277: loss=0.084, reward_mean=0.400, reward_bound=0.280, batch=220\n",
      "10278: loss=0.083, reward_mean=0.470, reward_bound=0.282, batch=211\n",
      "10279: loss=0.083, reward_mean=0.500, reward_bound=0.314, batch=190\n",
      "10280: loss=0.079, reward_mean=0.490, reward_bound=0.222, batch=203\n",
      "10281: loss=0.077, reward_mean=0.450, reward_bound=0.229, batch=209\n",
      "10282: loss=0.076, reward_mean=0.480, reward_bound=0.215, batch=216\n",
      "10283: loss=0.077, reward_mean=0.490, reward_bound=0.254, batch=216\n",
      "10284: loss=0.076, reward_mean=0.480, reward_bound=0.314, batch=215\n",
      "10285: loss=0.077, reward_mean=0.410, reward_bound=0.314, batch=219\n",
      "10286: loss=0.078, reward_mean=0.440, reward_bound=0.206, batch=222\n",
      "10287: loss=0.077, reward_mean=0.420, reward_bound=0.292, batch=225\n",
      "10288: loss=0.077, reward_mean=0.290, reward_bound=0.321, batch=227\n",
      "10289: loss=0.078, reward_mean=0.430, reward_bound=0.349, batch=198\n",
      "10290: loss=0.080, reward_mean=0.460, reward_bound=0.152, batch=208\n",
      "10291: loss=0.081, reward_mean=0.500, reward_bound=0.206, batch=213\n",
      "10292: loss=0.080, reward_mean=0.450, reward_bound=0.244, batch=219\n",
      "10293: loss=0.081, reward_mean=0.390, reward_bound=0.239, batch=223\n",
      "10294: loss=0.081, reward_mean=0.470, reward_bound=0.282, batch=223\n",
      "10295: loss=0.080, reward_mean=0.350, reward_bound=0.314, batch=221\n",
      "10296: loss=0.082, reward_mean=0.500, reward_bound=0.349, batch=216\n",
      "10297: loss=0.082, reward_mean=0.470, reward_bound=0.351, batch=221\n",
      "10298: loss=0.080, reward_mean=0.340, reward_bound=0.387, batch=175\n",
      "10299: loss=0.082, reward_mean=0.410, reward_bound=0.175, batch=192\n",
      "10300: loss=0.079, reward_mean=0.480, reward_bound=0.185, batch=203\n",
      "10301: loss=0.082, reward_mean=0.460, reward_bound=0.185, batch=211\n",
      "10302: loss=0.082, reward_mean=0.490, reward_bound=0.135, batch=217\n",
      "10303: loss=0.086, reward_mean=0.450, reward_bound=0.224, batch=222\n",
      "10304: loss=0.081, reward_mean=0.400, reward_bound=0.229, batch=224\n",
      "10305: loss=0.082, reward_mean=0.500, reward_bound=0.254, batch=222\n",
      "10306: loss=0.083, reward_mean=0.420, reward_bound=0.282, batch=219\n",
      "10307: loss=0.082, reward_mean=0.400, reward_bound=0.295, batch=223\n",
      "10308: loss=0.080, reward_mean=0.520, reward_bound=0.314, batch=217\n",
      "10309: loss=0.075, reward_mean=0.520, reward_bound=0.349, batch=205\n",
      "10310: loss=0.074, reward_mean=0.490, reward_bound=0.210, batch=213\n",
      "10311: loss=0.074, reward_mean=0.450, reward_bound=0.254, batch=216\n",
      "10312: loss=0.073, reward_mean=0.550, reward_bound=0.298, batch=221\n",
      "10313: loss=0.077, reward_mean=0.470, reward_bound=0.314, batch=216\n",
      "10314: loss=0.077, reward_mean=0.310, reward_bound=0.256, batch=221\n",
      "10315: loss=0.076, reward_mean=0.450, reward_bound=0.229, batch=222\n",
      "10316: loss=0.076, reward_mean=0.490, reward_bound=0.282, batch=223\n",
      "10317: loss=0.079, reward_mean=0.430, reward_bound=0.301, batch=226\n",
      "10318: loss=0.080, reward_mean=0.530, reward_bound=0.349, batch=223\n",
      "10319: loss=0.080, reward_mean=0.390, reward_bound=0.372, batch=226\n",
      "10320: loss=0.080, reward_mean=0.450, reward_bound=0.368, batch=228\n",
      "10321: loss=0.079, reward_mean=0.460, reward_bound=0.387, batch=214\n",
      "10322: loss=0.078, reward_mean=0.440, reward_bound=0.252, batch=220\n",
      "10323: loss=0.077, reward_mean=0.520, reward_bound=0.282, batch=222\n",
      "10324: loss=0.077, reward_mean=0.510, reward_bound=0.282, batch=224\n",
      "10325: loss=0.079, reward_mean=0.520, reward_bound=0.314, batch=226\n",
      "10326: loss=0.078, reward_mean=0.490, reward_bound=0.349, batch=225\n",
      "10327: loss=0.077, reward_mean=0.430, reward_bound=0.356, batch=227\n",
      "10328: loss=0.077, reward_mean=0.490, reward_bound=0.380, batch=229\n",
      "10329: loss=0.077, reward_mean=0.540, reward_bound=0.387, batch=227\n",
      "10330: loss=0.077, reward_mean=0.560, reward_bound=0.277, batch=229\n",
      "10331: loss=0.083, reward_mean=0.410, reward_bound=0.430, batch=168\n",
      "10332: loss=0.077, reward_mean=0.450, reward_bound=0.100, batch=187\n",
      "10333: loss=0.082, reward_mean=0.460, reward_bound=0.132, batch=201\n",
      "10334: loss=0.084, reward_mean=0.440, reward_bound=0.185, batch=205\n",
      "10335: loss=0.084, reward_mean=0.500, reward_bound=0.206, batch=211\n",
      "10336: loss=0.085, reward_mean=0.530, reward_bound=0.229, batch=214\n",
      "10337: loss=0.082, reward_mean=0.450, reward_bound=0.254, batch=208\n",
      "10338: loss=0.081, reward_mean=0.470, reward_bound=0.254, batch=214\n",
      "10339: loss=0.080, reward_mean=0.350, reward_bound=0.206, batch=219\n",
      "10340: loss=0.083, reward_mean=0.430, reward_bound=0.239, batch=223\n",
      "10341: loss=0.081, reward_mean=0.400, reward_bound=0.282, batch=214\n",
      "10342: loss=0.082, reward_mean=0.490, reward_bound=0.282, batch=219\n",
      "10343: loss=0.082, reward_mean=0.390, reward_bound=0.314, batch=211\n",
      "10344: loss=0.079, reward_mean=0.390, reward_bound=0.229, batch=217\n",
      "10345: loss=0.080, reward_mean=0.470, reward_bound=0.254, batch=220\n",
      "10346: loss=0.081, reward_mean=0.360, reward_bound=0.282, batch=223\n",
      "10347: loss=0.081, reward_mean=0.530, reward_bound=0.314, batch=224\n",
      "10348: loss=0.081, reward_mean=0.440, reward_bound=0.311, batch=227\n",
      "10349: loss=0.082, reward_mean=0.420, reward_bound=0.349, batch=211\n",
      "10350: loss=0.082, reward_mean=0.450, reward_bound=0.254, batch=214\n",
      "10351: loss=0.080, reward_mean=0.370, reward_bound=0.311, batch=220\n",
      "10352: loss=0.080, reward_mean=0.440, reward_bound=0.304, batch=224\n",
      "10353: loss=0.079, reward_mean=0.460, reward_bound=0.314, batch=225\n",
      "10354: loss=0.081, reward_mean=0.470, reward_bound=0.349, batch=224\n",
      "10355: loss=0.081, reward_mean=0.440, reward_bound=0.384, batch=227\n",
      "10356: loss=0.079, reward_mean=0.490, reward_bound=0.387, batch=208\n",
      "10357: loss=0.079, reward_mean=0.430, reward_bound=0.286, batch=215\n",
      "10358: loss=0.079, reward_mean=0.410, reward_bound=0.282, batch=219\n",
      "10359: loss=0.082, reward_mean=0.400, reward_bound=0.314, batch=222\n",
      "10360: loss=0.081, reward_mean=0.480, reward_bound=0.349, batch=221\n",
      "10361: loss=0.081, reward_mean=0.440, reward_bound=0.349, batch=223\n",
      "10362: loss=0.080, reward_mean=0.460, reward_bound=0.387, batch=219\n",
      "10363: loss=0.080, reward_mean=0.500, reward_bound=0.405, batch=223\n",
      "10364: loss=0.080, reward_mean=0.490, reward_bound=0.349, batch=225\n",
      "10365: loss=0.080, reward_mean=0.450, reward_bound=0.356, batch=227\n",
      "10366: loss=0.081, reward_mean=0.450, reward_bound=0.387, batch=227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10367: loss=0.081, reward_mean=0.520, reward_bound=0.349, batch=228\n",
      "10368: loss=0.082, reward_mean=0.370, reward_bound=0.392, batch=229\n",
      "10369: loss=0.081, reward_mean=0.490, reward_bound=0.430, batch=199\n",
      "10370: loss=0.079, reward_mean=0.470, reward_bound=0.229, batch=208\n",
      "10371: loss=0.081, reward_mean=0.490, reward_bound=0.231, batch=215\n",
      "10372: loss=0.078, reward_mean=0.400, reward_bound=0.282, batch=218\n",
      "10373: loss=0.079, reward_mean=0.440, reward_bound=0.314, batch=217\n",
      "10374: loss=0.079, reward_mean=0.400, reward_bound=0.342, batch=222\n",
      "10375: loss=0.079, reward_mean=0.400, reward_bound=0.314, batch=224\n",
      "10376: loss=0.077, reward_mean=0.510, reward_bound=0.349, batch=219\n",
      "10377: loss=0.078, reward_mean=0.460, reward_bound=0.282, batch=222\n",
      "10378: loss=0.077, reward_mean=0.470, reward_bound=0.349, batch=224\n",
      "10379: loss=0.076, reward_mean=0.370, reward_bound=0.345, batch=227\n",
      "10380: loss=0.076, reward_mean=0.410, reward_bound=0.229, batch=228\n",
      "10381: loss=0.076, reward_mean=0.450, reward_bound=0.349, batch=227\n",
      "10382: loss=0.076, reward_mean=0.440, reward_bound=0.373, batch=229\n",
      "10383: loss=0.076, reward_mean=0.500, reward_bound=0.387, batch=225\n",
      "10384: loss=0.075, reward_mean=0.520, reward_bound=0.356, batch=227\n",
      "10385: loss=0.075, reward_mean=0.490, reward_bound=0.314, batch=227\n",
      "10386: loss=0.076, reward_mean=0.480, reward_bound=0.422, batch=229\n",
      "10387: loss=0.077, reward_mean=0.450, reward_bound=0.430, batch=218\n",
      "10388: loss=0.076, reward_mean=0.420, reward_bound=0.231, batch=222\n",
      "10389: loss=0.077, reward_mean=0.510, reward_bound=0.263, batch=225\n",
      "10390: loss=0.077, reward_mean=0.510, reward_bound=0.349, batch=225\n",
      "10391: loss=0.077, reward_mean=0.460, reward_bound=0.349, batch=226\n",
      "10392: loss=0.076, reward_mean=0.430, reward_bound=0.409, batch=228\n",
      "10393: loss=0.076, reward_mean=0.440, reward_bound=0.430, batch=226\n",
      "10394: loss=0.076, reward_mean=0.510, reward_bound=0.433, batch=228\n",
      "10395: loss=0.076, reward_mean=0.440, reward_bound=0.430, batch=228\n",
      "10396: loss=0.077, reward_mean=0.420, reward_bound=0.397, batch=229\n",
      "10397: loss=0.076, reward_mean=0.420, reward_bound=0.424, batch=230\n",
      "10398: loss=0.076, reward_mean=0.510, reward_bound=0.439, batch=231\n",
      "10399: loss=0.075, reward_mean=0.420, reward_bound=0.478, batch=149\n",
      "10400: loss=0.076, reward_mean=0.580, reward_bound=0.114, batch=174\n",
      "10401: loss=0.076, reward_mean=0.430, reward_bound=0.070, batch=192\n",
      "10402: loss=0.076, reward_mean=0.500, reward_bound=0.135, batch=201\n",
      "10403: loss=0.079, reward_mean=0.470, reward_bound=0.167, batch=204\n",
      "10404: loss=0.077, reward_mean=0.560, reward_bound=0.185, batch=207\n",
      "10405: loss=0.079, reward_mean=0.440, reward_bound=0.206, batch=204\n",
      "10406: loss=0.079, reward_mean=0.510, reward_bound=0.252, batch=213\n",
      "10407: loss=0.082, reward_mean=0.410, reward_bound=0.254, batch=207\n",
      "10408: loss=0.083, reward_mean=0.460, reward_bound=0.272, batch=215\n",
      "10409: loss=0.083, reward_mean=0.400, reward_bound=0.282, batch=204\n",
      "10410: loss=0.080, reward_mean=0.480, reward_bound=0.277, batch=213\n",
      "10411: loss=0.079, reward_mean=0.430, reward_bound=0.244, batch=219\n",
      "10412: loss=0.079, reward_mean=0.440, reward_bound=0.254, batch=221\n",
      "10413: loss=0.079, reward_mean=0.480, reward_bound=0.254, batch=224\n",
      "10414: loss=0.080, reward_mean=0.420, reward_bound=0.280, batch=227\n",
      "10415: loss=0.080, reward_mean=0.430, reward_bound=0.282, batch=227\n",
      "10416: loss=0.079, reward_mean=0.240, reward_bound=0.253, batch=229\n",
      "10417: loss=0.076, reward_mean=0.330, reward_bound=0.314, batch=213\n",
      "10418: loss=0.077, reward_mean=0.450, reward_bound=0.322, batch=219\n",
      "10419: loss=0.077, reward_mean=0.430, reward_bound=0.295, batch=223\n",
      "10420: loss=0.076, reward_mean=0.410, reward_bound=0.282, batch=225\n",
      "10421: loss=0.076, reward_mean=0.410, reward_bound=0.321, batch=227\n",
      "10422: loss=0.076, reward_mean=0.490, reward_bound=0.342, batch=229\n",
      "10423: loss=0.078, reward_mean=0.430, reward_bound=0.349, batch=213\n",
      "10424: loss=0.076, reward_mean=0.460, reward_bound=0.254, batch=218\n",
      "10425: loss=0.078, reward_mean=0.410, reward_bound=0.282, batch=221\n",
      "10426: loss=0.078, reward_mean=0.440, reward_bound=0.349, batch=221\n",
      "10427: loss=0.077, reward_mean=0.430, reward_bound=0.314, batch=224\n",
      "10428: loss=0.078, reward_mean=0.480, reward_bound=0.314, batch=226\n",
      "10429: loss=0.078, reward_mean=0.520, reward_bound=0.368, batch=228\n",
      "10430: loss=0.077, reward_mean=0.480, reward_bound=0.387, batch=204\n",
      "10431: loss=0.075, reward_mean=0.500, reward_bound=0.229, batch=210\n",
      "10432: loss=0.077, reward_mean=0.420, reward_bound=0.254, batch=215\n",
      "10433: loss=0.080, reward_mean=0.510, reward_bound=0.282, batch=217\n",
      "10434: loss=0.078, reward_mean=0.420, reward_bound=0.314, batch=219\n",
      "10435: loss=0.080, reward_mean=0.470, reward_bound=0.309, batch=223\n",
      "10436: loss=0.080, reward_mean=0.380, reward_bound=0.235, batch=226\n",
      "10437: loss=0.078, reward_mean=0.480, reward_bound=0.349, batch=221\n",
      "10438: loss=0.078, reward_mean=0.420, reward_bound=0.282, batch=224\n",
      "10439: loss=0.081, reward_mean=0.380, reward_bound=0.303, batch=227\n",
      "10440: loss=0.076, reward_mean=0.410, reward_bound=0.387, batch=220\n",
      "10441: loss=0.077, reward_mean=0.460, reward_bound=0.387, batch=222\n",
      "10442: loss=0.077, reward_mean=0.460, reward_bound=0.360, batch=225\n",
      "10443: loss=0.077, reward_mean=0.490, reward_bound=0.430, batch=190\n",
      "10444: loss=0.075, reward_mean=0.440, reward_bound=0.157, batch=203\n",
      "10445: loss=0.072, reward_mean=0.470, reward_bound=0.229, batch=209\n",
      "10446: loss=0.074, reward_mean=0.480, reward_bound=0.254, batch=210\n",
      "10447: loss=0.077, reward_mean=0.460, reward_bound=0.229, batch=216\n",
      "10448: loss=0.075, reward_mean=0.460, reward_bound=0.282, batch=216\n",
      "10449: loss=0.075, reward_mean=0.540, reward_bound=0.268, batch=221\n",
      "10450: loss=0.075, reward_mean=0.450, reward_bound=0.282, batch=221\n",
      "10451: loss=0.075, reward_mean=0.460, reward_bound=0.314, batch=218\n",
      "10452: loss=0.077, reward_mean=0.420, reward_bound=0.349, batch=214\n",
      "10453: loss=0.075, reward_mean=0.390, reward_bound=0.282, batch=219\n",
      "10454: loss=0.077, reward_mean=0.560, reward_bound=0.328, batch=223\n",
      "10455: loss=0.076, reward_mean=0.440, reward_bound=0.349, batch=225\n",
      "10456: loss=0.076, reward_mean=0.390, reward_bound=0.387, batch=212\n",
      "10457: loss=0.075, reward_mean=0.450, reward_bound=0.387, batch=214\n",
      "10458: loss=0.076, reward_mean=0.450, reward_bound=0.384, batch=220\n",
      "10459: loss=0.075, reward_mean=0.430, reward_bound=0.387, batch=221\n",
      "10460: loss=0.074, reward_mean=0.520, reward_bound=0.387, batch=224\n",
      "10461: loss=0.074, reward_mean=0.480, reward_bound=0.387, batch=226\n",
      "10462: loss=0.076, reward_mean=0.490, reward_bound=0.430, batch=212\n",
      "10463: loss=0.078, reward_mean=0.520, reward_bound=0.283, batch=218\n",
      "10464: loss=0.079, reward_mean=0.500, reward_bound=0.286, batch=222\n",
      "10465: loss=0.077, reward_mean=0.430, reward_bound=0.314, batch=224\n",
      "10466: loss=0.078, reward_mean=0.370, reward_bound=0.277, batch=227\n",
      "10467: loss=0.078, reward_mean=0.390, reward_bound=0.349, batch=226\n",
      "10468: loss=0.078, reward_mean=0.370, reward_bound=0.351, batch=228\n",
      "10469: loss=0.077, reward_mean=0.440, reward_bound=0.387, batch=224\n",
      "10470: loss=0.076, reward_mean=0.420, reward_bound=0.380, batch=227\n",
      "10471: loss=0.076, reward_mean=0.440, reward_bound=0.349, batch=228\n",
      "10472: loss=0.076, reward_mean=0.470, reward_bound=0.392, batch=229\n",
      "10473: loss=0.075, reward_mean=0.420, reward_bound=0.387, batch=229\n",
      "10474: loss=0.074, reward_mean=0.380, reward_bound=0.430, batch=224\n",
      "10475: loss=0.073, reward_mean=0.540, reward_bound=0.314, batch=226\n",
      "10476: loss=0.073, reward_mean=0.500, reward_bound=0.454, batch=228\n",
      "10477: loss=0.074, reward_mean=0.400, reward_bound=0.478, batch=232\n",
      "10478: loss=0.073, reward_mean=0.490, reward_bound=0.478, batch=188\n",
      "10479: loss=0.073, reward_mean=0.370, reward_bound=0.167, batch=200\n",
      "10480: loss=0.070, reward_mean=0.530, reward_bound=0.206, batch=213\n",
      "10481: loss=0.073, reward_mean=0.500, reward_bound=0.206, batch=217\n",
      "10482: loss=0.071, reward_mean=0.440, reward_bound=0.220, batch=222\n",
      "10483: loss=0.074, reward_mean=0.500, reward_bound=0.254, batch=223\n",
      "10484: loss=0.073, reward_mean=0.440, reward_bound=0.282, batch=220\n",
      "10485: loss=0.073, reward_mean=0.480, reward_bound=0.304, batch=224\n",
      "10486: loss=0.077, reward_mean=0.440, reward_bound=0.314, batch=217\n",
      "10487: loss=0.073, reward_mean=0.490, reward_bound=0.349, batch=217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10488: loss=0.072, reward_mean=0.460, reward_bound=0.380, batch=222\n",
      "10489: loss=0.073, reward_mean=0.480, reward_bound=0.324, batch=225\n",
      "10490: loss=0.074, reward_mean=0.360, reward_bound=0.356, batch=227\n",
      "10491: loss=0.076, reward_mean=0.440, reward_bound=0.387, batch=215\n",
      "10492: loss=0.076, reward_mean=0.480, reward_bound=0.281, batch=220\n",
      "10493: loss=0.076, reward_mean=0.430, reward_bound=0.338, batch=224\n",
      "10494: loss=0.073, reward_mean=0.490, reward_bound=0.430, batch=207\n",
      "10495: loss=0.071, reward_mean=0.380, reward_bound=0.314, batch=212\n",
      "10496: loss=0.076, reward_mean=0.420, reward_bound=0.213, batch=218\n",
      "10497: loss=0.075, reward_mean=0.320, reward_bound=0.257, batch=222\n",
      "10498: loss=0.073, reward_mean=0.430, reward_bound=0.314, batch=222\n",
      "10499: loss=0.073, reward_mean=0.520, reward_bound=0.349, batch=221\n",
      "10500: loss=0.073, reward_mean=0.510, reward_bound=0.349, batch=223\n",
      "10501: loss=0.072, reward_mean=0.520, reward_bound=0.335, batch=226\n",
      "10502: loss=0.071, reward_mean=0.510, reward_bound=0.331, batch=228\n",
      "10503: loss=0.071, reward_mean=0.410, reward_bound=0.387, batch=221\n",
      "10504: loss=0.070, reward_mean=0.410, reward_bound=0.349, batch=224\n",
      "10505: loss=0.070, reward_mean=0.470, reward_bound=0.282, batch=226\n",
      "10506: loss=0.069, reward_mean=0.470, reward_bound=0.331, batch=228\n",
      "10507: loss=0.070, reward_mean=0.520, reward_bound=0.349, batch=227\n",
      "10508: loss=0.071, reward_mean=0.430, reward_bound=0.380, batch=229\n",
      "10509: loss=0.072, reward_mean=0.490, reward_bound=0.387, batch=229\n",
      "10510: loss=0.074, reward_mean=0.500, reward_bound=0.430, batch=220\n",
      "10511: loss=0.076, reward_mean=0.520, reward_bound=0.387, batch=223\n",
      "10512: loss=0.079, reward_mean=0.350, reward_bound=0.314, batch=224\n",
      "10513: loss=0.079, reward_mean=0.410, reward_bound=0.384, batch=227\n",
      "10514: loss=0.077, reward_mean=0.400, reward_bound=0.422, batch=229\n",
      "10515: loss=0.074, reward_mean=0.450, reward_bound=0.430, batch=225\n",
      "10516: loss=0.074, reward_mean=0.420, reward_bound=0.440, batch=227\n",
      "10517: loss=0.074, reward_mean=0.490, reward_bound=0.314, batch=228\n",
      "10518: loss=0.075, reward_mean=0.470, reward_bound=0.435, batch=229\n",
      "10519: loss=0.075, reward_mean=0.380, reward_bound=0.349, batch=229\n",
      "10520: loss=0.074, reward_mean=0.450, reward_bound=0.478, batch=231\n",
      "10521: loss=0.072, reward_mean=0.470, reward_bound=0.478, batch=208\n",
      "10522: loss=0.075, reward_mean=0.370, reward_bound=0.190, batch=215\n",
      "10523: loss=0.071, reward_mean=0.460, reward_bound=0.234, batch=220\n",
      "10524: loss=0.069, reward_mean=0.540, reward_bound=0.282, batch=222\n",
      "10525: loss=0.070, reward_mean=0.450, reward_bound=0.292, batch=225\n",
      "10526: loss=0.070, reward_mean=0.460, reward_bound=0.349, batch=224\n",
      "10527: loss=0.071, reward_mean=0.410, reward_bound=0.387, batch=222\n",
      "10528: loss=0.072, reward_mean=0.440, reward_bound=0.349, batch=224\n",
      "10529: loss=0.073, reward_mean=0.400, reward_bound=0.384, batch=227\n",
      "10530: loss=0.072, reward_mean=0.480, reward_bound=0.314, batch=228\n",
      "10531: loss=0.072, reward_mean=0.470, reward_bound=0.353, batch=229\n",
      "10532: loss=0.072, reward_mean=0.490, reward_bound=0.387, batch=228\n",
      "10533: loss=0.071, reward_mean=0.470, reward_bound=0.430, batch=219\n",
      "10534: loss=0.071, reward_mean=0.480, reward_bound=0.387, batch=221\n",
      "10535: loss=0.071, reward_mean=0.450, reward_bound=0.349, batch=223\n",
      "10536: loss=0.070, reward_mean=0.470, reward_bound=0.335, batch=226\n",
      "10537: loss=0.070, reward_mean=0.430, reward_bound=0.349, batch=227\n",
      "10538: loss=0.070, reward_mean=0.460, reward_bound=0.387, batch=228\n",
      "10539: loss=0.071, reward_mean=0.500, reward_bound=0.392, batch=229\n",
      "10540: loss=0.072, reward_mean=0.530, reward_bound=0.430, batch=225\n",
      "10541: loss=0.071, reward_mean=0.370, reward_bound=0.356, batch=227\n",
      "10542: loss=0.071, reward_mean=0.410, reward_bound=0.380, batch=229\n",
      "10543: loss=0.072, reward_mean=0.420, reward_bound=0.364, batch=230\n",
      "10544: loss=0.072, reward_mean=0.450, reward_bound=0.418, batch=231\n",
      "10545: loss=0.073, reward_mean=0.510, reward_bound=0.430, batch=231\n",
      "10546: loss=0.070, reward_mean=0.450, reward_bound=0.478, batch=222\n",
      "10547: loss=0.072, reward_mean=0.370, reward_bound=0.349, batch=224\n",
      "10548: loss=0.072, reward_mean=0.550, reward_bound=0.314, batch=225\n",
      "10549: loss=0.074, reward_mean=0.520, reward_bound=0.365, batch=227\n",
      "10550: loss=0.074, reward_mean=0.490, reward_bound=0.335, batch=229\n",
      "10551: loss=0.074, reward_mean=0.480, reward_bound=0.387, batch=229\n",
      "10552: loss=0.074, reward_mean=0.420, reward_bound=0.405, batch=230\n",
      "10553: loss=0.075, reward_mean=0.460, reward_bound=0.338, batch=231\n",
      "10554: loss=0.071, reward_mean=0.410, reward_bound=0.430, batch=226\n",
      "10555: loss=0.071, reward_mean=0.520, reward_bound=0.478, batch=225\n",
      "10556: loss=0.071, reward_mean=0.480, reward_bound=0.365, batch=227\n",
      "10557: loss=0.070, reward_mean=0.360, reward_bound=0.422, batch=229\n",
      "10558: loss=0.070, reward_mean=0.450, reward_bound=0.430, batch=227\n",
      "10559: loss=0.071, reward_mean=0.460, reward_bound=0.460, batch=229\n",
      "10560: loss=0.071, reward_mean=0.490, reward_bound=0.405, batch=230\n",
      "10561: loss=0.072, reward_mean=0.540, reward_bound=0.338, batch=231\n",
      "10562: loss=0.071, reward_mean=0.470, reward_bound=0.430, batch=231\n",
      "10563: loss=0.071, reward_mean=0.430, reward_bound=0.387, batch=231\n",
      "10564: loss=0.071, reward_mean=0.440, reward_bound=0.387, batch=231\n",
      "10565: loss=0.072, reward_mean=0.390, reward_bound=0.478, batch=228\n",
      "10566: loss=0.071, reward_mean=0.350, reward_bound=0.441, batch=229\n",
      "10567: loss=0.071, reward_mean=0.470, reward_bound=0.430, batch=229\n",
      "10568: loss=0.071, reward_mean=0.430, reward_bound=0.405, batch=230\n",
      "10569: loss=0.071, reward_mean=0.390, reward_bound=0.464, batch=231\n",
      "10570: loss=0.071, reward_mean=0.420, reward_bound=0.430, batch=231\n",
      "10571: loss=0.071, reward_mean=0.410, reward_bound=0.478, batch=230\n",
      "10572: loss=0.071, reward_mean=0.490, reward_bound=0.478, batch=230\n",
      "10573: loss=0.071, reward_mean=0.510, reward_bound=0.430, batch=230\n",
      "10574: loss=0.071, reward_mean=0.450, reward_bound=0.488, batch=231\n",
      "10575: loss=0.071, reward_mean=0.390, reward_bound=0.478, batch=231\n",
      "10576: loss=0.071, reward_mean=0.470, reward_bound=0.478, batch=231\n",
      "10578: loss=0.057, reward_mean=0.390, reward_bound=0.000, batch=39\n",
      "10579: loss=0.060, reward_mean=0.390, reward_bound=0.000, batch=78\n",
      "10580: loss=0.061, reward_mean=0.370, reward_bound=0.000, batch=115\n",
      "10581: loss=0.064, reward_mean=0.390, reward_bound=0.000, batch=150\n",
      "10582: loss=0.065, reward_mean=0.450, reward_bound=0.004, batch=174\n",
      "10583: loss=0.063, reward_mean=0.400, reward_bound=0.016, batch=192\n",
      "10584: loss=0.067, reward_mean=0.420, reward_bound=0.025, batch=200\n",
      "10585: loss=0.064, reward_mean=0.450, reward_bound=0.034, batch=205\n",
      "10586: loss=0.061, reward_mean=0.420, reward_bound=0.047, batch=211\n",
      "10587: loss=0.065, reward_mean=0.500, reward_bound=0.065, batch=208\n",
      "10588: loss=0.064, reward_mean=0.440, reward_bound=0.080, batch=212\n",
      "10589: loss=0.062, reward_mean=0.410, reward_bound=0.098, batch=206\n",
      "10590: loss=0.064, reward_mean=0.440, reward_bound=0.109, batch=203\n",
      "10591: loss=0.060, reward_mean=0.460, reward_bound=0.122, batch=207\n",
      "10592: loss=0.062, reward_mean=0.420, reward_bound=0.135, batch=207\n",
      "10593: loss=0.065, reward_mean=0.360, reward_bound=0.150, batch=203\n",
      "10594: loss=0.066, reward_mean=0.380, reward_bound=0.167, batch=198\n",
      "10595: loss=0.071, reward_mean=0.480, reward_bound=0.185, batch=194\n",
      "10596: loss=0.076, reward_mean=0.440, reward_bound=0.206, batch=180\n",
      "10597: loss=0.072, reward_mean=0.380, reward_bound=0.131, batch=196\n",
      "10598: loss=0.070, reward_mean=0.540, reward_bound=0.150, batch=206\n",
      "10599: loss=0.071, reward_mean=0.440, reward_bound=0.185, batch=210\n",
      "10600: loss=0.070, reward_mean=0.450, reward_bound=0.206, batch=219\n",
      "10601: loss=0.070, reward_mean=0.480, reward_bound=0.229, batch=189\n",
      "10602: loss=0.072, reward_mean=0.440, reward_bound=0.229, batch=201\n",
      "10603: loss=0.069, reward_mean=0.520, reward_bound=0.254, batch=179\n",
      "10604: loss=0.069, reward_mean=0.420, reward_bound=0.135, batch=194\n",
      "10605: loss=0.072, reward_mean=0.490, reward_bound=0.183, batch=206\n",
      "10606: loss=0.074, reward_mean=0.450, reward_bound=0.196, batch=214\n",
      "10607: loss=0.074, reward_mean=0.440, reward_bound=0.206, batch=217\n",
      "10608: loss=0.073, reward_mean=0.540, reward_bound=0.254, batch=213\n",
      "10609: loss=0.070, reward_mean=0.490, reward_bound=0.282, batch=181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10610: loss=0.076, reward_mean=0.450, reward_bound=0.135, batch=196\n",
      "10611: loss=0.075, reward_mean=0.510, reward_bound=0.178, batch=207\n",
      "10612: loss=0.073, reward_mean=0.440, reward_bound=0.206, batch=214\n",
      "10613: loss=0.072, reward_mean=0.400, reward_bound=0.229, batch=217\n",
      "10614: loss=0.070, reward_mean=0.470, reward_bound=0.254, batch=212\n",
      "10615: loss=0.070, reward_mean=0.450, reward_bound=0.282, batch=211\n",
      "10616: loss=0.070, reward_mean=0.490, reward_bound=0.314, batch=169\n",
      "10617: loss=0.066, reward_mean=0.440, reward_bound=0.065, batch=187\n",
      "10618: loss=0.069, reward_mean=0.400, reward_bound=0.087, batch=201\n",
      "10619: loss=0.074, reward_mean=0.330, reward_bound=0.109, batch=206\n",
      "10620: loss=0.071, reward_mean=0.490, reward_bound=0.167, batch=211\n",
      "10621: loss=0.072, reward_mean=0.430, reward_bound=0.206, batch=215\n",
      "10622: loss=0.071, reward_mean=0.440, reward_bound=0.229, batch=214\n",
      "10623: loss=0.073, reward_mean=0.440, reward_bound=0.254, batch=212\n",
      "10624: loss=0.074, reward_mean=0.410, reward_bound=0.254, batch=217\n",
      "10625: loss=0.072, reward_mean=0.470, reward_bound=0.245, batch=222\n",
      "10626: loss=0.069, reward_mean=0.470, reward_bound=0.282, batch=216\n",
      "10627: loss=0.069, reward_mean=0.390, reward_bound=0.314, batch=207\n",
      "10628: loss=0.069, reward_mean=0.460, reward_bound=0.206, batch=214\n",
      "10629: loss=0.069, reward_mean=0.450, reward_bound=0.282, batch=219\n",
      "10630: loss=0.070, reward_mean=0.490, reward_bound=0.254, batch=221\n",
      "10631: loss=0.070, reward_mean=0.470, reward_bound=0.314, batch=219\n",
      "10632: loss=0.066, reward_mean=0.460, reward_bound=0.349, batch=160\n",
      "10633: loss=0.068, reward_mean=0.420, reward_bound=0.135, batch=180\n",
      "10634: loss=0.068, reward_mean=0.470, reward_bound=0.122, batch=193\n",
      "10635: loss=0.064, reward_mean=0.460, reward_bound=0.130, batch=205\n",
      "10636: loss=0.069, reward_mean=0.420, reward_bound=0.135, batch=211\n",
      "10637: loss=0.073, reward_mean=0.560, reward_bound=0.185, batch=213\n",
      "10638: loss=0.066, reward_mean=0.390, reward_bound=0.206, batch=215\n",
      "10639: loss=0.068, reward_mean=0.430, reward_bound=0.229, batch=216\n",
      "10640: loss=0.065, reward_mean=0.380, reward_bound=0.254, batch=214\n",
      "10641: loss=0.064, reward_mean=0.460, reward_bound=0.280, batch=220\n",
      "10642: loss=0.065, reward_mean=0.390, reward_bound=0.282, batch=220\n",
      "10643: loss=0.068, reward_mean=0.460, reward_bound=0.314, batch=211\n",
      "10644: loss=0.068, reward_mean=0.420, reward_bound=0.254, batch=216\n",
      "10645: loss=0.069, reward_mean=0.470, reward_bound=0.282, batch=220\n",
      "10646: loss=0.069, reward_mean=0.410, reward_bound=0.338, batch=224\n",
      "10647: loss=0.068, reward_mean=0.490, reward_bound=0.345, batch=227\n",
      "10648: loss=0.067, reward_mean=0.440, reward_bound=0.349, batch=214\n",
      "10649: loss=0.067, reward_mean=0.550, reward_bound=0.252, batch=220\n",
      "10650: loss=0.066, reward_mean=0.430, reward_bound=0.274, batch=224\n",
      "10651: loss=0.067, reward_mean=0.410, reward_bound=0.311, batch=227\n",
      "10652: loss=0.067, reward_mean=0.450, reward_bound=0.314, batch=228\n",
      "10653: loss=0.067, reward_mean=0.460, reward_bound=0.317, batch=229\n",
      "10654: loss=0.068, reward_mean=0.460, reward_bound=0.349, batch=224\n",
      "10655: loss=0.067, reward_mean=0.430, reward_bound=0.311, batch=227\n",
      "10656: loss=0.068, reward_mean=0.520, reward_bound=0.342, batch=229\n",
      "10657: loss=0.068, reward_mean=0.470, reward_bound=0.349, batch=229\n",
      "10658: loss=0.064, reward_mean=0.440, reward_bound=0.387, batch=147\n",
      "10659: loss=0.062, reward_mean=0.360, reward_bound=0.014, batch=173\n",
      "10660: loss=0.056, reward_mean=0.390, reward_bound=0.058, batch=189\n",
      "10661: loss=0.060, reward_mean=0.430, reward_bound=0.080, batch=201\n",
      "10662: loss=0.056, reward_mean=0.380, reward_bound=0.109, batch=209\n",
      "10663: loss=0.058, reward_mean=0.470, reward_bound=0.150, batch=213\n",
      "10664: loss=0.056, reward_mean=0.340, reward_bound=0.167, batch=208\n",
      "10665: loss=0.058, reward_mean=0.400, reward_bound=0.185, batch=213\n",
      "10666: loss=0.059, reward_mean=0.400, reward_bound=0.206, batch=211\n",
      "10667: loss=0.054, reward_mean=0.500, reward_bound=0.229, batch=214\n",
      "10668: loss=0.056, reward_mean=0.370, reward_bound=0.254, batch=209\n",
      "10669: loss=0.055, reward_mean=0.480, reward_bound=0.229, batch=214\n",
      "10670: loss=0.055, reward_mean=0.380, reward_bound=0.204, batch=220\n",
      "10671: loss=0.053, reward_mean=0.460, reward_bound=0.254, batch=223\n",
      "10672: loss=0.055, reward_mean=0.450, reward_bound=0.282, batch=210\n",
      "10673: loss=0.054, reward_mean=0.370, reward_bound=0.247, batch=217\n",
      "10674: loss=0.052, reward_mean=0.420, reward_bound=0.277, batch=222\n",
      "10675: loss=0.060, reward_mean=0.500, reward_bound=0.314, batch=204\n",
      "10676: loss=0.057, reward_mean=0.450, reward_bound=0.252, batch=213\n",
      "10677: loss=0.059, reward_mean=0.330, reward_bound=0.254, batch=218\n",
      "10678: loss=0.059, reward_mean=0.500, reward_bound=0.229, batch=220\n",
      "10679: loss=0.061, reward_mean=0.460, reward_bound=0.282, batch=222\n",
      "10680: loss=0.061, reward_mean=0.340, reward_bound=0.254, batch=225\n",
      "10681: loss=0.061, reward_mean=0.570, reward_bound=0.314, batch=222\n",
      "10682: loss=0.062, reward_mean=0.400, reward_bound=0.349, batch=202\n",
      "10683: loss=0.063, reward_mean=0.510, reward_bound=0.179, batch=211\n",
      "10684: loss=0.064, reward_mean=0.460, reward_bound=0.229, batch=215\n",
      "10685: loss=0.065, reward_mean=0.490, reward_bound=0.254, batch=219\n",
      "10686: loss=0.064, reward_mean=0.440, reward_bound=0.314, batch=215\n",
      "10687: loss=0.063, reward_mean=0.400, reward_bound=0.234, batch=220\n",
      "10688: loss=0.064, reward_mean=0.400, reward_bound=0.282, batch=223\n",
      "10689: loss=0.067, reward_mean=0.490, reward_bound=0.349, batch=221\n",
      "10690: loss=0.067, reward_mean=0.460, reward_bound=0.314, batch=224\n",
      "10691: loss=0.066, reward_mean=0.430, reward_bound=0.345, batch=227\n",
      "10692: loss=0.066, reward_mean=0.440, reward_bound=0.380, batch=229\n",
      "10693: loss=0.062, reward_mean=0.430, reward_bound=0.387, batch=200\n",
      "10694: loss=0.062, reward_mean=0.430, reward_bound=0.185, batch=208\n",
      "10695: loss=0.064, reward_mean=0.480, reward_bound=0.190, batch=215\n",
      "10696: loss=0.063, reward_mean=0.500, reward_bound=0.260, batch=220\n",
      "10697: loss=0.062, reward_mean=0.470, reward_bound=0.282, batch=223\n",
      "10698: loss=0.062, reward_mean=0.490, reward_bound=0.271, batch=226\n",
      "10699: loss=0.059, reward_mean=0.390, reward_bound=0.314, batch=219\n",
      "10700: loss=0.058, reward_mean=0.400, reward_bound=0.239, batch=223\n",
      "10701: loss=0.059, reward_mean=0.420, reward_bound=0.335, batch=226\n",
      "10702: loss=0.062, reward_mean=0.450, reward_bound=0.349, batch=219\n",
      "10703: loss=0.062, reward_mean=0.430, reward_bound=0.364, batch=223\n",
      "10704: loss=0.063, reward_mean=0.420, reward_bound=0.387, batch=219\n",
      "10705: loss=0.061, reward_mean=0.420, reward_bound=0.295, batch=223\n",
      "10706: loss=0.062, reward_mean=0.490, reward_bound=0.349, batch=222\n",
      "10707: loss=0.063, reward_mean=0.460, reward_bound=0.373, batch=225\n",
      "10708: loss=0.075, reward_mean=0.420, reward_bound=0.430, batch=113\n",
      "10709: loss=0.079, reward_mean=0.510, reward_bound=0.034, batch=148\n",
      "10710: loss=0.073, reward_mean=0.370, reward_bound=0.035, batch=173\n",
      "10711: loss=0.074, reward_mean=0.450, reward_bound=0.047, batch=190\n",
      "10712: loss=0.073, reward_mean=0.450, reward_bound=0.080, batch=200\n",
      "10713: loss=0.072, reward_mean=0.470, reward_bound=0.089, batch=209\n",
      "10714: loss=0.080, reward_mean=0.450, reward_bound=0.114, batch=216\n",
      "10715: loss=0.076, reward_mean=0.420, reward_bound=0.122, batch=217\n",
      "10716: loss=0.078, reward_mean=0.410, reward_bound=0.135, batch=221\n",
      "10717: loss=0.078, reward_mean=0.460, reward_bound=0.167, batch=218\n",
      "10718: loss=0.078, reward_mean=0.400, reward_bound=0.185, batch=217\n",
      "10719: loss=0.080, reward_mean=0.460, reward_bound=0.206, batch=216\n",
      "10720: loss=0.078, reward_mean=0.430, reward_bound=0.229, batch=199\n",
      "10721: loss=0.080, reward_mean=0.430, reward_bound=0.239, batch=209\n",
      "10722: loss=0.078, reward_mean=0.460, reward_bound=0.225, batch=216\n",
      "10723: loss=0.075, reward_mean=0.450, reward_bound=0.254, batch=211\n",
      "10724: loss=0.074, reward_mean=0.530, reward_bound=0.282, batch=198\n",
      "10725: loss=0.075, reward_mean=0.480, reward_bound=0.187, batch=208\n",
      "10726: loss=0.074, reward_mean=0.410, reward_bound=0.206, batch=214\n",
      "10727: loss=0.075, reward_mean=0.510, reward_bound=0.254, batch=217\n",
      "10728: loss=0.075, reward_mean=0.450, reward_bound=0.282, batch=221\n",
      "10729: loss=0.068, reward_mean=0.410, reward_bound=0.314, batch=200\n",
      "10730: loss=0.068, reward_mean=0.440, reward_bound=0.247, batch=210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10731: loss=0.066, reward_mean=0.440, reward_bound=0.247, batch=217\n",
      "10732: loss=0.068, reward_mean=0.450, reward_bound=0.254, batch=221\n",
      "10733: loss=0.069, reward_mean=0.330, reward_bound=0.282, batch=219\n",
      "10734: loss=0.068, reward_mean=0.430, reward_bound=0.314, batch=218\n",
      "10735: loss=0.068, reward_mean=0.380, reward_bound=0.254, batch=221\n",
      "10736: loss=0.067, reward_mean=0.500, reward_bound=0.282, batch=223\n",
      "10737: loss=0.073, reward_mean=0.510, reward_bound=0.349, batch=191\n",
      "10738: loss=0.072, reward_mean=0.520, reward_bound=0.229, batch=202\n",
      "10739: loss=0.071, reward_mean=0.390, reward_bound=0.213, batch=211\n",
      "10740: loss=0.073, reward_mean=0.520, reward_bound=0.206, batch=217\n",
      "10741: loss=0.072, reward_mean=0.420, reward_bound=0.249, batch=222\n",
      "10742: loss=0.072, reward_mean=0.410, reward_bound=0.254, batch=220\n",
      "10743: loss=0.073, reward_mean=0.470, reward_bound=0.282, batch=215\n",
      "10744: loss=0.073, reward_mean=0.480, reward_bound=0.234, batch=220\n",
      "10745: loss=0.073, reward_mean=0.520, reward_bound=0.229, batch=223\n",
      "10746: loss=0.074, reward_mean=0.470, reward_bound=0.314, batch=219\n",
      "10747: loss=0.075, reward_mean=0.490, reward_bound=0.328, batch=223\n",
      "10748: loss=0.073, reward_mean=0.490, reward_bound=0.349, batch=218\n",
      "10749: loss=0.073, reward_mean=0.500, reward_bound=0.317, batch=222\n",
      "10750: loss=0.075, reward_mean=0.460, reward_bound=0.387, batch=184\n",
      "10751: loss=0.077, reward_mean=0.420, reward_bound=0.134, batch=199\n",
      "10752: loss=0.073, reward_mean=0.390, reward_bound=0.102, batch=209\n",
      "10753: loss=0.073, reward_mean=0.440, reward_bound=0.174, batch=216\n",
      "10754: loss=0.071, reward_mean=0.490, reward_bound=0.206, batch=220\n",
      "10755: loss=0.073, reward_mean=0.430, reward_bound=0.247, batch=224\n",
      "10756: loss=0.074, reward_mean=0.570, reward_bound=0.254, batch=225\n",
      "10757: loss=0.074, reward_mean=0.470, reward_bound=0.282, batch=222\n",
      "10758: loss=0.073, reward_mean=0.510, reward_bound=0.314, batch=217\n",
      "10759: loss=0.074, reward_mean=0.430, reward_bound=0.342, batch=222\n",
      "10760: loss=0.074, reward_mean=0.430, reward_bound=0.314, batch=224\n",
      "10761: loss=0.073, reward_mean=0.460, reward_bound=0.349, batch=222\n",
      "10762: loss=0.071, reward_mean=0.440, reward_bound=0.387, batch=211\n",
      "10763: loss=0.074, reward_mean=0.420, reward_bound=0.254, batch=215\n",
      "10764: loss=0.075, reward_mean=0.400, reward_bound=0.282, batch=217\n",
      "10765: loss=0.076, reward_mean=0.470, reward_bound=0.308, batch=222\n",
      "10766: loss=0.076, reward_mean=0.440, reward_bound=0.314, batch=222\n",
      "10767: loss=0.072, reward_mean=0.480, reward_bound=0.349, batch=223\n",
      "10768: loss=0.072, reward_mean=0.440, reward_bound=0.387, batch=220\n",
      "10769: loss=0.072, reward_mean=0.530, reward_bound=0.349, batch=223\n",
      "10770: loss=0.073, reward_mean=0.450, reward_bound=0.271, batch=226\n",
      "10771: loss=0.071, reward_mean=0.340, reward_bound=0.298, batch=228\n",
      "10772: loss=0.072, reward_mean=0.420, reward_bound=0.353, batch=229\n",
      "10773: loss=0.072, reward_mean=0.450, reward_bound=0.387, batch=227\n",
      "10774: loss=0.070, reward_mean=0.410, reward_bound=0.430, batch=173\n",
      "10775: loss=0.070, reward_mean=0.440, reward_bound=0.117, batch=191\n",
      "10776: loss=0.068, reward_mean=0.350, reward_bound=0.150, batch=200\n",
      "10777: loss=0.066, reward_mean=0.460, reward_bound=0.162, batch=210\n",
      "10778: loss=0.061, reward_mean=0.340, reward_bound=0.167, batch=213\n",
      "10779: loss=0.064, reward_mean=0.420, reward_bound=0.206, batch=217\n",
      "10780: loss=0.063, reward_mean=0.530, reward_bound=0.229, batch=219\n",
      "10781: loss=0.062, reward_mean=0.410, reward_bound=0.254, batch=215\n",
      "10782: loss=0.064, reward_mean=0.320, reward_bound=0.282, batch=212\n",
      "10783: loss=0.065, reward_mean=0.400, reward_bound=0.314, batch=207\n",
      "10784: loss=0.063, reward_mean=0.420, reward_bound=0.314, batch=213\n",
      "10785: loss=0.063, reward_mean=0.460, reward_bound=0.335, batch=219\n",
      "10786: loss=0.064, reward_mean=0.450, reward_bound=0.229, batch=222\n",
      "10787: loss=0.070, reward_mean=0.420, reward_bound=0.349, batch=214\n",
      "10788: loss=0.069, reward_mean=0.440, reward_bound=0.349, batch=218\n",
      "10789: loss=0.069, reward_mean=0.480, reward_bound=0.353, batch=222\n",
      "10790: loss=0.068, reward_mean=0.470, reward_bound=0.336, batch=225\n",
      "10791: loss=0.068, reward_mean=0.440, reward_bound=0.356, batch=227\n",
      "10792: loss=0.069, reward_mean=0.470, reward_bound=0.342, batch=229\n",
      "10793: loss=0.067, reward_mean=0.520, reward_bound=0.387, batch=211\n",
      "10794: loss=0.068, reward_mean=0.460, reward_bound=0.314, batch=217\n",
      "10795: loss=0.067, reward_mean=0.420, reward_bound=0.314, batch=221\n",
      "10796: loss=0.067, reward_mean=0.450, reward_bound=0.314, batch=224\n",
      "10797: loss=0.068, reward_mean=0.430, reward_bound=0.311, batch=227\n",
      "10798: loss=0.068, reward_mean=0.500, reward_bound=0.314, batch=227\n",
      "10799: loss=0.068, reward_mean=0.420, reward_bound=0.342, batch=229\n",
      "10800: loss=0.068, reward_mean=0.560, reward_bound=0.364, batch=230\n",
      "10801: loss=0.068, reward_mean=0.580, reward_bound=0.376, batch=231\n",
      "10802: loss=0.069, reward_mean=0.460, reward_bound=0.387, batch=226\n",
      "10803: loss=0.068, reward_mean=0.520, reward_bound=0.351, batch=228\n",
      "10804: loss=0.069, reward_mean=0.520, reward_bound=0.392, batch=229\n",
      "10805: loss=0.068, reward_mean=0.550, reward_bound=0.430, batch=200\n",
      "10806: loss=0.071, reward_mean=0.420, reward_bound=0.122, batch=209\n",
      "10807: loss=0.071, reward_mean=0.410, reward_bound=0.185, batch=215\n",
      "10808: loss=0.072, reward_mean=0.480, reward_bound=0.210, batch=220\n",
      "10809: loss=0.071, reward_mean=0.480, reward_bound=0.282, batch=220\n",
      "10810: loss=0.071, reward_mean=0.450, reward_bound=0.274, batch=224\n",
      "10811: loss=0.070, reward_mean=0.470, reward_bound=0.280, batch=227\n",
      "10812: loss=0.069, reward_mean=0.440, reward_bound=0.314, batch=222\n",
      "10813: loss=0.069, reward_mean=0.460, reward_bound=0.324, batch=225\n",
      "10814: loss=0.070, reward_mean=0.480, reward_bound=0.349, batch=225\n",
      "10815: loss=0.072, reward_mean=0.510, reward_bound=0.329, batch=227\n",
      "10816: loss=0.071, reward_mean=0.460, reward_bound=0.380, batch=229\n",
      "10817: loss=0.070, reward_mean=0.480, reward_bound=0.387, batch=222\n",
      "10818: loss=0.069, reward_mean=0.450, reward_bound=0.314, batch=224\n",
      "10819: loss=0.071, reward_mean=0.420, reward_bound=0.387, batch=226\n",
      "10820: loss=0.071, reward_mean=0.460, reward_bound=0.390, batch=228\n",
      "10821: loss=0.070, reward_mean=0.450, reward_bound=0.430, batch=219\n",
      "10822: loss=0.069, reward_mean=0.460, reward_bound=0.430, batch=222\n",
      "10823: loss=0.070, reward_mean=0.460, reward_bound=0.360, batch=225\n",
      "10824: loss=0.070, reward_mean=0.390, reward_bound=0.387, batch=226\n",
      "10825: loss=0.069, reward_mean=0.490, reward_bound=0.409, batch=228\n",
      "10826: loss=0.069, reward_mean=0.390, reward_bound=0.357, batch=229\n",
      "10827: loss=0.070, reward_mean=0.420, reward_bound=0.430, batch=226\n",
      "10828: loss=0.069, reward_mean=0.380, reward_bound=0.433, batch=228\n",
      "10829: loss=0.069, reward_mean=0.410, reward_bound=0.430, batch=228\n",
      "10830: loss=0.069, reward_mean=0.440, reward_bound=0.430, batch=228\n",
      "10831: loss=0.069, reward_mean=0.480, reward_bound=0.435, batch=229\n",
      "10832: loss=0.069, reward_mean=0.460, reward_bound=0.387, batch=229\n",
      "10833: loss=0.069, reward_mean=0.490, reward_bound=0.405, batch=230\n",
      "10834: loss=0.069, reward_mean=0.430, reward_bound=0.418, batch=231\n",
      "10835: loss=0.069, reward_mean=0.470, reward_bound=0.314, batch=231\n",
      "10836: loss=0.069, reward_mean=0.400, reward_bound=0.430, batch=229\n",
      "10837: loss=0.069, reward_mean=0.470, reward_bound=0.450, batch=230\n",
      "10838: loss=0.064, reward_mean=0.490, reward_bound=0.478, batch=93\n",
      "10839: loss=0.062, reward_mean=0.490, reward_bound=0.011, batch=135\n",
      "10840: loss=0.064, reward_mean=0.470, reward_bound=0.026, batch=164\n",
      "10841: loss=0.067, reward_mean=0.440, reward_bound=0.052, batch=185\n",
      "10842: loss=0.057, reward_mean=0.450, reward_bound=0.065, batch=192\n",
      "10843: loss=0.061, reward_mean=0.400, reward_bound=0.080, batch=199\n",
      "10844: loss=0.069, reward_mean=0.430, reward_bound=0.098, batch=206\n",
      "10845: loss=0.067, reward_mean=0.420, reward_bound=0.150, batch=209\n",
      "10846: loss=0.064, reward_mean=0.530, reward_bound=0.167, batch=209\n",
      "10847: loss=0.060, reward_mean=0.520, reward_bound=0.194, batch=216\n",
      "10848: loss=0.063, reward_mean=0.460, reward_bound=0.206, batch=220\n",
      "10849: loss=0.065, reward_mean=0.480, reward_bound=0.229, batch=209\n",
      "10850: loss=0.066, reward_mean=0.410, reward_bound=0.239, batch=216\n",
      "10851: loss=0.066, reward_mean=0.420, reward_bound=0.196, batch=221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10852: loss=0.068, reward_mean=0.410, reward_bound=0.254, batch=197\n",
      "10853: loss=0.067, reward_mean=0.450, reward_bound=0.150, batch=207\n",
      "10854: loss=0.069, reward_mean=0.430, reward_bound=0.206, batch=214\n",
      "10855: loss=0.072, reward_mean=0.440, reward_bound=0.229, batch=219\n",
      "10856: loss=0.069, reward_mean=0.400, reward_bound=0.254, batch=220\n",
      "10857: loss=0.065, reward_mean=0.450, reward_bound=0.282, batch=195\n",
      "10858: loss=0.066, reward_mean=0.480, reward_bound=0.153, batch=206\n",
      "10859: loss=0.065, reward_mean=0.460, reward_bound=0.176, batch=214\n",
      "10860: loss=0.067, reward_mean=0.560, reward_bound=0.226, batch=220\n",
      "10861: loss=0.065, reward_mean=0.450, reward_bound=0.229, batch=223\n",
      "10862: loss=0.067, reward_mean=0.460, reward_bound=0.254, batch=220\n",
      "10863: loss=0.066, reward_mean=0.410, reward_bound=0.282, batch=220\n",
      "10864: loss=0.067, reward_mean=0.440, reward_bound=0.314, batch=201\n",
      "10865: loss=0.069, reward_mean=0.440, reward_bound=0.167, batch=209\n",
      "10866: loss=0.068, reward_mean=0.500, reward_bound=0.282, batch=215\n",
      "10867: loss=0.067, reward_mean=0.470, reward_bound=0.314, batch=219\n",
      "10868: loss=0.068, reward_mean=0.560, reward_bound=0.254, batch=222\n",
      "10869: loss=0.067, reward_mean=0.490, reward_bound=0.314, batch=224\n",
      "10870: loss=0.067, reward_mean=0.410, reward_bound=0.345, batch=227\n",
      "10871: loss=0.069, reward_mean=0.480, reward_bound=0.349, batch=189\n",
      "10872: loss=0.074, reward_mean=0.470, reward_bound=0.239, batch=202\n",
      "10873: loss=0.078, reward_mean=0.480, reward_bound=0.155, batch=211\n",
      "10874: loss=0.074, reward_mean=0.460, reward_bound=0.206, batch=216\n",
      "10875: loss=0.074, reward_mean=0.390, reward_bound=0.241, batch=221\n",
      "10876: loss=0.073, reward_mean=0.490, reward_bound=0.282, batch=218\n",
      "10877: loss=0.073, reward_mean=0.550, reward_bound=0.314, batch=214\n",
      "10878: loss=0.072, reward_mean=0.430, reward_bound=0.206, batch=218\n",
      "10879: loss=0.072, reward_mean=0.380, reward_bound=0.257, batch=222\n",
      "10880: loss=0.071, reward_mean=0.380, reward_bound=0.282, batch=224\n",
      "10881: loss=0.073, reward_mean=0.480, reward_bound=0.314, batch=222\n",
      "10882: loss=0.074, reward_mean=0.410, reward_bound=0.263, batch=225\n",
      "10883: loss=0.075, reward_mean=0.520, reward_bound=0.289, batch=227\n",
      "10884: loss=0.072, reward_mean=0.520, reward_bound=0.342, batch=229\n",
      "10885: loss=0.072, reward_mean=0.440, reward_bound=0.349, batch=223\n",
      "10886: loss=0.071, reward_mean=0.400, reward_bound=0.387, batch=184\n",
      "10887: loss=0.075, reward_mean=0.500, reward_bound=0.204, batch=199\n",
      "10888: loss=0.075, reward_mean=0.450, reward_bound=0.206, batch=206\n",
      "10889: loss=0.073, reward_mean=0.430, reward_bound=0.229, batch=212\n",
      "10890: loss=0.071, reward_mean=0.500, reward_bound=0.254, batch=215\n",
      "10891: loss=0.072, reward_mean=0.470, reward_bound=0.289, batch=220\n",
      "10892: loss=0.071, reward_mean=0.520, reward_bound=0.314, batch=217\n",
      "10893: loss=0.070, reward_mean=0.410, reward_bound=0.254, batch=221\n",
      "10894: loss=0.070, reward_mean=0.500, reward_bound=0.282, batch=224\n",
      "10895: loss=0.072, reward_mean=0.460, reward_bound=0.349, batch=215\n",
      "10896: loss=0.070, reward_mean=0.420, reward_bound=0.281, batch=220\n",
      "10897: loss=0.071, reward_mean=0.500, reward_bound=0.314, batch=223\n",
      "10898: loss=0.071, reward_mean=0.490, reward_bound=0.358, batch=226\n",
      "10899: loss=0.071, reward_mean=0.440, reward_bound=0.387, batch=213\n",
      "10900: loss=0.070, reward_mean=0.330, reward_bound=0.219, batch=219\n",
      "10901: loss=0.073, reward_mean=0.410, reward_bound=0.282, batch=221\n",
      "10902: loss=0.072, reward_mean=0.460, reward_bound=0.314, batch=222\n",
      "10903: loss=0.071, reward_mean=0.420, reward_bound=0.282, batch=224\n",
      "10904: loss=0.072, reward_mean=0.410, reward_bound=0.380, batch=227\n",
      "10905: loss=0.070, reward_mean=0.460, reward_bound=0.387, batch=224\n",
      "10906: loss=0.070, reward_mean=0.480, reward_bound=0.384, batch=227\n",
      "10907: loss=0.070, reward_mean=0.370, reward_bound=0.314, batch=228\n",
      "10908: loss=0.073, reward_mean=0.500, reward_bound=0.430, batch=178\n",
      "10909: loss=0.074, reward_mean=0.380, reward_bound=0.111, batch=194\n",
      "10910: loss=0.078, reward_mean=0.420, reward_bound=0.135, batch=205\n",
      "10911: loss=0.078, reward_mean=0.350, reward_bound=0.167, batch=208\n",
      "10912: loss=0.077, reward_mean=0.480, reward_bound=0.185, batch=214\n",
      "10913: loss=0.076, reward_mean=0.460, reward_bound=0.252, batch=220\n",
      "10914: loss=0.078, reward_mean=0.450, reward_bound=0.254, batch=219\n",
      "10915: loss=0.078, reward_mean=0.520, reward_bound=0.282, batch=215\n",
      "10916: loss=0.077, reward_mean=0.520, reward_bound=0.314, batch=211\n",
      "10917: loss=0.075, reward_mean=0.470, reward_bound=0.282, batch=217\n",
      "10918: loss=0.076, reward_mean=0.540, reward_bound=0.314, batch=221\n",
      "10919: loss=0.076, reward_mean=0.440, reward_bound=0.314, batch=224\n",
      "10920: loss=0.078, reward_mean=0.560, reward_bound=0.349, batch=216\n",
      "10921: loss=0.078, reward_mean=0.440, reward_bound=0.314, batch=218\n",
      "10922: loss=0.077, reward_mean=0.480, reward_bound=0.353, batch=222\n",
      "10923: loss=0.076, reward_mean=0.410, reward_bound=0.387, batch=208\n",
      "10924: loss=0.075, reward_mean=0.440, reward_bound=0.206, batch=214\n",
      "10925: loss=0.076, reward_mean=0.480, reward_bound=0.254, batch=219\n",
      "10926: loss=0.076, reward_mean=0.490, reward_bound=0.282, batch=220\n",
      "10927: loss=0.077, reward_mean=0.480, reward_bound=0.314, batch=221\n",
      "10928: loss=0.075, reward_mean=0.470, reward_bound=0.349, batch=224\n",
      "10929: loss=0.076, reward_mean=0.460, reward_bound=0.387, batch=218\n",
      "10930: loss=0.075, reward_mean=0.450, reward_bound=0.387, batch=221\n",
      "10931: loss=0.074, reward_mean=0.540, reward_bound=0.430, batch=208\n",
      "10932: loss=0.075, reward_mean=0.440, reward_bound=0.282, batch=214\n",
      "10933: loss=0.074, reward_mean=0.410, reward_bound=0.305, batch=220\n",
      "10934: loss=0.072, reward_mean=0.500, reward_bound=0.314, batch=223\n",
      "10935: loss=0.071, reward_mean=0.550, reward_bound=0.335, batch=226\n",
      "10936: loss=0.073, reward_mean=0.440, reward_bound=0.349, batch=224\n",
      "10937: loss=0.074, reward_mean=0.470, reward_bound=0.384, batch=227\n",
      "10938: loss=0.075, reward_mean=0.440, reward_bound=0.387, batch=221\n",
      "10939: loss=0.074, reward_mean=0.450, reward_bound=0.349, batch=223\n",
      "10940: loss=0.074, reward_mean=0.390, reward_bound=0.229, batch=225\n",
      "10941: loss=0.073, reward_mean=0.400, reward_bound=0.387, batch=226\n",
      "10942: loss=0.074, reward_mean=0.480, reward_bound=0.409, batch=228\n",
      "10943: loss=0.074, reward_mean=0.390, reward_bound=0.392, batch=229\n",
      "10944: loss=0.074, reward_mean=0.440, reward_bound=0.430, batch=219\n",
      "10945: loss=0.075, reward_mean=0.380, reward_bound=0.314, batch=222\n",
      "10946: loss=0.075, reward_mean=0.420, reward_bound=0.349, batch=223\n",
      "10947: loss=0.074, reward_mean=0.410, reward_bound=0.349, batch=224\n",
      "10948: loss=0.075, reward_mean=0.470, reward_bound=0.384, batch=227\n",
      "10949: loss=0.075, reward_mean=0.440, reward_bound=0.349, batch=228\n",
      "10950: loss=0.074, reward_mean=0.420, reward_bound=0.430, batch=224\n",
      "10951: loss=0.075, reward_mean=0.510, reward_bound=0.474, batch=227\n",
      "10952: loss=0.075, reward_mean=0.520, reward_bound=0.387, batch=228\n",
      "10953: loss=0.074, reward_mean=0.480, reward_bound=0.353, batch=229\n",
      "10954: loss=0.074, reward_mean=0.540, reward_bound=0.405, batch=230\n",
      "10955: loss=0.074, reward_mean=0.540, reward_bound=0.430, batch=230\n",
      "10956: loss=0.076, reward_mean=0.480, reward_bound=0.478, batch=159\n",
      "10957: loss=0.081, reward_mean=0.450, reward_bound=0.083, batch=181\n",
      "10958: loss=0.083, reward_mean=0.490, reward_bound=0.135, batch=192\n",
      "10959: loss=0.081, reward_mean=0.390, reward_bound=0.155, batch=204\n",
      "10960: loss=0.075, reward_mean=0.470, reward_bound=0.185, batch=211\n",
      "10961: loss=0.077, reward_mean=0.510, reward_bound=0.229, batch=206\n",
      "10962: loss=0.079, reward_mean=0.500, reward_bound=0.196, batch=214\n",
      "10963: loss=0.075, reward_mean=0.470, reward_bound=0.254, batch=208\n",
      "10964: loss=0.077, reward_mean=0.420, reward_bound=0.187, batch=215\n",
      "10965: loss=0.078, reward_mean=0.450, reward_bound=0.234, batch=220\n",
      "10966: loss=0.075, reward_mean=0.490, reward_bound=0.254, batch=220\n",
      "10967: loss=0.075, reward_mean=0.400, reward_bound=0.274, batch=224\n",
      "10968: loss=0.077, reward_mean=0.400, reward_bound=0.282, batch=219\n",
      "10969: loss=0.077, reward_mean=0.440, reward_bound=0.295, batch=223\n",
      "10970: loss=0.080, reward_mean=0.480, reward_bound=0.314, batch=203\n",
      "10971: loss=0.081, reward_mean=0.490, reward_bound=0.229, batch=210\n",
      "10972: loss=0.081, reward_mean=0.470, reward_bound=0.254, batch=216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10973: loss=0.081, reward_mean=0.500, reward_bound=0.282, batch=220\n",
      "10974: loss=0.082, reward_mean=0.410, reward_bound=0.254, batch=222\n",
      "10975: loss=0.082, reward_mean=0.470, reward_bound=0.314, batch=221\n",
      "10976: loss=0.082, reward_mean=0.420, reward_bound=0.314, batch=223\n",
      "10977: loss=0.082, reward_mean=0.470, reward_bound=0.335, batch=226\n",
      "10978: loss=0.078, reward_mean=0.520, reward_bound=0.349, batch=211\n",
      "10979: loss=0.077, reward_mean=0.370, reward_bound=0.254, batch=215\n",
      "10980: loss=0.079, reward_mean=0.470, reward_bound=0.314, batch=219\n",
      "10981: loss=0.079, reward_mean=0.500, reward_bound=0.314, batch=222\n",
      "10982: loss=0.080, reward_mean=0.520, reward_bound=0.229, batch=224\n",
      "10983: loss=0.080, reward_mean=0.410, reward_bound=0.345, batch=227\n",
      "10984: loss=0.078, reward_mean=0.380, reward_bound=0.349, batch=223\n",
      "10985: loss=0.079, reward_mean=0.360, reward_bound=0.372, batch=226\n",
      "10986: loss=0.079, reward_mean=0.500, reward_bound=0.387, batch=206\n",
      "10987: loss=0.076, reward_mean=0.510, reward_bound=0.241, batch=214\n",
      "10988: loss=0.076, reward_mean=0.490, reward_bound=0.254, batch=218\n",
      "10989: loss=0.077, reward_mean=0.390, reward_bound=0.282, batch=221\n",
      "10990: loss=0.079, reward_mean=0.420, reward_bound=0.314, batch=218\n",
      "10991: loss=0.078, reward_mean=0.480, reward_bound=0.282, batch=221\n",
      "10992: loss=0.078, reward_mean=0.430, reward_bound=0.314, batch=224\n",
      "10993: loss=0.076, reward_mean=0.410, reward_bound=0.349, batch=224\n",
      "10994: loss=0.077, reward_mean=0.510, reward_bound=0.314, batch=226\n",
      "10995: loss=0.076, reward_mean=0.460, reward_bound=0.349, batch=226\n",
      "10996: loss=0.076, reward_mean=0.450, reward_bound=0.314, batch=227\n",
      "10997: loss=0.075, reward_mean=0.410, reward_bound=0.342, batch=229\n",
      "10998: loss=0.075, reward_mean=0.400, reward_bound=0.387, batch=221\n",
      "10999: loss=0.074, reward_mean=0.510, reward_bound=0.314, batch=224\n",
      "11000: loss=0.073, reward_mean=0.310, reward_bound=0.249, batch=227\n",
      "11001: loss=0.074, reward_mean=0.400, reward_bound=0.387, batch=223\n",
      "11002: loss=0.074, reward_mean=0.470, reward_bound=0.335, batch=226\n",
      "11003: loss=0.074, reward_mean=0.440, reward_bound=0.387, batch=227\n",
      "11004: loss=0.073, reward_mean=0.450, reward_bound=0.380, batch=229\n",
      "11005: loss=0.073, reward_mean=0.510, reward_bound=0.387, batch=229\n",
      "11006: loss=0.073, reward_mean=0.450, reward_bound=0.405, batch=230\n",
      "11007: loss=0.074, reward_mean=0.430, reward_bound=0.430, batch=201\n",
      "11008: loss=0.072, reward_mean=0.400, reward_bound=0.282, batch=209\n",
      "11009: loss=0.075, reward_mean=0.450, reward_bound=0.174, batch=216\n",
      "11010: loss=0.073, reward_mean=0.500, reward_bound=0.241, batch=221\n",
      "11011: loss=0.074, reward_mean=0.510, reward_bound=0.282, batch=221\n",
      "11012: loss=0.075, reward_mean=0.400, reward_bound=0.314, batch=221\n",
      "11013: loss=0.074, reward_mean=0.360, reward_bound=0.206, batch=224\n",
      "11014: loss=0.076, reward_mean=0.490, reward_bound=0.349, batch=220\n",
      "11015: loss=0.077, reward_mean=0.460, reward_bound=0.387, batch=219\n",
      "11016: loss=0.076, reward_mean=0.530, reward_bound=0.387, batch=220\n",
      "11017: loss=0.077, reward_mean=0.430, reward_bound=0.266, batch=224\n",
      "11018: loss=0.077, reward_mean=0.390, reward_bound=0.311, batch=227\n",
      "11019: loss=0.077, reward_mean=0.410, reward_bound=0.314, batch=227\n",
      "11020: loss=0.077, reward_mean=0.440, reward_bound=0.342, batch=229\n",
      "11021: loss=0.077, reward_mean=0.500, reward_bound=0.349, batch=225\n",
      "11022: loss=0.078, reward_mean=0.400, reward_bound=0.303, batch=227\n",
      "11023: loss=0.079, reward_mean=0.460, reward_bound=0.387, batch=228\n",
      "11024: loss=0.080, reward_mean=0.470, reward_bound=0.321, batch=229\n",
      "11025: loss=0.076, reward_mean=0.450, reward_bound=0.430, batch=222\n",
      "11026: loss=0.077, reward_mean=0.440, reward_bound=0.282, batch=223\n",
      "11027: loss=0.076, reward_mean=0.460, reward_bound=0.372, batch=226\n",
      "11028: loss=0.078, reward_mean=0.460, reward_bound=0.430, batch=226\n",
      "11029: loss=0.077, reward_mean=0.410, reward_bound=0.387, batch=227\n",
      "11030: loss=0.077, reward_mean=0.450, reward_bound=0.430, batch=227\n",
      "11031: loss=0.077, reward_mean=0.430, reward_bound=0.335, batch=229\n",
      "11032: loss=0.077, reward_mean=0.530, reward_bound=0.424, batch=230\n",
      "11033: loss=0.076, reward_mean=0.430, reward_bound=0.376, batch=231\n",
      "11034: loss=0.077, reward_mean=0.420, reward_bound=0.387, batch=231\n",
      "11035: loss=0.077, reward_mean=0.520, reward_bound=0.430, batch=231\n",
      "11036: loss=0.078, reward_mean=0.440, reward_bound=0.478, batch=193\n",
      "11037: loss=0.076, reward_mean=0.380, reward_bound=0.185, batch=204\n",
      "11038: loss=0.080, reward_mean=0.500, reward_bound=0.229, batch=212\n",
      "11039: loss=0.078, reward_mean=0.500, reward_bound=0.282, batch=214\n",
      "11040: loss=0.075, reward_mean=0.510, reward_bound=0.314, batch=213\n",
      "11041: loss=0.074, reward_mean=0.410, reward_bound=0.322, batch=219\n",
      "11042: loss=0.076, reward_mean=0.420, reward_bound=0.349, batch=219\n",
      "11043: loss=0.076, reward_mean=0.530, reward_bound=0.349, batch=222\n",
      "11044: loss=0.075, reward_mean=0.420, reward_bound=0.292, batch=225\n",
      "11045: loss=0.076, reward_mean=0.540, reward_bound=0.329, batch=227\n",
      "11046: loss=0.075, reward_mean=0.450, reward_bound=0.380, batch=229\n",
      "11047: loss=0.077, reward_mean=0.400, reward_bound=0.387, batch=213\n",
      "11048: loss=0.078, reward_mean=0.530, reward_bound=0.322, batch=219\n",
      "11049: loss=0.077, reward_mean=0.450, reward_bound=0.349, batch=221\n",
      "11050: loss=0.077, reward_mean=0.430, reward_bound=0.349, batch=224\n",
      "11051: loss=0.078, reward_mean=0.400, reward_bound=0.280, batch=227\n",
      "11052: loss=0.076, reward_mean=0.450, reward_bound=0.314, batch=227\n",
      "11053: loss=0.077, reward_mean=0.470, reward_bound=0.314, batch=228\n",
      "11054: loss=0.075, reward_mean=0.460, reward_bound=0.387, batch=226\n",
      "11055: loss=0.078, reward_mean=0.360, reward_bound=0.430, batch=210\n",
      "11056: loss=0.076, reward_mean=0.420, reward_bound=0.304, batch=217\n",
      "11057: loss=0.075, reward_mean=0.420, reward_bound=0.229, batch=221\n",
      "11058: loss=0.077, reward_mean=0.540, reward_bound=0.282, batch=223\n",
      "11059: loss=0.076, reward_mean=0.460, reward_bound=0.314, batch=223\n",
      "11060: loss=0.076, reward_mean=0.470, reward_bound=0.322, batch=226\n",
      "11061: loss=0.076, reward_mean=0.480, reward_bound=0.349, batch=222\n",
      "11062: loss=0.076, reward_mean=0.460, reward_bound=0.387, batch=222\n",
      "11063: loss=0.075, reward_mean=0.440, reward_bound=0.324, batch=225\n",
      "11064: loss=0.075, reward_mean=0.420, reward_bound=0.349, batch=226\n",
      "11065: loss=0.075, reward_mean=0.380, reward_bound=0.331, batch=228\n",
      "11066: loss=0.074, reward_mean=0.450, reward_bound=0.353, batch=229\n",
      "11067: loss=0.076, reward_mean=0.410, reward_bound=0.430, batch=222\n",
      "11068: loss=0.078, reward_mean=0.380, reward_bound=0.478, batch=205\n",
      "11069: loss=0.074, reward_mean=0.370, reward_bound=0.185, batch=212\n",
      "11070: loss=0.074, reward_mean=0.480, reward_bound=0.263, batch=218\n",
      "11071: loss=0.076, reward_mean=0.360, reward_bound=0.282, batch=217\n",
      "11072: loss=0.074, reward_mean=0.370, reward_bound=0.342, batch=222\n",
      "11073: loss=0.075, reward_mean=0.420, reward_bound=0.292, batch=225\n",
      "11074: loss=0.076, reward_mean=0.480, reward_bound=0.349, batch=220\n",
      "11075: loss=0.077, reward_mean=0.430, reward_bound=0.387, batch=217\n",
      "11076: loss=0.076, reward_mean=0.560, reward_bound=0.282, batch=221\n",
      "11077: loss=0.075, reward_mean=0.410, reward_bound=0.314, batch=223\n",
      "11078: loss=0.076, reward_mean=0.460, reward_bound=0.387, batch=224\n",
      "11079: loss=0.078, reward_mean=0.420, reward_bound=0.384, batch=227\n",
      "11080: loss=0.080, reward_mean=0.430, reward_bound=0.380, batch=229\n",
      "11081: loss=0.080, reward_mean=0.350, reward_bound=0.387, batch=228\n",
      "11082: loss=0.078, reward_mean=0.420, reward_bound=0.430, batch=215\n",
      "11083: loss=0.076, reward_mean=0.430, reward_bound=0.260, batch=220\n",
      "11084: loss=0.078, reward_mean=0.480, reward_bound=0.304, batch=224\n",
      "11085: loss=0.078, reward_mean=0.420, reward_bound=0.282, batch=226\n",
      "11086: loss=0.078, reward_mean=0.460, reward_bound=0.314, batch=226\n",
      "11087: loss=0.079, reward_mean=0.570, reward_bound=0.387, batch=224\n",
      "11088: loss=0.078, reward_mean=0.380, reward_bound=0.430, batch=224\n",
      "11089: loss=0.077, reward_mean=0.390, reward_bound=0.426, batch=227\n",
      "11090: loss=0.077, reward_mean=0.390, reward_bound=0.249, batch=229\n",
      "11091: loss=0.078, reward_mean=0.420, reward_bound=0.349, batch=228\n",
      "11092: loss=0.077, reward_mean=0.450, reward_bound=0.430, batch=225\n",
      "11093: loss=0.077, reward_mean=0.510, reward_bound=0.396, batch=227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11094: loss=0.077, reward_mean=0.550, reward_bound=0.387, batch=228\n",
      "11095: loss=0.077, reward_mean=0.530, reward_bound=0.430, batch=226\n",
      "11096: loss=0.078, reward_mean=0.480, reward_bound=0.331, batch=228\n",
      "11097: loss=0.078, reward_mean=0.440, reward_bound=0.387, batch=227\n",
      "11098: loss=0.080, reward_mean=0.370, reward_bound=0.478, batch=214\n",
      "11099: loss=0.083, reward_mean=0.440, reward_bound=0.282, batch=219\n",
      "11100: loss=0.081, reward_mean=0.470, reward_bound=0.349, batch=221\n",
      "11101: loss=0.080, reward_mean=0.400, reward_bound=0.430, batch=221\n",
      "11102: loss=0.080, reward_mean=0.450, reward_bound=0.349, batch=224\n",
      "11103: loss=0.079, reward_mean=0.490, reward_bound=0.426, batch=227\n",
      "11104: loss=0.079, reward_mean=0.480, reward_bound=0.422, batch=229\n",
      "11105: loss=0.079, reward_mean=0.440, reward_bound=0.405, batch=230\n",
      "11106: loss=0.079, reward_mean=0.440, reward_bound=0.365, batch=231\n",
      "11107: loss=0.079, reward_mean=0.480, reward_bound=0.430, batch=226\n",
      "11108: loss=0.080, reward_mean=0.400, reward_bound=0.478, batch=222\n",
      "11109: loss=0.080, reward_mean=0.480, reward_bound=0.324, batch=225\n",
      "11110: loss=0.079, reward_mean=0.510, reward_bound=0.356, batch=227\n",
      "11111: loss=0.080, reward_mean=0.390, reward_bound=0.380, batch=229\n",
      "11112: loss=0.081, reward_mean=0.430, reward_bound=0.387, batch=228\n",
      "11113: loss=0.080, reward_mean=0.410, reward_bound=0.260, batch=229\n",
      "11114: loss=0.080, reward_mean=0.350, reward_bound=0.360, batch=230\n",
      "11115: loss=0.081, reward_mean=0.520, reward_bound=0.418, batch=231\n",
      "11116: loss=0.079, reward_mean=0.430, reward_bound=0.430, batch=229\n",
      "11117: loss=0.079, reward_mean=0.420, reward_bound=0.401, batch=230\n",
      "11118: loss=0.079, reward_mean=0.420, reward_bound=0.387, batch=230\n",
      "11119: loss=0.079, reward_mean=0.450, reward_bound=0.464, batch=231\n",
      "11120: loss=0.079, reward_mean=0.440, reward_bound=0.430, batch=231\n",
      "11121: loss=0.079, reward_mean=0.470, reward_bound=0.387, batch=231\n",
      "11122: loss=0.079, reward_mean=0.460, reward_bound=0.430, batch=231\n",
      "11123: loss=0.079, reward_mean=0.450, reward_bound=0.478, batch=225\n",
      "11124: loss=0.079, reward_mean=0.380, reward_bound=0.387, batch=226\n",
      "11125: loss=0.080, reward_mean=0.480, reward_bound=0.368, batch=228\n",
      "11126: loss=0.080, reward_mean=0.410, reward_bound=0.430, batch=228\n",
      "11127: loss=0.080, reward_mean=0.380, reward_bound=0.435, batch=229\n",
      "11128: loss=0.080, reward_mean=0.570, reward_bound=0.405, batch=230\n",
      "11129: loss=0.080, reward_mean=0.330, reward_bound=0.418, batch=231\n",
      "11130: loss=0.080, reward_mean=0.440, reward_bound=0.430, batch=231\n",
      "11131: loss=0.080, reward_mean=0.460, reward_bound=0.478, batch=230\n",
      "11132: loss=0.080, reward_mean=0.410, reward_bound=0.386, batch=231\n",
      "11133: loss=0.080, reward_mean=0.480, reward_bound=0.430, batch=231\n",
      "11134: loss=0.080, reward_mean=0.410, reward_bound=0.478, batch=231\n",
      "11136: loss=0.064, reward_mean=0.380, reward_bound=0.000, batch=38\n",
      "11137: loss=0.058, reward_mean=0.430, reward_bound=0.000, batch=81\n",
      "11138: loss=0.057, reward_mean=0.370, reward_bound=0.000, batch=118\n",
      "11139: loss=0.065, reward_mean=0.440, reward_bound=0.002, batch=151\n",
      "11140: loss=0.068, reward_mean=0.490, reward_bound=0.010, batch=173\n",
      "11141: loss=0.068, reward_mean=0.450, reward_bound=0.024, batch=191\n",
      "11142: loss=0.064, reward_mean=0.490, reward_bound=0.034, batch=202\n",
      "11143: loss=0.062, reward_mean=0.380, reward_bound=0.052, batch=210\n",
      "11144: loss=0.063, reward_mean=0.360, reward_bound=0.065, batch=206\n",
      "11145: loss=0.063, reward_mean=0.510, reward_bound=0.084, batch=214\n",
      "11146: loss=0.067, reward_mean=0.450, reward_bound=0.109, batch=202\n",
      "11147: loss=0.066, reward_mean=0.470, reward_bound=0.122, batch=209\n",
      "11148: loss=0.063, reward_mean=0.510, reward_bound=0.135, batch=201\n",
      "11149: loss=0.066, reward_mean=0.380, reward_bound=0.150, batch=192\n",
      "11150: loss=0.062, reward_mean=0.500, reward_bound=0.167, batch=185\n",
      "11151: loss=0.062, reward_mean=0.450, reward_bound=0.127, batch=199\n",
      "11152: loss=0.061, reward_mean=0.420, reward_bound=0.150, batch=206\n",
      "11153: loss=0.063, reward_mean=0.390, reward_bound=0.185, batch=203\n",
      "11154: loss=0.066, reward_mean=0.530, reward_bound=0.206, batch=198\n",
      "11155: loss=0.065, reward_mean=0.530, reward_bound=0.154, batch=208\n",
      "11156: loss=0.068, reward_mean=0.540, reward_bound=0.208, batch=215\n",
      "11157: loss=0.069, reward_mean=0.520, reward_bound=0.229, batch=188\n",
      "11158: loss=0.067, reward_mean=0.480, reward_bound=0.229, batch=199\n",
      "11159: loss=0.067, reward_mean=0.450, reward_bound=0.182, batch=209\n",
      "11160: loss=0.066, reward_mean=0.570, reward_bound=0.206, batch=215\n",
      "11161: loss=0.064, reward_mean=0.510, reward_bound=0.254, batch=190\n",
      "11162: loss=0.064, reward_mean=0.370, reward_bound=0.096, batch=203\n",
      "11163: loss=0.070, reward_mean=0.500, reward_bound=0.206, batch=210\n",
      "11164: loss=0.067, reward_mean=0.470, reward_bound=0.254, batch=215\n",
      "11165: loss=0.066, reward_mean=0.350, reward_bound=0.282, batch=181\n",
      "11166: loss=0.064, reward_mean=0.410, reward_bound=0.122, batch=196\n",
      "11167: loss=0.063, reward_mean=0.450, reward_bound=0.150, batch=205\n",
      "11168: loss=0.067, reward_mean=0.480, reward_bound=0.167, batch=212\n",
      "11169: loss=0.064, reward_mean=0.310, reward_bound=0.185, batch=215\n",
      "11170: loss=0.065, reward_mean=0.410, reward_bound=0.229, batch=216\n",
      "11171: loss=0.063, reward_mean=0.420, reward_bound=0.254, batch=219\n",
      "11172: loss=0.063, reward_mean=0.480, reward_bound=0.250, batch=223\n",
      "11173: loss=0.064, reward_mean=0.450, reward_bound=0.282, batch=216\n",
      "11174: loss=0.067, reward_mean=0.540, reward_bound=0.314, batch=172\n",
      "11175: loss=0.066, reward_mean=0.520, reward_bound=0.167, batch=186\n",
      "11176: loss=0.066, reward_mean=0.470, reward_bound=0.185, batch=196\n",
      "11177: loss=0.065, reward_mean=0.420, reward_bound=0.217, batch=207\n",
      "11178: loss=0.065, reward_mean=0.440, reward_bound=0.150, batch=214\n",
      "11179: loss=0.064, reward_mean=0.480, reward_bound=0.226, batch=220\n",
      "11180: loss=0.062, reward_mean=0.360, reward_bound=0.229, batch=221\n",
      "11181: loss=0.063, reward_mean=0.370, reward_bound=0.254, batch=219\n",
      "11182: loss=0.065, reward_mean=0.410, reward_bound=0.282, batch=217\n",
      "11183: loss=0.064, reward_mean=0.480, reward_bound=0.314, batch=216\n",
      "11184: loss=0.063, reward_mean=0.440, reward_bound=0.331, batch=221\n",
      "11185: loss=0.057, reward_mean=0.400, reward_bound=0.349, batch=157\n",
      "11186: loss=0.060, reward_mean=0.540, reward_bound=0.122, batch=179\n",
      "11187: loss=0.060, reward_mean=0.530, reward_bound=0.135, batch=194\n",
      "11188: loss=0.062, reward_mean=0.540, reward_bound=0.167, batch=205\n",
      "11189: loss=0.060, reward_mean=0.450, reward_bound=0.185, batch=212\n",
      "11190: loss=0.062, reward_mean=0.400, reward_bound=0.206, batch=225\n",
      "11191: loss=0.062, reward_mean=0.480, reward_bound=0.229, batch=221\n",
      "11192: loss=0.059, reward_mean=0.390, reward_bound=0.254, batch=220\n",
      "11193: loss=0.060, reward_mean=0.530, reward_bound=0.282, batch=212\n",
      "11194: loss=0.063, reward_mean=0.430, reward_bound=0.314, batch=200\n",
      "11195: loss=0.067, reward_mean=0.540, reward_bound=0.200, batch=210\n",
      "11196: loss=0.068, reward_mean=0.410, reward_bound=0.222, batch=217\n",
      "11197: loss=0.069, reward_mean=0.480, reward_bound=0.249, batch=222\n",
      "11198: loss=0.068, reward_mean=0.350, reward_bound=0.254, batch=220\n",
      "11199: loss=0.068, reward_mean=0.400, reward_bound=0.206, batch=227\n",
      "11200: loss=0.066, reward_mean=0.430, reward_bound=0.229, batch=228\n",
      "11201: loss=0.069, reward_mean=0.470, reward_bound=0.282, batch=224\n",
      "11202: loss=0.071, reward_mean=0.490, reward_bound=0.345, batch=227\n",
      "11203: loss=0.065, reward_mean=0.440, reward_bound=0.349, batch=207\n",
      "11204: loss=0.064, reward_mean=0.510, reward_bound=0.249, batch=215\n",
      "11205: loss=0.066, reward_mean=0.450, reward_bound=0.289, batch=220\n",
      "11206: loss=0.065, reward_mean=0.440, reward_bound=0.314, batch=222\n",
      "11207: loss=0.065, reward_mean=0.470, reward_bound=0.349, batch=218\n",
      "11208: loss=0.066, reward_mean=0.520, reward_bound=0.321, batch=222\n",
      "11209: loss=0.065, reward_mean=0.420, reward_bound=0.387, batch=150\n",
      "11210: loss=0.067, reward_mean=0.470, reward_bound=0.089, batch=174\n",
      "11211: loss=0.067, reward_mean=0.500, reward_bound=0.098, batch=191\n",
      "11212: loss=0.068, reward_mean=0.420, reward_bound=0.122, batch=201\n",
      "11213: loss=0.064, reward_mean=0.360, reward_bound=0.135, batch=208\n",
      "11214: loss=0.063, reward_mean=0.490, reward_bound=0.167, batch=211\n",
      "11215: loss=0.064, reward_mean=0.480, reward_bound=0.185, batch=217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11216: loss=0.067, reward_mean=0.580, reward_bound=0.229, batch=221\n",
      "11217: loss=0.063, reward_mean=0.520, reward_bound=0.254, batch=215\n",
      "11218: loss=0.061, reward_mean=0.430, reward_bound=0.189, batch=220\n",
      "11219: loss=0.062, reward_mean=0.450, reward_bound=0.282, batch=209\n",
      "11220: loss=0.063, reward_mean=0.500, reward_bound=0.254, batch=215\n",
      "11221: loss=0.063, reward_mean=0.400, reward_bound=0.314, batch=206\n",
      "11222: loss=0.065, reward_mean=0.380, reward_bound=0.185, batch=213\n",
      "11223: loss=0.064, reward_mean=0.480, reward_bound=0.244, batch=219\n",
      "11224: loss=0.063, reward_mean=0.420, reward_bound=0.265, batch=223\n",
      "11225: loss=0.062, reward_mean=0.370, reward_bound=0.229, batch=225\n",
      "11226: loss=0.062, reward_mean=0.450, reward_bound=0.314, batch=223\n",
      "11227: loss=0.061, reward_mean=0.320, reward_bound=0.349, batch=209\n",
      "11228: loss=0.059, reward_mean=0.420, reward_bound=0.314, batch=215\n",
      "11229: loss=0.058, reward_mean=0.450, reward_bound=0.296, batch=220\n",
      "11230: loss=0.059, reward_mean=0.410, reward_bound=0.329, batch=224\n",
      "11231: loss=0.058, reward_mean=0.440, reward_bound=0.349, batch=220\n",
      "11232: loss=0.060, reward_mean=0.500, reward_bound=0.387, batch=197\n",
      "11233: loss=0.061, reward_mean=0.470, reward_bound=0.254, batch=207\n",
      "11234: loss=0.059, reward_mean=0.440, reward_bound=0.249, batch=215\n",
      "11235: loss=0.058, reward_mean=0.440, reward_bound=0.229, batch=219\n",
      "11236: loss=0.057, reward_mean=0.410, reward_bound=0.254, batch=221\n",
      "11237: loss=0.059, reward_mean=0.540, reward_bound=0.314, batch=216\n",
      "11238: loss=0.060, reward_mean=0.500, reward_bound=0.349, batch=217\n",
      "11239: loss=0.060, reward_mean=0.520, reward_bound=0.249, batch=222\n",
      "11240: loss=0.063, reward_mean=0.410, reward_bound=0.349, batch=223\n",
      "11241: loss=0.062, reward_mean=0.490, reward_bound=0.349, batch=225\n",
      "11242: loss=0.062, reward_mean=0.470, reward_bound=0.387, batch=214\n",
      "11243: loss=0.063, reward_mean=0.300, reward_bound=0.161, batch=220\n",
      "11244: loss=0.063, reward_mean=0.420, reward_bound=0.314, batch=223\n",
      "11245: loss=0.061, reward_mean=0.380, reward_bound=0.349, batch=222\n",
      "11246: loss=0.061, reward_mean=0.400, reward_bound=0.387, batch=220\n",
      "11247: loss=0.063, reward_mean=0.520, reward_bound=0.365, batch=224\n",
      "11248: loss=0.064, reward_mean=0.390, reward_bound=0.387, batch=226\n",
      "11249: loss=0.063, reward_mean=0.410, reward_bound=0.260, batch=228\n",
      "11250: loss=0.063, reward_mean=0.410, reward_bound=0.321, batch=229\n",
      "11251: loss=0.072, reward_mean=0.430, reward_bound=0.430, batch=127\n",
      "11252: loss=0.066, reward_mean=0.500, reward_bound=0.052, batch=157\n",
      "11253: loss=0.066, reward_mean=0.420, reward_bound=0.078, batch=180\n",
      "11254: loss=0.070, reward_mean=0.480, reward_bound=0.106, batch=196\n",
      "11255: loss=0.067, reward_mean=0.400, reward_bound=0.122, batch=206\n",
      "11256: loss=0.072, reward_mean=0.420, reward_bound=0.143, batch=214\n",
      "11257: loss=0.070, reward_mean=0.450, reward_bound=0.150, batch=215\n",
      "11258: loss=0.072, reward_mean=0.490, reward_bound=0.185, batch=212\n",
      "11259: loss=0.071, reward_mean=0.370, reward_bound=0.206, batch=220\n",
      "11260: loss=0.069, reward_mean=0.470, reward_bound=0.206, batch=229\n",
      "11261: loss=0.073, reward_mean=0.390, reward_bound=0.206, batch=223\n",
      "11262: loss=0.073, reward_mean=0.380, reward_bound=0.211, batch=226\n",
      "11263: loss=0.074, reward_mean=0.410, reward_bound=0.229, batch=218\n",
      "11264: loss=0.074, reward_mean=0.410, reward_bound=0.254, batch=209\n",
      "11265: loss=0.073, reward_mean=0.450, reward_bound=0.215, batch=216\n",
      "11266: loss=0.075, reward_mean=0.410, reward_bound=0.268, batch=221\n",
      "11267: loss=0.071, reward_mean=0.500, reward_bound=0.282, batch=207\n",
      "11268: loss=0.070, reward_mean=0.440, reward_bound=0.277, batch=215\n",
      "11269: loss=0.071, reward_mean=0.500, reward_bound=0.289, batch=220\n",
      "11270: loss=0.072, reward_mean=0.480, reward_bound=0.314, batch=200\n",
      "11271: loss=0.072, reward_mean=0.430, reward_bound=0.274, batch=210\n",
      "11272: loss=0.072, reward_mean=0.440, reward_bound=0.274, batch=217\n",
      "11273: loss=0.073, reward_mean=0.390, reward_bound=0.282, batch=219\n",
      "11274: loss=0.072, reward_mean=0.440, reward_bound=0.314, batch=222\n",
      "11275: loss=0.065, reward_mean=0.530, reward_bound=0.349, batch=192\n",
      "11276: loss=0.064, reward_mean=0.440, reward_bound=0.213, batch=204\n",
      "11277: loss=0.066, reward_mean=0.470, reward_bound=0.226, batch=213\n",
      "11278: loss=0.063, reward_mean=0.430, reward_bound=0.271, batch=219\n",
      "11279: loss=0.066, reward_mean=0.500, reward_bound=0.282, batch=219\n",
      "11280: loss=0.065, reward_mean=0.480, reward_bound=0.314, batch=222\n",
      "11281: loss=0.064, reward_mean=0.480, reward_bound=0.349, batch=220\n",
      "11282: loss=0.064, reward_mean=0.350, reward_bound=0.304, batch=224\n",
      "11283: loss=0.066, reward_mean=0.480, reward_bound=0.345, batch=227\n",
      "11284: loss=0.068, reward_mean=0.530, reward_bound=0.349, batch=227\n",
      "11285: loss=0.067, reward_mean=0.430, reward_bound=0.349, batch=228\n",
      "11286: loss=0.068, reward_mean=0.400, reward_bound=0.387, batch=187\n",
      "11287: loss=0.066, reward_mean=0.440, reward_bound=0.167, batch=198\n",
      "11288: loss=0.069, reward_mean=0.420, reward_bound=0.206, batch=207\n",
      "11289: loss=0.069, reward_mean=0.460, reward_bound=0.254, batch=210\n",
      "11290: loss=0.067, reward_mean=0.380, reward_bound=0.282, batch=213\n",
      "11291: loss=0.066, reward_mean=0.500, reward_bound=0.271, batch=219\n",
      "11292: loss=0.070, reward_mean=0.400, reward_bound=0.314, batch=219\n",
      "11293: loss=0.069, reward_mean=0.360, reward_bound=0.229, batch=222\n",
      "11294: loss=0.068, reward_mean=0.390, reward_bound=0.282, batch=224\n",
      "11295: loss=0.068, reward_mean=0.420, reward_bound=0.349, batch=217\n",
      "11296: loss=0.072, reward_mean=0.510, reward_bound=0.314, batch=221\n",
      "11297: loss=0.069, reward_mean=0.500, reward_bound=0.387, batch=207\n",
      "11298: loss=0.072, reward_mean=0.350, reward_bound=0.182, batch=215\n",
      "11299: loss=0.071, reward_mean=0.470, reward_bound=0.314, batch=216\n",
      "11300: loss=0.070, reward_mean=0.410, reward_bound=0.241, batch=221\n",
      "11301: loss=0.070, reward_mean=0.510, reward_bound=0.314, batch=223\n",
      "11302: loss=0.069, reward_mean=0.520, reward_bound=0.349, batch=221\n",
      "11303: loss=0.070, reward_mean=0.480, reward_bound=0.349, batch=224\n",
      "11304: loss=0.070, reward_mean=0.370, reward_bound=0.345, batch=227\n",
      "11305: loss=0.070, reward_mean=0.410, reward_bound=0.349, batch=228\n",
      "11306: loss=0.067, reward_mean=0.540, reward_bound=0.387, batch=224\n",
      "11307: loss=0.066, reward_mean=0.510, reward_bound=0.349, batch=226\n",
      "11308: loss=0.066, reward_mean=0.460, reward_bound=0.387, batch=227\n",
      "11309: loss=0.065, reward_mean=0.480, reward_bound=0.342, batch=229\n",
      "11310: loss=0.066, reward_mean=0.500, reward_bound=0.430, batch=176\n",
      "11311: loss=0.060, reward_mean=0.420, reward_bound=0.135, batch=192\n",
      "11312: loss=0.071, reward_mean=0.480, reward_bound=0.167, batch=202\n",
      "11313: loss=0.068, reward_mean=0.420, reward_bound=0.185, batch=209\n",
      "11314: loss=0.069, reward_mean=0.420, reward_bound=0.206, batch=211\n",
      "11315: loss=0.065, reward_mean=0.430, reward_bound=0.229, batch=213\n",
      "11316: loss=0.067, reward_mean=0.480, reward_bound=0.254, batch=215\n",
      "11317: loss=0.070, reward_mean=0.460, reward_bound=0.282, batch=211\n",
      "11318: loss=0.070, reward_mean=0.550, reward_bound=0.314, batch=208\n",
      "11319: loss=0.072, reward_mean=0.400, reward_bound=0.254, batch=214\n",
      "11320: loss=0.073, reward_mean=0.430, reward_bound=0.229, batch=218\n",
      "11321: loss=0.073, reward_mean=0.460, reward_bound=0.317, batch=222\n",
      "11322: loss=0.072, reward_mean=0.460, reward_bound=0.349, batch=210\n",
      "11323: loss=0.070, reward_mean=0.500, reward_bound=0.304, batch=217\n",
      "11324: loss=0.071, reward_mean=0.450, reward_bound=0.314, batch=219\n",
      "11325: loss=0.075, reward_mean=0.490, reward_bound=0.387, batch=211\n",
      "11326: loss=0.073, reward_mean=0.520, reward_bound=0.349, batch=216\n",
      "11327: loss=0.075, reward_mean=0.460, reward_bound=0.316, batch=221\n",
      "11328: loss=0.075, reward_mean=0.550, reward_bound=0.349, batch=224\n",
      "11329: loss=0.074, reward_mean=0.460, reward_bound=0.345, batch=227\n",
      "11330: loss=0.074, reward_mean=0.500, reward_bound=0.380, batch=229\n",
      "11331: loss=0.073, reward_mean=0.520, reward_bound=0.387, batch=224\n",
      "11332: loss=0.069, reward_mean=0.430, reward_bound=0.430, batch=200\n",
      "11333: loss=0.068, reward_mean=0.480, reward_bound=0.247, batch=210\n",
      "11334: loss=0.069, reward_mean=0.450, reward_bound=0.254, batch=215\n",
      "11335: loss=0.069, reward_mean=0.430, reward_bound=0.282, batch=218\n",
      "11336: loss=0.069, reward_mean=0.490, reward_bound=0.314, batch=219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11337: loss=0.072, reward_mean=0.450, reward_bound=0.349, batch=219\n",
      "11338: loss=0.074, reward_mean=0.420, reward_bound=0.265, batch=223\n",
      "11339: loss=0.073, reward_mean=0.450, reward_bound=0.335, batch=226\n",
      "11340: loss=0.072, reward_mean=0.460, reward_bound=0.349, batch=227\n",
      "11341: loss=0.068, reward_mean=0.440, reward_bound=0.387, batch=222\n",
      "11342: loss=0.067, reward_mean=0.400, reward_bound=0.272, batch=225\n",
      "11343: loss=0.067, reward_mean=0.360, reward_bound=0.314, batch=225\n",
      "11344: loss=0.067, reward_mean=0.380, reward_bound=0.387, batch=225\n",
      "11345: loss=0.067, reward_mean=0.420, reward_bound=0.396, batch=227\n",
      "11346: loss=0.066, reward_mean=0.500, reward_bound=0.387, batch=228\n",
      "11347: loss=0.066, reward_mean=0.400, reward_bound=0.357, batch=229\n",
      "11348: loss=0.068, reward_mean=0.420, reward_bound=0.430, batch=216\n",
      "11349: loss=0.067, reward_mean=0.450, reward_bound=0.314, batch=220\n",
      "11350: loss=0.068, reward_mean=0.460, reward_bound=0.349, batch=222\n",
      "11351: loss=0.067, reward_mean=0.420, reward_bound=0.360, batch=225\n",
      "11352: loss=0.066, reward_mean=0.450, reward_bound=0.387, batch=225\n",
      "11353: loss=0.065, reward_mean=0.480, reward_bound=0.349, batch=226\n",
      "11354: loss=0.065, reward_mean=0.390, reward_bound=0.409, batch=228\n",
      "11355: loss=0.065, reward_mean=0.510, reward_bound=0.387, batch=228\n",
      "11356: loss=0.067, reward_mean=0.490, reward_bound=0.430, batch=220\n",
      "11357: loss=0.067, reward_mean=0.480, reward_bound=0.430, batch=223\n",
      "11358: loss=0.069, reward_mean=0.380, reward_bound=0.413, batch=226\n",
      "11359: loss=0.066, reward_mean=0.460, reward_bound=0.430, batch=226\n",
      "11360: loss=0.066, reward_mean=0.370, reward_bound=0.298, batch=228\n",
      "11361: loss=0.066, reward_mean=0.500, reward_bound=0.430, batch=227\n",
      "11362: loss=0.067, reward_mean=0.460, reward_bound=0.314, batch=228\n",
      "11363: loss=0.065, reward_mean=0.510, reward_bound=0.392, batch=229\n",
      "11364: loss=0.066, reward_mean=0.440, reward_bound=0.430, batch=227\n",
      "11365: loss=0.065, reward_mean=0.450, reward_bound=0.414, batch=229\n",
      "11366: loss=0.065, reward_mean=0.410, reward_bound=0.478, batch=231\n",
      "11367: loss=0.065, reward_mean=0.560, reward_bound=0.387, batch=231\n",
      "11368: loss=0.068, reward_mean=0.460, reward_bound=0.478, batch=100\n",
      "11369: loss=0.061, reward_mean=0.450, reward_bound=0.014, batch=140\n",
      "11370: loss=0.060, reward_mean=0.420, reward_bound=0.020, batch=167\n",
      "11371: loss=0.058, reward_mean=0.530, reward_bound=0.058, batch=189\n",
      "11372: loss=0.063, reward_mean=0.430, reward_bound=0.072, batch=201\n",
      "11373: loss=0.063, reward_mean=0.470, reward_bound=0.098, batch=205\n",
      "11374: loss=0.060, reward_mean=0.470, reward_bound=0.122, batch=211\n",
      "11375: loss=0.061, reward_mean=0.370, reward_bound=0.135, batch=216\n",
      "11376: loss=0.060, reward_mean=0.430, reward_bound=0.167, batch=205\n",
      "11377: loss=0.056, reward_mean=0.500, reward_bound=0.185, batch=207\n",
      "11378: loss=0.056, reward_mean=0.410, reward_bound=0.182, batch=215\n",
      "11379: loss=0.058, reward_mean=0.430, reward_bound=0.206, batch=201\n",
      "11380: loss=0.061, reward_mean=0.430, reward_bound=0.109, batch=210\n",
      "11381: loss=0.057, reward_mean=0.440, reward_bound=0.206, batch=218\n",
      "11382: loss=0.056, reward_mean=0.480, reward_bound=0.206, batch=221\n",
      "11383: loss=0.062, reward_mean=0.440, reward_bound=0.229, batch=202\n",
      "11384: loss=0.068, reward_mean=0.470, reward_bound=0.254, batch=191\n",
      "11385: loss=0.068, reward_mean=0.470, reward_bound=0.167, batch=202\n",
      "11386: loss=0.070, reward_mean=0.540, reward_bound=0.236, batch=211\n",
      "11387: loss=0.072, reward_mean=0.470, reward_bound=0.254, batch=216\n",
      "11388: loss=0.071, reward_mean=0.510, reward_bound=0.268, batch=221\n",
      "11389: loss=0.066, reward_mean=0.440, reward_bound=0.282, batch=202\n",
      "11390: loss=0.070, reward_mean=0.430, reward_bound=0.140, batch=211\n",
      "11391: loss=0.068, reward_mean=0.530, reward_bound=0.254, batch=217\n",
      "11392: loss=0.069, reward_mean=0.540, reward_bound=0.282, batch=217\n",
      "11393: loss=0.069, reward_mean=0.420, reward_bound=0.314, batch=194\n",
      "11394: loss=0.067, reward_mean=0.460, reward_bound=0.229, batch=204\n",
      "11395: loss=0.065, reward_mean=0.510, reward_bound=0.226, batch=213\n",
      "11396: loss=0.067, reward_mean=0.470, reward_bound=0.244, batch=219\n",
      "11397: loss=0.065, reward_mean=0.370, reward_bound=0.254, batch=219\n",
      "11398: loss=0.064, reward_mean=0.480, reward_bound=0.282, batch=220\n",
      "11399: loss=0.067, reward_mean=0.480, reward_bound=0.314, batch=221\n",
      "11400: loss=0.066, reward_mean=0.390, reward_bound=0.314, batch=224\n",
      "11401: loss=0.064, reward_mean=0.530, reward_bound=0.349, batch=197\n",
      "11402: loss=0.063, reward_mean=0.480, reward_bound=0.249, batch=208\n",
      "11403: loss=0.064, reward_mean=0.390, reward_bound=0.254, batch=212\n",
      "11404: loss=0.066, reward_mean=0.400, reward_bound=0.282, batch=212\n",
      "11405: loss=0.064, reward_mean=0.380, reward_bound=0.229, batch=216\n",
      "11406: loss=0.065, reward_mean=0.430, reward_bound=0.282, batch=218\n",
      "11407: loss=0.064, reward_mean=0.450, reward_bound=0.314, batch=217\n",
      "11408: loss=0.064, reward_mean=0.400, reward_bound=0.349, batch=219\n",
      "11409: loss=0.066, reward_mean=0.270, reward_bound=0.206, batch=222\n",
      "11410: loss=0.065, reward_mean=0.450, reward_bound=0.324, batch=225\n",
      "11411: loss=0.066, reward_mean=0.470, reward_bound=0.321, batch=227\n",
      "11412: loss=0.065, reward_mean=0.470, reward_bound=0.349, batch=227\n",
      "11413: loss=0.065, reward_mean=0.500, reward_bound=0.387, batch=184\n",
      "11414: loss=0.071, reward_mean=0.460, reward_bound=0.135, batch=198\n",
      "11415: loss=0.065, reward_mean=0.400, reward_bound=0.185, batch=204\n",
      "11416: loss=0.065, reward_mean=0.480, reward_bound=0.206, batch=210\n",
      "11417: loss=0.064, reward_mean=0.400, reward_bound=0.229, batch=214\n",
      "11418: loss=0.069, reward_mean=0.400, reward_bound=0.280, batch=220\n",
      "11419: loss=0.068, reward_mean=0.440, reward_bound=0.274, batch=224\n",
      "11420: loss=0.068, reward_mean=0.400, reward_bound=0.282, batch=218\n",
      "11421: loss=0.067, reward_mean=0.430, reward_bound=0.254, batch=221\n",
      "11422: loss=0.068, reward_mean=0.520, reward_bound=0.282, batch=223\n",
      "11423: loss=0.067, reward_mean=0.450, reward_bound=0.301, batch=226\n",
      "11424: loss=0.067, reward_mean=0.500, reward_bound=0.314, batch=217\n",
      "11425: loss=0.068, reward_mean=0.380, reward_bound=0.308, batch=222\n",
      "11426: loss=0.068, reward_mean=0.460, reward_bound=0.324, batch=225\n",
      "11427: loss=0.066, reward_mean=0.350, reward_bound=0.349, batch=210\n",
      "11428: loss=0.065, reward_mean=0.460, reward_bound=0.274, batch=217\n",
      "11429: loss=0.065, reward_mean=0.400, reward_bound=0.314, batch=221\n",
      "11430: loss=0.065, reward_mean=0.470, reward_bound=0.282, batch=224\n",
      "11431: loss=0.065, reward_mean=0.410, reward_bound=0.349, batch=222\n",
      "11432: loss=0.066, reward_mean=0.310, reward_bound=0.387, batch=211\n",
      "11433: loss=0.070, reward_mean=0.480, reward_bound=0.167, batch=217\n",
      "11434: loss=0.074, reward_mean=0.440, reward_bound=0.249, batch=222\n",
      "11435: loss=0.067, reward_mean=0.360, reward_bound=0.282, batch=224\n",
      "11436: loss=0.065, reward_mean=0.510, reward_bound=0.345, batch=227\n",
      "11437: loss=0.066, reward_mean=0.500, reward_bound=0.349, batch=225\n",
      "11438: loss=0.065, reward_mean=0.480, reward_bound=0.387, batch=226\n",
      "11439: loss=0.066, reward_mean=0.380, reward_bound=0.409, batch=228\n",
      "11440: loss=0.066, reward_mean=0.500, reward_bound=0.314, batch=228\n",
      "11441: loss=0.063, reward_mean=0.490, reward_bound=0.430, batch=157\n",
      "11442: loss=0.059, reward_mean=0.440, reward_bound=0.063, batch=180\n",
      "11443: loss=0.062, reward_mean=0.420, reward_bound=0.098, batch=193\n",
      "11444: loss=0.060, reward_mean=0.500, reward_bound=0.117, batch=205\n",
      "11445: loss=0.058, reward_mean=0.500, reward_bound=0.150, batch=210\n",
      "11446: loss=0.060, reward_mean=0.530, reward_bound=0.185, batch=214\n",
      "11447: loss=0.057, reward_mean=0.450, reward_bound=0.206, batch=219\n",
      "11448: loss=0.054, reward_mean=0.420, reward_bound=0.229, batch=218\n",
      "11449: loss=0.060, reward_mean=0.490, reward_bound=0.254, batch=210\n",
      "11450: loss=0.058, reward_mean=0.320, reward_bound=0.222, batch=217\n",
      "11451: loss=0.059, reward_mean=0.450, reward_bound=0.282, batch=213\n",
      "11452: loss=0.059, reward_mean=0.390, reward_bound=0.301, batch=219\n",
      "11453: loss=0.058, reward_mean=0.370, reward_bound=0.265, batch=223\n",
      "11454: loss=0.059, reward_mean=0.430, reward_bound=0.282, batch=224\n",
      "11455: loss=0.060, reward_mean=0.400, reward_bound=0.314, batch=215\n",
      "11456: loss=0.062, reward_mean=0.450, reward_bound=0.254, batch=219\n",
      "11457: loss=0.063, reward_mean=0.550, reward_bound=0.349, batch=206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11458: loss=0.061, reward_mean=0.490, reward_bound=0.268, batch=214\n",
      "11459: loss=0.059, reward_mean=0.440, reward_bound=0.280, batch=220\n",
      "11460: loss=0.058, reward_mean=0.430, reward_bound=0.266, batch=224\n",
      "11461: loss=0.059, reward_mean=0.470, reward_bound=0.311, batch=227\n",
      "11462: loss=0.060, reward_mean=0.460, reward_bound=0.314, batch=223\n",
      "11463: loss=0.059, reward_mean=0.430, reward_bound=0.349, batch=223\n",
      "11464: loss=0.058, reward_mean=0.380, reward_bound=0.282, batch=224\n",
      "11465: loss=0.058, reward_mean=0.420, reward_bound=0.308, batch=227\n",
      "11466: loss=0.057, reward_mean=0.470, reward_bound=0.387, batch=198\n",
      "11467: loss=0.061, reward_mean=0.430, reward_bound=0.229, batch=207\n",
      "11468: loss=0.055, reward_mean=0.480, reward_bound=0.277, batch=215\n",
      "11469: loss=0.055, reward_mean=0.420, reward_bound=0.282, batch=213\n",
      "11470: loss=0.059, reward_mean=0.500, reward_bound=0.314, batch=216\n",
      "11471: loss=0.058, reward_mean=0.450, reward_bound=0.298, batch=221\n",
      "11472: loss=0.059, reward_mean=0.490, reward_bound=0.282, batch=224\n",
      "11473: loss=0.063, reward_mean=0.490, reward_bound=0.345, batch=227\n",
      "11474: loss=0.063, reward_mean=0.410, reward_bound=0.349, batch=226\n",
      "11475: loss=0.064, reward_mean=0.420, reward_bound=0.387, batch=218\n",
      "11476: loss=0.063, reward_mean=0.540, reward_bound=0.234, batch=222\n",
      "11477: loss=0.065, reward_mean=0.410, reward_bound=0.282, batch=224\n",
      "11478: loss=0.065, reward_mean=0.500, reward_bound=0.314, batch=225\n",
      "11479: loss=0.066, reward_mean=0.370, reward_bound=0.356, batch=227\n",
      "11480: loss=0.066, reward_mean=0.370, reward_bound=0.387, batch=227\n",
      "11481: loss=0.067, reward_mean=0.540, reward_bound=0.422, batch=229\n",
      "11482: loss=0.067, reward_mean=0.360, reward_bound=0.405, batch=230\n",
      "11483: loss=0.066, reward_mean=0.470, reward_bound=0.430, batch=192\n",
      "11484: loss=0.065, reward_mean=0.440, reward_bound=0.191, batch=204\n",
      "11485: loss=0.065, reward_mean=0.540, reward_bound=0.229, batch=210\n",
      "11486: loss=0.062, reward_mean=0.440, reward_bound=0.338, batch=217\n",
      "11487: loss=0.062, reward_mean=0.420, reward_bound=0.249, batch=222\n",
      "11488: loss=0.062, reward_mean=0.420, reward_bound=0.282, batch=223\n",
      "11489: loss=0.061, reward_mean=0.530, reward_bound=0.335, batch=226\n",
      "11490: loss=0.061, reward_mean=0.440, reward_bound=0.331, batch=228\n",
      "11491: loss=0.059, reward_mean=0.470, reward_bound=0.349, batch=221\n",
      "11492: loss=0.062, reward_mean=0.440, reward_bound=0.387, batch=214\n",
      "11493: loss=0.064, reward_mean=0.480, reward_bound=0.280, batch=220\n",
      "11494: loss=0.062, reward_mean=0.520, reward_bound=0.349, batch=222\n",
      "11495: loss=0.061, reward_mean=0.450, reward_bound=0.314, batch=225\n",
      "11496: loss=0.063, reward_mean=0.440, reward_bound=0.387, batch=226\n",
      "11497: loss=0.062, reward_mean=0.470, reward_bound=0.409, batch=228\n",
      "11498: loss=0.064, reward_mean=0.450, reward_bound=0.430, batch=209\n",
      "11499: loss=0.065, reward_mean=0.410, reward_bound=0.254, batch=215\n",
      "11500: loss=0.064, reward_mean=0.370, reward_bound=0.282, batch=219\n",
      "11501: loss=0.062, reward_mean=0.460, reward_bound=0.314, batch=220\n",
      "11502: loss=0.063, reward_mean=0.450, reward_bound=0.282, batch=223\n",
      "11503: loss=0.063, reward_mean=0.490, reward_bound=0.282, batch=224\n",
      "11504: loss=0.066, reward_mean=0.470, reward_bound=0.342, batch=227\n",
      "11505: loss=0.068, reward_mean=0.400, reward_bound=0.349, batch=225\n",
      "11506: loss=0.066, reward_mean=0.520, reward_bound=0.387, batch=222\n",
      "11507: loss=0.066, reward_mean=0.440, reward_bound=0.387, batch=224\n",
      "11508: loss=0.065, reward_mean=0.460, reward_bound=0.345, batch=227\n",
      "11509: loss=0.068, reward_mean=0.460, reward_bound=0.387, batch=228\n",
      "11510: loss=0.064, reward_mean=0.360, reward_bound=0.430, batch=221\n",
      "11511: loss=0.064, reward_mean=0.480, reward_bound=0.430, batch=223\n",
      "11512: loss=0.063, reward_mean=0.420, reward_bound=0.349, batch=225\n",
      "11513: loss=0.065, reward_mean=0.430, reward_bound=0.430, batch=225\n",
      "11514: loss=0.064, reward_mean=0.460, reward_bound=0.260, batch=227\n",
      "11515: loss=0.064, reward_mean=0.440, reward_bound=0.380, batch=229\n",
      "11516: loss=0.065, reward_mean=0.490, reward_bound=0.343, batch=230\n",
      "11517: loss=0.064, reward_mean=0.500, reward_bound=0.387, batch=230\n",
      "11518: loss=0.064, reward_mean=0.490, reward_bound=0.430, batch=228\n",
      "11519: loss=0.064, reward_mean=0.460, reward_bound=0.435, batch=229\n",
      "11520: loss=0.064, reward_mean=0.500, reward_bound=0.381, batch=230\n",
      "11521: loss=0.064, reward_mean=0.410, reward_bound=0.464, batch=231\n",
      "11522: loss=0.064, reward_mean=0.420, reward_bound=0.478, batch=148\n",
      "11523: loss=0.058, reward_mean=0.380, reward_bound=0.089, batch=172\n",
      "11524: loss=0.064, reward_mean=0.530, reward_bound=0.113, batch=190\n",
      "11525: loss=0.065, reward_mean=0.420, reward_bound=0.162, batch=203\n",
      "11526: loss=0.063, reward_mean=0.420, reward_bound=0.167, batch=210\n",
      "11527: loss=0.066, reward_mean=0.490, reward_bound=0.200, batch=217\n",
      "11528: loss=0.060, reward_mean=0.400, reward_bound=0.206, batch=217\n",
      "11529: loss=0.064, reward_mean=0.360, reward_bound=0.229, batch=216\n",
      "11530: loss=0.065, reward_mean=0.480, reward_bound=0.254, batch=212\n",
      "11531: loss=0.070, reward_mean=0.440, reward_bound=0.282, batch=200\n",
      "11532: loss=0.069, reward_mean=0.420, reward_bound=0.216, batch=210\n",
      "11533: loss=0.072, reward_mean=0.460, reward_bound=0.247, batch=217\n",
      "11534: loss=0.070, reward_mean=0.400, reward_bound=0.224, batch=222\n",
      "11535: loss=0.072, reward_mean=0.440, reward_bound=0.263, batch=225\n",
      "11536: loss=0.072, reward_mean=0.470, reward_bound=0.240, batch=227\n",
      "11537: loss=0.071, reward_mean=0.450, reward_bound=0.282, batch=223\n",
      "11538: loss=0.076, reward_mean=0.400, reward_bound=0.314, batch=211\n",
      "11539: loss=0.075, reward_mean=0.370, reward_bound=0.314, batch=216\n",
      "11540: loss=0.075, reward_mean=0.420, reward_bound=0.282, batch=220\n",
      "11541: loss=0.075, reward_mean=0.500, reward_bound=0.274, batch=224\n",
      "11542: loss=0.075, reward_mean=0.320, reward_bound=0.252, batch=227\n",
      "11543: loss=0.076, reward_mean=0.390, reward_bound=0.282, batch=225\n",
      "11544: loss=0.071, reward_mean=0.450, reward_bound=0.349, batch=206\n",
      "11545: loss=0.070, reward_mean=0.590, reward_bound=0.254, batch=213\n",
      "11546: loss=0.071, reward_mean=0.470, reward_bound=0.282, batch=218\n",
      "11547: loss=0.071, reward_mean=0.460, reward_bound=0.314, batch=221\n",
      "11548: loss=0.070, reward_mean=0.470, reward_bound=0.349, batch=222\n",
      "11549: loss=0.069, reward_mean=0.530, reward_bound=0.314, batch=224\n",
      "11550: loss=0.061, reward_mean=0.430, reward_bound=0.387, batch=192\n",
      "11551: loss=0.060, reward_mean=0.420, reward_bound=0.155, batch=204\n",
      "11552: loss=0.062, reward_mean=0.460, reward_bound=0.226, batch=213\n",
      "11553: loss=0.065, reward_mean=0.490, reward_bound=0.229, batch=217\n",
      "11554: loss=0.065, reward_mean=0.520, reward_bound=0.254, batch=219\n",
      "11555: loss=0.065, reward_mean=0.420, reward_bound=0.282, batch=221\n",
      "11556: loss=0.066, reward_mean=0.360, reward_bound=0.229, batch=223\n",
      "11557: loss=0.065, reward_mean=0.510, reward_bound=0.314, batch=224\n",
      "11558: loss=0.063, reward_mean=0.530, reward_bound=0.349, batch=223\n",
      "11559: loss=0.063, reward_mean=0.380, reward_bound=0.335, batch=226\n",
      "11560: loss=0.063, reward_mean=0.430, reward_bound=0.349, batch=227\n",
      "11561: loss=0.062, reward_mean=0.460, reward_bound=0.387, batch=216\n",
      "11562: loss=0.060, reward_mean=0.470, reward_bound=0.268, batch=221\n",
      "11563: loss=0.060, reward_mean=0.370, reward_bound=0.282, batch=221\n",
      "11564: loss=0.062, reward_mean=0.480, reward_bound=0.349, batch=222\n",
      "11565: loss=0.063, reward_mean=0.500, reward_bound=0.400, batch=225\n",
      "11566: loss=0.063, reward_mean=0.410, reward_bound=0.387, batch=226\n",
      "11567: loss=0.064, reward_mean=0.440, reward_bound=0.430, batch=192\n",
      "11568: loss=0.060, reward_mean=0.400, reward_bound=0.185, batch=203\n",
      "11569: loss=0.064, reward_mean=0.380, reward_bound=0.229, batch=210\n",
      "11570: loss=0.060, reward_mean=0.440, reward_bound=0.254, batch=211\n",
      "11571: loss=0.058, reward_mean=0.420, reward_bound=0.206, batch=217\n",
      "11572: loss=0.057, reward_mean=0.390, reward_bound=0.277, batch=222\n",
      "11573: loss=0.059, reward_mean=0.500, reward_bound=0.292, batch=225\n",
      "11574: loss=0.057, reward_mean=0.500, reward_bound=0.314, batch=221\n",
      "11575: loss=0.059, reward_mean=0.440, reward_bound=0.349, batch=216\n",
      "11576: loss=0.060, reward_mean=0.330, reward_bound=0.351, batch=221\n",
      "11577: loss=0.059, reward_mean=0.520, reward_bound=0.314, batch=224\n",
      "11578: loss=0.059, reward_mean=0.420, reward_bound=0.349, batch=225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11579: loss=0.061, reward_mean=0.440, reward_bound=0.387, batch=212\n",
      "11580: loss=0.060, reward_mean=0.390, reward_bound=0.191, batch=218\n",
      "11581: loss=0.063, reward_mean=0.460, reward_bound=0.231, batch=222\n",
      "11582: loss=0.061, reward_mean=0.480, reward_bound=0.292, batch=225\n",
      "11583: loss=0.061, reward_mean=0.470, reward_bound=0.387, batch=222\n",
      "11584: loss=0.061, reward_mean=0.470, reward_bound=0.400, batch=225\n",
      "11585: loss=0.060, reward_mean=0.360, reward_bound=0.321, batch=227\n",
      "11586: loss=0.060, reward_mean=0.450, reward_bound=0.387, batch=227\n",
      "11587: loss=0.060, reward_mean=0.460, reward_bound=0.349, batch=228\n",
      "11588: loss=0.062, reward_mean=0.520, reward_bound=0.430, batch=214\n",
      "11589: loss=0.060, reward_mean=0.460, reward_bound=0.254, batch=219\n",
      "11590: loss=0.060, reward_mean=0.430, reward_bound=0.229, batch=221\n",
      "11591: loss=0.061, reward_mean=0.430, reward_bound=0.314, batch=223\n",
      "11592: loss=0.060, reward_mean=0.420, reward_bound=0.271, batch=226\n",
      "11593: loss=0.064, reward_mean=0.430, reward_bound=0.349, batch=226\n",
      "11594: loss=0.061, reward_mean=0.440, reward_bound=0.387, batch=224\n",
      "11595: loss=0.061, reward_mean=0.450, reward_bound=0.380, batch=227\n",
      "11596: loss=0.062, reward_mean=0.370, reward_bound=0.387, batch=228\n",
      "11597: loss=0.062, reward_mean=0.470, reward_bound=0.357, batch=229\n",
      "11598: loss=0.062, reward_mean=0.560, reward_bound=0.430, batch=227\n",
      "11599: loss=0.062, reward_mean=0.440, reward_bound=0.478, batch=178\n",
      "11600: loss=0.069, reward_mean=0.460, reward_bound=0.152, batch=194\n",
      "11601: loss=0.069, reward_mean=0.360, reward_bound=0.183, batch=206\n",
      "11602: loss=0.071, reward_mean=0.510, reward_bound=0.196, batch=214\n",
      "11603: loss=0.070, reward_mean=0.420, reward_bound=0.206, batch=215\n",
      "11604: loss=0.067, reward_mean=0.480, reward_bound=0.229, batch=213\n",
      "11605: loss=0.067, reward_mean=0.350, reward_bound=0.254, batch=211\n",
      "11606: loss=0.069, reward_mean=0.520, reward_bound=0.282, batch=208\n",
      "11607: loss=0.072, reward_mean=0.480, reward_bound=0.314, batch=210\n",
      "11608: loss=0.071, reward_mean=0.450, reward_bound=0.206, batch=218\n",
      "11609: loss=0.073, reward_mean=0.450, reward_bound=0.254, batch=221\n",
      "11610: loss=0.073, reward_mean=0.410, reward_bound=0.314, batch=223\n",
      "11611: loss=0.069, reward_mean=0.490, reward_bound=0.349, batch=212\n",
      "11612: loss=0.070, reward_mean=0.470, reward_bound=0.263, batch=218\n",
      "11613: loss=0.070, reward_mean=0.440, reward_bound=0.140, batch=222\n",
      "11614: loss=0.071, reward_mean=0.430, reward_bound=0.254, batch=224\n",
      "11615: loss=0.069, reward_mean=0.440, reward_bound=0.311, batch=227\n",
      "11616: loss=0.070, reward_mean=0.370, reward_bound=0.314, batch=227\n",
      "11617: loss=0.066, reward_mean=0.430, reward_bound=0.387, batch=212\n",
      "11618: loss=0.066, reward_mean=0.430, reward_bound=0.229, batch=217\n",
      "11619: loss=0.067, reward_mean=0.430, reward_bound=0.206, batch=220\n",
      "11620: loss=0.068, reward_mean=0.440, reward_bound=0.304, batch=224\n",
      "11621: loss=0.069, reward_mean=0.460, reward_bound=0.314, batch=226\n",
      "11622: loss=0.068, reward_mean=0.450, reward_bound=0.314, batch=227\n",
      "11623: loss=0.067, reward_mean=0.430, reward_bound=0.387, batch=223\n",
      "11624: loss=0.066, reward_mean=0.420, reward_bound=0.314, batch=225\n",
      "11625: loss=0.066, reward_mean=0.550, reward_bound=0.356, batch=227\n",
      "11626: loss=0.063, reward_mean=0.520, reward_bound=0.430, batch=201\n",
      "11627: loss=0.064, reward_mean=0.490, reward_bound=0.229, batch=210\n",
      "11628: loss=0.063, reward_mean=0.360, reward_bound=0.274, batch=217\n",
      "11629: loss=0.063, reward_mean=0.420, reward_bound=0.282, batch=219\n",
      "11630: loss=0.063, reward_mean=0.450, reward_bound=0.254, batch=222\n",
      "11631: loss=0.063, reward_mean=0.370, reward_bound=0.314, batch=223\n",
      "11632: loss=0.064, reward_mean=0.480, reward_bound=0.314, batch=225\n",
      "11633: loss=0.060, reward_mean=0.450, reward_bound=0.349, batch=217\n",
      "11634: loss=0.059, reward_mean=0.500, reward_bound=0.342, batch=222\n",
      "11635: loss=0.059, reward_mean=0.450, reward_bound=0.314, batch=223\n",
      "11636: loss=0.060, reward_mean=0.460, reward_bound=0.349, batch=225\n",
      "11637: loss=0.062, reward_mean=0.480, reward_bound=0.289, batch=227\n",
      "11638: loss=0.061, reward_mean=0.440, reward_bound=0.314, batch=228\n",
      "11639: loss=0.059, reward_mean=0.530, reward_bound=0.387, batch=222\n",
      "11640: loss=0.060, reward_mean=0.470, reward_bound=0.349, batch=224\n",
      "11641: loss=0.061, reward_mean=0.480, reward_bound=0.384, batch=227\n",
      "11642: loss=0.062, reward_mean=0.410, reward_bound=0.380, batch=229\n",
      "11643: loss=0.059, reward_mean=0.450, reward_bound=0.387, batch=229\n",
      "11644: loss=0.061, reward_mean=0.410, reward_bound=0.430, batch=216\n",
      "11645: loss=0.061, reward_mean=0.390, reward_bound=0.387, batch=220\n",
      "11646: loss=0.060, reward_mean=0.400, reward_bound=0.274, batch=224\n",
      "11647: loss=0.060, reward_mean=0.360, reward_bound=0.282, batch=224\n",
      "11648: loss=0.060, reward_mean=0.440, reward_bound=0.387, batch=225\n",
      "11649: loss=0.062, reward_mean=0.390, reward_bound=0.430, batch=219\n",
      "11650: loss=0.064, reward_mean=0.470, reward_bound=0.328, batch=223\n",
      "11651: loss=0.067, reward_mean=0.430, reward_bound=0.335, batch=226\n",
      "11652: loss=0.063, reward_mean=0.470, reward_bound=0.349, batch=227\n",
      "11653: loss=0.062, reward_mean=0.410, reward_bound=0.387, batch=226\n",
      "11654: loss=0.062, reward_mean=0.410, reward_bound=0.314, batch=227\n",
      "11655: loss=0.061, reward_mean=0.460, reward_bound=0.342, batch=229\n",
      "11656: loss=0.062, reward_mean=0.500, reward_bound=0.349, batch=228\n",
      "11657: loss=0.061, reward_mean=0.470, reward_bound=0.392, batch=229\n",
      "11658: loss=0.061, reward_mean=0.450, reward_bound=0.430, batch=229\n",
      "11659: loss=0.061, reward_mean=0.480, reward_bound=0.381, batch=230\n",
      "11660: loss=0.061, reward_mean=0.440, reward_bound=0.418, batch=231\n",
      "11661: loss=0.061, reward_mean=0.430, reward_bound=0.349, batch=231\n",
      "11662: loss=0.061, reward_mean=0.430, reward_bound=0.430, batch=230\n",
      "11663: loss=0.061, reward_mean=0.490, reward_bound=0.464, batch=231\n",
      "11664: loss=0.061, reward_mean=0.470, reward_bound=0.430, batch=231\n",
      "11665: loss=0.062, reward_mean=0.410, reward_bound=0.478, batch=196\n",
      "11666: loss=0.060, reward_mean=0.400, reward_bound=0.185, batch=206\n",
      "11667: loss=0.061, reward_mean=0.440, reward_bound=0.185, batch=213\n",
      "11668: loss=0.061, reward_mean=0.470, reward_bound=0.229, batch=218\n",
      "11669: loss=0.063, reward_mean=0.410, reward_bound=0.254, batch=219\n",
      "11670: loss=0.064, reward_mean=0.410, reward_bound=0.282, batch=220\n",
      "11671: loss=0.065, reward_mean=0.470, reward_bound=0.314, batch=219\n",
      "11672: loss=0.064, reward_mean=0.400, reward_bound=0.349, batch=214\n",
      "11673: loss=0.064, reward_mean=0.530, reward_bound=0.384, batch=220\n",
      "11674: loss=0.063, reward_mean=0.430, reward_bound=0.338, batch=224\n",
      "11675: loss=0.062, reward_mean=0.410, reward_bound=0.314, batch=226\n",
      "11676: loss=0.066, reward_mean=0.480, reward_bound=0.387, batch=218\n",
      "11677: loss=0.066, reward_mean=0.380, reward_bound=0.282, batch=221\n",
      "11678: loss=0.066, reward_mean=0.420, reward_bound=0.314, batch=223\n",
      "11679: loss=0.065, reward_mean=0.500, reward_bound=0.398, batch=226\n",
      "11680: loss=0.063, reward_mean=0.420, reward_bound=0.430, batch=216\n",
      "11681: loss=0.063, reward_mean=0.440, reward_bound=0.260, batch=221\n",
      "11682: loss=0.061, reward_mean=0.350, reward_bound=0.314, batch=221\n",
      "11683: loss=0.061, reward_mean=0.410, reward_bound=0.282, batch=223\n",
      "11684: loss=0.063, reward_mean=0.380, reward_bound=0.349, batch=222\n",
      "11685: loss=0.062, reward_mean=0.360, reward_bound=0.324, batch=225\n",
      "11686: loss=0.062, reward_mean=0.450, reward_bound=0.349, batch=225\n",
      "11687: loss=0.063, reward_mean=0.500, reward_bound=0.387, batch=225\n",
      "11688: loss=0.062, reward_mean=0.520, reward_bound=0.430, batch=225\n",
      "11689: loss=0.063, reward_mean=0.500, reward_bound=0.478, batch=217\n",
      "11690: loss=0.063, reward_mean=0.430, reward_bound=0.380, batch=222\n",
      "11691: loss=0.063, reward_mean=0.520, reward_bound=0.387, batch=222\n",
      "11692: loss=0.064, reward_mean=0.420, reward_bound=0.400, batch=225\n",
      "11693: loss=0.064, reward_mean=0.490, reward_bound=0.430, batch=226\n",
      "11694: loss=0.063, reward_mean=0.430, reward_bound=0.409, batch=228\n",
      "11695: loss=0.063, reward_mean=0.520, reward_bound=0.392, batch=229\n",
      "11696: loss=0.063, reward_mean=0.470, reward_bound=0.430, batch=229\n",
      "11697: loss=0.063, reward_mean=0.430, reward_bound=0.478, batch=231\n",
      "11698: loss=0.063, reward_mean=0.380, reward_bound=0.478, batch=222\n",
      "11699: loss=0.063, reward_mean=0.480, reward_bound=0.430, batch=223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11700: loss=0.062, reward_mean=0.390, reward_bound=0.282, batch=225\n",
      "11701: loss=0.064, reward_mean=0.490, reward_bound=0.396, batch=227\n",
      "11702: loss=0.063, reward_mean=0.410, reward_bound=0.387, batch=228\n",
      "11703: loss=0.063, reward_mean=0.440, reward_bound=0.353, batch=229\n",
      "11704: loss=0.064, reward_mean=0.420, reward_bound=0.430, batch=227\n",
      "11705: loss=0.063, reward_mean=0.380, reward_bound=0.373, batch=229\n",
      "11706: loss=0.063, reward_mean=0.430, reward_bound=0.387, batch=229\n",
      "11707: loss=0.063, reward_mean=0.300, reward_bound=0.424, batch=230\n",
      "11708: loss=0.063, reward_mean=0.450, reward_bound=0.430, batch=230\n",
      "11709: loss=0.063, reward_mean=0.420, reward_bound=0.430, batch=230\n",
      "11710: loss=0.064, reward_mean=0.430, reward_bound=0.338, batch=231\n",
      "11711: loss=0.063, reward_mean=0.360, reward_bound=0.478, batch=225\n",
      "11712: loss=0.062, reward_mean=0.520, reward_bound=0.387, batch=226\n",
      "11713: loss=0.062, reward_mean=0.400, reward_bound=0.430, batch=226\n",
      "11714: loss=0.062, reward_mean=0.420, reward_bound=0.409, batch=228\n",
      "11715: loss=0.062, reward_mean=0.470, reward_bound=0.349, batch=228\n",
      "11716: loss=0.062, reward_mean=0.470, reward_bound=0.430, batch=228\n",
      "11717: loss=0.062, reward_mean=0.460, reward_bound=0.357, batch=229\n",
      "11718: loss=0.062, reward_mean=0.500, reward_bound=0.450, batch=230\n",
      "11719: loss=0.061, reward_mean=0.280, reward_bound=0.418, batch=231\n",
      "11720: loss=0.061, reward_mean=0.470, reward_bound=0.430, batch=231\n",
      "11721: loss=0.061, reward_mean=0.470, reward_bound=0.282, batch=231\n",
      "11722: loss=0.061, reward_mean=0.510, reward_bound=0.430, batch=231\n",
      "11723: loss=0.061, reward_mean=0.460, reward_bound=0.430, batch=231\n",
      "11724: loss=0.062, reward_mean=0.430, reward_bound=0.478, batch=229\n",
      "11725: loss=0.062, reward_mean=0.430, reward_bound=0.450, batch=230\n",
      "11726: loss=0.063, reward_mean=0.460, reward_bound=0.451, batch=231\n",
      "11727: loss=0.063, reward_mean=0.490, reward_bound=0.478, batch=230\n",
      "11728: loss=0.063, reward_mean=0.470, reward_bound=0.501, batch=231\n",
      "11729: loss=0.063, reward_mean=0.420, reward_bound=0.430, batch=231\n",
      "11730: loss=0.063, reward_mean=0.430, reward_bound=0.430, batch=231\n",
      "11731: loss=0.063, reward_mean=0.410, reward_bound=0.478, batch=231\n",
      "11732: loss=0.063, reward_mean=0.460, reward_bound=0.387, batch=231\n",
      "11734: loss=0.054, reward_mean=0.520, reward_bound=0.000, batch=52\n",
      "11735: loss=0.061, reward_mean=0.380, reward_bound=0.000, batch=90\n",
      "11736: loss=0.061, reward_mean=0.380, reward_bound=0.000, batch=128\n",
      "11737: loss=0.059, reward_mean=0.430, reward_bound=0.002, batch=159\n",
      "11738: loss=0.058, reward_mean=0.460, reward_bound=0.008, batch=181\n",
      "11739: loss=0.061, reward_mean=0.490, reward_bound=0.016, batch=196\n",
      "11740: loss=0.061, reward_mean=0.360, reward_bound=0.031, batch=206\n",
      "11741: loss=0.063, reward_mean=0.400, reward_bound=0.042, batch=213\n",
      "11742: loss=0.065, reward_mean=0.480, reward_bound=0.058, batch=207\n",
      "11743: loss=0.066, reward_mean=0.400, reward_bound=0.065, batch=212\n",
      "11744: loss=0.071, reward_mean=0.440, reward_bound=0.080, batch=213\n",
      "11745: loss=0.074, reward_mean=0.400, reward_bound=0.089, batch=216\n",
      "11746: loss=0.077, reward_mean=0.400, reward_bound=0.098, batch=217\n",
      "11747: loss=0.079, reward_mean=0.500, reward_bound=0.119, batch=222\n",
      "11748: loss=0.076, reward_mean=0.430, reward_bound=0.126, batch=225\n",
      "11749: loss=0.079, reward_mean=0.410, reward_bound=0.135, batch=208\n",
      "11750: loss=0.079, reward_mean=0.430, reward_bound=0.150, batch=204\n",
      "11751: loss=0.083, reward_mean=0.500, reward_bound=0.167, batch=206\n",
      "11752: loss=0.083, reward_mean=0.420, reward_bound=0.185, batch=193\n",
      "11753: loss=0.082, reward_mean=0.470, reward_bound=0.198, batch=205\n",
      "11754: loss=0.084, reward_mean=0.460, reward_bound=0.206, batch=189\n",
      "11755: loss=0.084, reward_mean=0.460, reward_bound=0.120, batch=202\n",
      "11756: loss=0.082, reward_mean=0.420, reward_bound=0.140, batch=211\n",
      "11757: loss=0.081, reward_mean=0.360, reward_bound=0.167, batch=216\n",
      "11758: loss=0.080, reward_mean=0.370, reward_bound=0.206, batch=218\n",
      "11759: loss=0.079, reward_mean=0.440, reward_bound=0.229, batch=197\n",
      "11760: loss=0.080, reward_mean=0.500, reward_bound=0.163, batch=208\n",
      "11761: loss=0.081, reward_mean=0.530, reward_bound=0.169, batch=215\n",
      "11762: loss=0.083, reward_mean=0.440, reward_bound=0.206, batch=219\n",
      "11763: loss=0.081, reward_mean=0.390, reward_bound=0.229, batch=221\n",
      "11764: loss=0.079, reward_mean=0.480, reward_bound=0.254, batch=188\n",
      "11765: loss=0.079, reward_mean=0.480, reward_bound=0.254, batch=200\n",
      "11766: loss=0.077, reward_mean=0.440, reward_bound=0.185, batch=208\n",
      "11767: loss=0.078, reward_mean=0.390, reward_bound=0.208, batch=215\n",
      "11768: loss=0.077, reward_mean=0.440, reward_bound=0.229, batch=219\n",
      "11769: loss=0.078, reward_mean=0.440, reward_bound=0.254, batch=221\n",
      "11770: loss=0.078, reward_mean=0.480, reward_bound=0.282, batch=189\n",
      "11771: loss=0.078, reward_mean=0.470, reward_bound=0.254, batch=200\n",
      "11772: loss=0.077, reward_mean=0.510, reward_bound=0.229, batch=209\n",
      "11773: loss=0.076, reward_mean=0.380, reward_bound=0.206, batch=215\n",
      "11774: loss=0.075, reward_mean=0.450, reward_bound=0.254, batch=215\n",
      "11775: loss=0.076, reward_mean=0.430, reward_bound=0.282, batch=216\n",
      "11776: loss=0.078, reward_mean=0.400, reward_bound=0.282, batch=220\n",
      "11777: loss=0.077, reward_mean=0.480, reward_bound=0.304, batch=224\n",
      "11778: loss=0.067, reward_mean=0.470, reward_bound=0.314, batch=168\n",
      "11779: loss=0.067, reward_mean=0.460, reward_bound=0.089, batch=186\n",
      "11780: loss=0.067, reward_mean=0.410, reward_bound=0.098, batch=198\n",
      "11781: loss=0.067, reward_mean=0.410, reward_bound=0.167, batch=206\n",
      "11782: loss=0.067, reward_mean=0.460, reward_bound=0.185, batch=213\n",
      "11783: loss=0.066, reward_mean=0.480, reward_bound=0.229, batch=214\n",
      "11784: loss=0.066, reward_mean=0.500, reward_bound=0.229, batch=219\n",
      "11785: loss=0.068, reward_mean=0.420, reward_bound=0.254, batch=213\n",
      "11786: loss=0.066, reward_mean=0.520, reward_bound=0.185, batch=218\n",
      "11787: loss=0.066, reward_mean=0.470, reward_bound=0.254, batch=221\n",
      "11788: loss=0.066, reward_mean=0.400, reward_bound=0.282, batch=219\n",
      "11789: loss=0.066, reward_mean=0.440, reward_bound=0.314, batch=214\n",
      "11790: loss=0.069, reward_mean=0.420, reward_bound=0.252, batch=220\n",
      "11791: loss=0.064, reward_mean=0.440, reward_bound=0.314, batch=223\n",
      "11792: loss=0.062, reward_mean=0.490, reward_bound=0.349, batch=172\n",
      "11793: loss=0.058, reward_mean=0.400, reward_bound=0.102, batch=190\n",
      "11794: loss=0.055, reward_mean=0.500, reward_bound=0.150, batch=202\n",
      "11795: loss=0.056, reward_mean=0.360, reward_bound=0.191, batch=211\n",
      "11796: loss=0.056, reward_mean=0.470, reward_bound=0.206, batch=212\n",
      "11797: loss=0.058, reward_mean=0.470, reward_bound=0.229, batch=216\n",
      "11798: loss=0.058, reward_mean=0.440, reward_bound=0.241, batch=221\n",
      "11799: loss=0.057, reward_mean=0.590, reward_bound=0.254, batch=219\n",
      "11800: loss=0.057, reward_mean=0.460, reward_bound=0.282, batch=219\n",
      "11801: loss=0.056, reward_mean=0.490, reward_bound=0.282, batch=222\n",
      "11802: loss=0.055, reward_mean=0.470, reward_bound=0.314, batch=212\n",
      "11803: loss=0.058, reward_mean=0.500, reward_bound=0.349, batch=206\n",
      "11804: loss=0.058, reward_mean=0.490, reward_bound=0.282, batch=212\n",
      "11805: loss=0.056, reward_mean=0.540, reward_bound=0.314, batch=215\n",
      "11806: loss=0.056, reward_mean=0.480, reward_bound=0.349, batch=216\n",
      "11807: loss=0.056, reward_mean=0.460, reward_bound=0.335, batch=221\n",
      "11808: loss=0.056, reward_mean=0.430, reward_bound=0.349, batch=224\n",
      "11809: loss=0.055, reward_mean=0.450, reward_bound=0.384, batch=227\n",
      "11810: loss=0.064, reward_mean=0.460, reward_bound=0.387, batch=146\n",
      "11811: loss=0.059, reward_mean=0.440, reward_bound=0.061, batch=172\n",
      "11812: loss=0.061, reward_mean=0.430, reward_bound=0.074, batch=190\n",
      "11813: loss=0.061, reward_mean=0.450, reward_bound=0.109, batch=202\n",
      "11814: loss=0.061, reward_mean=0.370, reward_bound=0.126, batch=211\n",
      "11815: loss=0.065, reward_mean=0.410, reward_bound=0.150, batch=213\n",
      "11816: loss=0.067, reward_mean=0.330, reward_bound=0.167, batch=218\n",
      "11817: loss=0.065, reward_mean=0.470, reward_bound=0.206, batch=215\n",
      "11818: loss=0.064, reward_mean=0.440, reward_bound=0.229, batch=217\n",
      "11819: loss=0.067, reward_mean=0.510, reward_bound=0.254, batch=210\n",
      "11820: loss=0.067, reward_mean=0.510, reward_bound=0.229, batch=216\n",
      "11821: loss=0.068, reward_mean=0.500, reward_bound=0.282, batch=204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11822: loss=0.067, reward_mean=0.470, reward_bound=0.229, batch=212\n",
      "11823: loss=0.067, reward_mean=0.430, reward_bound=0.206, batch=218\n",
      "11824: loss=0.070, reward_mean=0.440, reward_bound=0.314, batch=209\n",
      "11825: loss=0.069, reward_mean=0.520, reward_bound=0.314, batch=213\n",
      "11826: loss=0.068, reward_mean=0.460, reward_bound=0.282, batch=217\n",
      "11827: loss=0.068, reward_mean=0.430, reward_bound=0.277, batch=222\n",
      "11828: loss=0.070, reward_mean=0.400, reward_bound=0.314, batch=223\n",
      "11829: loss=0.070, reward_mean=0.500, reward_bound=0.282, batch=225\n",
      "11830: loss=0.069, reward_mean=0.420, reward_bound=0.266, batch=227\n",
      "11831: loss=0.067, reward_mean=0.440, reward_bound=0.349, batch=206\n",
      "11832: loss=0.067, reward_mean=0.380, reward_bound=0.230, batch=214\n",
      "11833: loss=0.065, reward_mean=0.450, reward_bound=0.204, batch=220\n",
      "11834: loss=0.068, reward_mean=0.430, reward_bound=0.274, batch=224\n",
      "11835: loss=0.068, reward_mean=0.520, reward_bound=0.345, batch=227\n",
      "11836: loss=0.066, reward_mean=0.460, reward_bound=0.349, batch=223\n",
      "11837: loss=0.060, reward_mean=0.470, reward_bound=0.387, batch=197\n",
      "11838: loss=0.061, reward_mean=0.420, reward_bound=0.182, batch=208\n",
      "11839: loss=0.060, reward_mean=0.380, reward_bound=0.206, batch=213\n",
      "11840: loss=0.057, reward_mean=0.440, reward_bound=0.271, batch=219\n",
      "11841: loss=0.056, reward_mean=0.500, reward_bound=0.314, batch=219\n",
      "11842: loss=0.055, reward_mean=0.380, reward_bound=0.295, batch=223\n",
      "11843: loss=0.055, reward_mean=0.440, reward_bound=0.349, batch=217\n",
      "11844: loss=0.055, reward_mean=0.500, reward_bound=0.349, batch=220\n",
      "11845: loss=0.054, reward_mean=0.450, reward_bound=0.254, batch=223\n",
      "11846: loss=0.055, reward_mean=0.410, reward_bound=0.322, batch=226\n",
      "11847: loss=0.055, reward_mean=0.490, reward_bound=0.368, batch=228\n",
      "11848: loss=0.059, reward_mean=0.490, reward_bound=0.387, batch=219\n",
      "11849: loss=0.058, reward_mean=0.450, reward_bound=0.328, batch=223\n",
      "11850: loss=0.060, reward_mean=0.410, reward_bound=0.301, batch=226\n",
      "11851: loss=0.057, reward_mean=0.470, reward_bound=0.314, batch=225\n",
      "11852: loss=0.058, reward_mean=0.420, reward_bound=0.356, batch=227\n",
      "11853: loss=0.057, reward_mean=0.450, reward_bound=0.387, batch=226\n",
      "11854: loss=0.057, reward_mean=0.490, reward_bound=0.409, batch=228\n",
      "11855: loss=0.068, reward_mean=0.440, reward_bound=0.430, batch=121\n",
      "11856: loss=0.063, reward_mean=0.480, reward_bound=0.023, batch=154\n",
      "11857: loss=0.064, reward_mean=0.510, reward_bound=0.052, batch=177\n",
      "11858: loss=0.066, reward_mean=0.560, reward_bound=0.080, batch=191\n",
      "11859: loss=0.068, reward_mean=0.460, reward_bound=0.098, batch=203\n",
      "11860: loss=0.063, reward_mean=0.560, reward_bound=0.135, batch=205\n",
      "11861: loss=0.064, reward_mean=0.390, reward_bound=0.150, batch=210\n",
      "11862: loss=0.062, reward_mean=0.450, reward_bound=0.167, batch=215\n",
      "11863: loss=0.060, reward_mean=0.460, reward_bound=0.189, batch=220\n",
      "11864: loss=0.061, reward_mean=0.370, reward_bound=0.206, batch=231\n",
      "11865: loss=0.062, reward_mean=0.410, reward_bound=0.206, batch=228\n",
      "11866: loss=0.062, reward_mean=0.460, reward_bound=0.229, batch=216\n",
      "11867: loss=0.063, reward_mean=0.360, reward_bound=0.206, batch=220\n",
      "11868: loss=0.064, reward_mean=0.400, reward_bound=0.247, batch=224\n",
      "11869: loss=0.064, reward_mean=0.370, reward_bound=0.254, batch=205\n",
      "11870: loss=0.062, reward_mean=0.370, reward_bound=0.260, batch=213\n",
      "11871: loss=0.062, reward_mean=0.460, reward_bound=0.220, batch=219\n",
      "11872: loss=0.067, reward_mean=0.500, reward_bound=0.282, batch=198\n",
      "11873: loss=0.066, reward_mean=0.430, reward_bound=0.167, batch=205\n",
      "11874: loss=0.066, reward_mean=0.390, reward_bound=0.210, batch=213\n",
      "11875: loss=0.064, reward_mean=0.420, reward_bound=0.229, batch=218\n",
      "11876: loss=0.062, reward_mean=0.460, reward_bound=0.257, batch=222\n",
      "11877: loss=0.063, reward_mean=0.440, reward_bound=0.282, batch=217\n",
      "11878: loss=0.063, reward_mean=0.440, reward_bound=0.229, batch=221\n",
      "11879: loss=0.064, reward_mean=0.490, reward_bound=0.282, batch=223\n",
      "11880: loss=0.064, reward_mean=0.520, reward_bound=0.314, batch=201\n",
      "11881: loss=0.064, reward_mean=0.480, reward_bound=0.229, batch=209\n",
      "11882: loss=0.063, reward_mean=0.470, reward_bound=0.314, batch=215\n",
      "11883: loss=0.057, reward_mean=0.470, reward_bound=0.349, batch=196\n",
      "11884: loss=0.053, reward_mean=0.420, reward_bound=0.158, batch=207\n",
      "11885: loss=0.051, reward_mean=0.440, reward_bound=0.167, batch=214\n",
      "11886: loss=0.050, reward_mean=0.520, reward_bound=0.226, batch=220\n",
      "11887: loss=0.053, reward_mean=0.410, reward_bound=0.229, batch=221\n",
      "11888: loss=0.055, reward_mean=0.480, reward_bound=0.254, batch=222\n",
      "11889: loss=0.055, reward_mean=0.390, reward_bound=0.282, batch=221\n",
      "11890: loss=0.054, reward_mean=0.490, reward_bound=0.314, batch=222\n",
      "11891: loss=0.054, reward_mean=0.420, reward_bound=0.349, batch=218\n",
      "11892: loss=0.052, reward_mean=0.400, reward_bound=0.211, batch=222\n",
      "11893: loss=0.052, reward_mean=0.420, reward_bound=0.349, batch=224\n",
      "11894: loss=0.059, reward_mean=0.380, reward_bound=0.387, batch=187\n",
      "11895: loss=0.056, reward_mean=0.490, reward_bound=0.182, batch=201\n",
      "11896: loss=0.055, reward_mean=0.470, reward_bound=0.206, batch=206\n",
      "11897: loss=0.056, reward_mean=0.530, reward_bound=0.217, batch=214\n",
      "11898: loss=0.056, reward_mean=0.440, reward_bound=0.229, batch=218\n",
      "11899: loss=0.057, reward_mean=0.420, reward_bound=0.257, batch=222\n",
      "11900: loss=0.059, reward_mean=0.450, reward_bound=0.282, batch=223\n",
      "11901: loss=0.060, reward_mean=0.410, reward_bound=0.244, batch=226\n",
      "11902: loss=0.060, reward_mean=0.400, reward_bound=0.314, batch=219\n",
      "11903: loss=0.059, reward_mean=0.420, reward_bound=0.295, batch=223\n",
      "11904: loss=0.061, reward_mean=0.430, reward_bound=0.244, batch=226\n",
      "11905: loss=0.060, reward_mean=0.430, reward_bound=0.241, batch=228\n",
      "11906: loss=0.059, reward_mean=0.390, reward_bound=0.317, batch=229\n",
      "11907: loss=0.060, reward_mean=0.440, reward_bound=0.349, batch=226\n",
      "11908: loss=0.060, reward_mean=0.470, reward_bound=0.351, batch=228\n",
      "11909: loss=0.059, reward_mean=0.420, reward_bound=0.387, batch=220\n",
      "11910: loss=0.059, reward_mean=0.500, reward_bound=0.349, batch=222\n",
      "11911: loss=0.058, reward_mean=0.430, reward_bound=0.360, batch=225\n",
      "11912: loss=0.058, reward_mean=0.430, reward_bound=0.387, batch=226\n",
      "11913: loss=0.066, reward_mean=0.390, reward_bound=0.430, batch=177\n",
      "11914: loss=0.063, reward_mean=0.380, reward_bound=0.087, batch=194\n",
      "11915: loss=0.062, reward_mean=0.460, reward_bound=0.150, batch=203\n",
      "11916: loss=0.065, reward_mean=0.390, reward_bound=0.185, batch=209\n",
      "11917: loss=0.063, reward_mean=0.450, reward_bound=0.206, batch=215\n",
      "11918: loss=0.065, reward_mean=0.440, reward_bound=0.229, batch=212\n",
      "11919: loss=0.065, reward_mean=0.410, reward_bound=0.254, batch=213\n",
      "11920: loss=0.065, reward_mean=0.490, reward_bound=0.282, batch=214\n",
      "11921: loss=0.064, reward_mean=0.410, reward_bound=0.280, batch=220\n",
      "11922: loss=0.068, reward_mean=0.370, reward_bound=0.282, batch=223\n",
      "11923: loss=0.069, reward_mean=0.480, reward_bound=0.314, batch=218\n",
      "11924: loss=0.062, reward_mean=0.460, reward_bound=0.349, batch=210\n",
      "11925: loss=0.061, reward_mean=0.430, reward_bound=0.329, batch=217\n",
      "11926: loss=0.060, reward_mean=0.470, reward_bound=0.349, batch=221\n",
      "11927: loss=0.062, reward_mean=0.380, reward_bound=0.387, batch=212\n",
      "11928: loss=0.062, reward_mean=0.460, reward_bound=0.229, batch=218\n",
      "11929: loss=0.061, reward_mean=0.370, reward_bound=0.257, batch=222\n",
      "11930: loss=0.063, reward_mean=0.400, reward_bound=0.282, batch=224\n",
      "11931: loss=0.062, reward_mean=0.470, reward_bound=0.349, batch=220\n",
      "11932: loss=0.064, reward_mean=0.510, reward_bound=0.387, batch=221\n",
      "11933: loss=0.065, reward_mean=0.450, reward_bound=0.387, batch=223\n",
      "11934: loss=0.064, reward_mean=0.320, reward_bound=0.301, batch=226\n",
      "11935: loss=0.063, reward_mean=0.390, reward_bound=0.331, batch=228\n",
      "11936: loss=0.063, reward_mean=0.560, reward_bound=0.392, batch=229\n",
      "11937: loss=0.066, reward_mean=0.400, reward_bound=0.430, batch=205\n",
      "11938: loss=0.066, reward_mean=0.510, reward_bound=0.282, batch=211\n",
      "11939: loss=0.065, reward_mean=0.360, reward_bound=0.135, batch=217\n",
      "11940: loss=0.068, reward_mean=0.480, reward_bound=0.254, batch=219\n",
      "11941: loss=0.065, reward_mean=0.480, reward_bound=0.349, batch=221\n",
      "11942: loss=0.067, reward_mean=0.490, reward_bound=0.185, batch=224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11943: loss=0.062, reward_mean=0.480, reward_bound=0.387, batch=222\n",
      "11944: loss=0.062, reward_mean=0.410, reward_bound=0.254, batch=224\n",
      "11945: loss=0.062, reward_mean=0.500, reward_bound=0.311, batch=227\n",
      "11946: loss=0.064, reward_mean=0.450, reward_bound=0.430, batch=216\n",
      "11947: loss=0.062, reward_mean=0.450, reward_bound=0.316, batch=221\n",
      "11948: loss=0.061, reward_mean=0.460, reward_bound=0.206, batch=224\n",
      "11949: loss=0.061, reward_mean=0.440, reward_bound=0.349, batch=226\n",
      "11950: loss=0.064, reward_mean=0.410, reward_bound=0.387, batch=223\n",
      "11951: loss=0.063, reward_mean=0.440, reward_bound=0.322, batch=226\n",
      "11952: loss=0.063, reward_mean=0.540, reward_bound=0.349, batch=226\n",
      "11953: loss=0.063, reward_mean=0.440, reward_bound=0.409, batch=228\n",
      "11954: loss=0.063, reward_mean=0.470, reward_bound=0.430, batch=221\n",
      "11955: loss=0.062, reward_mean=0.470, reward_bound=0.349, batch=224\n",
      "11956: loss=0.062, reward_mean=0.410, reward_bound=0.426, batch=227\n",
      "11957: loss=0.061, reward_mean=0.390, reward_bound=0.422, batch=229\n",
      "11958: loss=0.061, reward_mean=0.480, reward_bound=0.430, batch=229\n",
      "11959: loss=0.061, reward_mean=0.400, reward_bound=0.424, batch=230\n",
      "11960: loss=0.061, reward_mean=0.490, reward_bound=0.464, batch=231\n",
      "11961: loss=0.061, reward_mean=0.460, reward_bound=0.430, batch=231\n",
      "11962: loss=0.058, reward_mean=0.490, reward_bound=0.478, batch=100\n",
      "11963: loss=0.056, reward_mean=0.460, reward_bound=0.014, batch=140\n",
      "11964: loss=0.055, reward_mean=0.490, reward_bound=0.031, batch=166\n",
      "11965: loss=0.052, reward_mean=0.400, reward_bound=0.038, batch=185\n",
      "11966: loss=0.053, reward_mean=0.440, reward_bound=0.052, batch=197\n",
      "11967: loss=0.054, reward_mean=0.470, reward_bound=0.078, batch=208\n",
      "11968: loss=0.052, reward_mean=0.440, reward_bound=0.090, batch=215\n",
      "11969: loss=0.053, reward_mean=0.460, reward_bound=0.122, batch=213\n",
      "11970: loss=0.055, reward_mean=0.410, reward_bound=0.150, batch=208\n",
      "11971: loss=0.057, reward_mean=0.500, reward_bound=0.167, batch=212\n",
      "11972: loss=0.057, reward_mean=0.530, reward_bound=0.185, batch=207\n",
      "11973: loss=0.057, reward_mean=0.510, reward_bound=0.206, batch=200\n",
      "11974: loss=0.055, reward_mean=0.490, reward_bound=0.229, batch=194\n",
      "11975: loss=0.057, reward_mean=0.430, reward_bound=0.150, batch=205\n",
      "11976: loss=0.057, reward_mean=0.470, reward_bound=0.229, batch=210\n",
      "11977: loss=0.054, reward_mean=0.440, reward_bound=0.254, batch=195\n",
      "11978: loss=0.057, reward_mean=0.370, reward_bound=0.135, batch=205\n",
      "11979: loss=0.057, reward_mean=0.460, reward_bound=0.229, batch=212\n",
      "11980: loss=0.058, reward_mean=0.470, reward_bound=0.254, batch=216\n",
      "11981: loss=0.061, reward_mean=0.480, reward_bound=0.282, batch=204\n",
      "11982: loss=0.062, reward_mean=0.480, reward_bound=0.280, batch=213\n",
      "11983: loss=0.064, reward_mean=0.350, reward_bound=0.254, batch=218\n",
      "11984: loss=0.060, reward_mean=0.460, reward_bound=0.282, batch=219\n",
      "11985: loss=0.064, reward_mean=0.490, reward_bound=0.314, batch=192\n",
      "11986: loss=0.064, reward_mean=0.430, reward_bound=0.198, batch=204\n",
      "11987: loss=0.062, reward_mean=0.450, reward_bound=0.206, batch=212\n",
      "11988: loss=0.063, reward_mean=0.430, reward_bound=0.254, batch=214\n",
      "11989: loss=0.062, reward_mean=0.420, reward_bound=0.314, batch=212\n",
      "11990: loss=0.063, reward_mean=0.440, reward_bound=0.265, batch=218\n",
      "11991: loss=0.062, reward_mean=0.470, reward_bound=0.349, batch=190\n",
      "11992: loss=0.066, reward_mean=0.470, reward_bound=0.185, batch=202\n",
      "11993: loss=0.062, reward_mean=0.510, reward_bound=0.229, batch=210\n",
      "11994: loss=0.061, reward_mean=0.460, reward_bound=0.229, batch=215\n",
      "11995: loss=0.060, reward_mean=0.440, reward_bound=0.254, batch=217\n",
      "11996: loss=0.062, reward_mean=0.440, reward_bound=0.282, batch=220\n",
      "11997: loss=0.063, reward_mean=0.430, reward_bound=0.314, batch=216\n",
      "11998: loss=0.061, reward_mean=0.510, reward_bound=0.349, batch=216\n",
      "11999: loss=0.061, reward_mean=0.390, reward_bound=0.268, batch=221\n",
      "12000: loss=0.061, reward_mean=0.460, reward_bound=0.282, batch=224\n",
      "12001: loss=0.060, reward_mean=0.530, reward_bound=0.314, batch=222\n",
      "12002: loss=0.061, reward_mean=0.440, reward_bound=0.314, batch=224\n",
      "12003: loss=0.062, reward_mean=0.420, reward_bound=0.349, batch=225\n",
      "12004: loss=0.060, reward_mean=0.540, reward_bound=0.387, batch=180\n",
      "12005: loss=0.064, reward_mean=0.500, reward_bound=0.162, batch=196\n",
      "12006: loss=0.064, reward_mean=0.510, reward_bound=0.158, batch=207\n",
      "12007: loss=0.062, reward_mean=0.440, reward_bound=0.167, batch=214\n",
      "12008: loss=0.066, reward_mean=0.570, reward_bound=0.229, batch=213\n",
      "12009: loss=0.063, reward_mean=0.360, reward_bound=0.254, batch=214\n",
      "12010: loss=0.063, reward_mean=0.430, reward_bound=0.282, batch=216\n",
      "12011: loss=0.065, reward_mean=0.420, reward_bound=0.314, batch=215\n",
      "12012: loss=0.064, reward_mean=0.440, reward_bound=0.246, batch=220\n",
      "12013: loss=0.064, reward_mean=0.400, reward_bound=0.304, batch=224\n",
      "12014: loss=0.064, reward_mean=0.430, reward_bound=0.314, batch=224\n",
      "12015: loss=0.060, reward_mean=0.470, reward_bound=0.349, batch=210\n",
      "12016: loss=0.059, reward_mean=0.520, reward_bound=0.274, batch=217\n",
      "12017: loss=0.060, reward_mean=0.410, reward_bound=0.282, batch=220\n",
      "12018: loss=0.062, reward_mean=0.410, reward_bound=0.304, batch=224\n",
      "12019: loss=0.063, reward_mean=0.510, reward_bound=0.349, batch=222\n",
      "12020: loss=0.064, reward_mean=0.410, reward_bound=0.387, batch=219\n",
      "12021: loss=0.063, reward_mean=0.420, reward_bound=0.292, batch=223\n",
      "12022: loss=0.064, reward_mean=0.340, reward_bound=0.349, batch=224\n",
      "12023: loss=0.064, reward_mean=0.430, reward_bound=0.349, batch=226\n",
      "12024: loss=0.064, reward_mean=0.520, reward_bound=0.387, batch=226\n",
      "12025: loss=0.064, reward_mean=0.510, reward_bound=0.331, batch=228\n",
      "12026: loss=0.064, reward_mean=0.390, reward_bound=0.353, batch=229\n",
      "12027: loss=0.064, reward_mean=0.470, reward_bound=0.387, batch=229\n",
      "12028: loss=0.063, reward_mean=0.460, reward_bound=0.295, batch=230\n",
      "12029: loss=0.063, reward_mean=0.450, reward_bound=0.418, batch=231\n",
      "12030: loss=0.063, reward_mean=0.440, reward_bound=0.430, batch=175\n",
      "12031: loss=0.062, reward_mean=0.440, reward_bound=0.153, batch=192\n",
      "12032: loss=0.064, reward_mean=0.460, reward_bound=0.155, batch=204\n",
      "12033: loss=0.064, reward_mean=0.440, reward_bound=0.185, batch=207\n",
      "12034: loss=0.060, reward_mean=0.420, reward_bound=0.206, batch=209\n",
      "12035: loss=0.059, reward_mean=0.360, reward_bound=0.229, batch=212\n",
      "12036: loss=0.058, reward_mean=0.380, reward_bound=0.254, batch=217\n",
      "12037: loss=0.058, reward_mean=0.380, reward_bound=0.282, batch=212\n",
      "12038: loss=0.056, reward_mean=0.490, reward_bound=0.263, batch=218\n",
      "12039: loss=0.056, reward_mean=0.480, reward_bound=0.282, batch=221\n",
      "12040: loss=0.058, reward_mean=0.550, reward_bound=0.254, batch=224\n",
      "12041: loss=0.057, reward_mean=0.410, reward_bound=0.314, batch=213\n",
      "12042: loss=0.055, reward_mean=0.430, reward_bound=0.301, batch=219\n",
      "12043: loss=0.055, reward_mean=0.580, reward_bound=0.314, batch=222\n",
      "12044: loss=0.054, reward_mean=0.480, reward_bound=0.324, batch=225\n",
      "12045: loss=0.054, reward_mean=0.380, reward_bound=0.282, batch=226\n",
      "12046: loss=0.054, reward_mean=0.470, reward_bound=0.349, batch=218\n",
      "12047: loss=0.053, reward_mean=0.440, reward_bound=0.314, batch=221\n",
      "12048: loss=0.054, reward_mean=0.460, reward_bound=0.314, batch=224\n",
      "12049: loss=0.053, reward_mean=0.460, reward_bound=0.349, batch=225\n",
      "12050: loss=0.056, reward_mean=0.560, reward_bound=0.387, batch=204\n",
      "12051: loss=0.055, reward_mean=0.480, reward_bound=0.314, batch=209\n",
      "12052: loss=0.055, reward_mean=0.390, reward_bound=0.265, batch=216\n",
      "12053: loss=0.055, reward_mean=0.350, reward_bound=0.282, batch=216\n",
      "12054: loss=0.054, reward_mean=0.330, reward_bound=0.206, batch=220\n",
      "12055: loss=0.054, reward_mean=0.410, reward_bound=0.282, batch=221\n",
      "12056: loss=0.054, reward_mean=0.430, reward_bound=0.314, batch=222\n",
      "12057: loss=0.054, reward_mean=0.460, reward_bound=0.349, batch=217\n",
      "12058: loss=0.053, reward_mean=0.390, reward_bound=0.254, batch=220\n",
      "12059: loss=0.052, reward_mean=0.500, reward_bound=0.338, batch=224\n",
      "12060: loss=0.052, reward_mean=0.420, reward_bound=0.349, batch=225\n",
      "12061: loss=0.052, reward_mean=0.400, reward_bound=0.321, batch=227\n",
      "12062: loss=0.053, reward_mean=0.390, reward_bound=0.302, batch=229\n",
      "12063: loss=0.051, reward_mean=0.480, reward_bound=0.349, batch=229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12064: loss=0.053, reward_mean=0.430, reward_bound=0.387, batch=223\n",
      "12065: loss=0.052, reward_mean=0.500, reward_bound=0.387, batch=224\n",
      "12066: loss=0.052, reward_mean=0.520, reward_bound=0.387, batch=225\n",
      "12067: loss=0.052, reward_mean=0.450, reward_bound=0.387, batch=226\n",
      "12068: loss=0.052, reward_mean=0.420, reward_bound=0.387, batch=227\n",
      "12069: loss=0.052, reward_mean=0.500, reward_bound=0.387, batch=227\n",
      "12070: loss=0.052, reward_mean=0.500, reward_bound=0.422, batch=229\n",
      "12071: loss=0.057, reward_mean=0.460, reward_bound=0.430, batch=206\n",
      "12072: loss=0.054, reward_mean=0.540, reward_bound=0.241, batch=214\n",
      "12073: loss=0.053, reward_mean=0.490, reward_bound=0.254, batch=219\n",
      "12074: loss=0.052, reward_mean=0.520, reward_bound=0.314, batch=222\n",
      "12075: loss=0.052, reward_mean=0.410, reward_bound=0.324, batch=225\n",
      "12076: loss=0.056, reward_mean=0.500, reward_bound=0.349, batch=218\n",
      "12077: loss=0.055, reward_mean=0.350, reward_bound=0.349, batch=221\n",
      "12078: loss=0.056, reward_mean=0.430, reward_bound=0.229, batch=224\n",
      "12079: loss=0.058, reward_mean=0.400, reward_bound=0.387, batch=219\n",
      "12080: loss=0.059, reward_mean=0.460, reward_bound=0.349, batch=221\n",
      "12081: loss=0.058, reward_mean=0.440, reward_bound=0.349, batch=224\n",
      "12082: loss=0.058, reward_mean=0.460, reward_bound=0.387, batch=224\n",
      "12083: loss=0.057, reward_mean=0.440, reward_bound=0.384, batch=227\n",
      "12084: loss=0.057, reward_mean=0.490, reward_bound=0.430, batch=221\n",
      "12085: loss=0.057, reward_mean=0.400, reward_bound=0.349, batch=223\n",
      "12086: loss=0.058, reward_mean=0.490, reward_bound=0.413, batch=226\n",
      "12087: loss=0.059, reward_mean=0.460, reward_bound=0.351, batch=228\n",
      "12088: loss=0.057, reward_mean=0.420, reward_bound=0.387, batch=228\n",
      "12089: loss=0.058, reward_mean=0.510, reward_bound=0.430, batch=227\n",
      "12090: loss=0.060, reward_mean=0.350, reward_bound=0.478, batch=156\n",
      "12091: loss=0.057, reward_mean=0.500, reward_bound=0.089, batch=178\n",
      "12092: loss=0.062, reward_mean=0.450, reward_bound=0.135, batch=192\n",
      "12093: loss=0.062, reward_mean=0.470, reward_bound=0.150, batch=203\n",
      "12094: loss=0.060, reward_mean=0.510, reward_bound=0.185, batch=200\n",
      "12095: loss=0.060, reward_mean=0.390, reward_bound=0.180, batch=210\n",
      "12096: loss=0.060, reward_mean=0.360, reward_bound=0.206, batch=218\n",
      "12097: loss=0.060, reward_mean=0.480, reward_bound=0.206, batch=215\n",
      "12098: loss=0.056, reward_mean=0.460, reward_bound=0.229, batch=216\n",
      "12099: loss=0.056, reward_mean=0.400, reward_bound=0.254, batch=208\n",
      "12100: loss=0.055, reward_mean=0.480, reward_bound=0.192, batch=215\n",
      "12101: loss=0.054, reward_mean=0.450, reward_bound=0.254, batch=216\n",
      "12102: loss=0.055, reward_mean=0.420, reward_bound=0.282, batch=210\n",
      "12103: loss=0.054, reward_mean=0.480, reward_bound=0.282, batch=216\n",
      "12104: loss=0.052, reward_mean=0.470, reward_bound=0.314, batch=206\n",
      "12105: loss=0.050, reward_mean=0.490, reward_bound=0.206, batch=213\n",
      "12106: loss=0.049, reward_mean=0.440, reward_bound=0.229, batch=218\n",
      "12107: loss=0.048, reward_mean=0.480, reward_bound=0.286, batch=222\n",
      "12108: loss=0.049, reward_mean=0.340, reward_bound=0.314, batch=220\n",
      "12109: loss=0.049, reward_mean=0.320, reward_bound=0.282, batch=222\n",
      "12110: loss=0.051, reward_mean=0.360, reward_bound=0.349, batch=207\n",
      "12111: loss=0.050, reward_mean=0.390, reward_bound=0.202, batch=215\n",
      "12112: loss=0.053, reward_mean=0.440, reward_bound=0.260, batch=220\n",
      "12113: loss=0.054, reward_mean=0.440, reward_bound=0.282, batch=222\n",
      "12114: loss=0.057, reward_mean=0.450, reward_bound=0.292, batch=225\n",
      "12115: loss=0.053, reward_mean=0.550, reward_bound=0.321, batch=227\n",
      "12116: loss=0.050, reward_mean=0.460, reward_bound=0.349, batch=224\n",
      "12117: loss=0.051, reward_mean=0.360, reward_bound=0.384, batch=227\n",
      "12118: loss=0.056, reward_mean=0.460, reward_bound=0.387, batch=208\n",
      "12119: loss=0.058, reward_mean=0.410, reward_bound=0.257, batch=215\n",
      "12120: loss=0.056, reward_mean=0.520, reward_bound=0.314, batch=219\n",
      "12121: loss=0.057, reward_mean=0.440, reward_bound=0.349, batch=222\n",
      "12122: loss=0.058, reward_mean=0.430, reward_bound=0.387, batch=215\n",
      "12123: loss=0.056, reward_mean=0.480, reward_bound=0.234, batch=220\n",
      "12124: loss=0.055, reward_mean=0.390, reward_bound=0.222, batch=224\n",
      "12125: loss=0.058, reward_mean=0.540, reward_bound=0.314, batch=225\n",
      "12126: loss=0.057, reward_mean=0.410, reward_bound=0.349, batch=225\n",
      "12127: loss=0.056, reward_mean=0.450, reward_bound=0.387, batch=224\n",
      "12128: loss=0.056, reward_mean=0.430, reward_bound=0.314, batch=226\n",
      "12129: loss=0.055, reward_mean=0.460, reward_bound=0.368, batch=228\n",
      "12130: loss=0.055, reward_mean=0.540, reward_bound=0.387, batch=228\n",
      "12131: loss=0.055, reward_mean=0.450, reward_bound=0.317, batch=229\n",
      "12132: loss=0.055, reward_mean=0.500, reward_bound=0.405, batch=230\n",
      "12133: loss=0.055, reward_mean=0.420, reward_bound=0.418, batch=231\n",
      "12134: loss=0.055, reward_mean=0.470, reward_bound=0.430, batch=200\n",
      "12135: loss=0.055, reward_mean=0.530, reward_bound=0.206, batch=211\n",
      "12136: loss=0.060, reward_mean=0.470, reward_bound=0.167, batch=217\n",
      "12137: loss=0.059, reward_mean=0.470, reward_bound=0.224, batch=222\n",
      "12138: loss=0.057, reward_mean=0.430, reward_bound=0.254, batch=223\n",
      "12139: loss=0.054, reward_mean=0.390, reward_bound=0.314, batch=218\n",
      "12140: loss=0.053, reward_mean=0.510, reward_bound=0.349, batch=217\n",
      "12141: loss=0.054, reward_mean=0.480, reward_bound=0.342, batch=222\n",
      "12142: loss=0.053, reward_mean=0.420, reward_bound=0.324, batch=225\n",
      "12143: loss=0.054, reward_mean=0.470, reward_bound=0.349, batch=224\n",
      "12144: loss=0.056, reward_mean=0.510, reward_bound=0.387, batch=222\n",
      "12145: loss=0.057, reward_mean=0.490, reward_bound=0.254, batch=225\n",
      "12146: loss=0.055, reward_mean=0.480, reward_bound=0.314, batch=226\n",
      "12147: loss=0.055, reward_mean=0.480, reward_bound=0.368, batch=228\n",
      "12148: loss=0.055, reward_mean=0.450, reward_bound=0.387, batch=227\n",
      "12149: loss=0.055, reward_mean=0.450, reward_bound=0.414, batch=229\n",
      "12150: loss=0.057, reward_mean=0.400, reward_bound=0.430, batch=219\n",
      "12151: loss=0.056, reward_mean=0.540, reward_bound=0.324, batch=223\n",
      "12152: loss=0.056, reward_mean=0.430, reward_bound=0.349, batch=225\n",
      "12153: loss=0.055, reward_mean=0.470, reward_bound=0.396, batch=227\n",
      "12154: loss=0.055, reward_mean=0.410, reward_bound=0.390, batch=229\n",
      "12155: loss=0.056, reward_mean=0.460, reward_bound=0.430, batch=225\n",
      "12156: loss=0.055, reward_mean=0.390, reward_bound=0.396, batch=227\n",
      "12157: loss=0.055, reward_mean=0.450, reward_bound=0.308, batch=229\n",
      "12158: loss=0.055, reward_mean=0.520, reward_bound=0.349, batch=229\n",
      "12159: loss=0.055, reward_mean=0.500, reward_bound=0.343, batch=230\n",
      "12160: loss=0.055, reward_mean=0.370, reward_bound=0.387, batch=229\n",
      "12161: loss=0.055, reward_mean=0.380, reward_bound=0.314, batch=229\n",
      "12162: loss=0.056, reward_mean=0.360, reward_bound=0.364, batch=230\n",
      "12163: loss=0.056, reward_mean=0.390, reward_bound=0.365, batch=231\n",
      "12164: loss=0.054, reward_mean=0.520, reward_bound=0.387, batch=231\n",
      "12165: loss=0.057, reward_mean=0.480, reward_bound=0.430, batch=229\n",
      "12166: loss=0.057, reward_mean=0.360, reward_bound=0.349, batch=229\n",
      "12167: loss=0.056, reward_mean=0.480, reward_bound=0.450, batch=230\n",
      "12168: loss=0.056, reward_mean=0.380, reward_bound=0.451, batch=231\n",
      "12169: loss=0.056, reward_mean=0.430, reward_bound=0.430, batch=231\n",
      "12170: loss=0.059, reward_mean=0.530, reward_bound=0.478, batch=186\n",
      "12171: loss=0.065, reward_mean=0.440, reward_bound=0.158, batch=200\n",
      "12172: loss=0.063, reward_mean=0.440, reward_bound=0.206, batch=213\n",
      "12173: loss=0.063, reward_mean=0.440, reward_bound=0.206, batch=216\n",
      "12174: loss=0.068, reward_mean=0.560, reward_bound=0.254, batch=219\n",
      "12175: loss=0.069, reward_mean=0.540, reward_bound=0.314, batch=218\n",
      "12176: loss=0.069, reward_mean=0.430, reward_bound=0.317, batch=222\n",
      "12177: loss=0.062, reward_mean=0.440, reward_bound=0.349, batch=215\n",
      "12178: loss=0.064, reward_mean=0.390, reward_bound=0.234, batch=220\n",
      "12179: loss=0.062, reward_mean=0.520, reward_bound=0.314, batch=223\n",
      "12180: loss=0.061, reward_mean=0.360, reward_bound=0.349, batch=223\n",
      "12181: loss=0.060, reward_mean=0.360, reward_bound=0.335, batch=226\n",
      "12182: loss=0.060, reward_mean=0.430, reward_bound=0.368, batch=228\n",
      "12183: loss=0.062, reward_mean=0.380, reward_bound=0.387, batch=215\n",
      "12184: loss=0.066, reward_mean=0.400, reward_bound=0.349, batch=218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12185: loss=0.065, reward_mean=0.460, reward_bound=0.317, batch=222\n",
      "12186: loss=0.065, reward_mean=0.480, reward_bound=0.349, batch=223\n",
      "12187: loss=0.066, reward_mean=0.420, reward_bound=0.229, batch=225\n",
      "12188: loss=0.067, reward_mean=0.410, reward_bound=0.356, batch=227\n",
      "12189: loss=0.064, reward_mean=0.460, reward_bound=0.387, batch=225\n",
      "12190: loss=0.065, reward_mean=0.490, reward_bound=0.296, batch=227\n",
      "12191: loss=0.064, reward_mean=0.430, reward_bound=0.349, batch=226\n",
      "12192: loss=0.063, reward_mean=0.380, reward_bound=0.409, batch=228\n",
      "12193: loss=0.065, reward_mean=0.420, reward_bound=0.353, batch=229\n",
      "12194: loss=0.061, reward_mean=0.510, reward_bound=0.430, batch=202\n",
      "12195: loss=0.060, reward_mean=0.470, reward_bound=0.191, batch=211\n",
      "12196: loss=0.059, reward_mean=0.480, reward_bound=0.206, batch=217\n",
      "12197: loss=0.058, reward_mean=0.470, reward_bound=0.229, batch=220\n",
      "12198: loss=0.059, reward_mean=0.460, reward_bound=0.254, batch=223\n",
      "12199: loss=0.058, reward_mean=0.540, reward_bound=0.282, batch=222\n",
      "12200: loss=0.057, reward_mean=0.370, reward_bound=0.292, batch=225\n",
      "12201: loss=0.057, reward_mean=0.380, reward_bound=0.246, batch=227\n",
      "12202: loss=0.056, reward_mean=0.430, reward_bound=0.314, batch=227\n",
      "12203: loss=0.057, reward_mean=0.530, reward_bound=0.349, batch=225\n",
      "12204: loss=0.056, reward_mean=0.400, reward_bound=0.329, batch=227\n",
      "12205: loss=0.058, reward_mean=0.320, reward_bound=0.387, batch=220\n",
      "12206: loss=0.059, reward_mean=0.480, reward_bound=0.304, batch=224\n",
      "12207: loss=0.060, reward_mean=0.390, reward_bound=0.314, batch=226\n",
      "12208: loss=0.059, reward_mean=0.340, reward_bound=0.331, batch=228\n",
      "12209: loss=0.061, reward_mean=0.490, reward_bound=0.353, batch=229\n",
      "12210: loss=0.058, reward_mean=0.460, reward_bound=0.387, batch=226\n",
      "12211: loss=0.058, reward_mean=0.460, reward_bound=0.356, batch=228\n",
      "12212: loss=0.058, reward_mean=0.450, reward_bound=0.387, batch=228\n",
      "12213: loss=0.058, reward_mean=0.430, reward_bound=0.357, batch=229\n",
      "12214: loss=0.060, reward_mean=0.480, reward_bound=0.430, batch=215\n",
      "12215: loss=0.062, reward_mean=0.440, reward_bound=0.229, batch=219\n",
      "12216: loss=0.063, reward_mean=0.460, reward_bound=0.314, batch=220\n",
      "12217: loss=0.065, reward_mean=0.350, reward_bound=0.266, batch=224\n",
      "12218: loss=0.063, reward_mean=0.440, reward_bound=0.349, batch=226\n",
      "12219: loss=0.064, reward_mean=0.390, reward_bound=0.331, batch=228\n",
      "12220: loss=0.064, reward_mean=0.450, reward_bound=0.317, batch=229\n",
      "12221: loss=0.064, reward_mean=0.430, reward_bound=0.349, batch=229\n",
      "12222: loss=0.063, reward_mean=0.430, reward_bound=0.387, batch=228\n",
      "12223: loss=0.063, reward_mean=0.480, reward_bound=0.430, batch=227\n",
      "12224: loss=0.063, reward_mean=0.510, reward_bound=0.430, batch=228\n",
      "12225: loss=0.063, reward_mean=0.440, reward_bound=0.430, batch=228\n",
      "12226: loss=0.063, reward_mean=0.460, reward_bound=0.430, batch=228\n",
      "12227: loss=0.063, reward_mean=0.430, reward_bound=0.435, batch=229\n",
      "12228: loss=0.062, reward_mean=0.530, reward_bound=0.478, batch=231\n",
      "12229: loss=0.060, reward_mean=0.450, reward_bound=0.478, batch=204\n",
      "12230: loss=0.063, reward_mean=0.460, reward_bound=0.311, batch=213\n",
      "12231: loss=0.064, reward_mean=0.410, reward_bound=0.301, batch=219\n",
      "12232: loss=0.061, reward_mean=0.520, reward_bound=0.314, batch=220\n",
      "12233: loss=0.062, reward_mean=0.450, reward_bound=0.338, batch=224\n",
      "12234: loss=0.062, reward_mean=0.530, reward_bound=0.349, batch=224\n",
      "12235: loss=0.063, reward_mean=0.450, reward_bound=0.377, batch=227\n",
      "12236: loss=0.062, reward_mean=0.430, reward_bound=0.373, batch=229\n",
      "12237: loss=0.062, reward_mean=0.450, reward_bound=0.387, batch=225\n",
      "12238: loss=0.062, reward_mean=0.420, reward_bound=0.387, batch=226\n",
      "12239: loss=0.061, reward_mean=0.530, reward_bound=0.368, batch=228\n",
      "12240: loss=0.061, reward_mean=0.430, reward_bound=0.353, batch=229\n",
      "12241: loss=0.061, reward_mean=0.480, reward_bound=0.405, batch=230\n",
      "12242: loss=0.062, reward_mean=0.390, reward_bound=0.430, batch=221\n",
      "12243: loss=0.061, reward_mean=0.430, reward_bound=0.430, batch=223\n",
      "12244: loss=0.061, reward_mean=0.420, reward_bound=0.387, batch=225\n",
      "12245: loss=0.062, reward_mean=0.410, reward_bound=0.349, batch=226\n",
      "12246: loss=0.061, reward_mean=0.420, reward_bound=0.387, batch=227\n",
      "12247: loss=0.060, reward_mean=0.360, reward_bound=0.430, batch=228\n",
      "12248: loss=0.060, reward_mean=0.400, reward_bound=0.397, batch=229\n",
      "12249: loss=0.060, reward_mean=0.410, reward_bound=0.430, batch=229\n",
      "12250: loss=0.061, reward_mean=0.440, reward_bound=0.424, batch=230\n",
      "12251: loss=0.063, reward_mean=0.500, reward_bound=0.478, batch=213\n",
      "12252: loss=0.064, reward_mean=0.500, reward_bound=0.211, batch=219\n",
      "12253: loss=0.064, reward_mean=0.440, reward_bound=0.254, batch=222\n",
      "12254: loss=0.061, reward_mean=0.420, reward_bound=0.314, batch=224\n",
      "12255: loss=0.061, reward_mean=0.400, reward_bound=0.345, batch=227\n",
      "12256: loss=0.063, reward_mean=0.380, reward_bound=0.349, batch=228\n",
      "12257: loss=0.062, reward_mean=0.560, reward_bound=0.387, batch=225\n",
      "12258: loss=0.062, reward_mean=0.460, reward_bound=0.365, batch=227\n",
      "12259: loss=0.062, reward_mean=0.440, reward_bound=0.249, batch=229\n",
      "12260: loss=0.064, reward_mean=0.400, reward_bound=0.254, batch=229\n",
      "12261: loss=0.063, reward_mean=0.500, reward_bound=0.387, batch=229\n",
      "12262: loss=0.063, reward_mean=0.460, reward_bound=0.387, batch=229\n",
      "12263: loss=0.065, reward_mean=0.500, reward_bound=0.430, batch=220\n",
      "12264: loss=0.064, reward_mean=0.390, reward_bound=0.338, batch=224\n",
      "12265: loss=0.063, reward_mean=0.370, reward_bound=0.311, batch=227\n",
      "12266: loss=0.063, reward_mean=0.560, reward_bound=0.387, batch=227\n",
      "12267: loss=0.063, reward_mean=0.390, reward_bound=0.277, batch=229\n",
      "12268: loss=0.065, reward_mean=0.390, reward_bound=0.430, batch=226\n",
      "12269: loss=0.065, reward_mean=0.350, reward_bound=0.390, batch=228\n",
      "12270: loss=0.065, reward_mean=0.500, reward_bound=0.430, batch=228\n",
      "12271: loss=0.066, reward_mean=0.350, reward_bound=0.478, batch=231\n",
      "12272: loss=0.065, reward_mean=0.450, reward_bound=0.478, batch=222\n",
      "12273: loss=0.065, reward_mean=0.360, reward_bound=0.314, batch=224\n",
      "12274: loss=0.067, reward_mean=0.500, reward_bound=0.387, batch=225\n",
      "12275: loss=0.064, reward_mean=0.540, reward_bound=0.430, batch=225\n",
      "12276: loss=0.064, reward_mean=0.430, reward_bound=0.349, batch=226\n",
      "12277: loss=0.063, reward_mean=0.510, reward_bound=0.409, batch=228\n",
      "12278: loss=0.063, reward_mean=0.440, reward_bound=0.353, batch=229\n",
      "12279: loss=0.064, reward_mean=0.410, reward_bound=0.430, batch=227\n",
      "12280: loss=0.063, reward_mean=0.380, reward_bound=0.297, batch=229\n",
      "12281: loss=0.063, reward_mean=0.410, reward_bound=0.478, batch=231\n",
      "12282: loss=0.064, reward_mean=0.450, reward_bound=0.478, batch=226\n",
      "12283: loss=0.063, reward_mean=0.410, reward_bound=0.368, batch=228\n",
      "12284: loss=0.064, reward_mean=0.430, reward_bound=0.387, batch=227\n",
      "12285: loss=0.065, reward_mean=0.420, reward_bound=0.407, batch=229\n",
      "12286: loss=0.065, reward_mean=0.440, reward_bound=0.450, batch=230\n",
      "12287: loss=0.065, reward_mean=0.420, reward_bound=0.430, batch=230\n",
      "12288: loss=0.064, reward_mean=0.420, reward_bound=0.406, batch=231\n",
      "12289: loss=0.063, reward_mean=0.360, reward_bound=0.478, batch=230\n",
      "12290: loss=0.064, reward_mean=0.480, reward_bound=0.365, batch=231\n",
      "12291: loss=0.063, reward_mean=0.420, reward_bound=0.387, batch=231\n",
      "12292: loss=0.063, reward_mean=0.460, reward_bound=0.478, batch=230\n",
      "12293: loss=0.063, reward_mean=0.370, reward_bound=0.365, batch=231\n",
      "12294: loss=0.063, reward_mean=0.420, reward_bound=0.430, batch=231\n",
      "12295: loss=0.063, reward_mean=0.470, reward_bound=0.478, batch=230\n",
      "12297: loss=0.049, reward_mean=0.350, reward_bound=0.000, batch=35\n",
      "12298: loss=0.057, reward_mean=0.500, reward_bound=0.000, batch=85\n",
      "12299: loss=0.056, reward_mean=0.390, reward_bound=0.000, batch=124\n",
      "12300: loss=0.058, reward_mean=0.510, reward_bound=0.003, batch=156\n",
      "12301: loss=0.058, reward_mean=0.420, reward_bound=0.010, batch=178\n",
      "12302: loss=0.060, reward_mean=0.490, reward_bound=0.025, batch=192\n",
      "12303: loss=0.057, reward_mean=0.460, reward_bound=0.042, batch=200\n",
      "12304: loss=0.054, reward_mean=0.410, reward_bound=0.058, batch=204\n",
      "12305: loss=0.051, reward_mean=0.470, reward_bound=0.080, batch=207\n",
      "12306: loss=0.054, reward_mean=0.400, reward_bound=0.097, batch=215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12307: loss=0.054, reward_mean=0.510, reward_bound=0.101, batch=220\n",
      "12308: loss=0.053, reward_mean=0.480, reward_bound=0.118, batch=224\n",
      "12309: loss=0.053, reward_mean=0.450, reward_bound=0.122, batch=225\n",
      "12310: loss=0.054, reward_mean=0.400, reward_bound=0.135, batch=223\n",
      "12311: loss=0.052, reward_mean=0.490, reward_bound=0.150, batch=224\n",
      "12312: loss=0.051, reward_mean=0.370, reward_bound=0.167, batch=206\n",
      "12313: loss=0.052, reward_mean=0.410, reward_bound=0.138, batch=214\n",
      "12314: loss=0.055, reward_mean=0.470, reward_bound=0.185, batch=204\n",
      "12315: loss=0.053, reward_mean=0.410, reward_bound=0.206, batch=185\n",
      "12316: loss=0.053, reward_mean=0.330, reward_bound=0.052, batch=198\n",
      "12317: loss=0.052, reward_mean=0.460, reward_bound=0.154, batch=208\n",
      "12318: loss=0.051, reward_mean=0.490, reward_bound=0.206, batch=213\n",
      "12319: loss=0.049, reward_mean=0.420, reward_bound=0.229, batch=191\n",
      "12320: loss=0.047, reward_mean=0.450, reward_bound=0.150, batch=203\n",
      "12321: loss=0.048, reward_mean=0.460, reward_bound=0.229, batch=210\n",
      "12322: loss=0.048, reward_mean=0.460, reward_bound=0.162, batch=217\n",
      "12323: loss=0.050, reward_mean=0.460, reward_bound=0.254, batch=193\n",
      "12324: loss=0.048, reward_mean=0.400, reward_bound=0.122, batch=204\n",
      "12325: loss=0.048, reward_mean=0.550, reward_bound=0.229, batch=212\n",
      "12326: loss=0.047, reward_mean=0.540, reward_bound=0.254, batch=215\n",
      "12327: loss=0.052, reward_mean=0.410, reward_bound=0.282, batch=176\n",
      "12328: loss=0.049, reward_mean=0.500, reward_bound=0.109, batch=191\n",
      "12329: loss=0.050, reward_mean=0.460, reward_bound=0.206, batch=203\n",
      "12330: loss=0.048, reward_mean=0.460, reward_bound=0.198, batch=212\n",
      "12331: loss=0.048, reward_mean=0.450, reward_bound=0.229, batch=213\n",
      "12332: loss=0.049, reward_mean=0.530, reward_bound=0.254, batch=213\n",
      "12333: loss=0.049, reward_mean=0.390, reward_bound=0.254, batch=218\n",
      "12334: loss=0.049, reward_mean=0.390, reward_bound=0.257, batch=222\n",
      "12335: loss=0.049, reward_mean=0.520, reward_bound=0.282, batch=221\n",
      "12336: loss=0.049, reward_mean=0.510, reward_bound=0.282, batch=224\n",
      "12337: loss=0.046, reward_mean=0.460, reward_bound=0.314, batch=177\n",
      "12338: loss=0.044, reward_mean=0.490, reward_bound=0.130, batch=194\n",
      "12339: loss=0.043, reward_mean=0.450, reward_bound=0.165, batch=206\n",
      "12340: loss=0.046, reward_mean=0.430, reward_bound=0.176, batch=214\n",
      "12341: loss=0.047, reward_mean=0.540, reward_bound=0.204, batch=220\n",
      "12342: loss=0.048, reward_mean=0.460, reward_bound=0.206, batch=230\n",
      "12343: loss=0.048, reward_mean=0.550, reward_bound=0.206, batch=242\n",
      "12344: loss=0.047, reward_mean=0.400, reward_bound=0.206, batch=251\n",
      "12345: loss=0.043, reward_mean=0.540, reward_bound=0.229, batch=242\n",
      "12346: loss=0.043, reward_mean=0.440, reward_bound=0.254, batch=232\n",
      "12347: loss=0.045, reward_mean=0.410, reward_bound=0.282, batch=231\n",
      "12348: loss=0.048, reward_mean=0.420, reward_bound=0.314, batch=224\n",
      "12349: loss=0.047, reward_mean=0.490, reward_bound=0.282, batch=225\n",
      "12350: loss=0.053, reward_mean=0.430, reward_bound=0.349, batch=163\n",
      "12351: loss=0.049, reward_mean=0.390, reward_bound=0.095, batch=184\n",
      "12352: loss=0.048, reward_mean=0.350, reward_bound=0.098, batch=198\n",
      "12353: loss=0.049, reward_mean=0.490, reward_bound=0.150, batch=206\n",
      "12354: loss=0.053, reward_mean=0.350, reward_bound=0.167, batch=213\n",
      "12355: loss=0.051, reward_mean=0.470, reward_bound=0.185, batch=216\n",
      "12356: loss=0.050, reward_mean=0.370, reward_bound=0.217, batch=221\n",
      "12357: loss=0.050, reward_mean=0.450, reward_bound=0.229, batch=221\n",
      "12358: loss=0.050, reward_mean=0.410, reward_bound=0.254, batch=223\n",
      "12359: loss=0.052, reward_mean=0.500, reward_bound=0.282, batch=216\n",
      "12360: loss=0.051, reward_mean=0.460, reward_bound=0.314, batch=208\n",
      "12361: loss=0.052, reward_mean=0.400, reward_bound=0.229, batch=214\n",
      "12362: loss=0.051, reward_mean=0.370, reward_bound=0.229, batch=219\n",
      "12363: loss=0.053, reward_mean=0.440, reward_bound=0.282, batch=222\n",
      "12364: loss=0.052, reward_mean=0.390, reward_bound=0.292, batch=225\n",
      "12365: loss=0.052, reward_mean=0.500, reward_bound=0.314, batch=220\n",
      "12366: loss=0.050, reward_mean=0.580, reward_bound=0.349, batch=211\n",
      "12367: loss=0.049, reward_mean=0.410, reward_bound=0.282, batch=217\n",
      "12368: loss=0.050, reward_mean=0.530, reward_bound=0.314, batch=221\n",
      "12369: loss=0.049, reward_mean=0.470, reward_bound=0.349, batch=224\n",
      "12370: loss=0.050, reward_mean=0.370, reward_bound=0.311, batch=227\n",
      "12371: loss=0.049, reward_mean=0.470, reward_bound=0.380, batch=229\n",
      "12372: loss=0.050, reward_mean=0.440, reward_bound=0.387, batch=159\n",
      "12373: loss=0.051, reward_mean=0.390, reward_bound=0.064, batch=181\n",
      "12374: loss=0.055, reward_mean=0.510, reward_bound=0.109, batch=196\n",
      "12375: loss=0.059, reward_mean=0.420, reward_bound=0.150, batch=203\n",
      "12376: loss=0.052, reward_mean=0.410, reward_bound=0.167, batch=205\n",
      "12377: loss=0.054, reward_mean=0.490, reward_bound=0.185, batch=211\n",
      "12378: loss=0.053, reward_mean=0.510, reward_bound=0.206, batch=212\n",
      "12379: loss=0.054, reward_mean=0.380, reward_bound=0.172, batch=218\n",
      "12380: loss=0.052, reward_mean=0.450, reward_bound=0.229, batch=214\n",
      "12381: loss=0.052, reward_mean=0.390, reward_bound=0.206, batch=219\n",
      "12382: loss=0.051, reward_mean=0.440, reward_bound=0.239, batch=223\n",
      "12383: loss=0.052, reward_mean=0.480, reward_bound=0.254, batch=223\n",
      "12384: loss=0.051, reward_mean=0.460, reward_bound=0.282, batch=209\n",
      "12385: loss=0.052, reward_mean=0.450, reward_bound=0.254, batch=214\n",
      "12386: loss=0.052, reward_mean=0.480, reward_bound=0.254, batch=219\n",
      "12387: loss=0.052, reward_mean=0.430, reward_bound=0.282, batch=221\n",
      "12388: loss=0.053, reward_mean=0.550, reward_bound=0.254, batch=224\n",
      "12389: loss=0.052, reward_mean=0.410, reward_bound=0.280, batch=227\n",
      "12390: loss=0.047, reward_mean=0.420, reward_bound=0.314, batch=216\n",
      "12391: loss=0.047, reward_mean=0.480, reward_bound=0.331, batch=221\n",
      "12392: loss=0.045, reward_mean=0.450, reward_bound=0.349, batch=205\n",
      "12393: loss=0.043, reward_mean=0.490, reward_bound=0.254, batch=212\n",
      "12394: loss=0.042, reward_mean=0.400, reward_bound=0.263, batch=218\n",
      "12395: loss=0.041, reward_mean=0.390, reward_bound=0.254, batch=221\n",
      "12396: loss=0.042, reward_mean=0.440, reward_bound=0.282, batch=222\n",
      "12397: loss=0.044, reward_mean=0.490, reward_bound=0.349, batch=219\n",
      "12398: loss=0.044, reward_mean=0.490, reward_bound=0.387, batch=200\n",
      "12399: loss=0.043, reward_mean=0.400, reward_bound=0.167, batch=209\n",
      "12400: loss=0.042, reward_mean=0.480, reward_bound=0.229, batch=215\n",
      "12401: loss=0.042, reward_mean=0.530, reward_bound=0.254, batch=219\n",
      "12402: loss=0.041, reward_mean=0.430, reward_bound=0.282, batch=217\n",
      "12403: loss=0.040, reward_mean=0.560, reward_bound=0.277, batch=222\n",
      "12404: loss=0.041, reward_mean=0.520, reward_bound=0.282, batch=224\n",
      "12405: loss=0.044, reward_mean=0.400, reward_bound=0.314, batch=221\n",
      "12406: loss=0.046, reward_mean=0.440, reward_bound=0.349, batch=217\n",
      "12407: loss=0.047, reward_mean=0.450, reward_bound=0.277, batch=222\n",
      "12408: loss=0.048, reward_mean=0.380, reward_bound=0.324, batch=225\n",
      "12409: loss=0.048, reward_mean=0.440, reward_bound=0.356, batch=227\n",
      "12410: loss=0.046, reward_mean=0.540, reward_bound=0.387, batch=219\n",
      "12411: loss=0.046, reward_mean=0.400, reward_bound=0.349, batch=222\n",
      "12412: loss=0.045, reward_mean=0.390, reward_bound=0.314, batch=225\n",
      "12413: loss=0.045, reward_mean=0.430, reward_bound=0.387, batch=226\n",
      "12414: loss=0.045, reward_mean=0.440, reward_bound=0.390, batch=228\n",
      "12415: loss=0.045, reward_mean=0.430, reward_bound=0.392, batch=229\n",
      "12416: loss=0.045, reward_mean=0.430, reward_bound=0.343, batch=230\n",
      "12417: loss=0.044, reward_mean=0.350, reward_bound=0.356, batch=231\n",
      "12418: loss=0.045, reward_mean=0.480, reward_bound=0.387, batch=230\n",
      "12419: loss=0.044, reward_mean=0.560, reward_bound=0.395, batch=231\n",
      "12420: loss=0.044, reward_mean=0.430, reward_bound=0.387, batch=231\n",
      "12421: loss=0.043, reward_mean=0.480, reward_bound=0.430, batch=116\n",
      "12422: loss=0.039, reward_mean=0.410, reward_bound=0.008, batch=150\n",
      "12423: loss=0.037, reward_mean=0.470, reward_bound=0.032, batch=175\n",
      "12424: loss=0.041, reward_mean=0.470, reward_bound=0.065, batch=191\n",
      "12425: loss=0.042, reward_mean=0.460, reward_bound=0.080, batch=201\n",
      "12426: loss=0.038, reward_mean=0.410, reward_bound=0.098, batch=208\n",
      "12427: loss=0.042, reward_mean=0.380, reward_bound=0.122, batch=214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12428: loss=0.042, reward_mean=0.480, reward_bound=0.135, batch=218\n",
      "12429: loss=0.039, reward_mean=0.420, reward_bound=0.167, batch=217\n",
      "12430: loss=0.037, reward_mean=0.410, reward_bound=0.185, batch=210\n",
      "12431: loss=0.038, reward_mean=0.430, reward_bound=0.206, batch=225\n",
      "12432: loss=0.038, reward_mean=0.370, reward_bound=0.206, batch=218\n",
      "12433: loss=0.038, reward_mean=0.470, reward_bound=0.229, batch=207\n",
      "12434: loss=0.040, reward_mean=0.500, reward_bound=0.254, batch=199\n",
      "12435: loss=0.040, reward_mean=0.470, reward_bound=0.229, batch=208\n",
      "12436: loss=0.039, reward_mean=0.450, reward_bound=0.254, batch=214\n",
      "12437: loss=0.038, reward_mean=0.440, reward_bound=0.229, batch=219\n",
      "12438: loss=0.044, reward_mean=0.520, reward_bound=0.282, batch=201\n",
      "12439: loss=0.044, reward_mean=0.360, reward_bound=0.167, batch=210\n",
      "12440: loss=0.043, reward_mean=0.450, reward_bound=0.247, batch=217\n",
      "12441: loss=0.042, reward_mean=0.490, reward_bound=0.277, batch=222\n",
      "12442: loss=0.042, reward_mean=0.360, reward_bound=0.254, batch=224\n",
      "12443: loss=0.042, reward_mean=0.500, reward_bound=0.282, batch=223\n",
      "12444: loss=0.045, reward_mean=0.440, reward_bound=0.314, batch=205\n",
      "12445: loss=0.045, reward_mean=0.430, reward_bound=0.314, batch=212\n",
      "12446: loss=0.044, reward_mean=0.510, reward_bound=0.324, batch=218\n",
      "12447: loss=0.044, reward_mean=0.530, reward_bound=0.349, batch=186\n",
      "12448: loss=0.042, reward_mean=0.380, reward_bound=0.094, batch=200\n",
      "12449: loss=0.041, reward_mean=0.420, reward_bound=0.118, batch=210\n",
      "12450: loss=0.045, reward_mean=0.460, reward_bound=0.254, batch=215\n",
      "12451: loss=0.044, reward_mean=0.340, reward_bound=0.260, batch=220\n",
      "12452: loss=0.043, reward_mean=0.450, reward_bound=0.282, batch=220\n",
      "12453: loss=0.043, reward_mean=0.340, reward_bound=0.229, batch=223\n",
      "12454: loss=0.042, reward_mean=0.390, reward_bound=0.301, batch=226\n",
      "12455: loss=0.043, reward_mean=0.410, reward_bound=0.314, batch=221\n",
      "12456: loss=0.043, reward_mean=0.450, reward_bound=0.314, batch=224\n",
      "12457: loss=0.043, reward_mean=0.370, reward_bound=0.349, batch=211\n",
      "12458: loss=0.042, reward_mean=0.560, reward_bound=0.185, batch=216\n",
      "12459: loss=0.041, reward_mean=0.490, reward_bound=0.241, batch=221\n",
      "12460: loss=0.041, reward_mean=0.470, reward_bound=0.282, batch=223\n",
      "12461: loss=0.041, reward_mean=0.400, reward_bound=0.314, batch=225\n",
      "12462: loss=0.042, reward_mean=0.450, reward_bound=0.349, batch=223\n",
      "12463: loss=0.041, reward_mean=0.510, reward_bound=0.349, batch=225\n",
      "12464: loss=0.046, reward_mean=0.440, reward_bound=0.387, batch=193\n",
      "12465: loss=0.045, reward_mean=0.520, reward_bound=0.178, batch=205\n",
      "12466: loss=0.048, reward_mean=0.520, reward_bound=0.254, batch=210\n",
      "12467: loss=0.048, reward_mean=0.380, reward_bound=0.206, batch=220\n",
      "12468: loss=0.045, reward_mean=0.430, reward_bound=0.206, batch=229\n",
      "12469: loss=0.047, reward_mean=0.440, reward_bound=0.229, batch=228\n",
      "12470: loss=0.045, reward_mean=0.420, reward_bound=0.282, batch=225\n",
      "12471: loss=0.045, reward_mean=0.560, reward_bound=0.314, batch=220\n",
      "12472: loss=0.044, reward_mean=0.340, reward_bound=0.304, batch=224\n",
      "12473: loss=0.045, reward_mean=0.480, reward_bound=0.349, batch=220\n",
      "12474: loss=0.046, reward_mean=0.460, reward_bound=0.376, batch=224\n",
      "12475: loss=0.045, reward_mean=0.440, reward_bound=0.387, batch=210\n",
      "12476: loss=0.045, reward_mean=0.450, reward_bound=0.282, batch=216\n",
      "12477: loss=0.045, reward_mean=0.430, reward_bound=0.254, batch=219\n",
      "12478: loss=0.046, reward_mean=0.490, reward_bound=0.295, batch=223\n",
      "12479: loss=0.046, reward_mean=0.470, reward_bound=0.314, batch=222\n",
      "12480: loss=0.045, reward_mean=0.410, reward_bound=0.349, batch=218\n",
      "12481: loss=0.046, reward_mean=0.470, reward_bound=0.353, batch=222\n",
      "12482: loss=0.045, reward_mean=0.520, reward_bound=0.387, batch=222\n",
      "12483: loss=0.044, reward_mean=0.470, reward_bound=0.430, batch=173\n",
      "12484: loss=0.046, reward_mean=0.520, reward_bound=0.135, batch=189\n",
      "12485: loss=0.045, reward_mean=0.480, reward_bound=0.167, batch=199\n",
      "12486: loss=0.046, reward_mean=0.490, reward_bound=0.185, batch=206\n",
      "12487: loss=0.042, reward_mean=0.420, reward_bound=0.229, batch=208\n",
      "12488: loss=0.040, reward_mean=0.370, reward_bound=0.231, batch=215\n",
      "12489: loss=0.039, reward_mean=0.450, reward_bound=0.254, batch=215\n",
      "12490: loss=0.038, reward_mean=0.370, reward_bound=0.260, batch=220\n",
      "12491: loss=0.036, reward_mean=0.620, reward_bound=0.304, batch=224\n",
      "12492: loss=0.042, reward_mean=0.450, reward_bound=0.314, batch=215\n",
      "12493: loss=0.044, reward_mean=0.380, reward_bound=0.296, batch=220\n",
      "12494: loss=0.044, reward_mean=0.370, reward_bound=0.254, batch=222\n",
      "12495: loss=0.045, reward_mean=0.520, reward_bound=0.349, batch=212\n",
      "12496: loss=0.043, reward_mean=0.510, reward_bound=0.292, batch=218\n",
      "12497: loss=0.042, reward_mean=0.470, reward_bound=0.231, batch=222\n",
      "12498: loss=0.043, reward_mean=0.400, reward_bound=0.254, batch=222\n",
      "12499: loss=0.044, reward_mean=0.450, reward_bound=0.324, batch=225\n",
      "12500: loss=0.043, reward_mean=0.430, reward_bound=0.321, batch=227\n",
      "12501: loss=0.043, reward_mean=0.400, reward_bound=0.349, batch=222\n",
      "12502: loss=0.040, reward_mean=0.400, reward_bound=0.387, batch=210\n",
      "12503: loss=0.038, reward_mean=0.440, reward_bound=0.247, batch=217\n",
      "12504: loss=0.040, reward_mean=0.540, reward_bound=0.314, batch=219\n",
      "12505: loss=0.038, reward_mean=0.440, reward_bound=0.349, batch=221\n",
      "12506: loss=0.042, reward_mean=0.420, reward_bound=0.387, batch=220\n",
      "12507: loss=0.041, reward_mean=0.430, reward_bound=0.356, batch=224\n",
      "12508: loss=0.042, reward_mean=0.560, reward_bound=0.387, batch=223\n",
      "12509: loss=0.043, reward_mean=0.380, reward_bound=0.345, batch=226\n",
      "12510: loss=0.043, reward_mean=0.350, reward_bound=0.368, batch=228\n",
      "12511: loss=0.043, reward_mean=0.400, reward_bound=0.353, batch=229\n",
      "12512: loss=0.045, reward_mean=0.400, reward_bound=0.430, batch=205\n",
      "12513: loss=0.043, reward_mean=0.430, reward_bound=0.210, batch=213\n",
      "12514: loss=0.044, reward_mean=0.440, reward_bound=0.271, batch=219\n",
      "12515: loss=0.043, reward_mean=0.520, reward_bound=0.250, batch=223\n",
      "12516: loss=0.042, reward_mean=0.430, reward_bound=0.282, batch=221\n",
      "12517: loss=0.042, reward_mean=0.460, reward_bound=0.349, batch=221\n",
      "12518: loss=0.044, reward_mean=0.420, reward_bound=0.229, batch=224\n",
      "12519: loss=0.043, reward_mean=0.460, reward_bound=0.426, batch=227\n",
      "12520: loss=0.043, reward_mean=0.440, reward_bound=0.387, batch=227\n",
      "12521: loss=0.043, reward_mean=0.490, reward_bound=0.422, batch=229\n",
      "12522: loss=0.043, reward_mean=0.520, reward_bound=0.430, batch=218\n",
      "12523: loss=0.044, reward_mean=0.390, reward_bound=0.231, batch=222\n",
      "12524: loss=0.042, reward_mean=0.470, reward_bound=0.263, batch=225\n",
      "12525: loss=0.042, reward_mean=0.380, reward_bound=0.314, batch=226\n",
      "12526: loss=0.042, reward_mean=0.490, reward_bound=0.387, batch=227\n",
      "12527: loss=0.041, reward_mean=0.410, reward_bound=0.373, batch=229\n",
      "12528: loss=0.041, reward_mean=0.400, reward_bound=0.405, batch=230\n",
      "12529: loss=0.041, reward_mean=0.390, reward_bound=0.387, batch=230\n",
      "12530: loss=0.042, reward_mean=0.420, reward_bound=0.430, batch=225\n",
      "12531: loss=0.042, reward_mean=0.420, reward_bound=0.289, batch=227\n",
      "12532: loss=0.042, reward_mean=0.480, reward_bound=0.422, batch=229\n",
      "12533: loss=0.042, reward_mean=0.480, reward_bound=0.387, batch=229\n",
      "12534: loss=0.042, reward_mean=0.450, reward_bound=0.405, batch=230\n",
      "12535: loss=0.041, reward_mean=0.350, reward_bound=0.464, batch=231\n",
      "12536: loss=0.039, reward_mean=0.470, reward_bound=0.478, batch=97\n",
      "12537: loss=0.042, reward_mean=0.450, reward_bound=0.003, batch=138\n",
      "12538: loss=0.043, reward_mean=0.430, reward_bound=0.012, batch=166\n",
      "12539: loss=0.040, reward_mean=0.490, reward_bound=0.036, batch=186\n",
      "12540: loss=0.042, reward_mean=0.370, reward_bound=0.050, batch=200\n",
      "12541: loss=0.043, reward_mean=0.460, reward_bound=0.086, batch=210\n",
      "12542: loss=0.042, reward_mean=0.440, reward_bound=0.109, batch=211\n",
      "12543: loss=0.043, reward_mean=0.450, reward_bound=0.122, batch=217\n",
      "12544: loss=0.043, reward_mean=0.400, reward_bound=0.135, batch=221\n",
      "12545: loss=0.044, reward_mean=0.510, reward_bound=0.167, batch=224\n",
      "12546: loss=0.045, reward_mean=0.420, reward_bound=0.185, batch=211\n",
      "12547: loss=0.039, reward_mean=0.490, reward_bound=0.206, batch=202\n",
      "12548: loss=0.046, reward_mean=0.450, reward_bound=0.150, batch=210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12549: loss=0.048, reward_mean=0.350, reward_bound=0.185, batch=216\n",
      "12550: loss=0.048, reward_mean=0.510, reward_bound=0.229, batch=214\n",
      "12551: loss=0.048, reward_mean=0.480, reward_bound=0.229, batch=219\n",
      "12552: loss=0.054, reward_mean=0.430, reward_bound=0.254, batch=205\n",
      "12553: loss=0.055, reward_mean=0.480, reward_bound=0.210, batch=213\n",
      "12554: loss=0.055, reward_mean=0.390, reward_bound=0.229, batch=218\n",
      "12555: loss=0.051, reward_mean=0.380, reward_bound=0.282, batch=196\n",
      "12556: loss=0.052, reward_mean=0.540, reward_bound=0.298, batch=207\n",
      "12557: loss=0.052, reward_mean=0.360, reward_bound=0.206, batch=213\n",
      "12558: loss=0.052, reward_mean=0.470, reward_bound=0.254, batch=217\n",
      "12559: loss=0.051, reward_mean=0.480, reward_bound=0.308, batch=222\n",
      "12560: loss=0.050, reward_mean=0.440, reward_bound=0.314, batch=200\n",
      "12561: loss=0.049, reward_mean=0.480, reward_bound=0.222, batch=210\n",
      "12562: loss=0.049, reward_mean=0.360, reward_bound=0.222, batch=217\n",
      "12563: loss=0.054, reward_mean=0.500, reward_bound=0.229, batch=221\n",
      "12564: loss=0.051, reward_mean=0.330, reward_bound=0.254, batch=222\n",
      "12565: loss=0.052, reward_mean=0.360, reward_bound=0.282, batch=224\n",
      "12566: loss=0.052, reward_mean=0.410, reward_bound=0.314, batch=219\n",
      "12567: loss=0.051, reward_mean=0.520, reward_bound=0.349, batch=196\n",
      "12568: loss=0.049, reward_mean=0.420, reward_bound=0.136, batch=207\n",
      "12569: loss=0.048, reward_mean=0.430, reward_bound=0.163, batch=215\n",
      "12570: loss=0.049, reward_mean=0.510, reward_bound=0.206, batch=219\n",
      "12571: loss=0.046, reward_mean=0.460, reward_bound=0.229, batch=222\n",
      "12572: loss=0.049, reward_mean=0.440, reward_bound=0.282, batch=222\n",
      "12573: loss=0.050, reward_mean=0.410, reward_bound=0.254, batch=225\n",
      "12574: loss=0.049, reward_mean=0.390, reward_bound=0.314, batch=220\n",
      "12575: loss=0.049, reward_mean=0.430, reward_bound=0.338, batch=224\n",
      "12576: loss=0.050, reward_mean=0.420, reward_bound=0.311, batch=227\n",
      "12577: loss=0.050, reward_mean=0.370, reward_bound=0.349, batch=219\n",
      "12578: loss=0.051, reward_mean=0.510, reward_bound=0.314, batch=222\n",
      "12579: loss=0.051, reward_mean=0.500, reward_bound=0.349, batch=224\n",
      "12580: loss=0.051, reward_mean=0.410, reward_bound=0.349, batch=225\n",
      "12581: loss=0.050, reward_mean=0.420, reward_bound=0.356, batch=227\n",
      "12582: loss=0.053, reward_mean=0.470, reward_bound=0.387, batch=188\n",
      "12583: loss=0.058, reward_mean=0.450, reward_bound=0.185, batch=199\n",
      "12584: loss=0.056, reward_mean=0.460, reward_bound=0.164, batch=209\n",
      "12585: loss=0.057, reward_mean=0.420, reward_bound=0.215, batch=216\n",
      "12586: loss=0.058, reward_mean=0.430, reward_bound=0.268, batch=221\n",
      "12587: loss=0.060, reward_mean=0.480, reward_bound=0.254, batch=223\n",
      "12588: loss=0.059, reward_mean=0.490, reward_bound=0.282, batch=217\n",
      "12589: loss=0.060, reward_mean=0.460, reward_bound=0.206, batch=221\n",
      "12590: loss=0.059, reward_mean=0.370, reward_bound=0.254, batch=224\n",
      "12591: loss=0.058, reward_mean=0.340, reward_bound=0.311, batch=227\n",
      "12592: loss=0.059, reward_mean=0.410, reward_bound=0.308, batch=229\n",
      "12593: loss=0.056, reward_mean=0.530, reward_bound=0.314, batch=223\n",
      "12594: loss=0.054, reward_mean=0.410, reward_bound=0.349, batch=213\n",
      "12595: loss=0.053, reward_mean=0.540, reward_bound=0.282, batch=218\n",
      "12596: loss=0.053, reward_mean=0.390, reward_bound=0.349, batch=219\n",
      "12597: loss=0.052, reward_mean=0.380, reward_bound=0.328, batch=223\n",
      "12598: loss=0.053, reward_mean=0.400, reward_bound=0.387, batch=213\n",
      "12599: loss=0.056, reward_mean=0.410, reward_bound=0.301, batch=219\n",
      "12600: loss=0.056, reward_mean=0.430, reward_bound=0.265, batch=223\n",
      "12601: loss=0.053, reward_mean=0.440, reward_bound=0.349, batch=221\n",
      "12602: loss=0.053, reward_mean=0.470, reward_bound=0.387, batch=222\n",
      "12603: loss=0.054, reward_mean=0.400, reward_bound=0.324, batch=225\n",
      "12604: loss=0.053, reward_mean=0.500, reward_bound=0.387, batch=223\n",
      "12605: loss=0.052, reward_mean=0.520, reward_bound=0.413, batch=226\n",
      "12606: loss=0.052, reward_mean=0.440, reward_bound=0.349, batch=227\n",
      "12607: loss=0.052, reward_mean=0.450, reward_bound=0.387, batch=227\n",
      "12608: loss=0.052, reward_mean=0.380, reward_bound=0.349, batch=228\n",
      "12609: loss=0.052, reward_mean=0.500, reward_bound=0.353, batch=229\n",
      "12610: loss=0.044, reward_mean=0.380, reward_bound=0.430, batch=161\n",
      "12611: loss=0.054, reward_mean=0.420, reward_bound=0.047, batch=181\n",
      "12612: loss=0.050, reward_mean=0.400, reward_bound=0.122, batch=196\n",
      "12613: loss=0.049, reward_mean=0.510, reward_bound=0.150, batch=205\n",
      "12614: loss=0.049, reward_mean=0.400, reward_bound=0.185, batch=209\n",
      "12615: loss=0.048, reward_mean=0.400, reward_bound=0.206, batch=211\n",
      "12616: loss=0.048, reward_mean=0.520, reward_bound=0.229, batch=216\n",
      "12617: loss=0.049, reward_mean=0.490, reward_bound=0.254, batch=209\n",
      "12618: loss=0.051, reward_mean=0.490, reward_bound=0.282, batch=209\n",
      "12619: loss=0.052, reward_mean=0.440, reward_bound=0.282, batch=215\n",
      "12620: loss=0.051, reward_mean=0.420, reward_bound=0.282, batch=218\n",
      "12621: loss=0.049, reward_mean=0.600, reward_bound=0.314, batch=208\n",
      "12622: loss=0.048, reward_mean=0.430, reward_bound=0.282, batch=214\n",
      "12623: loss=0.046, reward_mean=0.380, reward_bound=0.277, batch=220\n",
      "12624: loss=0.047, reward_mean=0.430, reward_bound=0.247, batch=224\n",
      "12625: loss=0.046, reward_mean=0.470, reward_bound=0.282, batch=223\n",
      "12626: loss=0.048, reward_mean=0.500, reward_bound=0.314, batch=223\n",
      "12627: loss=0.047, reward_mean=0.490, reward_bound=0.314, batch=225\n",
      "12628: loss=0.048, reward_mean=0.420, reward_bound=0.349, batch=205\n",
      "12629: loss=0.050, reward_mean=0.440, reward_bound=0.210, batch=213\n",
      "12630: loss=0.051, reward_mean=0.450, reward_bound=0.244, batch=219\n",
      "12631: loss=0.052, reward_mean=0.380, reward_bound=0.314, batch=221\n",
      "12632: loss=0.051, reward_mean=0.380, reward_bound=0.254, batch=224\n",
      "12633: loss=0.052, reward_mean=0.470, reward_bound=0.349, batch=221\n",
      "12634: loss=0.052, reward_mean=0.490, reward_bound=0.387, batch=202\n",
      "12635: loss=0.052, reward_mean=0.430, reward_bound=0.229, batch=209\n",
      "12636: loss=0.052, reward_mean=0.430, reward_bound=0.254, batch=215\n",
      "12637: loss=0.052, reward_mean=0.440, reward_bound=0.260, batch=220\n",
      "12638: loss=0.054, reward_mean=0.460, reward_bound=0.314, batch=219\n",
      "12639: loss=0.050, reward_mean=0.510, reward_bound=0.349, batch=220\n",
      "12640: loss=0.051, reward_mean=0.460, reward_bound=0.387, batch=215\n",
      "12641: loss=0.049, reward_mean=0.440, reward_bound=0.216, batch=220\n",
      "12642: loss=0.049, reward_mean=0.500, reward_bound=0.304, batch=224\n",
      "12643: loss=0.049, reward_mean=0.450, reward_bound=0.282, batch=226\n",
      "12644: loss=0.054, reward_mean=0.490, reward_bound=0.314, batch=226\n",
      "12645: loss=0.051, reward_mean=0.430, reward_bound=0.387, batch=226\n",
      "12646: loss=0.050, reward_mean=0.450, reward_bound=0.372, batch=228\n",
      "12647: loss=0.050, reward_mean=0.370, reward_bound=0.392, batch=229\n",
      "12648: loss=0.050, reward_mean=0.360, reward_bound=0.405, batch=230\n",
      "12649: loss=0.044, reward_mean=0.450, reward_bound=0.430, batch=203\n",
      "12650: loss=0.042, reward_mean=0.440, reward_bound=0.271, batch=212\n",
      "12651: loss=0.041, reward_mean=0.390, reward_bound=0.254, batch=217\n",
      "12652: loss=0.041, reward_mean=0.500, reward_bound=0.282, batch=219\n",
      "12653: loss=0.043, reward_mean=0.530, reward_bound=0.314, batch=218\n",
      "12654: loss=0.042, reward_mean=0.380, reward_bound=0.231, batch=222\n",
      "12655: loss=0.045, reward_mean=0.460, reward_bound=0.349, batch=219\n",
      "12656: loss=0.046, reward_mean=0.450, reward_bound=0.295, batch=223\n",
      "12657: loss=0.046, reward_mean=0.490, reward_bound=0.314, batch=225\n",
      "12658: loss=0.046, reward_mean=0.400, reward_bound=0.321, batch=227\n",
      "12659: loss=0.047, reward_mean=0.440, reward_bound=0.282, batch=228\n",
      "12660: loss=0.048, reward_mean=0.460, reward_bound=0.349, batch=227\n",
      "12661: loss=0.047, reward_mean=0.390, reward_bound=0.380, batch=229\n",
      "12662: loss=0.047, reward_mean=0.380, reward_bound=0.364, batch=230\n",
      "12663: loss=0.046, reward_mean=0.430, reward_bound=0.387, batch=226\n",
      "12664: loss=0.046, reward_mean=0.490, reward_bound=0.409, batch=228\n",
      "12665: loss=0.047, reward_mean=0.420, reward_bound=0.430, batch=221\n",
      "12666: loss=0.046, reward_mean=0.420, reward_bound=0.430, batch=224\n",
      "12667: loss=0.046, reward_mean=0.400, reward_bound=0.314, batch=225\n",
      "12668: loss=0.048, reward_mean=0.420, reward_bound=0.329, batch=227\n",
      "12669: loss=0.047, reward_mean=0.400, reward_bound=0.342, batch=229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12670: loss=0.047, reward_mean=0.470, reward_bound=0.364, batch=230\n",
      "12671: loss=0.047, reward_mean=0.490, reward_bound=0.365, batch=231\n",
      "12672: loss=0.047, reward_mean=0.460, reward_bound=0.430, batch=231\n",
      "12673: loss=0.047, reward_mean=0.460, reward_bound=0.387, batch=231\n",
      "12674: loss=0.047, reward_mean=0.440, reward_bound=0.387, batch=231\n",
      "12675: loss=0.047, reward_mean=0.520, reward_bound=0.430, batch=231\n",
      "12676: loss=0.047, reward_mean=0.420, reward_bound=0.282, batch=231\n",
      "12677: loss=0.047, reward_mean=0.480, reward_bound=0.430, batch=231\n",
      "12678: loss=0.047, reward_mean=0.430, reward_bound=0.387, batch=231\n",
      "12679: loss=0.047, reward_mean=0.400, reward_bound=0.387, batch=231\n",
      "12680: loss=0.041, reward_mean=0.560, reward_bound=0.478, batch=150\n",
      "12681: loss=0.037, reward_mean=0.430, reward_bound=0.109, batch=174\n",
      "12682: loss=0.040, reward_mean=0.410, reward_bound=0.108, batch=192\n",
      "12683: loss=0.041, reward_mean=0.470, reward_bound=0.122, batch=201\n",
      "12684: loss=0.045, reward_mean=0.380, reward_bound=0.150, batch=203\n",
      "12685: loss=0.041, reward_mean=0.470, reward_bound=0.167, batch=209\n",
      "12686: loss=0.040, reward_mean=0.480, reward_bound=0.185, batch=214\n",
      "12687: loss=0.042, reward_mean=0.440, reward_bound=0.206, batch=214\n",
      "12688: loss=0.041, reward_mean=0.440, reward_bound=0.206, batch=219\n",
      "12689: loss=0.043, reward_mean=0.410, reward_bound=0.229, batch=213\n",
      "12690: loss=0.044, reward_mean=0.430, reward_bound=0.229, batch=218\n",
      "12691: loss=0.043, reward_mean=0.440, reward_bound=0.231, batch=222\n",
      "12692: loss=0.043, reward_mean=0.360, reward_bound=0.254, batch=218\n",
      "12693: loss=0.046, reward_mean=0.500, reward_bound=0.282, batch=205\n",
      "12694: loss=0.044, reward_mean=0.350, reward_bound=0.240, batch=213\n",
      "12695: loss=0.043, reward_mean=0.440, reward_bound=0.282, batch=218\n",
      "12696: loss=0.044, reward_mean=0.460, reward_bound=0.282, batch=221\n",
      "12697: loss=0.043, reward_mean=0.420, reward_bound=0.254, batch=224\n",
      "12698: loss=0.045, reward_mean=0.490, reward_bound=0.314, batch=208\n",
      "12699: loss=0.045, reward_mean=0.390, reward_bound=0.254, batch=214\n",
      "12700: loss=0.046, reward_mean=0.460, reward_bound=0.282, batch=218\n",
      "12701: loss=0.046, reward_mean=0.470, reward_bound=0.282, batch=221\n",
      "12702: loss=0.044, reward_mean=0.380, reward_bound=0.314, batch=221\n",
      "12703: loss=0.045, reward_mean=0.510, reward_bound=0.254, batch=224\n",
      "12704: loss=0.046, reward_mean=0.400, reward_bound=0.311, batch=227\n",
      "12705: loss=0.045, reward_mean=0.440, reward_bound=0.314, batch=228\n",
      "12706: loss=0.046, reward_mean=0.450, reward_bound=0.349, batch=202\n",
      "12707: loss=0.046, reward_mean=0.500, reward_bound=0.254, batch=209\n",
      "12708: loss=0.048, reward_mean=0.420, reward_bound=0.265, batch=216\n",
      "12709: loss=0.043, reward_mean=0.420, reward_bound=0.298, batch=221\n",
      "12710: loss=0.044, reward_mean=0.440, reward_bound=0.314, batch=216\n",
      "12711: loss=0.045, reward_mean=0.460, reward_bound=0.314, batch=220\n",
      "12712: loss=0.046, reward_mean=0.520, reward_bound=0.349, batch=220\n",
      "12713: loss=0.045, reward_mean=0.490, reward_bound=0.349, batch=223\n",
      "12714: loss=0.045, reward_mean=0.470, reward_bound=0.372, batch=226\n",
      "12715: loss=0.046, reward_mean=0.440, reward_bound=0.387, batch=195\n",
      "12716: loss=0.046, reward_mean=0.440, reward_bound=0.229, batch=203\n",
      "12717: loss=0.048, reward_mean=0.460, reward_bound=0.254, batch=211\n",
      "12718: loss=0.050, reward_mean=0.550, reward_bound=0.254, batch=216\n",
      "12719: loss=0.047, reward_mean=0.480, reward_bound=0.298, batch=221\n",
      "12720: loss=0.048, reward_mean=0.470, reward_bound=0.314, batch=217\n",
      "12721: loss=0.049, reward_mean=0.530, reward_bound=0.308, batch=222\n",
      "12722: loss=0.047, reward_mean=0.410, reward_bound=0.314, batch=221\n",
      "12723: loss=0.047, reward_mean=0.400, reward_bound=0.282, batch=222\n",
      "12724: loss=0.052, reward_mean=0.510, reward_bound=0.349, batch=213\n",
      "12725: loss=0.051, reward_mean=0.470, reward_bound=0.314, batch=218\n",
      "12726: loss=0.050, reward_mean=0.530, reward_bound=0.349, batch=221\n",
      "12727: loss=0.050, reward_mean=0.410, reward_bound=0.282, batch=224\n",
      "12728: loss=0.051, reward_mean=0.440, reward_bound=0.342, batch=227\n",
      "12729: loss=0.049, reward_mean=0.400, reward_bound=0.349, batch=226\n",
      "12730: loss=0.049, reward_mean=0.490, reward_bound=0.387, batch=219\n",
      "12731: loss=0.052, reward_mean=0.420, reward_bound=0.309, batch=223\n",
      "12732: loss=0.053, reward_mean=0.460, reward_bound=0.349, batch=223\n",
      "12733: loss=0.052, reward_mean=0.530, reward_bound=0.387, batch=224\n",
      "12734: loss=0.051, reward_mean=0.420, reward_bound=0.349, batch=226\n",
      "12735: loss=0.051, reward_mean=0.400, reward_bound=0.387, batch=226\n",
      "12736: loss=0.051, reward_mean=0.420, reward_bound=0.409, batch=228\n",
      "12737: loss=0.051, reward_mean=0.470, reward_bound=0.357, batch=229\n",
      "12738: loss=0.043, reward_mean=0.380, reward_bound=0.430, batch=195\n",
      "12739: loss=0.048, reward_mean=0.380, reward_bound=0.234, batch=206\n",
      "12740: loss=0.048, reward_mean=0.430, reward_bound=0.241, batch=214\n",
      "12741: loss=0.047, reward_mean=0.510, reward_bound=0.282, batch=219\n",
      "12742: loss=0.047, reward_mean=0.470, reward_bound=0.314, batch=220\n",
      "12743: loss=0.046, reward_mean=0.410, reward_bound=0.349, batch=216\n",
      "12744: loss=0.049, reward_mean=0.410, reward_bound=0.368, batch=221\n",
      "12745: loss=0.049, reward_mean=0.450, reward_bound=0.349, batch=223\n",
      "12746: loss=0.046, reward_mean=0.530, reward_bound=0.387, batch=212\n",
      "12747: loss=0.044, reward_mean=0.420, reward_bound=0.229, batch=217\n",
      "12748: loss=0.044, reward_mean=0.560, reward_bound=0.282, batch=221\n",
      "12749: loss=0.043, reward_mean=0.440, reward_bound=0.282, batch=224\n",
      "12750: loss=0.043, reward_mean=0.430, reward_bound=0.314, batch=226\n",
      "12751: loss=0.043, reward_mean=0.530, reward_bound=0.349, batch=225\n",
      "12752: loss=0.043, reward_mean=0.430, reward_bound=0.356, batch=227\n",
      "12753: loss=0.042, reward_mean=0.410, reward_bound=0.342, batch=229\n",
      "12754: loss=0.043, reward_mean=0.470, reward_bound=0.387, batch=227\n",
      "12755: loss=0.043, reward_mean=0.430, reward_bound=0.422, batch=229\n",
      "12756: loss=0.040, reward_mean=0.420, reward_bound=0.430, batch=215\n",
      "12757: loss=0.039, reward_mean=0.440, reward_bound=0.282, batch=218\n",
      "12758: loss=0.038, reward_mean=0.430, reward_bound=0.317, batch=222\n",
      "12759: loss=0.039, reward_mean=0.470, reward_bound=0.349, batch=221\n",
      "12760: loss=0.039, reward_mean=0.430, reward_bound=0.387, batch=222\n",
      "12761: loss=0.038, reward_mean=0.440, reward_bound=0.400, batch=225\n",
      "12762: loss=0.038, reward_mean=0.450, reward_bound=0.430, batch=223\n",
      "12763: loss=0.040, reward_mean=0.500, reward_bound=0.387, batch=225\n",
      "12764: loss=0.042, reward_mean=0.410, reward_bound=0.387, batch=226\n",
      "12765: loss=0.042, reward_mean=0.450, reward_bound=0.331, batch=228\n",
      "12766: loss=0.040, reward_mean=0.410, reward_bound=0.430, batch=227\n",
      "12767: loss=0.040, reward_mean=0.460, reward_bound=0.422, batch=229\n",
      "12768: loss=0.039, reward_mean=0.580, reward_bound=0.478, batch=232\n",
      "12769: loss=0.039, reward_mean=0.480, reward_bound=0.363, batch=232\n",
      "12770: loss=0.042, reward_mean=0.410, reward_bound=0.478, batch=187\n",
      "12771: loss=0.042, reward_mean=0.360, reward_bound=0.122, batch=200\n",
      "12772: loss=0.040, reward_mean=0.440, reward_bound=0.162, batch=210\n",
      "12773: loss=0.040, reward_mean=0.460, reward_bound=0.222, batch=217\n",
      "12774: loss=0.041, reward_mean=0.520, reward_bound=0.229, batch=216\n",
      "12775: loss=0.040, reward_mean=0.410, reward_bound=0.229, batch=220\n",
      "12776: loss=0.042, reward_mean=0.460, reward_bound=0.254, batch=221\n",
      "12777: loss=0.040, reward_mean=0.410, reward_bound=0.282, batch=216\n",
      "12778: loss=0.038, reward_mean=0.390, reward_bound=0.314, batch=215\n",
      "12779: loss=0.039, reward_mean=0.470, reward_bound=0.349, batch=212\n",
      "12780: loss=0.038, reward_mean=0.390, reward_bound=0.236, batch=218\n",
      "12781: loss=0.038, reward_mean=0.420, reward_bound=0.282, batch=219\n",
      "12782: loss=0.039, reward_mean=0.500, reward_bound=0.295, batch=223\n",
      "12783: loss=0.039, reward_mean=0.470, reward_bound=0.271, batch=226\n",
      "12784: loss=0.038, reward_mean=0.440, reward_bound=0.298, batch=228\n",
      "12785: loss=0.039, reward_mean=0.520, reward_bound=0.349, batch=226\n",
      "12786: loss=0.040, reward_mean=0.450, reward_bound=0.387, batch=213\n",
      "12787: loss=0.039, reward_mean=0.350, reward_bound=0.185, batch=216\n",
      "12788: loss=0.038, reward_mean=0.450, reward_bound=0.368, batch=221\n",
      "12789: loss=0.038, reward_mean=0.440, reward_bound=0.314, batch=224\n",
      "12790: loss=0.037, reward_mean=0.490, reward_bound=0.384, batch=227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12791: loss=0.038, reward_mean=0.490, reward_bound=0.387, batch=226\n",
      "12792: loss=0.037, reward_mean=0.460, reward_bound=0.368, batch=228\n",
      "12793: loss=0.039, reward_mean=0.450, reward_bound=0.430, batch=205\n",
      "12794: loss=0.038, reward_mean=0.450, reward_bound=0.289, batch=213\n",
      "12795: loss=0.040, reward_mean=0.460, reward_bound=0.314, batch=215\n",
      "12796: loss=0.039, reward_mean=0.400, reward_bound=0.349, batch=219\n",
      "12797: loss=0.038, reward_mean=0.520, reward_bound=0.295, batch=223\n",
      "12798: loss=0.038, reward_mean=0.440, reward_bound=0.314, batch=225\n",
      "12799: loss=0.040, reward_mean=0.340, reward_bound=0.356, batch=227\n",
      "12800: loss=0.038, reward_mean=0.510, reward_bound=0.387, batch=225\n",
      "12801: loss=0.038, reward_mean=0.430, reward_bound=0.349, batch=226\n",
      "12802: loss=0.040, reward_mean=0.430, reward_bound=0.430, batch=217\n",
      "12803: loss=0.039, reward_mean=0.440, reward_bound=0.422, batch=222\n",
      "12804: loss=0.038, reward_mean=0.450, reward_bound=0.324, batch=225\n",
      "12805: loss=0.040, reward_mean=0.460, reward_bound=0.356, batch=227\n",
      "12806: loss=0.040, reward_mean=0.400, reward_bound=0.342, batch=229\n",
      "12807: loss=0.040, reward_mean=0.440, reward_bound=0.349, batch=229\n",
      "12808: loss=0.038, reward_mean=0.480, reward_bound=0.387, batch=228\n",
      "12809: loss=0.038, reward_mean=0.520, reward_bound=0.392, batch=229\n",
      "12810: loss=0.038, reward_mean=0.380, reward_bound=0.381, batch=230\n",
      "12811: loss=0.039, reward_mean=0.480, reward_bound=0.430, batch=223\n",
      "12812: loss=0.038, reward_mean=0.450, reward_bound=0.387, batch=225\n",
      "12813: loss=0.038, reward_mean=0.420, reward_bound=0.337, batch=227\n",
      "12814: loss=0.040, reward_mean=0.400, reward_bound=0.422, batch=229\n",
      "12815: loss=0.038, reward_mean=0.490, reward_bound=0.430, batch=227\n",
      "12816: loss=0.038, reward_mean=0.420, reward_bound=0.430, batch=227\n",
      "12817: loss=0.038, reward_mean=0.480, reward_bound=0.460, batch=229\n",
      "12818: loss=0.038, reward_mean=0.490, reward_bound=0.478, batch=231\n",
      "12819: loss=0.038, reward_mean=0.500, reward_bound=0.387, batch=231\n",
      "12820: loss=0.040, reward_mean=0.470, reward_bound=0.478, batch=203\n",
      "12821: loss=0.038, reward_mean=0.440, reward_bound=0.229, batch=210\n",
      "12822: loss=0.041, reward_mean=0.420, reward_bound=0.274, batch=217\n",
      "12823: loss=0.042, reward_mean=0.520, reward_bound=0.282, batch=221\n",
      "12824: loss=0.045, reward_mean=0.520, reward_bound=0.314, batch=218\n",
      "12825: loss=0.042, reward_mean=0.570, reward_bound=0.349, batch=215\n",
      "12826: loss=0.041, reward_mean=0.530, reward_bound=0.314, batch=218\n",
      "12827: loss=0.041, reward_mean=0.350, reward_bound=0.211, batch=222\n",
      "12828: loss=0.040, reward_mean=0.500, reward_bound=0.282, batch=224\n",
      "12829: loss=0.041, reward_mean=0.470, reward_bound=0.349, batch=223\n",
      "12830: loss=0.040, reward_mean=0.510, reward_bound=0.372, batch=226\n",
      "12831: loss=0.044, reward_mean=0.530, reward_bound=0.387, batch=224\n",
      "12832: loss=0.044, reward_mean=0.420, reward_bound=0.282, batch=226\n",
      "12833: loss=0.046, reward_mean=0.490, reward_bound=0.387, batch=227\n",
      "12834: loss=0.045, reward_mean=0.430, reward_bound=0.366, batch=229\n",
      "12835: loss=0.040, reward_mean=0.420, reward_bound=0.430, batch=213\n",
      "12836: loss=0.039, reward_mean=0.440, reward_bound=0.372, batch=219\n",
      "12837: loss=0.039, reward_mean=0.500, reward_bound=0.328, batch=223\n",
      "12838: loss=0.038, reward_mean=0.450, reward_bound=0.282, batch=225\n",
      "12839: loss=0.038, reward_mean=0.440, reward_bound=0.349, batch=226\n",
      "12840: loss=0.039, reward_mean=0.490, reward_bound=0.387, batch=219\n",
      "12841: loss=0.040, reward_mean=0.460, reward_bound=0.430, batch=218\n",
      "12842: loss=0.039, reward_mean=0.350, reward_bound=0.231, batch=222\n",
      "12843: loss=0.039, reward_mean=0.410, reward_bound=0.349, batch=223\n",
      "12844: loss=0.040, reward_mean=0.510, reward_bound=0.372, batch=226\n",
      "12845: loss=0.039, reward_mean=0.450, reward_bound=0.387, batch=224\n",
      "12846: loss=0.039, reward_mean=0.440, reward_bound=0.430, batch=223\n",
      "12847: loss=0.039, reward_mean=0.480, reward_bound=0.282, batch=224\n",
      "12848: loss=0.043, reward_mean=0.520, reward_bound=0.349, batch=225\n",
      "12849: loss=0.042, reward_mean=0.430, reward_bound=0.356, batch=227\n",
      "12850: loss=0.042, reward_mean=0.450, reward_bound=0.387, batch=228\n",
      "12851: loss=0.038, reward_mean=0.460, reward_bound=0.430, batch=227\n",
      "12852: loss=0.038, reward_mean=0.460, reward_bound=0.430, batch=228\n",
      "12853: loss=0.040, reward_mean=0.360, reward_bound=0.478, batch=230\n",
      "12854: loss=0.040, reward_mean=0.500, reward_bound=0.464, batch=231\n",
      "12855: loss=0.040, reward_mean=0.410, reward_bound=0.387, batch=231\n",
      "12856: loss=0.038, reward_mean=0.420, reward_bound=0.478, batch=219\n",
      "12857: loss=0.037, reward_mean=0.460, reward_bound=0.387, batch=222\n",
      "12858: loss=0.039, reward_mean=0.510, reward_bound=0.430, batch=222\n",
      "12859: loss=0.039, reward_mean=0.410, reward_bound=0.360, batch=225\n",
      "12860: loss=0.041, reward_mean=0.460, reward_bound=0.387, batch=226\n",
      "12861: loss=0.041, reward_mean=0.460, reward_bound=0.349, batch=227\n",
      "12862: loss=0.040, reward_mean=0.470, reward_bound=0.380, batch=229\n",
      "12863: loss=0.040, reward_mean=0.440, reward_bound=0.387, batch=229\n",
      "12864: loss=0.040, reward_mean=0.460, reward_bound=0.405, batch=230\n",
      "12865: loss=0.040, reward_mean=0.430, reward_bound=0.430, batch=228\n",
      "12866: loss=0.040, reward_mean=0.520, reward_bound=0.435, batch=229\n",
      "12867: loss=0.042, reward_mean=0.450, reward_bound=0.343, batch=230\n",
      "12868: loss=0.040, reward_mean=0.440, reward_bound=0.387, batch=230\n",
      "12869: loss=0.041, reward_mean=0.460, reward_bound=0.478, batch=222\n",
      "12870: loss=0.043, reward_mean=0.450, reward_bound=0.445, batch=225\n",
      "12871: loss=0.044, reward_mean=0.490, reward_bound=0.349, batch=226\n",
      "12872: loss=0.044, reward_mean=0.390, reward_bound=0.372, batch=228\n",
      "12873: loss=0.043, reward_mean=0.440, reward_bound=0.430, batch=226\n",
      "12874: loss=0.044, reward_mean=0.480, reward_bound=0.282, batch=227\n",
      "12875: loss=0.048, reward_mean=0.440, reward_bound=0.414, batch=229\n",
      "12876: loss=0.046, reward_mean=0.390, reward_bound=0.430, batch=228\n",
      "12877: loss=0.046, reward_mean=0.420, reward_bound=0.353, batch=229\n",
      "12878: loss=0.046, reward_mean=0.470, reward_bound=0.478, batch=231\n",
      "12879: loss=0.044, reward_mean=0.540, reward_bound=0.478, batch=227\n",
      "12880: loss=0.044, reward_mean=0.400, reward_bound=0.469, batch=229\n",
      "12881: loss=0.044, reward_mean=0.440, reward_bound=0.405, batch=230\n",
      "12882: loss=0.044, reward_mean=0.480, reward_bound=0.430, batch=230\n",
      "12883: loss=0.044, reward_mean=0.380, reward_bound=0.478, batch=228\n",
      "12884: loss=0.044, reward_mean=0.510, reward_bound=0.367, batch=229\n",
      "12885: loss=0.044, reward_mean=0.390, reward_bound=0.401, batch=230\n",
      "12886: loss=0.044, reward_mean=0.430, reward_bound=0.387, batch=230\n",
      "12887: loss=0.044, reward_mean=0.360, reward_bound=0.451, batch=231\n",
      "12888: loss=0.044, reward_mean=0.390, reward_bound=0.387, batch=231\n",
      "12889: loss=0.044, reward_mean=0.480, reward_bound=0.478, batch=231\n",
      "12891: loss=0.036, reward_mean=0.380, reward_bound=0.000, batch=38\n",
      "12892: loss=0.033, reward_mean=0.460, reward_bound=0.000, batch=84\n",
      "12893: loss=0.031, reward_mean=0.450, reward_bound=0.000, batch=129\n",
      "12894: loss=0.033, reward_mean=0.440, reward_bound=0.002, batch=160\n",
      "12895: loss=0.036, reward_mean=0.490, reward_bound=0.008, batch=182\n",
      "12896: loss=0.042, reward_mean=0.440, reward_bound=0.020, batch=196\n",
      "12897: loss=0.042, reward_mean=0.460, reward_bound=0.038, batch=206\n",
      "12898: loss=0.039, reward_mean=0.430, reward_bound=0.058, batch=211\n",
      "12899: loss=0.039, reward_mean=0.480, reward_bound=0.072, batch=217\n",
      "12900: loss=0.037, reward_mean=0.490, reward_bound=0.098, batch=219\n",
      "12901: loss=0.042, reward_mean=0.420, reward_bound=0.122, batch=210\n",
      "12902: loss=0.051, reward_mean=0.430, reward_bound=0.135, batch=214\n",
      "12903: loss=0.054, reward_mean=0.420, reward_bound=0.150, batch=214\n",
      "12904: loss=0.057, reward_mean=0.530, reward_bound=0.167, batch=211\n",
      "12905: loss=0.053, reward_mean=0.510, reward_bound=0.185, batch=203\n",
      "12906: loss=0.053, reward_mean=0.480, reward_bound=0.206, batch=189\n",
      "12907: loss=0.053, reward_mean=0.480, reward_bound=0.167, batch=201\n",
      "12908: loss=0.052, reward_mean=0.330, reward_bound=0.150, batch=210\n",
      "12909: loss=0.053, reward_mean=0.430, reward_bound=0.229, batch=182\n",
      "12910: loss=0.053, reward_mean=0.460, reward_bound=0.155, batch=197\n",
      "12911: loss=0.055, reward_mean=0.400, reward_bound=0.185, batch=206\n",
      "12912: loss=0.055, reward_mean=0.410, reward_bound=0.196, batch=214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12913: loss=0.053, reward_mean=0.480, reward_bound=0.229, batch=215\n",
      "12914: loss=0.056, reward_mean=0.470, reward_bound=0.254, batch=184\n",
      "12915: loss=0.056, reward_mean=0.460, reward_bound=0.149, batch=199\n",
      "12916: loss=0.060, reward_mean=0.490, reward_bound=0.185, batch=207\n",
      "12917: loss=0.058, reward_mean=0.400, reward_bound=0.206, batch=212\n",
      "12918: loss=0.058, reward_mean=0.440, reward_bound=0.229, batch=213\n",
      "12919: loss=0.057, reward_mean=0.400, reward_bound=0.220, batch=219\n",
      "12920: loss=0.059, reward_mean=0.450, reward_bound=0.254, batch=215\n",
      "12921: loss=0.064, reward_mean=0.420, reward_bound=0.282, batch=182\n",
      "12922: loss=0.062, reward_mean=0.460, reward_bound=0.167, batch=196\n",
      "12923: loss=0.065, reward_mean=0.330, reward_bound=0.168, batch=207\n",
      "12924: loss=0.067, reward_mean=0.470, reward_bound=0.185, batch=214\n",
      "12925: loss=0.066, reward_mean=0.390, reward_bound=0.206, batch=217\n",
      "12926: loss=0.066, reward_mean=0.400, reward_bound=0.229, batch=218\n",
      "12927: loss=0.066, reward_mean=0.430, reward_bound=0.254, batch=213\n",
      "12928: loss=0.067, reward_mean=0.430, reward_bound=0.282, batch=216\n",
      "12929: loss=0.068, reward_mean=0.400, reward_bound=0.314, batch=172\n",
      "12930: loss=0.072, reward_mean=0.430, reward_bound=0.095, batch=190\n",
      "12931: loss=0.071, reward_mean=0.420, reward_bound=0.162, batch=203\n",
      "12932: loss=0.066, reward_mean=0.530, reward_bound=0.167, batch=211\n",
      "12933: loss=0.065, reward_mean=0.420, reward_bound=0.206, batch=211\n",
      "12934: loss=0.065, reward_mean=0.500, reward_bound=0.229, batch=216\n",
      "12935: loss=0.064, reward_mean=0.380, reward_bound=0.254, batch=214\n",
      "12936: loss=0.063, reward_mean=0.360, reward_bound=0.280, batch=220\n",
      "12937: loss=0.061, reward_mean=0.490, reward_bound=0.282, batch=214\n",
      "12938: loss=0.061, reward_mean=0.530, reward_bound=0.314, batch=211\n",
      "12939: loss=0.062, reward_mean=0.510, reward_bound=0.282, batch=217\n",
      "12940: loss=0.065, reward_mean=0.410, reward_bound=0.349, batch=149\n",
      "12941: loss=0.063, reward_mean=0.500, reward_bound=0.097, batch=174\n",
      "12942: loss=0.060, reward_mean=0.480, reward_bound=0.135, batch=190\n",
      "12943: loss=0.062, reward_mean=0.430, reward_bound=0.180, batch=203\n",
      "12944: loss=0.058, reward_mean=0.510, reward_bound=0.206, batch=205\n",
      "12945: loss=0.058, reward_mean=0.430, reward_bound=0.153, batch=213\n",
      "12946: loss=0.060, reward_mean=0.400, reward_bound=0.229, batch=213\n",
      "12947: loss=0.058, reward_mean=0.320, reward_bound=0.185, batch=218\n",
      "12948: loss=0.057, reward_mean=0.420, reward_bound=0.254, batch=214\n",
      "12949: loss=0.057, reward_mean=0.430, reward_bound=0.282, batch=205\n",
      "12950: loss=0.058, reward_mean=0.360, reward_bound=0.138, batch=213\n",
      "12951: loss=0.058, reward_mean=0.450, reward_bound=0.178, batch=219\n",
      "12952: loss=0.057, reward_mean=0.490, reward_bound=0.206, batch=221\n",
      "12953: loss=0.056, reward_mean=0.480, reward_bound=0.282, batch=220\n",
      "12954: loss=0.057, reward_mean=0.500, reward_bound=0.314, batch=208\n",
      "12955: loss=0.057, reward_mean=0.470, reward_bound=0.211, batch=215\n",
      "12956: loss=0.057, reward_mean=0.420, reward_bound=0.289, batch=220\n",
      "12957: loss=0.058, reward_mean=0.530, reward_bound=0.314, batch=219\n",
      "12958: loss=0.057, reward_mean=0.440, reward_bound=0.309, batch=223\n",
      "12959: loss=0.056, reward_mean=0.370, reward_bound=0.335, batch=226\n",
      "12960: loss=0.059, reward_mean=0.470, reward_bound=0.349, batch=201\n",
      "12961: loss=0.059, reward_mean=0.410, reward_bound=0.185, batch=210\n",
      "12962: loss=0.063, reward_mean=0.460, reward_bound=0.180, batch=217\n",
      "12963: loss=0.061, reward_mean=0.430, reward_bound=0.185, batch=220\n",
      "12964: loss=0.058, reward_mean=0.420, reward_bound=0.254, batch=220\n",
      "12965: loss=0.055, reward_mean=0.400, reward_bound=0.282, batch=221\n",
      "12966: loss=0.055, reward_mean=0.350, reward_bound=0.282, batch=224\n",
      "12967: loss=0.055, reward_mean=0.360, reward_bound=0.308, batch=227\n",
      "12968: loss=0.055, reward_mean=0.480, reward_bound=0.314, batch=227\n",
      "12969: loss=0.055, reward_mean=0.480, reward_bound=0.314, batch=228\n",
      "12970: loss=0.056, reward_mean=0.470, reward_bound=0.353, batch=229\n",
      "12971: loss=0.062, reward_mean=0.530, reward_bound=0.387, batch=147\n",
      "12972: loss=0.060, reward_mean=0.480, reward_bound=0.047, batch=172\n",
      "12973: loss=0.063, reward_mean=0.410, reward_bound=0.080, batch=188\n",
      "12974: loss=0.063, reward_mean=0.500, reward_bound=0.111, batch=201\n",
      "12975: loss=0.067, reward_mean=0.470, reward_bound=0.167, batch=204\n",
      "12976: loss=0.067, reward_mean=0.470, reward_bound=0.185, batch=206\n",
      "12977: loss=0.067, reward_mean=0.470, reward_bound=0.206, batch=203\n",
      "12978: loss=0.065, reward_mean=0.440, reward_bound=0.229, batch=209\n",
      "12979: loss=0.067, reward_mean=0.400, reward_bound=0.239, batch=216\n",
      "12980: loss=0.065, reward_mean=0.460, reward_bound=0.254, batch=220\n",
      "12981: loss=0.063, reward_mean=0.440, reward_bound=0.282, batch=214\n",
      "12982: loss=0.062, reward_mean=0.420, reward_bound=0.314, batch=202\n",
      "12983: loss=0.063, reward_mean=0.510, reward_bound=0.236, batch=211\n",
      "12984: loss=0.064, reward_mean=0.470, reward_bound=0.282, batch=217\n",
      "12985: loss=0.063, reward_mean=0.440, reward_bound=0.342, batch=222\n",
      "12986: loss=0.063, reward_mean=0.450, reward_bound=0.349, batch=206\n",
      "12987: loss=0.065, reward_mean=0.480, reward_bound=0.229, batch=213\n",
      "12988: loss=0.067, reward_mean=0.380, reward_bound=0.220, batch=219\n",
      "12989: loss=0.065, reward_mean=0.450, reward_bound=0.254, batch=221\n",
      "12990: loss=0.065, reward_mean=0.420, reward_bound=0.314, batch=223\n",
      "12991: loss=0.066, reward_mean=0.440, reward_bound=0.335, batch=226\n",
      "12992: loss=0.065, reward_mean=0.470, reward_bound=0.349, batch=224\n",
      "12993: loss=0.065, reward_mean=0.410, reward_bound=0.387, batch=203\n",
      "12994: loss=0.062, reward_mean=0.470, reward_bound=0.185, batch=211\n",
      "12995: loss=0.063, reward_mean=0.430, reward_bound=0.229, batch=217\n",
      "12996: loss=0.063, reward_mean=0.430, reward_bound=0.282, batch=216\n",
      "12997: loss=0.065, reward_mean=0.360, reward_bound=0.298, batch=221\n",
      "12998: loss=0.064, reward_mean=0.460, reward_bound=0.314, batch=219\n",
      "12999: loss=0.063, reward_mean=0.400, reward_bound=0.295, batch=223\n",
      "13000: loss=0.065, reward_mean=0.500, reward_bound=0.290, batch=226\n",
      "13001: loss=0.066, reward_mean=0.410, reward_bound=0.349, batch=225\n",
      "13002: loss=0.067, reward_mean=0.440, reward_bound=0.387, batch=219\n",
      "13003: loss=0.067, reward_mean=0.430, reward_bound=0.349, batch=221\n",
      "13004: loss=0.066, reward_mean=0.430, reward_bound=0.314, batch=223\n",
      "13005: loss=0.070, reward_mean=0.440, reward_bound=0.430, batch=126\n",
      "13006: loss=0.069, reward_mean=0.520, reward_bound=0.042, batch=155\n",
      "13007: loss=0.070, reward_mean=0.430, reward_bound=0.039, batch=178\n",
      "13008: loss=0.074, reward_mean=0.390, reward_bound=0.052, batch=193\n",
      "13009: loss=0.075, reward_mean=0.460, reward_bound=0.080, batch=204\n",
      "13010: loss=0.073, reward_mean=0.520, reward_bound=0.098, batch=211\n",
      "13011: loss=0.080, reward_mean=0.400, reward_bound=0.135, batch=209\n",
      "13012: loss=0.076, reward_mean=0.520, reward_bound=0.167, batch=212\n",
      "13013: loss=0.078, reward_mean=0.380, reward_bound=0.185, batch=214\n",
      "13014: loss=0.077, reward_mean=0.450, reward_bound=0.206, batch=211\n",
      "13015: loss=0.081, reward_mean=0.510, reward_bound=0.229, batch=211\n",
      "13016: loss=0.079, reward_mean=0.450, reward_bound=0.254, batch=216\n",
      "13017: loss=0.079, reward_mean=0.500, reward_bound=0.268, batch=221\n",
      "13018: loss=0.081, reward_mean=0.410, reward_bound=0.282, batch=204\n",
      "13019: loss=0.085, reward_mean=0.440, reward_bound=0.185, batch=212\n",
      "13020: loss=0.081, reward_mean=0.410, reward_bound=0.254, batch=215\n",
      "13021: loss=0.081, reward_mean=0.430, reward_bound=0.234, batch=220\n",
      "13022: loss=0.083, reward_mean=0.360, reward_bound=0.254, batch=222\n",
      "13023: loss=0.081, reward_mean=0.410, reward_bound=0.292, batch=225\n",
      "13024: loss=0.082, reward_mean=0.470, reward_bound=0.314, batch=204\n",
      "13025: loss=0.079, reward_mean=0.490, reward_bound=0.135, batch=212\n",
      "13026: loss=0.083, reward_mean=0.490, reward_bound=0.229, batch=217\n",
      "13027: loss=0.083, reward_mean=0.500, reward_bound=0.282, batch=220\n",
      "13028: loss=0.082, reward_mean=0.530, reward_bound=0.304, batch=224\n",
      "13029: loss=0.081, reward_mean=0.370, reward_bound=0.345, batch=227\n",
      "13030: loss=0.080, reward_mean=0.470, reward_bound=0.349, batch=202\n",
      "13031: loss=0.081, reward_mean=0.430, reward_bound=0.282, batch=210\n",
      "13032: loss=0.080, reward_mean=0.470, reward_bound=0.304, batch=217\n",
      "13033: loss=0.080, reward_mean=0.470, reward_bound=0.282, batch=221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13034: loss=0.079, reward_mean=0.510, reward_bound=0.349, batch=219\n",
      "13035: loss=0.080, reward_mean=0.390, reward_bound=0.254, batch=222\n",
      "13036: loss=0.081, reward_mean=0.450, reward_bound=0.314, batch=222\n",
      "13037: loss=0.078, reward_mean=0.420, reward_bound=0.360, batch=225\n",
      "13038: loss=0.083, reward_mean=0.500, reward_bound=0.387, batch=195\n",
      "13039: loss=0.083, reward_mean=0.380, reward_bound=0.210, batch=206\n",
      "13040: loss=0.082, reward_mean=0.530, reward_bound=0.282, batch=212\n",
      "13041: loss=0.084, reward_mean=0.440, reward_bound=0.314, batch=213\n",
      "13042: loss=0.083, reward_mean=0.570, reward_bound=0.301, batch=219\n",
      "13043: loss=0.085, reward_mean=0.490, reward_bound=0.314, batch=221\n",
      "13044: loss=0.085, reward_mean=0.420, reward_bound=0.349, batch=216\n",
      "13045: loss=0.084, reward_mean=0.430, reward_bound=0.349, batch=219\n",
      "13046: loss=0.084, reward_mean=0.380, reward_bound=0.295, batch=223\n",
      "13047: loss=0.084, reward_mean=0.470, reward_bound=0.349, batch=223\n",
      "13048: loss=0.085, reward_mean=0.390, reward_bound=0.372, batch=226\n",
      "13049: loss=0.084, reward_mean=0.460, reward_bound=0.331, batch=228\n",
      "13050: loss=0.083, reward_mean=0.420, reward_bound=0.387, batch=219\n",
      "13051: loss=0.081, reward_mean=0.460, reward_bound=0.295, batch=223\n",
      "13052: loss=0.081, reward_mean=0.410, reward_bound=0.301, batch=226\n",
      "13053: loss=0.081, reward_mean=0.420, reward_bound=0.314, batch=227\n",
      "13054: loss=0.082, reward_mean=0.420, reward_bound=0.349, batch=226\n",
      "13055: loss=0.082, reward_mean=0.430, reward_bound=0.387, batch=224\n",
      "13056: loss=0.085, reward_mean=0.440, reward_bound=0.311, batch=227\n",
      "13057: loss=0.084, reward_mean=0.390, reward_bound=0.314, batch=227\n",
      "13058: loss=0.081, reward_mean=0.510, reward_bound=0.349, batch=228\n",
      "13059: loss=0.083, reward_mean=0.510, reward_bound=0.387, batch=227\n",
      "13060: loss=0.076, reward_mean=0.450, reward_bound=0.430, batch=185\n",
      "13061: loss=0.073, reward_mean=0.400, reward_bound=0.112, batch=199\n",
      "13062: loss=0.071, reward_mean=0.430, reward_bound=0.194, batch=209\n",
      "13063: loss=0.074, reward_mean=0.440, reward_bound=0.206, batch=212\n",
      "13064: loss=0.072, reward_mean=0.390, reward_bound=0.229, batch=209\n",
      "13065: loss=0.070, reward_mean=0.480, reward_bound=0.254, batch=208\n",
      "13066: loss=0.071, reward_mean=0.500, reward_bound=0.282, batch=213\n",
      "13067: loss=0.070, reward_mean=0.420, reward_bound=0.282, batch=218\n",
      "13068: loss=0.071, reward_mean=0.430, reward_bound=0.314, batch=215\n",
      "13069: loss=0.072, reward_mean=0.380, reward_bound=0.349, batch=211\n",
      "13070: loss=0.072, reward_mean=0.480, reward_bound=0.206, batch=217\n",
      "13071: loss=0.071, reward_mean=0.490, reward_bound=0.282, batch=221\n",
      "13072: loss=0.071, reward_mean=0.520, reward_bound=0.314, batch=222\n",
      "13073: loss=0.070, reward_mean=0.440, reward_bound=0.292, batch=225\n",
      "13074: loss=0.069, reward_mean=0.430, reward_bound=0.349, batch=224\n",
      "13075: loss=0.070, reward_mean=0.480, reward_bound=0.384, batch=227\n",
      "13076: loss=0.072, reward_mean=0.440, reward_bound=0.380, batch=229\n",
      "13077: loss=0.072, reward_mean=0.440, reward_bound=0.387, batch=219\n",
      "13078: loss=0.071, reward_mean=0.410, reward_bound=0.309, batch=223\n",
      "13079: loss=0.072, reward_mean=0.450, reward_bound=0.349, batch=225\n",
      "13080: loss=0.072, reward_mean=0.440, reward_bound=0.303, batch=227\n",
      "13081: loss=0.071, reward_mean=0.420, reward_bound=0.380, batch=229\n",
      "13082: loss=0.072, reward_mean=0.450, reward_bound=0.387, batch=226\n",
      "13083: loss=0.074, reward_mean=0.480, reward_bound=0.430, batch=208\n",
      "13084: loss=0.076, reward_mean=0.480, reward_bound=0.317, batch=215\n",
      "13085: loss=0.075, reward_mean=0.450, reward_bound=0.349, batch=218\n",
      "13086: loss=0.075, reward_mean=0.410, reward_bound=0.317, batch=222\n",
      "13087: loss=0.076, reward_mean=0.470, reward_bound=0.236, batch=225\n",
      "13088: loss=0.078, reward_mean=0.480, reward_bound=0.314, batch=226\n",
      "13089: loss=0.078, reward_mean=0.390, reward_bound=0.349, batch=226\n",
      "13090: loss=0.078, reward_mean=0.440, reward_bound=0.349, batch=226\n",
      "13091: loss=0.077, reward_mean=0.440, reward_bound=0.368, batch=228\n",
      "13092: loss=0.073, reward_mean=0.560, reward_bound=0.387, batch=223\n",
      "13093: loss=0.073, reward_mean=0.420, reward_bound=0.314, batch=225\n",
      "13094: loss=0.072, reward_mean=0.520, reward_bound=0.387, batch=226\n",
      "13095: loss=0.072, reward_mean=0.440, reward_bound=0.430, batch=218\n",
      "13096: loss=0.071, reward_mean=0.490, reward_bound=0.387, batch=221\n",
      "13097: loss=0.071, reward_mean=0.420, reward_bound=0.349, batch=223\n",
      "13098: loss=0.071, reward_mean=0.360, reward_bound=0.372, batch=226\n",
      "13099: loss=0.070, reward_mean=0.400, reward_bound=0.387, batch=226\n",
      "13100: loss=0.069, reward_mean=0.480, reward_bound=0.390, batch=228\n",
      "13101: loss=0.070, reward_mean=0.540, reward_bound=0.430, batch=225\n",
      "13102: loss=0.071, reward_mean=0.410, reward_bound=0.356, batch=227\n",
      "13103: loss=0.070, reward_mean=0.400, reward_bound=0.380, batch=229\n",
      "13104: loss=0.069, reward_mean=0.450, reward_bound=0.405, batch=230\n",
      "13105: loss=0.070, reward_mean=0.500, reward_bound=0.430, batch=230\n",
      "13106: loss=0.063, reward_mean=0.550, reward_bound=0.478, batch=96\n",
      "13107: loss=0.060, reward_mean=0.420, reward_bound=0.001, batch=137\n",
      "13108: loss=0.060, reward_mean=0.440, reward_bound=0.005, batch=166\n",
      "13109: loss=0.060, reward_mean=0.470, reward_bound=0.028, batch=186\n",
      "13110: loss=0.061, reward_mean=0.420, reward_bound=0.052, batch=199\n",
      "13111: loss=0.062, reward_mean=0.450, reward_bound=0.080, batch=204\n",
      "13112: loss=0.062, reward_mean=0.370, reward_bound=0.089, batch=211\n",
      "13113: loss=0.063, reward_mean=0.520, reward_bound=0.122, batch=210\n",
      "13114: loss=0.059, reward_mean=0.350, reward_bound=0.135, batch=210\n",
      "13115: loss=0.059, reward_mean=0.500, reward_bound=0.150, batch=215\n",
      "13116: loss=0.062, reward_mean=0.460, reward_bound=0.167, batch=208\n",
      "13117: loss=0.061, reward_mean=0.460, reward_bound=0.185, batch=214\n",
      "13118: loss=0.059, reward_mean=0.420, reward_bound=0.206, batch=207\n",
      "13119: loss=0.060, reward_mean=0.430, reward_bound=0.198, batch=215\n",
      "13120: loss=0.060, reward_mean=0.430, reward_bound=0.229, batch=205\n",
      "13121: loss=0.058, reward_mean=0.480, reward_bound=0.254, batch=194\n",
      "13122: loss=0.058, reward_mean=0.570, reward_bound=0.206, batch=205\n",
      "13123: loss=0.059, reward_mean=0.360, reward_bound=0.210, batch=213\n",
      "13124: loss=0.059, reward_mean=0.390, reward_bound=0.220, batch=219\n",
      "13125: loss=0.056, reward_mean=0.470, reward_bound=0.229, batch=219\n",
      "13126: loss=0.060, reward_mean=0.400, reward_bound=0.254, batch=218\n",
      "13127: loss=0.062, reward_mean=0.430, reward_bound=0.282, batch=204\n",
      "13128: loss=0.063, reward_mean=0.470, reward_bound=0.254, batch=212\n",
      "13129: loss=0.062, reward_mean=0.460, reward_bound=0.282, batch=217\n",
      "13130: loss=0.061, reward_mean=0.460, reward_bound=0.249, batch=222\n",
      "13131: loss=0.061, reward_mean=0.460, reward_bound=0.263, batch=225\n",
      "13132: loss=0.061, reward_mean=0.410, reward_bound=0.282, batch=226\n",
      "13133: loss=0.059, reward_mean=0.410, reward_bound=0.314, batch=205\n",
      "13134: loss=0.057, reward_mean=0.460, reward_bound=0.282, batch=212\n",
      "13135: loss=0.058, reward_mean=0.530, reward_bound=0.292, batch=218\n",
      "13136: loss=0.061, reward_mean=0.520, reward_bound=0.314, batch=219\n",
      "13137: loss=0.060, reward_mean=0.400, reward_bound=0.254, batch=222\n",
      "13138: loss=0.063, reward_mean=0.470, reward_bound=0.349, batch=187\n",
      "13139: loss=0.061, reward_mean=0.430, reward_bound=0.198, batch=201\n",
      "13140: loss=0.062, reward_mean=0.530, reward_bound=0.206, batch=208\n",
      "13141: loss=0.061, reward_mean=0.460, reward_bound=0.229, batch=212\n",
      "13142: loss=0.060, reward_mean=0.460, reward_bound=0.254, batch=216\n",
      "13143: loss=0.064, reward_mean=0.460, reward_bound=0.282, batch=219\n",
      "13144: loss=0.063, reward_mean=0.440, reward_bound=0.278, batch=223\n",
      "13145: loss=0.064, reward_mean=0.410, reward_bound=0.314, batch=216\n",
      "13146: loss=0.066, reward_mean=0.390, reward_bound=0.254, batch=220\n",
      "13147: loss=0.065, reward_mean=0.470, reward_bound=0.254, batch=222\n",
      "13148: loss=0.064, reward_mean=0.290, reward_bound=0.292, batch=225\n",
      "13149: loss=0.066, reward_mean=0.410, reward_bound=0.349, batch=213\n",
      "13150: loss=0.065, reward_mean=0.420, reward_bound=0.322, batch=219\n",
      "13151: loss=0.066, reward_mean=0.460, reward_bound=0.349, batch=222\n",
      "13152: loss=0.066, reward_mean=0.420, reward_bound=0.324, batch=225\n",
      "13153: loss=0.066, reward_mean=0.500, reward_bound=0.349, batch=226\n",
      "13154: loss=0.062, reward_mean=0.470, reward_bound=0.387, batch=182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13155: loss=0.061, reward_mean=0.490, reward_bound=0.185, batch=195\n",
      "13156: loss=0.060, reward_mean=0.490, reward_bound=0.150, batch=204\n",
      "13157: loss=0.059, reward_mean=0.470, reward_bound=0.206, batch=210\n",
      "13158: loss=0.058, reward_mean=0.440, reward_bound=0.229, batch=215\n",
      "13159: loss=0.063, reward_mean=0.460, reward_bound=0.210, batch=220\n",
      "13160: loss=0.065, reward_mean=0.480, reward_bound=0.254, batch=222\n",
      "13161: loss=0.068, reward_mean=0.400, reward_bound=0.282, batch=218\n",
      "13162: loss=0.067, reward_mean=0.450, reward_bound=0.231, batch=222\n",
      "13163: loss=0.068, reward_mean=0.510, reward_bound=0.314, batch=219\n",
      "13164: loss=0.063, reward_mean=0.380, reward_bound=0.349, batch=206\n",
      "13165: loss=0.062, reward_mean=0.490, reward_bound=0.282, batch=212\n",
      "13166: loss=0.064, reward_mean=0.430, reward_bound=0.229, batch=217\n",
      "13167: loss=0.063, reward_mean=0.460, reward_bound=0.282, batch=221\n",
      "13168: loss=0.064, reward_mean=0.430, reward_bound=0.282, batch=224\n",
      "13169: loss=0.065, reward_mean=0.450, reward_bound=0.314, batch=226\n",
      "13170: loss=0.063, reward_mean=0.450, reward_bound=0.349, batch=222\n",
      "13171: loss=0.063, reward_mean=0.460, reward_bound=0.349, batch=224\n",
      "13172: loss=0.063, reward_mean=0.440, reward_bound=0.314, batch=224\n",
      "13173: loss=0.063, reward_mean=0.330, reward_bound=0.374, batch=227\n",
      "13174: loss=0.066, reward_mean=0.340, reward_bound=0.387, batch=214\n",
      "13175: loss=0.064, reward_mean=0.610, reward_bound=0.387, batch=219\n",
      "13176: loss=0.065, reward_mean=0.500, reward_bound=0.328, batch=223\n",
      "13177: loss=0.063, reward_mean=0.360, reward_bound=0.372, batch=226\n",
      "13178: loss=0.063, reward_mean=0.400, reward_bound=0.387, batch=226\n",
      "13179: loss=0.064, reward_mean=0.500, reward_bound=0.368, batch=228\n",
      "13180: loss=0.064, reward_mean=0.470, reward_bound=0.430, batch=158\n",
      "13181: loss=0.056, reward_mean=0.490, reward_bound=0.098, batch=179\n",
      "13182: loss=0.062, reward_mean=0.470, reward_bound=0.135, batch=194\n",
      "13183: loss=0.062, reward_mean=0.350, reward_bound=0.097, batch=206\n",
      "13184: loss=0.061, reward_mean=0.500, reward_bound=0.150, batch=212\n",
      "13185: loss=0.061, reward_mean=0.510, reward_bound=0.167, batch=217\n",
      "13186: loss=0.058, reward_mean=0.370, reward_bound=0.202, batch=222\n",
      "13187: loss=0.055, reward_mean=0.380, reward_bound=0.206, batch=232\n",
      "13188: loss=0.056, reward_mean=0.430, reward_bound=0.206, batch=244\n",
      "13189: loss=0.056, reward_mean=0.510, reward_bound=0.206, batch=232\n",
      "13190: loss=0.058, reward_mean=0.450, reward_bound=0.229, batch=226\n",
      "13191: loss=0.058, reward_mean=0.420, reward_bound=0.254, batch=222\n",
      "13192: loss=0.060, reward_mean=0.430, reward_bound=0.245, batch=225\n",
      "13193: loss=0.061, reward_mean=0.510, reward_bound=0.282, batch=226\n",
      "13194: loss=0.063, reward_mean=0.460, reward_bound=0.314, batch=212\n",
      "13195: loss=0.061, reward_mean=0.530, reward_bound=0.254, batch=218\n",
      "13196: loss=0.063, reward_mean=0.460, reward_bound=0.286, batch=222\n",
      "13197: loss=0.066, reward_mean=0.540, reward_bound=0.349, batch=209\n",
      "13198: loss=0.065, reward_mean=0.460, reward_bound=0.314, batch=213\n",
      "13199: loss=0.065, reward_mean=0.430, reward_bound=0.198, batch=219\n",
      "13200: loss=0.064, reward_mean=0.400, reward_bound=0.254, batch=222\n",
      "13201: loss=0.065, reward_mean=0.490, reward_bound=0.314, batch=224\n",
      "13202: loss=0.064, reward_mean=0.480, reward_bound=0.311, batch=227\n",
      "13203: loss=0.065, reward_mean=0.440, reward_bound=0.349, batch=225\n",
      "13204: loss=0.064, reward_mean=0.380, reward_bound=0.349, batch=226\n",
      "13205: loss=0.064, reward_mean=0.380, reward_bound=0.368, batch=228\n",
      "13206: loss=0.062, reward_mean=0.470, reward_bound=0.387, batch=204\n",
      "13207: loss=0.062, reward_mean=0.360, reward_bound=0.229, batch=211\n",
      "13208: loss=0.062, reward_mean=0.450, reward_bound=0.282, batch=216\n",
      "13209: loss=0.062, reward_mean=0.400, reward_bound=0.268, batch=221\n",
      "13210: loss=0.064, reward_mean=0.430, reward_bound=0.314, batch=217\n",
      "13211: loss=0.064, reward_mean=0.500, reward_bound=0.302, batch=222\n",
      "13212: loss=0.062, reward_mean=0.460, reward_bound=0.349, batch=218\n",
      "13213: loss=0.062, reward_mean=0.440, reward_bound=0.387, batch=212\n",
      "13214: loss=0.062, reward_mean=0.540, reward_bound=0.349, batch=216\n",
      "13215: loss=0.065, reward_mean=0.420, reward_bound=0.314, batch=220\n",
      "13216: loss=0.065, reward_mean=0.370, reward_bound=0.349, batch=219\n",
      "13217: loss=0.064, reward_mean=0.420, reward_bound=0.229, batch=221\n",
      "13218: loss=0.062, reward_mean=0.460, reward_bound=0.387, batch=220\n",
      "13219: loss=0.064, reward_mean=0.510, reward_bound=0.387, batch=223\n",
      "13220: loss=0.063, reward_mean=0.480, reward_bound=0.314, batch=225\n",
      "13221: loss=0.063, reward_mean=0.490, reward_bound=0.387, batch=226\n",
      "13222: loss=0.063, reward_mean=0.480, reward_bound=0.409, batch=228\n",
      "13223: loss=0.061, reward_mean=0.370, reward_bound=0.430, batch=195\n",
      "13224: loss=0.060, reward_mean=0.450, reward_bound=0.175, batch=206\n",
      "13225: loss=0.064, reward_mean=0.450, reward_bound=0.229, batch=211\n",
      "13226: loss=0.062, reward_mean=0.530, reward_bound=0.254, batch=217\n",
      "13227: loss=0.061, reward_mean=0.430, reward_bound=0.249, batch=222\n",
      "13228: loss=0.062, reward_mean=0.440, reward_bound=0.282, batch=221\n",
      "13229: loss=0.062, reward_mean=0.460, reward_bound=0.282, batch=224\n",
      "13230: loss=0.060, reward_mean=0.440, reward_bound=0.314, batch=223\n",
      "13231: loss=0.061, reward_mean=0.410, reward_bound=0.301, batch=226\n",
      "13232: loss=0.060, reward_mean=0.500, reward_bound=0.349, batch=224\n",
      "13233: loss=0.060, reward_mean=0.470, reward_bound=0.380, batch=227\n",
      "13234: loss=0.060, reward_mean=0.520, reward_bound=0.387, batch=214\n",
      "13235: loss=0.059, reward_mean=0.400, reward_bound=0.252, batch=220\n",
      "13236: loss=0.059, reward_mean=0.470, reward_bound=0.274, batch=224\n",
      "13237: loss=0.057, reward_mean=0.550, reward_bound=0.282, batch=224\n",
      "13238: loss=0.057, reward_mean=0.450, reward_bound=0.314, batch=225\n",
      "13239: loss=0.057, reward_mean=0.430, reward_bound=0.349, batch=226\n",
      "13240: loss=0.057, reward_mean=0.480, reward_bound=0.387, batch=225\n",
      "13241: loss=0.057, reward_mean=0.420, reward_bound=0.329, batch=227\n",
      "13242: loss=0.056, reward_mean=0.440, reward_bound=0.380, batch=229\n",
      "13243: loss=0.056, reward_mean=0.460, reward_bound=0.430, batch=215\n",
      "13244: loss=0.057, reward_mean=0.360, reward_bound=0.289, batch=220\n",
      "13245: loss=0.058, reward_mean=0.370, reward_bound=0.365, batch=224\n",
      "13246: loss=0.059, reward_mean=0.490, reward_bound=0.314, batch=226\n",
      "13247: loss=0.058, reward_mean=0.420, reward_bound=0.331, batch=228\n",
      "13248: loss=0.057, reward_mean=0.340, reward_bound=0.387, batch=226\n",
      "13249: loss=0.058, reward_mean=0.380, reward_bound=0.430, batch=225\n",
      "13250: loss=0.057, reward_mean=0.420, reward_bound=0.314, batch=226\n",
      "13251: loss=0.057, reward_mean=0.380, reward_bound=0.301, batch=228\n",
      "13252: loss=0.057, reward_mean=0.470, reward_bound=0.387, batch=227\n",
      "13253: loss=0.057, reward_mean=0.370, reward_bound=0.422, batch=229\n",
      "13254: loss=0.057, reward_mean=0.370, reward_bound=0.405, batch=230\n",
      "13255: loss=0.057, reward_mean=0.480, reward_bound=0.430, batch=230\n",
      "13256: loss=0.057, reward_mean=0.450, reward_bound=0.464, batch=231\n",
      "13257: loss=0.065, reward_mean=0.430, reward_bound=0.478, batch=153\n",
      "13258: loss=0.064, reward_mean=0.420, reward_bound=0.050, batch=177\n",
      "13259: loss=0.067, reward_mean=0.430, reward_bound=0.089, batch=197\n",
      "13260: loss=0.067, reward_mean=0.410, reward_bound=0.089, batch=212\n",
      "13261: loss=0.066, reward_mean=0.530, reward_bound=0.135, batch=215\n",
      "13262: loss=0.066, reward_mean=0.510, reward_bound=0.167, batch=216\n",
      "13263: loss=0.067, reward_mean=0.440, reward_bound=0.185, batch=215\n",
      "13264: loss=0.073, reward_mean=0.410, reward_bound=0.229, batch=206\n",
      "13265: loss=0.075, reward_mean=0.440, reward_bound=0.254, batch=199\n",
      "13266: loss=0.075, reward_mean=0.480, reward_bound=0.239, batch=209\n",
      "13267: loss=0.076, reward_mean=0.470, reward_bound=0.254, batch=214\n",
      "13268: loss=0.076, reward_mean=0.550, reward_bound=0.282, batch=211\n",
      "13269: loss=0.075, reward_mean=0.390, reward_bound=0.229, batch=217\n",
      "13270: loss=0.077, reward_mean=0.520, reward_bound=0.314, batch=212\n",
      "13271: loss=0.078, reward_mean=0.440, reward_bound=0.236, batch=218\n",
      "13272: loss=0.079, reward_mean=0.410, reward_bound=0.282, batch=219\n",
      "13273: loss=0.078, reward_mean=0.420, reward_bound=0.295, batch=223\n",
      "13274: loss=0.076, reward_mean=0.440, reward_bound=0.335, batch=226\n",
      "13275: loss=0.075, reward_mean=0.410, reward_bound=0.349, batch=207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13276: loss=0.075, reward_mean=0.410, reward_bound=0.342, batch=215\n",
      "13277: loss=0.074, reward_mean=0.520, reward_bound=0.314, batch=219\n",
      "13278: loss=0.075, reward_mean=0.400, reward_bound=0.349, batch=222\n",
      "13279: loss=0.075, reward_mean=0.440, reward_bound=0.272, batch=225\n",
      "13280: loss=0.075, reward_mean=0.460, reward_bound=0.314, batch=226\n",
      "13281: loss=0.074, reward_mean=0.370, reward_bound=0.349, batch=227\n",
      "13282: loss=0.071, reward_mean=0.450, reward_bound=0.387, batch=197\n",
      "13283: loss=0.070, reward_mean=0.410, reward_bound=0.206, batch=207\n",
      "13284: loss=0.070, reward_mean=0.390, reward_bound=0.224, batch=215\n",
      "13285: loss=0.064, reward_mean=0.490, reward_bound=0.254, batch=218\n",
      "13286: loss=0.065, reward_mean=0.450, reward_bound=0.254, batch=220\n",
      "13287: loss=0.064, reward_mean=0.420, reward_bound=0.282, batch=223\n",
      "13288: loss=0.064, reward_mean=0.460, reward_bound=0.301, batch=226\n",
      "13289: loss=0.065, reward_mean=0.530, reward_bound=0.314, batch=221\n",
      "13290: loss=0.066, reward_mean=0.530, reward_bound=0.349, batch=221\n",
      "13291: loss=0.069, reward_mean=0.460, reward_bound=0.349, batch=224\n",
      "13292: loss=0.069, reward_mean=0.410, reward_bound=0.387, batch=218\n",
      "13293: loss=0.070, reward_mean=0.540, reward_bound=0.321, batch=222\n",
      "13294: loss=0.071, reward_mean=0.420, reward_bound=0.292, batch=225\n",
      "13295: loss=0.070, reward_mean=0.400, reward_bound=0.329, batch=227\n",
      "13296: loss=0.072, reward_mean=0.430, reward_bound=0.387, batch=226\n",
      "13297: loss=0.073, reward_mean=0.450, reward_bound=0.387, batch=227\n",
      "13298: loss=0.070, reward_mean=0.430, reward_bound=0.430, batch=197\n",
      "13299: loss=0.071, reward_mean=0.490, reward_bound=0.282, batch=204\n",
      "13300: loss=0.068, reward_mean=0.420, reward_bound=0.280, batch=213\n",
      "13301: loss=0.066, reward_mean=0.490, reward_bound=0.301, batch=219\n",
      "13302: loss=0.068, reward_mean=0.430, reward_bound=0.295, batch=223\n",
      "13303: loss=0.070, reward_mean=0.380, reward_bound=0.314, batch=221\n",
      "13304: loss=0.066, reward_mean=0.520, reward_bound=0.349, batch=214\n",
      "13305: loss=0.067, reward_mean=0.520, reward_bound=0.229, batch=217\n",
      "13306: loss=0.065, reward_mean=0.380, reward_bound=0.308, batch=222\n",
      "13307: loss=0.067, reward_mean=0.420, reward_bound=0.314, batch=224\n",
      "13308: loss=0.067, reward_mean=0.430, reward_bound=0.349, batch=225\n",
      "13309: loss=0.071, reward_mean=0.430, reward_bound=0.387, batch=213\n",
      "13310: loss=0.074, reward_mean=0.450, reward_bound=0.185, batch=218\n",
      "13311: loss=0.069, reward_mean=0.490, reward_bound=0.229, batch=221\n",
      "13312: loss=0.071, reward_mean=0.500, reward_bound=0.314, batch=224\n",
      "13313: loss=0.072, reward_mean=0.440, reward_bound=0.345, batch=227\n",
      "13314: loss=0.071, reward_mean=0.570, reward_bound=0.342, batch=229\n",
      "13315: loss=0.071, reward_mean=0.520, reward_bound=0.387, batch=228\n",
      "13316: loss=0.071, reward_mean=0.520, reward_bound=0.353, batch=229\n",
      "13317: loss=0.071, reward_mean=0.390, reward_bound=0.364, batch=230\n",
      "13318: loss=0.074, reward_mean=0.460, reward_bound=0.430, batch=212\n",
      "13319: loss=0.073, reward_mean=0.530, reward_bound=0.245, batch=218\n",
      "13320: loss=0.074, reward_mean=0.440, reward_bound=0.314, batch=219\n",
      "13321: loss=0.074, reward_mean=0.460, reward_bound=0.328, batch=223\n",
      "13322: loss=0.076, reward_mean=0.510, reward_bound=0.349, batch=223\n",
      "13323: loss=0.075, reward_mean=0.500, reward_bound=0.372, batch=226\n",
      "13324: loss=0.075, reward_mean=0.540, reward_bound=0.387, batch=224\n",
      "13325: loss=0.072, reward_mean=0.460, reward_bound=0.430, batch=221\n",
      "13326: loss=0.072, reward_mean=0.530, reward_bound=0.314, batch=224\n",
      "13327: loss=0.072, reward_mean=0.390, reward_bound=0.349, batch=226\n",
      "13328: loss=0.073, reward_mean=0.360, reward_bound=0.225, batch=228\n",
      "13329: loss=0.071, reward_mean=0.550, reward_bound=0.392, batch=229\n",
      "13330: loss=0.074, reward_mean=0.400, reward_bound=0.430, batch=226\n",
      "13331: loss=0.073, reward_mean=0.500, reward_bound=0.430, batch=227\n",
      "13332: loss=0.074, reward_mean=0.390, reward_bound=0.314, batch=228\n",
      "13333: loss=0.073, reward_mean=0.480, reward_bound=0.387, batch=227\n",
      "13334: loss=0.074, reward_mean=0.570, reward_bound=0.469, batch=229\n",
      "13335: loss=0.075, reward_mean=0.470, reward_bound=0.450, batch=230\n",
      "13336: loss=0.075, reward_mean=0.500, reward_bound=0.430, batch=230\n",
      "13337: loss=0.075, reward_mean=0.480, reward_bound=0.430, batch=230\n",
      "13338: loss=0.075, reward_mean=0.470, reward_bound=0.376, batch=231\n",
      "13339: loss=0.075, reward_mean=0.360, reward_bound=0.314, batch=231\n",
      "13340: loss=0.075, reward_mean=0.460, reward_bound=0.387, batch=231\n",
      "13341: loss=0.075, reward_mean=0.520, reward_bound=0.430, batch=231\n",
      "13342: loss=0.075, reward_mean=0.470, reward_bound=0.430, batch=231\n",
      "13343: loss=0.071, reward_mean=0.390, reward_bound=0.478, batch=184\n",
      "13344: loss=0.069, reward_mean=0.470, reward_bound=0.133, batch=199\n",
      "13345: loss=0.069, reward_mean=0.410, reward_bound=0.150, batch=208\n",
      "13346: loss=0.069, reward_mean=0.370, reward_bound=0.254, batch=211\n",
      "13347: loss=0.071, reward_mean=0.450, reward_bound=0.282, batch=214\n",
      "13348: loss=0.069, reward_mean=0.410, reward_bound=0.314, batch=212\n",
      "13349: loss=0.070, reward_mean=0.440, reward_bound=0.254, batch=217\n",
      "13350: loss=0.070, reward_mean=0.360, reward_bound=0.198, batch=222\n",
      "13351: loss=0.067, reward_mean=0.520, reward_bound=0.282, batch=222\n",
      "13352: loss=0.067, reward_mean=0.500, reward_bound=0.314, batch=223\n",
      "13353: loss=0.067, reward_mean=0.480, reward_bound=0.349, batch=215\n",
      "13354: loss=0.066, reward_mean=0.420, reward_bound=0.240, batch=220\n",
      "13355: loss=0.068, reward_mean=0.440, reward_bound=0.376, batch=224\n",
      "13356: loss=0.069, reward_mean=0.430, reward_bound=0.387, batch=210\n",
      "13357: loss=0.068, reward_mean=0.390, reward_bound=0.274, batch=217\n",
      "13358: loss=0.066, reward_mean=0.400, reward_bound=0.282, batch=220\n",
      "13359: loss=0.067, reward_mean=0.390, reward_bound=0.314, batch=223\n",
      "13360: loss=0.067, reward_mean=0.390, reward_bound=0.244, batch=226\n",
      "13361: loss=0.069, reward_mean=0.450, reward_bound=0.387, batch=222\n",
      "13362: loss=0.069, reward_mean=0.390, reward_bound=0.360, batch=225\n",
      "13363: loss=0.069, reward_mean=0.470, reward_bound=0.430, batch=205\n",
      "13364: loss=0.067, reward_mean=0.430, reward_bound=0.234, batch=213\n",
      "13365: loss=0.067, reward_mean=0.490, reward_bound=0.282, batch=218\n",
      "13366: loss=0.067, reward_mean=0.400, reward_bound=0.237, batch=222\n",
      "13367: loss=0.068, reward_mean=0.490, reward_bound=0.314, batch=222\n",
      "13368: loss=0.069, reward_mean=0.400, reward_bound=0.324, batch=225\n",
      "13369: loss=0.067, reward_mean=0.500, reward_bound=0.349, batch=225\n",
      "13370: loss=0.067, reward_mean=0.460, reward_bound=0.387, batch=220\n",
      "13371: loss=0.067, reward_mean=0.490, reward_bound=0.282, batch=222\n",
      "13372: loss=0.068, reward_mean=0.410, reward_bound=0.349, batch=224\n",
      "13373: loss=0.067, reward_mean=0.390, reward_bound=0.384, batch=227\n",
      "13374: loss=0.067, reward_mean=0.440, reward_bound=0.387, batch=226\n",
      "13375: loss=0.068, reward_mean=0.430, reward_bound=0.268, batch=228\n",
      "13376: loss=0.066, reward_mean=0.440, reward_bound=0.286, batch=229\n",
      "13377: loss=0.066, reward_mean=0.430, reward_bound=0.405, batch=230\n",
      "13378: loss=0.066, reward_mean=0.460, reward_bound=0.418, batch=231\n",
      "13379: loss=0.069, reward_mean=0.390, reward_bound=0.430, batch=220\n",
      "13380: loss=0.072, reward_mean=0.510, reward_bound=0.304, batch=224\n",
      "13381: loss=0.068, reward_mean=0.420, reward_bound=0.314, batch=223\n",
      "13382: loss=0.069, reward_mean=0.370, reward_bound=0.322, batch=226\n",
      "13383: loss=0.067, reward_mean=0.410, reward_bound=0.349, batch=227\n",
      "13384: loss=0.068, reward_mean=0.480, reward_bound=0.387, batch=225\n",
      "13385: loss=0.067, reward_mean=0.420, reward_bound=0.356, batch=227\n",
      "13386: loss=0.067, reward_mean=0.420, reward_bound=0.380, batch=229\n",
      "13387: loss=0.067, reward_mean=0.410, reward_bound=0.387, batch=229\n",
      "13388: loss=0.068, reward_mean=0.490, reward_bound=0.430, batch=227\n",
      "13389: loss=0.068, reward_mean=0.450, reward_bound=0.349, batch=228\n",
      "13390: loss=0.067, reward_mean=0.370, reward_bound=0.435, batch=229\n",
      "13391: loss=0.067, reward_mean=0.430, reward_bound=0.450, batch=230\n",
      "13392: loss=0.068, reward_mean=0.470, reward_bound=0.478, batch=205\n",
      "13393: loss=0.067, reward_mean=0.460, reward_bound=0.185, batch=212\n",
      "13394: loss=0.069, reward_mean=0.480, reward_bound=0.324, batch=218\n",
      "13395: loss=0.069, reward_mean=0.420, reward_bound=0.257, batch=222\n",
      "13396: loss=0.072, reward_mean=0.390, reward_bound=0.292, batch=225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13397: loss=0.071, reward_mean=0.540, reward_bound=0.349, batch=222\n",
      "13398: loss=0.070, reward_mean=0.490, reward_bound=0.387, batch=220\n",
      "13399: loss=0.071, reward_mean=0.510, reward_bound=0.349, batch=223\n",
      "13400: loss=0.072, reward_mean=0.420, reward_bound=0.314, batch=225\n",
      "13401: loss=0.071, reward_mean=0.420, reward_bound=0.273, batch=227\n",
      "13402: loss=0.071, reward_mean=0.500, reward_bound=0.335, batch=229\n",
      "13403: loss=0.072, reward_mean=0.400, reward_bound=0.405, batch=230\n",
      "13404: loss=0.073, reward_mean=0.480, reward_bound=0.338, batch=231\n",
      "13405: loss=0.072, reward_mean=0.430, reward_bound=0.349, batch=230\n",
      "13406: loss=0.073, reward_mean=0.550, reward_bound=0.430, batch=219\n",
      "13407: loss=0.075, reward_mean=0.480, reward_bound=0.349, batch=222\n",
      "13408: loss=0.074, reward_mean=0.380, reward_bound=0.387, batch=224\n",
      "13409: loss=0.074, reward_mean=0.430, reward_bound=0.380, batch=227\n",
      "13410: loss=0.073, reward_mean=0.440, reward_bound=0.342, batch=229\n",
      "13411: loss=0.073, reward_mean=0.490, reward_bound=0.328, batch=230\n",
      "13412: loss=0.075, reward_mean=0.420, reward_bound=0.387, batch=228\n",
      "13413: loss=0.074, reward_mean=0.410, reward_bound=0.430, batch=225\n",
      "13414: loss=0.074, reward_mean=0.450, reward_bound=0.349, batch=226\n",
      "13415: loss=0.074, reward_mean=0.480, reward_bound=0.430, batch=227\n",
      "13416: loss=0.075, reward_mean=0.390, reward_bound=0.452, batch=229\n",
      "13417: loss=0.074, reward_mean=0.480, reward_bound=0.342, batch=230\n",
      "13418: loss=0.074, reward_mean=0.560, reward_bound=0.418, batch=231\n",
      "13419: loss=0.074, reward_mean=0.400, reward_bound=0.430, batch=230\n",
      "13420: loss=0.072, reward_mean=0.460, reward_bound=0.478, batch=213\n",
      "13421: loss=0.071, reward_mean=0.490, reward_bound=0.229, batch=217\n",
      "13422: loss=0.073, reward_mean=0.430, reward_bound=0.314, batch=221\n",
      "13423: loss=0.074, reward_mean=0.430, reward_bound=0.229, batch=223\n",
      "13424: loss=0.073, reward_mean=0.460, reward_bound=0.349, batch=224\n",
      "13425: loss=0.074, reward_mean=0.480, reward_bound=0.349, batch=226\n",
      "13426: loss=0.074, reward_mean=0.410, reward_bound=0.387, batch=223\n",
      "13427: loss=0.075, reward_mean=0.370, reward_bound=0.398, batch=226\n",
      "13428: loss=0.074, reward_mean=0.390, reward_bound=0.409, batch=228\n",
      "13429: loss=0.073, reward_mean=0.490, reward_bound=0.430, batch=221\n",
      "13430: loss=0.072, reward_mean=0.440, reward_bound=0.349, batch=223\n",
      "13431: loss=0.071, reward_mean=0.480, reward_bound=0.335, batch=226\n",
      "13432: loss=0.074, reward_mean=0.510, reward_bound=0.349, batch=226\n",
      "13433: loss=0.072, reward_mean=0.430, reward_bound=0.409, batch=228\n",
      "13434: loss=0.072, reward_mean=0.480, reward_bound=0.430, batch=225\n",
      "13435: loss=0.074, reward_mean=0.400, reward_bound=0.321, batch=227\n",
      "13436: loss=0.075, reward_mean=0.510, reward_bound=0.387, batch=228\n",
      "13437: loss=0.075, reward_mean=0.420, reward_bound=0.392, batch=229\n",
      "13438: loss=0.073, reward_mean=0.460, reward_bound=0.430, batch=227\n",
      "13439: loss=0.072, reward_mean=0.490, reward_bound=0.330, batch=229\n",
      "13440: loss=0.072, reward_mean=0.410, reward_bound=0.328, batch=230\n",
      "13441: loss=0.073, reward_mean=0.510, reward_bound=0.406, batch=231\n",
      "13442: loss=0.073, reward_mean=0.470, reward_bound=0.430, batch=230\n",
      "13443: loss=0.074, reward_mean=0.460, reward_bound=0.464, batch=231\n",
      "13444: loss=0.074, reward_mean=0.490, reward_bound=0.478, batch=222\n",
      "13445: loss=0.074, reward_mean=0.470, reward_bound=0.400, batch=225\n",
      "13446: loss=0.074, reward_mean=0.430, reward_bound=0.440, batch=227\n",
      "13447: loss=0.074, reward_mean=0.450, reward_bound=0.422, batch=229\n",
      "13448: loss=0.074, reward_mean=0.350, reward_bound=0.430, batch=229\n",
      "13449: loss=0.073, reward_mean=0.460, reward_bound=0.478, batch=231\n",
      "13450: loss=0.073, reward_mean=0.390, reward_bound=0.478, batch=225\n",
      "13451: loss=0.073, reward_mean=0.450, reward_bound=0.329, batch=227\n",
      "13452: loss=0.074, reward_mean=0.420, reward_bound=0.387, batch=227\n",
      "13453: loss=0.074, reward_mean=0.400, reward_bound=0.282, batch=228\n",
      "13454: loss=0.074, reward_mean=0.430, reward_bound=0.478, batch=230\n",
      "13455: loss=0.073, reward_mean=0.430, reward_bound=0.439, batch=231\n",
      "13456: loss=0.073, reward_mean=0.350, reward_bound=0.430, batch=231\n",
      "13457: loss=0.073, reward_mean=0.500, reward_bound=0.430, batch=231\n",
      "13458: loss=0.074, reward_mean=0.500, reward_bound=0.478, batch=228\n",
      "13459: loss=0.074, reward_mean=0.500, reward_bound=0.484, batch=229\n",
      "13460: loss=0.074, reward_mean=0.420, reward_bound=0.387, batch=229\n",
      "13461: loss=0.074, reward_mean=0.400, reward_bound=0.445, batch=230\n",
      "13462: loss=0.073, reward_mean=0.440, reward_bound=0.418, batch=231\n",
      "13463: loss=0.074, reward_mean=0.420, reward_bound=0.430, batch=230\n",
      "13464: loss=0.073, reward_mean=0.460, reward_bound=0.464, batch=231\n",
      "13466: loss=0.069, reward_mean=0.550, reward_bound=0.000, batch=55\n",
      "13467: loss=0.072, reward_mean=0.370, reward_bound=0.000, batch=92\n",
      "13468: loss=0.067, reward_mean=0.340, reward_bound=0.000, batch=126\n",
      "13469: loss=0.072, reward_mean=0.380, reward_bound=0.002, batch=158\n",
      "13470: loss=0.072, reward_mean=0.490, reward_bound=0.008, batch=180\n",
      "13471: loss=0.073, reward_mean=0.390, reward_bound=0.013, batch=194\n",
      "13472: loss=0.076, reward_mean=0.480, reward_bound=0.025, batch=206\n",
      "13473: loss=0.078, reward_mean=0.580, reward_bound=0.050, batch=214\n",
      "13474: loss=0.075, reward_mean=0.430, reward_bound=0.065, batch=214\n",
      "13475: loss=0.078, reward_mean=0.500, reward_bound=0.080, batch=217\n",
      "13476: loss=0.080, reward_mean=0.550, reward_bound=0.098, batch=207\n",
      "13477: loss=0.081, reward_mean=0.470, reward_bound=0.122, batch=200\n",
      "13478: loss=0.084, reward_mean=0.460, reward_bound=0.135, batch=194\n",
      "13479: loss=0.086, reward_mean=0.400, reward_bound=0.150, batch=186\n",
      "13480: loss=0.088, reward_mean=0.460, reward_bound=0.128, batch=200\n",
      "13481: loss=0.087, reward_mean=0.480, reward_bound=0.162, batch=210\n",
      "13482: loss=0.081, reward_mean=0.390, reward_bound=0.167, batch=199\n",
      "13483: loss=0.080, reward_mean=0.520, reward_bound=0.185, batch=188\n",
      "13484: loss=0.080, reward_mean=0.490, reward_bound=0.169, batch=201\n",
      "13485: loss=0.079, reward_mean=0.470, reward_bound=0.167, batch=210\n",
      "13486: loss=0.078, reward_mean=0.470, reward_bound=0.180, batch=217\n",
      "13487: loss=0.075, reward_mean=0.460, reward_bound=0.206, batch=197\n",
      "13488: loss=0.075, reward_mean=0.310, reward_bound=0.229, batch=179\n",
      "13489: loss=0.075, reward_mean=0.500, reward_bound=0.148, batch=195\n",
      "13490: loss=0.076, reward_mean=0.370, reward_bound=0.101, batch=206\n",
      "13491: loss=0.076, reward_mean=0.470, reward_bound=0.185, batch=213\n",
      "13492: loss=0.071, reward_mean=0.420, reward_bound=0.206, batch=217\n",
      "13493: loss=0.071, reward_mean=0.470, reward_bound=0.249, batch=222\n",
      "13494: loss=0.072, reward_mean=0.420, reward_bound=0.254, batch=203\n",
      "13495: loss=0.073, reward_mean=0.440, reward_bound=0.185, batch=211\n",
      "13496: loss=0.072, reward_mean=0.420, reward_bound=0.254, batch=215\n",
      "13497: loss=0.083, reward_mean=0.430, reward_bound=0.282, batch=178\n",
      "13498: loss=0.077, reward_mean=0.340, reward_bound=0.111, batch=194\n",
      "13499: loss=0.075, reward_mean=0.430, reward_bound=0.134, batch=206\n",
      "13500: loss=0.079, reward_mean=0.430, reward_bound=0.176, batch=214\n",
      "13501: loss=0.077, reward_mean=0.400, reward_bound=0.206, batch=214\n",
      "13502: loss=0.079, reward_mean=0.390, reward_bound=0.229, batch=214\n",
      "13503: loss=0.080, reward_mean=0.420, reward_bound=0.134, batch=220\n",
      "13504: loss=0.079, reward_mean=0.400, reward_bound=0.222, batch=224\n",
      "13505: loss=0.078, reward_mean=0.410, reward_bound=0.254, batch=220\n",
      "13506: loss=0.078, reward_mean=0.320, reward_bound=0.247, batch=224\n",
      "13507: loss=0.080, reward_mean=0.380, reward_bound=0.282, batch=214\n",
      "13508: loss=0.080, reward_mean=0.460, reward_bound=0.314, batch=166\n",
      "13509: loss=0.075, reward_mean=0.370, reward_bound=0.028, batch=185\n",
      "13510: loss=0.077, reward_mean=0.420, reward_bound=0.077, batch=199\n",
      "13511: loss=0.076, reward_mean=0.460, reward_bound=0.135, batch=207\n",
      "13512: loss=0.080, reward_mean=0.500, reward_bound=0.150, batch=210\n",
      "13513: loss=0.082, reward_mean=0.460, reward_bound=0.180, batch=217\n",
      "13514: loss=0.082, reward_mean=0.450, reward_bound=0.206, batch=216\n",
      "13515: loss=0.084, reward_mean=0.510, reward_bound=0.229, batch=219\n",
      "13516: loss=0.085, reward_mean=0.440, reward_bound=0.229, batch=222\n",
      "13517: loss=0.084, reward_mean=0.360, reward_bound=0.254, batch=220\n",
      "13518: loss=0.080, reward_mean=0.500, reward_bound=0.282, batch=214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13519: loss=0.080, reward_mean=0.420, reward_bound=0.282, batch=216\n",
      "13520: loss=0.079, reward_mean=0.350, reward_bound=0.282, batch=219\n",
      "13521: loss=0.078, reward_mean=0.430, reward_bound=0.278, batch=223\n",
      "13522: loss=0.079, reward_mean=0.450, reward_bound=0.314, batch=208\n",
      "13523: loss=0.078, reward_mean=0.500, reward_bound=0.282, batch=213\n",
      "13524: loss=0.079, reward_mean=0.450, reward_bound=0.301, batch=219\n",
      "13525: loss=0.080, reward_mean=0.430, reward_bound=0.314, batch=220\n",
      "13526: loss=0.080, reward_mean=0.420, reward_bound=0.296, batch=224\n",
      "13527: loss=0.080, reward_mean=0.440, reward_bound=0.345, batch=227\n",
      "13528: loss=0.079, reward_mean=0.400, reward_bound=0.314, batch=228\n",
      "13529: loss=0.079, reward_mean=0.450, reward_bound=0.289, batch=229\n",
      "13530: loss=0.093, reward_mean=0.420, reward_bound=0.349, batch=160\n",
      "13531: loss=0.087, reward_mean=0.450, reward_bound=0.131, batch=182\n",
      "13532: loss=0.087, reward_mean=0.500, reward_bound=0.072, batch=196\n",
      "13533: loss=0.089, reward_mean=0.420, reward_bound=0.158, batch=207\n",
      "13534: loss=0.091, reward_mean=0.410, reward_bound=0.167, batch=213\n",
      "13535: loss=0.091, reward_mean=0.360, reward_bound=0.206, batch=215\n",
      "13536: loss=0.092, reward_mean=0.360, reward_bound=0.229, batch=216\n",
      "13537: loss=0.091, reward_mean=0.470, reward_bound=0.254, batch=214\n",
      "13538: loss=0.091, reward_mean=0.440, reward_bound=0.280, batch=220\n",
      "13539: loss=0.092, reward_mean=0.470, reward_bound=0.282, batch=208\n",
      "13540: loss=0.093, reward_mean=0.410, reward_bound=0.206, batch=214\n",
      "13541: loss=0.094, reward_mean=0.410, reward_bound=0.229, batch=219\n",
      "13542: loss=0.093, reward_mean=0.440, reward_bound=0.314, batch=209\n",
      "13543: loss=0.094, reward_mean=0.450, reward_bound=0.206, batch=215\n",
      "13544: loss=0.093, reward_mean=0.410, reward_bound=0.234, batch=220\n",
      "13545: loss=0.095, reward_mean=0.380, reward_bound=0.338, batch=224\n",
      "13546: loss=0.094, reward_mean=0.360, reward_bound=0.349, batch=202\n",
      "13547: loss=0.094, reward_mean=0.420, reward_bound=0.213, batch=211\n",
      "13548: loss=0.096, reward_mean=0.410, reward_bound=0.229, batch=216\n",
      "13549: loss=0.095, reward_mean=0.380, reward_bound=0.282, batch=218\n",
      "13550: loss=0.094, reward_mean=0.520, reward_bound=0.314, batch=221\n",
      "13551: loss=0.093, reward_mean=0.370, reward_bound=0.349, batch=218\n",
      "13552: loss=0.092, reward_mean=0.480, reward_bound=0.229, batch=220\n",
      "13553: loss=0.093, reward_mean=0.460, reward_bound=0.314, batch=222\n",
      "13554: loss=0.085, reward_mean=0.460, reward_bound=0.387, batch=143\n",
      "13555: loss=0.089, reward_mean=0.480, reward_bound=0.058, batch=169\n",
      "13556: loss=0.089, reward_mean=0.430, reward_bound=0.072, batch=185\n",
      "13557: loss=0.087, reward_mean=0.410, reward_bound=0.089, batch=202\n",
      "13558: loss=0.093, reward_mean=0.450, reward_bound=0.098, batch=210\n",
      "13559: loss=0.091, reward_mean=0.330, reward_bound=0.122, batch=213\n",
      "13560: loss=0.087, reward_mean=0.410, reward_bound=0.167, batch=212\n",
      "13561: loss=0.083, reward_mean=0.480, reward_bound=0.206, batch=223\n",
      "13562: loss=0.087, reward_mean=0.440, reward_bound=0.206, batch=221\n",
      "13563: loss=0.084, reward_mean=0.480, reward_bound=0.229, batch=211\n",
      "13564: loss=0.085, reward_mean=0.480, reward_bound=0.206, batch=217\n",
      "13565: loss=0.085, reward_mean=0.420, reward_bound=0.249, batch=222\n",
      "13566: loss=0.090, reward_mean=0.450, reward_bound=0.254, batch=210\n",
      "13567: loss=0.089, reward_mean=0.380, reward_bound=0.254, batch=216\n",
      "13568: loss=0.088, reward_mean=0.340, reward_bound=0.254, batch=219\n",
      "13569: loss=0.085, reward_mean=0.490, reward_bound=0.282, batch=214\n",
      "13570: loss=0.086, reward_mean=0.430, reward_bound=0.280, batch=220\n",
      "13571: loss=0.088, reward_mean=0.480, reward_bound=0.314, batch=209\n",
      "13572: loss=0.091, reward_mean=0.490, reward_bound=0.349, batch=185\n",
      "13573: loss=0.093, reward_mean=0.310, reward_bound=0.084, batch=199\n",
      "13574: loss=0.094, reward_mean=0.460, reward_bound=0.140, batch=209\n",
      "13575: loss=0.091, reward_mean=0.450, reward_bound=0.206, batch=213\n",
      "13576: loss=0.093, reward_mean=0.470, reward_bound=0.244, batch=219\n",
      "13577: loss=0.091, reward_mean=0.460, reward_bound=0.254, batch=218\n",
      "13578: loss=0.091, reward_mean=0.420, reward_bound=0.282, batch=214\n",
      "13579: loss=0.092, reward_mean=0.480, reward_bound=0.282, batch=219\n",
      "13580: loss=0.091, reward_mean=0.390, reward_bound=0.239, batch=223\n",
      "13581: loss=0.090, reward_mean=0.500, reward_bound=0.244, batch=226\n",
      "13582: loss=0.090, reward_mean=0.440, reward_bound=0.314, batch=222\n",
      "13583: loss=0.091, reward_mean=0.400, reward_bound=0.324, batch=225\n",
      "13584: loss=0.090, reward_mean=0.510, reward_bound=0.349, batch=221\n",
      "13585: loss=0.091, reward_mean=0.410, reward_bound=0.387, batch=190\n",
      "13586: loss=0.091, reward_mean=0.450, reward_bound=0.167, batch=200\n",
      "13587: loss=0.090, reward_mean=0.450, reward_bound=0.175, batch=210\n",
      "13588: loss=0.088, reward_mean=0.450, reward_bound=0.185, batch=216\n",
      "13589: loss=0.087, reward_mean=0.420, reward_bound=0.229, batch=217\n",
      "13590: loss=0.085, reward_mean=0.400, reward_bound=0.254, batch=221\n",
      "13591: loss=0.085, reward_mean=0.480, reward_bound=0.282, batch=224\n",
      "13592: loss=0.087, reward_mean=0.390, reward_bound=0.314, batch=224\n",
      "13593: loss=0.089, reward_mean=0.430, reward_bound=0.349, batch=216\n",
      "13594: loss=0.089, reward_mean=0.450, reward_bound=0.298, batch=221\n",
      "13595: loss=0.089, reward_mean=0.450, reward_bound=0.349, batch=223\n",
      "13596: loss=0.089, reward_mean=0.460, reward_bound=0.372, batch=226\n",
      "13597: loss=0.089, reward_mean=0.400, reward_bound=0.349, batch=227\n",
      "13598: loss=0.091, reward_mean=0.510, reward_bound=0.387, batch=221\n",
      "13599: loss=0.091, reward_mean=0.500, reward_bound=0.387, batch=224\n",
      "13600: loss=0.092, reward_mean=0.410, reward_bound=0.345, batch=227\n",
      "13601: loss=0.091, reward_mean=0.520, reward_bound=0.422, batch=229\n",
      "13602: loss=0.096, reward_mean=0.400, reward_bound=0.430, batch=124\n",
      "13603: loss=0.088, reward_mean=0.500, reward_bound=0.038, batch=156\n",
      "13604: loss=0.098, reward_mean=0.500, reward_bound=0.050, batch=179\n",
      "13605: loss=0.091, reward_mean=0.440, reward_bound=0.067, batch=195\n",
      "13606: loss=0.090, reward_mean=0.460, reward_bound=0.098, batch=201\n",
      "13607: loss=0.092, reward_mean=0.450, reward_bound=0.135, batch=204\n",
      "13608: loss=0.093, reward_mean=0.450, reward_bound=0.150, batch=211\n",
      "13609: loss=0.091, reward_mean=0.420, reward_bound=0.167, batch=215\n",
      "13610: loss=0.094, reward_mean=0.490, reward_bound=0.206, batch=215\n",
      "13611: loss=0.095, reward_mean=0.410, reward_bound=0.229, batch=212\n",
      "13612: loss=0.094, reward_mean=0.420, reward_bound=0.236, batch=218\n",
      "13613: loss=0.096, reward_mean=0.460, reward_bound=0.254, batch=201\n",
      "13614: loss=0.095, reward_mean=0.300, reward_bound=0.150, batch=210\n",
      "13615: loss=0.096, reward_mean=0.450, reward_bound=0.274, batch=217\n",
      "13616: loss=0.096, reward_mean=0.410, reward_bound=0.282, batch=203\n",
      "13617: loss=0.099, reward_mean=0.520, reward_bound=0.282, batch=211\n",
      "13618: loss=0.103, reward_mean=0.490, reward_bound=0.314, batch=188\n",
      "13619: loss=0.107, reward_mean=0.450, reward_bound=0.185, batch=200\n",
      "13620: loss=0.104, reward_mean=0.400, reward_bound=0.150, batch=209\n",
      "13621: loss=0.105, reward_mean=0.430, reward_bound=0.185, batch=213\n",
      "13622: loss=0.106, reward_mean=0.420, reward_bound=0.229, batch=216\n",
      "13623: loss=0.106, reward_mean=0.400, reward_bound=0.230, batch=221\n",
      "13624: loss=0.105, reward_mean=0.530, reward_bound=0.254, batch=222\n",
      "13625: loss=0.104, reward_mean=0.430, reward_bound=0.282, batch=221\n",
      "13626: loss=0.102, reward_mean=0.410, reward_bound=0.314, batch=218\n",
      "13627: loss=0.102, reward_mean=0.480, reward_bound=0.260, batch=222\n",
      "13628: loss=0.102, reward_mean=0.450, reward_bound=0.314, batch=224\n",
      "13629: loss=0.103, reward_mean=0.370, reward_bound=0.282, batch=226\n",
      "13630: loss=0.105, reward_mean=0.530, reward_bound=0.349, batch=195\n",
      "13631: loss=0.109, reward_mean=0.510, reward_bound=0.170, batch=206\n",
      "13632: loss=0.106, reward_mean=0.460, reward_bound=0.254, batch=212\n",
      "13633: loss=0.106, reward_mean=0.430, reward_bound=0.254, batch=216\n",
      "13634: loss=0.107, reward_mean=0.420, reward_bound=0.268, batch=221\n",
      "13635: loss=0.106, reward_mean=0.480, reward_bound=0.282, batch=224\n",
      "13636: loss=0.106, reward_mean=0.520, reward_bound=0.314, batch=223\n",
      "13637: loss=0.105, reward_mean=0.430, reward_bound=0.349, batch=223\n",
      "13638: loss=0.097, reward_mean=0.480, reward_bound=0.387, batch=193\n",
      "13639: loss=0.099, reward_mean=0.470, reward_bound=0.254, batch=202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13640: loss=0.096, reward_mean=0.410, reward_bound=0.254, batch=210\n",
      "13641: loss=0.096, reward_mean=0.410, reward_bound=0.282, batch=212\n",
      "13642: loss=0.098, reward_mean=0.370, reward_bound=0.206, batch=220\n",
      "13643: loss=0.095, reward_mean=0.460, reward_bound=0.222, batch=224\n",
      "13644: loss=0.093, reward_mean=0.510, reward_bound=0.314, batch=220\n",
      "13645: loss=0.093, reward_mean=0.420, reward_bound=0.254, batch=223\n",
      "13646: loss=0.094, reward_mean=0.540, reward_bound=0.349, batch=217\n",
      "13647: loss=0.096, reward_mean=0.450, reward_bound=0.254, batch=221\n",
      "13648: loss=0.095, reward_mean=0.430, reward_bound=0.314, batch=224\n",
      "13649: loss=0.097, reward_mean=0.390, reward_bound=0.349, batch=226\n",
      "13650: loss=0.096, reward_mean=0.400, reward_bound=0.368, batch=228\n",
      "13651: loss=0.098, reward_mean=0.380, reward_bound=0.387, batch=217\n",
      "13652: loss=0.097, reward_mean=0.400, reward_bound=0.314, batch=221\n",
      "13653: loss=0.097, reward_mean=0.440, reward_bound=0.387, batch=223\n",
      "13654: loss=0.096, reward_mean=0.440, reward_bound=0.372, batch=226\n",
      "13655: loss=0.096, reward_mean=0.410, reward_bound=0.368, batch=228\n",
      "13656: loss=0.096, reward_mean=0.440, reward_bound=0.387, batch=227\n",
      "13657: loss=0.096, reward_mean=0.380, reward_bound=0.387, batch=228\n",
      "13658: loss=0.090, reward_mean=0.410, reward_bound=0.430, batch=178\n",
      "13659: loss=0.091, reward_mean=0.460, reward_bound=0.137, batch=194\n",
      "13660: loss=0.086, reward_mean=0.420, reward_bound=0.120, batch=206\n",
      "13661: loss=0.086, reward_mean=0.340, reward_bound=0.167, batch=210\n",
      "13662: loss=0.092, reward_mean=0.400, reward_bound=0.200, batch=217\n",
      "13663: loss=0.092, reward_mean=0.440, reward_bound=0.254, batch=217\n",
      "13664: loss=0.088, reward_mean=0.480, reward_bound=0.282, batch=216\n",
      "13665: loss=0.087, reward_mean=0.460, reward_bound=0.298, batch=221\n",
      "13666: loss=0.091, reward_mean=0.490, reward_bound=0.314, batch=217\n",
      "13667: loss=0.089, reward_mean=0.480, reward_bound=0.277, batch=222\n",
      "13668: loss=0.090, reward_mean=0.460, reward_bound=0.324, batch=225\n",
      "13669: loss=0.088, reward_mean=0.400, reward_bound=0.349, batch=214\n",
      "13670: loss=0.089, reward_mean=0.500, reward_bound=0.282, batch=218\n",
      "13671: loss=0.088, reward_mean=0.430, reward_bound=0.254, batch=221\n",
      "13672: loss=0.089, reward_mean=0.450, reward_bound=0.282, batch=224\n",
      "13673: loss=0.089, reward_mean=0.430, reward_bound=0.314, batch=224\n",
      "13674: loss=0.089, reward_mean=0.430, reward_bound=0.305, batch=227\n",
      "13675: loss=0.088, reward_mean=0.500, reward_bound=0.349, batch=228\n",
      "13676: loss=0.093, reward_mean=0.440, reward_bound=0.387, batch=211\n",
      "13677: loss=0.092, reward_mean=0.370, reward_bound=0.206, batch=217\n",
      "13678: loss=0.097, reward_mean=0.530, reward_bound=0.254, batch=220\n",
      "13679: loss=0.093, reward_mean=0.430, reward_bound=0.282, batch=222\n",
      "13680: loss=0.093, reward_mean=0.420, reward_bound=0.292, batch=225\n",
      "13681: loss=0.093, reward_mean=0.440, reward_bound=0.289, batch=227\n",
      "13682: loss=0.090, reward_mean=0.510, reward_bound=0.349, batch=227\n",
      "13683: loss=0.090, reward_mean=0.400, reward_bound=0.308, batch=229\n",
      "13684: loss=0.090, reward_mean=0.450, reward_bound=0.314, batch=228\n",
      "13685: loss=0.090, reward_mean=0.460, reward_bound=0.387, batch=226\n",
      "13686: loss=0.091, reward_mean=0.490, reward_bound=0.409, batch=228\n",
      "13687: loss=0.093, reward_mean=0.510, reward_bound=0.430, batch=204\n",
      "13688: loss=0.091, reward_mean=0.420, reward_bound=0.206, batch=212\n",
      "13689: loss=0.094, reward_mean=0.520, reward_bound=0.245, batch=218\n",
      "13690: loss=0.092, reward_mean=0.410, reward_bound=0.282, batch=220\n",
      "13691: loss=0.091, reward_mean=0.360, reward_bound=0.282, batch=223\n",
      "13692: loss=0.091, reward_mean=0.410, reward_bound=0.335, batch=226\n",
      "13693: loss=0.091, reward_mean=0.460, reward_bound=0.349, batch=225\n",
      "13694: loss=0.093, reward_mean=0.390, reward_bound=0.387, batch=222\n",
      "13695: loss=0.092, reward_mean=0.370, reward_bound=0.229, batch=225\n",
      "13696: loss=0.091, reward_mean=0.460, reward_bound=0.356, batch=227\n",
      "13697: loss=0.091, reward_mean=0.370, reward_bound=0.387, batch=228\n",
      "13698: loss=0.092, reward_mean=0.450, reward_bound=0.430, batch=218\n",
      "13699: loss=0.092, reward_mean=0.420, reward_bound=0.387, batch=221\n",
      "13700: loss=0.092, reward_mean=0.470, reward_bound=0.430, batch=221\n",
      "13701: loss=0.093, reward_mean=0.410, reward_bound=0.349, batch=223\n",
      "13702: loss=0.093, reward_mean=0.490, reward_bound=0.358, batch=226\n",
      "13703: loss=0.094, reward_mean=0.350, reward_bound=0.409, batch=228\n",
      "13704: loss=0.093, reward_mean=0.430, reward_bound=0.430, batch=228\n",
      "13705: loss=0.093, reward_mean=0.420, reward_bound=0.478, batch=230\n",
      "13706: loss=0.092, reward_mean=0.470, reward_bound=0.464, batch=231\n",
      "13707: loss=0.092, reward_mean=0.400, reward_bound=0.430, batch=231\n",
      "13708: loss=0.092, reward_mean=0.380, reward_bound=0.430, batch=231\n",
      "13709: loss=0.091, reward_mean=0.530, reward_bound=0.478, batch=97\n",
      "13710: loss=0.086, reward_mean=0.490, reward_bound=0.018, batch=138\n",
      "13711: loss=0.083, reward_mean=0.420, reward_bound=0.025, batch=165\n",
      "13712: loss=0.084, reward_mean=0.390, reward_bound=0.031, batch=184\n",
      "13713: loss=0.092, reward_mean=0.400, reward_bound=0.052, batch=199\n",
      "13714: loss=0.093, reward_mean=0.440, reward_bound=0.072, batch=202\n",
      "13715: loss=0.097, reward_mean=0.540, reward_bound=0.098, batch=209\n",
      "13716: loss=0.098, reward_mean=0.420, reward_bound=0.109, batch=214\n",
      "13717: loss=0.097, reward_mean=0.410, reward_bound=0.122, batch=213\n",
      "13718: loss=0.100, reward_mean=0.440, reward_bound=0.135, batch=217\n",
      "13719: loss=0.101, reward_mean=0.460, reward_bound=0.150, batch=220\n",
      "13720: loss=0.103, reward_mean=0.460, reward_bound=0.167, batch=212\n",
      "13721: loss=0.098, reward_mean=0.330, reward_bound=0.185, batch=208\n",
      "13722: loss=0.098, reward_mean=0.410, reward_bound=0.187, batch=215\n",
      "13723: loss=0.104, reward_mean=0.400, reward_bound=0.206, batch=203\n",
      "13724: loss=0.104, reward_mean=0.410, reward_bound=0.190, batch=212\n",
      "13725: loss=0.104, reward_mean=0.420, reward_bound=0.206, batch=222\n",
      "13726: loss=0.106, reward_mean=0.420, reward_bound=0.229, batch=213\n",
      "13727: loss=0.102, reward_mean=0.520, reward_bound=0.254, batch=205\n",
      "13728: loss=0.099, reward_mean=0.380, reward_bound=0.229, batch=211\n",
      "13729: loss=0.101, reward_mean=0.490, reward_bound=0.229, batch=217\n",
      "13730: loss=0.100, reward_mean=0.390, reward_bound=0.254, batch=219\n",
      "13731: loss=0.097, reward_mean=0.480, reward_bound=0.282, batch=207\n",
      "13732: loss=0.096, reward_mean=0.400, reward_bound=0.185, batch=213\n",
      "13733: loss=0.097, reward_mean=0.460, reward_bound=0.244, batch=219\n",
      "13734: loss=0.096, reward_mean=0.420, reward_bound=0.282, batch=222\n",
      "13735: loss=0.100, reward_mean=0.490, reward_bound=0.314, batch=194\n",
      "13736: loss=0.099, reward_mean=0.460, reward_bound=0.229, batch=205\n",
      "13737: loss=0.098, reward_mean=0.450, reward_bound=0.189, batch=213\n",
      "13738: loss=0.101, reward_mean=0.440, reward_bound=0.229, batch=218\n",
      "13739: loss=0.098, reward_mean=0.460, reward_bound=0.254, batch=220\n",
      "13740: loss=0.099, reward_mean=0.450, reward_bound=0.282, batch=220\n",
      "13741: loss=0.100, reward_mean=0.450, reward_bound=0.314, batch=218\n",
      "13742: loss=0.100, reward_mean=0.500, reward_bound=0.349, batch=189\n",
      "13743: loss=0.098, reward_mean=0.510, reward_bound=0.203, batch=202\n",
      "13744: loss=0.096, reward_mean=0.430, reward_bound=0.213, batch=211\n",
      "13745: loss=0.100, reward_mean=0.450, reward_bound=0.206, batch=217\n",
      "13746: loss=0.099, reward_mean=0.380, reward_bound=0.249, batch=222\n",
      "13747: loss=0.098, reward_mean=0.500, reward_bound=0.282, batch=215\n",
      "13748: loss=0.096, reward_mean=0.520, reward_bound=0.314, batch=216\n",
      "13749: loss=0.097, reward_mean=0.320, reward_bound=0.268, batch=221\n",
      "13750: loss=0.096, reward_mean=0.470, reward_bound=0.314, batch=224\n",
      "13751: loss=0.098, reward_mean=0.490, reward_bound=0.308, batch=227\n",
      "13752: loss=0.096, reward_mean=0.420, reward_bound=0.342, batch=229\n",
      "13753: loss=0.098, reward_mean=0.480, reward_bound=0.349, batch=220\n",
      "13754: loss=0.099, reward_mean=0.460, reward_bound=0.320, batch=224\n",
      "13755: loss=0.097, reward_mean=0.420, reward_bound=0.311, batch=227\n",
      "13756: loss=0.098, reward_mean=0.440, reward_bound=0.349, batch=224\n",
      "13757: loss=0.098, reward_mean=0.460, reward_bound=0.349, batch=226\n",
      "13758: loss=0.094, reward_mean=0.480, reward_bound=0.387, batch=188\n",
      "13759: loss=0.090, reward_mean=0.430, reward_bound=0.185, batch=199\n",
      "13760: loss=0.093, reward_mean=0.460, reward_bound=0.265, batch=209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13761: loss=0.095, reward_mean=0.450, reward_bound=0.282, batch=210\n",
      "13762: loss=0.095, reward_mean=0.450, reward_bound=0.282, batch=215\n",
      "13763: loss=0.094, reward_mean=0.480, reward_bound=0.314, batch=213\n",
      "13764: loss=0.095, reward_mean=0.440, reward_bound=0.335, batch=219\n",
      "13765: loss=0.095, reward_mean=0.430, reward_bound=0.314, batch=222\n",
      "13766: loss=0.095, reward_mean=0.380, reward_bound=0.349, batch=210\n",
      "13767: loss=0.095, reward_mean=0.460, reward_bound=0.247, batch=217\n",
      "13768: loss=0.093, reward_mean=0.420, reward_bound=0.282, batch=219\n",
      "13769: loss=0.094, reward_mean=0.410, reward_bound=0.349, batch=220\n",
      "13770: loss=0.094, reward_mean=0.460, reward_bound=0.314, batch=223\n",
      "13771: loss=0.093, reward_mean=0.470, reward_bound=0.349, batch=224\n",
      "13772: loss=0.093, reward_mean=0.440, reward_bound=0.384, batch=227\n",
      "13773: loss=0.094, reward_mean=0.520, reward_bound=0.380, batch=229\n",
      "13774: loss=0.094, reward_mean=0.500, reward_bound=0.387, batch=219\n",
      "13775: loss=0.094, reward_mean=0.470, reward_bound=0.364, batch=223\n",
      "13776: loss=0.095, reward_mean=0.370, reward_bound=0.372, batch=226\n",
      "13777: loss=0.093, reward_mean=0.390, reward_bound=0.430, batch=171\n",
      "13778: loss=0.089, reward_mean=0.450, reward_bound=0.167, batch=185\n",
      "13779: loss=0.091, reward_mean=0.430, reward_bound=0.153, batch=199\n",
      "13780: loss=0.090, reward_mean=0.510, reward_bound=0.167, batch=208\n",
      "13781: loss=0.090, reward_mean=0.430, reward_bound=0.185, batch=209\n",
      "13782: loss=0.090, reward_mean=0.450, reward_bound=0.229, batch=213\n",
      "13783: loss=0.089, reward_mean=0.400, reward_bound=0.244, batch=219\n",
      "13784: loss=0.092, reward_mean=0.400, reward_bound=0.254, batch=214\n",
      "13785: loss=0.090, reward_mean=0.430, reward_bound=0.150, batch=219\n",
      "13786: loss=0.091, reward_mean=0.460, reward_bound=0.239, batch=223\n",
      "13787: loss=0.092, reward_mean=0.480, reward_bound=0.271, batch=226\n",
      "13788: loss=0.091, reward_mean=0.450, reward_bound=0.282, batch=221\n",
      "13789: loss=0.092, reward_mean=0.500, reward_bound=0.314, batch=216\n",
      "13790: loss=0.094, reward_mean=0.470, reward_bound=0.349, batch=208\n",
      "13791: loss=0.094, reward_mean=0.460, reward_bound=0.387, batch=199\n",
      "13792: loss=0.098, reward_mean=0.430, reward_bound=0.157, batch=209\n",
      "13793: loss=0.099, reward_mean=0.330, reward_bound=0.167, batch=215\n",
      "13794: loss=0.097, reward_mean=0.470, reward_bound=0.229, batch=218\n",
      "13795: loss=0.097, reward_mean=0.480, reward_bound=0.282, batch=217\n",
      "13796: loss=0.097, reward_mean=0.440, reward_bound=0.314, batch=216\n",
      "13797: loss=0.098, reward_mean=0.480, reward_bound=0.298, batch=221\n",
      "13798: loss=0.095, reward_mean=0.440, reward_bound=0.349, batch=218\n",
      "13799: loss=0.096, reward_mean=0.360, reward_bound=0.289, batch=222\n",
      "13800: loss=0.096, reward_mean=0.470, reward_bound=0.324, batch=225\n",
      "13801: loss=0.097, reward_mean=0.550, reward_bound=0.349, batch=225\n",
      "13802: loss=0.094, reward_mean=0.440, reward_bound=0.387, batch=214\n",
      "13803: loss=0.094, reward_mean=0.450, reward_bound=0.314, batch=219\n",
      "13804: loss=0.094, reward_mean=0.340, reward_bound=0.309, batch=223\n",
      "13805: loss=0.095, reward_mean=0.420, reward_bound=0.372, batch=226\n",
      "13806: loss=0.095, reward_mean=0.480, reward_bound=0.387, batch=226\n",
      "13807: loss=0.095, reward_mean=0.430, reward_bound=0.409, batch=228\n",
      "13808: loss=0.095, reward_mean=0.470, reward_bound=0.357, batch=229\n",
      "13809: loss=0.094, reward_mean=0.420, reward_bound=0.405, batch=230\n",
      "13810: loss=0.094, reward_mean=0.440, reward_bound=0.406, batch=231\n",
      "13811: loss=0.093, reward_mean=0.450, reward_bound=0.430, batch=206\n",
      "13812: loss=0.092, reward_mean=0.480, reward_bound=0.331, batch=214\n",
      "13813: loss=0.092, reward_mean=0.550, reward_bound=0.311, batch=220\n",
      "13814: loss=0.092, reward_mean=0.460, reward_bound=0.304, batch=224\n",
      "13815: loss=0.093, reward_mean=0.350, reward_bound=0.314, batch=226\n",
      "13816: loss=0.094, reward_mean=0.430, reward_bound=0.349, batch=220\n",
      "13817: loss=0.094, reward_mean=0.480, reward_bound=0.282, batch=223\n",
      "13818: loss=0.095, reward_mean=0.500, reward_bound=0.349, batch=224\n",
      "13819: loss=0.096, reward_mean=0.330, reward_bound=0.305, batch=227\n",
      "13820: loss=0.095, reward_mean=0.470, reward_bound=0.314, batch=227\n",
      "13821: loss=0.094, reward_mean=0.380, reward_bound=0.349, batch=228\n",
      "13822: loss=0.094, reward_mean=0.480, reward_bound=0.321, batch=229\n",
      "13823: loss=0.094, reward_mean=0.460, reward_bound=0.387, batch=219\n",
      "13824: loss=0.093, reward_mean=0.460, reward_bound=0.314, batch=221\n",
      "13825: loss=0.095, reward_mean=0.360, reward_bound=0.349, batch=223\n",
      "13826: loss=0.095, reward_mean=0.420, reward_bound=0.349, batch=224\n",
      "13827: loss=0.092, reward_mean=0.400, reward_bound=0.387, batch=225\n",
      "13828: loss=0.093, reward_mean=0.390, reward_bound=0.321, batch=227\n",
      "13829: loss=0.093, reward_mean=0.450, reward_bound=0.430, batch=218\n",
      "13830: loss=0.094, reward_mean=0.500, reward_bound=0.257, batch=222\n",
      "13831: loss=0.095, reward_mean=0.310, reward_bound=0.282, batch=224\n",
      "13832: loss=0.094, reward_mean=0.380, reward_bound=0.349, batch=225\n",
      "13833: loss=0.095, reward_mean=0.420, reward_bound=0.329, batch=227\n",
      "13834: loss=0.094, reward_mean=0.570, reward_bound=0.422, batch=229\n",
      "13835: loss=0.093, reward_mean=0.440, reward_bound=0.430, batch=223\n",
      "13836: loss=0.092, reward_mean=0.380, reward_bound=0.413, batch=226\n",
      "13837: loss=0.092, reward_mean=0.480, reward_bound=0.349, batch=227\n",
      "13838: loss=0.092, reward_mean=0.520, reward_bound=0.373, batch=229\n",
      "13839: loss=0.092, reward_mean=0.410, reward_bound=0.364, batch=230\n",
      "13840: loss=0.092, reward_mean=0.430, reward_bound=0.387, batch=229\n",
      "13841: loss=0.093, reward_mean=0.520, reward_bound=0.405, batch=230\n",
      "13842: loss=0.093, reward_mean=0.440, reward_bound=0.430, batch=227\n",
      "13843: loss=0.094, reward_mean=0.490, reward_bound=0.387, batch=228\n",
      "13844: loss=0.094, reward_mean=0.340, reward_bound=0.435, batch=229\n",
      "13845: loss=0.093, reward_mean=0.440, reward_bound=0.450, batch=230\n",
      "13846: loss=0.093, reward_mean=0.380, reward_bound=0.464, batch=231\n",
      "13847: loss=0.088, reward_mean=0.510, reward_bound=0.478, batch=149\n",
      "13848: loss=0.094, reward_mean=0.480, reward_bound=0.058, batch=172\n",
      "13849: loss=0.089, reward_mean=0.410, reward_bound=0.065, batch=187\n",
      "13850: loss=0.099, reward_mean=0.430, reward_bound=0.098, batch=200\n",
      "13851: loss=0.091, reward_mean=0.450, reward_bound=0.135, batch=207\n",
      "13852: loss=0.093, reward_mean=0.410, reward_bound=0.167, batch=209\n",
      "13853: loss=0.092, reward_mean=0.360, reward_bound=0.185, batch=209\n",
      "13854: loss=0.098, reward_mean=0.370, reward_bound=0.206, batch=211\n",
      "13855: loss=0.098, reward_mean=0.490, reward_bound=0.229, batch=215\n",
      "13856: loss=0.094, reward_mean=0.410, reward_bound=0.254, batch=208\n",
      "13857: loss=0.098, reward_mean=0.410, reward_bound=0.282, batch=203\n",
      "13858: loss=0.096, reward_mean=0.440, reward_bound=0.167, batch=210\n",
      "13859: loss=0.100, reward_mean=0.560, reward_bound=0.282, batch=212\n",
      "13860: loss=0.097, reward_mean=0.440, reward_bound=0.314, batch=194\n",
      "13861: loss=0.095, reward_mean=0.460, reward_bound=0.183, batch=206\n",
      "13862: loss=0.097, reward_mean=0.430, reward_bound=0.229, batch=213\n",
      "13863: loss=0.096, reward_mean=0.430, reward_bound=0.229, batch=216\n",
      "13864: loss=0.096, reward_mean=0.530, reward_bound=0.241, batch=221\n",
      "13865: loss=0.099, reward_mean=0.440, reward_bound=0.282, batch=218\n",
      "13866: loss=0.097, reward_mean=0.410, reward_bound=0.314, batch=216\n",
      "13867: loss=0.097, reward_mean=0.450, reward_bound=0.331, batch=221\n",
      "13868: loss=0.096, reward_mean=0.480, reward_bound=0.314, batch=223\n",
      "13869: loss=0.095, reward_mean=0.470, reward_bound=0.349, batch=205\n",
      "13870: loss=0.097, reward_mean=0.450, reward_bound=0.206, batch=212\n",
      "13871: loss=0.100, reward_mean=0.400, reward_bound=0.213, batch=218\n",
      "13872: loss=0.097, reward_mean=0.530, reward_bound=0.257, batch=222\n",
      "13873: loss=0.094, reward_mean=0.400, reward_bound=0.282, batch=221\n",
      "13874: loss=0.096, reward_mean=0.510, reward_bound=0.314, batch=222\n",
      "13875: loss=0.097, reward_mean=0.460, reward_bound=0.349, batch=220\n",
      "13876: loss=0.098, reward_mean=0.410, reward_bound=0.240, batch=224\n",
      "13877: loss=0.099, reward_mean=0.450, reward_bound=0.345, batch=227\n",
      "13878: loss=0.097, reward_mean=0.360, reward_bound=0.349, batch=228\n",
      "13879: loss=0.095, reward_mean=0.470, reward_bound=0.387, batch=201\n",
      "13880: loss=0.093, reward_mean=0.410, reward_bound=0.314, batch=210\n",
      "13881: loss=0.093, reward_mean=0.500, reward_bound=0.229, batch=216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13882: loss=0.093, reward_mean=0.440, reward_bound=0.254, batch=220\n",
      "13883: loss=0.093, reward_mean=0.560, reward_bound=0.338, batch=224\n",
      "13884: loss=0.095, reward_mean=0.480, reward_bound=0.311, batch=227\n",
      "13885: loss=0.092, reward_mean=0.440, reward_bound=0.314, batch=228\n",
      "13886: loss=0.092, reward_mean=0.440, reward_bound=0.349, batch=224\n",
      "13887: loss=0.092, reward_mean=0.510, reward_bound=0.387, batch=220\n",
      "13888: loss=0.094, reward_mean=0.460, reward_bound=0.274, batch=224\n",
      "13889: loss=0.094, reward_mean=0.510, reward_bound=0.349, batch=225\n",
      "13890: loss=0.094, reward_mean=0.400, reward_bound=0.349, batch=226\n",
      "13891: loss=0.093, reward_mean=0.380, reward_bound=0.368, batch=228\n",
      "13892: loss=0.093, reward_mean=0.400, reward_bound=0.387, batch=227\n",
      "13893: loss=0.089, reward_mean=0.450, reward_bound=0.430, batch=200\n",
      "13894: loss=0.088, reward_mean=0.500, reward_bound=0.222, batch=210\n",
      "13895: loss=0.088, reward_mean=0.500, reward_bound=0.274, batch=217\n",
      "13896: loss=0.088, reward_mean=0.510, reward_bound=0.282, batch=220\n",
      "13897: loss=0.090, reward_mean=0.390, reward_bound=0.338, batch=224\n",
      "13898: loss=0.090, reward_mean=0.490, reward_bound=0.349, batch=223\n",
      "13899: loss=0.090, reward_mean=0.450, reward_bound=0.387, batch=220\n",
      "13900: loss=0.091, reward_mean=0.450, reward_bound=0.338, batch=224\n",
      "13901: loss=0.090, reward_mean=0.480, reward_bound=0.430, batch=214\n",
      "13902: loss=0.089, reward_mean=0.410, reward_bound=0.252, batch=220\n",
      "13903: loss=0.089, reward_mean=0.450, reward_bound=0.247, batch=224\n",
      "13904: loss=0.088, reward_mean=0.490, reward_bound=0.282, batch=226\n",
      "13905: loss=0.089, reward_mean=0.530, reward_bound=0.349, batch=225\n",
      "13906: loss=0.090, reward_mean=0.530, reward_bound=0.387, batch=222\n",
      "13907: loss=0.089, reward_mean=0.450, reward_bound=0.314, batch=224\n",
      "13908: loss=0.090, reward_mean=0.430, reward_bound=0.384, batch=227\n",
      "13909: loss=0.090, reward_mean=0.470, reward_bound=0.387, batch=225\n",
      "13910: loss=0.090, reward_mean=0.370, reward_bound=0.396, batch=227\n",
      "13911: loss=0.089, reward_mean=0.400, reward_bound=0.314, batch=228\n",
      "13912: loss=0.089, reward_mean=0.390, reward_bound=0.430, batch=221\n",
      "13913: loss=0.088, reward_mean=0.470, reward_bound=0.349, batch=224\n",
      "13914: loss=0.087, reward_mean=0.450, reward_bound=0.345, batch=227\n",
      "13915: loss=0.086, reward_mean=0.410, reward_bound=0.380, batch=229\n",
      "13916: loss=0.087, reward_mean=0.400, reward_bound=0.387, batch=229\n",
      "13917: loss=0.087, reward_mean=0.490, reward_bound=0.430, batch=226\n",
      "13918: loss=0.087, reward_mean=0.430, reward_bound=0.454, batch=228\n",
      "13919: loss=0.086, reward_mean=0.540, reward_bound=0.478, batch=233\n",
      "13920: loss=0.084, reward_mean=0.490, reward_bound=0.478, batch=182\n",
      "13921: loss=0.079, reward_mean=0.450, reward_bound=0.155, batch=197\n",
      "13922: loss=0.078, reward_mean=0.370, reward_bound=0.167, batch=207\n",
      "13923: loss=0.078, reward_mean=0.530, reward_bound=0.167, batch=214\n",
      "13924: loss=0.082, reward_mean=0.440, reward_bound=0.206, batch=215\n",
      "13925: loss=0.082, reward_mean=0.440, reward_bound=0.229, batch=209\n",
      "13926: loss=0.081, reward_mean=0.480, reward_bound=0.229, batch=215\n",
      "13927: loss=0.082, reward_mean=0.440, reward_bound=0.254, batch=219\n",
      "13928: loss=0.083, reward_mean=0.480, reward_bound=0.282, batch=217\n",
      "13929: loss=0.082, reward_mean=0.450, reward_bound=0.308, batch=222\n",
      "13930: loss=0.085, reward_mean=0.460, reward_bound=0.314, batch=217\n",
      "13931: loss=0.084, reward_mean=0.400, reward_bound=0.349, batch=210\n",
      "13932: loss=0.082, reward_mean=0.390, reward_bound=0.222, batch=217\n",
      "13933: loss=0.086, reward_mean=0.410, reward_bound=0.314, batch=221\n",
      "13934: loss=0.086, reward_mean=0.320, reward_bound=0.349, batch=222\n",
      "13935: loss=0.086, reward_mean=0.370, reward_bound=0.324, batch=225\n",
      "13936: loss=0.086, reward_mean=0.540, reward_bound=0.349, batch=226\n",
      "13937: loss=0.083, reward_mean=0.490, reward_bound=0.387, batch=213\n",
      "13938: loss=0.083, reward_mean=0.420, reward_bound=0.314, batch=217\n",
      "13939: loss=0.082, reward_mean=0.440, reward_bound=0.229, batch=221\n",
      "13940: loss=0.082, reward_mean=0.390, reward_bound=0.282, batch=222\n",
      "13941: loss=0.082, reward_mean=0.410, reward_bound=0.254, batch=224\n",
      "13942: loss=0.083, reward_mean=0.450, reward_bound=0.314, batch=226\n",
      "13943: loss=0.083, reward_mean=0.430, reward_bound=0.331, batch=228\n",
      "13944: loss=0.081, reward_mean=0.410, reward_bound=0.349, batch=226\n",
      "13945: loss=0.081, reward_mean=0.480, reward_bound=0.387, batch=224\n",
      "13946: loss=0.080, reward_mean=0.400, reward_bound=0.349, batch=226\n",
      "13947: loss=0.081, reward_mean=0.530, reward_bound=0.387, batch=227\n",
      "13948: loss=0.081, reward_mean=0.440, reward_bound=0.380, batch=229\n",
      "13949: loss=0.083, reward_mean=0.530, reward_bound=0.387, batch=229\n",
      "13950: loss=0.082, reward_mean=0.380, reward_bound=0.360, batch=230\n",
      "13951: loss=0.082, reward_mean=0.460, reward_bound=0.406, batch=231\n",
      "13952: loss=0.084, reward_mean=0.500, reward_bound=0.430, batch=204\n",
      "13953: loss=0.083, reward_mean=0.430, reward_bound=0.206, batch=212\n",
      "13954: loss=0.084, reward_mean=0.470, reward_bound=0.282, batch=214\n",
      "13955: loss=0.083, reward_mean=0.440, reward_bound=0.229, batch=219\n",
      "13956: loss=0.088, reward_mean=0.410, reward_bound=0.295, batch=223\n",
      "13957: loss=0.083, reward_mean=0.510, reward_bound=0.314, batch=222\n",
      "13958: loss=0.083, reward_mean=0.370, reward_bound=0.324, batch=225\n",
      "13959: loss=0.084, reward_mean=0.370, reward_bound=0.349, batch=220\n",
      "13960: loss=0.085, reward_mean=0.440, reward_bound=0.247, batch=224\n",
      "13961: loss=0.084, reward_mean=0.480, reward_bound=0.314, batch=224\n",
      "13962: loss=0.085, reward_mean=0.490, reward_bound=0.387, batch=222\n",
      "13963: loss=0.085, reward_mean=0.470, reward_bound=0.336, batch=225\n",
      "13964: loss=0.087, reward_mean=0.430, reward_bound=0.356, batch=227\n",
      "13965: loss=0.084, reward_mean=0.490, reward_bound=0.422, batch=229\n",
      "13966: loss=0.085, reward_mean=0.490, reward_bound=0.430, batch=217\n",
      "13967: loss=0.085, reward_mean=0.480, reward_bound=0.308, batch=222\n",
      "13968: loss=0.086, reward_mean=0.440, reward_bound=0.360, batch=225\n",
      "13969: loss=0.085, reward_mean=0.480, reward_bound=0.356, batch=227\n",
      "13970: loss=0.085, reward_mean=0.450, reward_bound=0.380, batch=229\n",
      "13971: loss=0.084, reward_mean=0.450, reward_bound=0.387, batch=227\n",
      "13972: loss=0.086, reward_mean=0.460, reward_bound=0.380, batch=229\n",
      "13973: loss=0.084, reward_mean=0.450, reward_bound=0.387, batch=229\n",
      "13974: loss=0.084, reward_mean=0.420, reward_bound=0.364, batch=230\n",
      "13975: loss=0.085, reward_mean=0.370, reward_bound=0.376, batch=231\n",
      "13976: loss=0.085, reward_mean=0.370, reward_bound=0.387, batch=231\n",
      "13977: loss=0.085, reward_mean=0.420, reward_bound=0.430, batch=226\n",
      "13978: loss=0.084, reward_mean=0.430, reward_bound=0.298, batch=228\n",
      "13979: loss=0.085, reward_mean=0.430, reward_bound=0.286, batch=229\n",
      "13980: loss=0.083, reward_mean=0.520, reward_bound=0.405, batch=230\n",
      "13981: loss=0.084, reward_mean=0.480, reward_bound=0.430, batch=228\n",
      "13982: loss=0.084, reward_mean=0.530, reward_bound=0.478, batch=230\n",
      "13983: loss=0.084, reward_mean=0.380, reward_bound=0.451, batch=231\n",
      "13984: loss=0.083, reward_mean=0.430, reward_bound=0.478, batch=201\n",
      "13985: loss=0.082, reward_mean=0.440, reward_bound=0.254, batch=210\n",
      "13986: loss=0.081, reward_mean=0.390, reward_bound=0.247, batch=217\n",
      "13987: loss=0.083, reward_mean=0.420, reward_bound=0.254, batch=218\n",
      "13988: loss=0.084, reward_mean=0.440, reward_bound=0.282, batch=216\n",
      "13989: loss=0.084, reward_mean=0.360, reward_bound=0.314, batch=215\n",
      "13990: loss=0.084, reward_mean=0.460, reward_bound=0.296, batch=220\n",
      "13991: loss=0.081, reward_mean=0.460, reward_bound=0.349, batch=220\n",
      "13992: loss=0.082, reward_mean=0.440, reward_bound=0.314, batch=223\n",
      "13993: loss=0.082, reward_mean=0.470, reward_bound=0.387, batch=217\n",
      "13994: loss=0.081, reward_mean=0.430, reward_bound=0.254, batch=221\n",
      "13995: loss=0.082, reward_mean=0.390, reward_bound=0.349, batch=223\n",
      "13996: loss=0.082, reward_mean=0.420, reward_bound=0.335, batch=226\n",
      "13997: loss=0.083, reward_mean=0.480, reward_bound=0.349, batch=227\n",
      "13998: loss=0.082, reward_mean=0.440, reward_bound=0.277, batch=229\n",
      "13999: loss=0.083, reward_mean=0.400, reward_bound=0.387, batch=225\n",
      "14000: loss=0.082, reward_mean=0.470, reward_bound=0.396, batch=227\n",
      "14001: loss=0.083, reward_mean=0.400, reward_bound=0.380, batch=229\n",
      "14002: loss=0.082, reward_mean=0.390, reward_bound=0.387, batch=229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14003: loss=0.085, reward_mean=0.460, reward_bound=0.430, batch=214\n",
      "14004: loss=0.084, reward_mean=0.450, reward_bound=0.229, batch=219\n",
      "14005: loss=0.082, reward_mean=0.500, reward_bound=0.364, batch=223\n",
      "14006: loss=0.083, reward_mean=0.440, reward_bound=0.387, batch=225\n",
      "14007: loss=0.082, reward_mean=0.430, reward_bound=0.430, batch=224\n",
      "14008: loss=0.082, reward_mean=0.440, reward_bound=0.465, batch=227\n",
      "14009: loss=0.082, reward_mean=0.410, reward_bound=0.430, batch=228\n",
      "14010: loss=0.081, reward_mean=0.310, reward_bound=0.430, batch=228\n",
      "14011: loss=0.081, reward_mean=0.460, reward_bound=0.478, batch=230\n",
      "14012: loss=0.081, reward_mean=0.440, reward_bound=0.376, batch=231\n",
      "14013: loss=0.081, reward_mean=0.390, reward_bound=0.430, batch=230\n",
      "14014: loss=0.081, reward_mean=0.380, reward_bound=0.365, batch=231\n",
      "14015: loss=0.081, reward_mean=0.400, reward_bound=0.349, batch=231\n",
      "14016: loss=0.082, reward_mean=0.450, reward_bound=0.387, batch=231\n",
      "14017: loss=0.081, reward_mean=0.470, reward_bound=0.430, batch=231\n",
      "14018: loss=0.081, reward_mean=0.460, reward_bound=0.478, batch=216\n",
      "14019: loss=0.081, reward_mean=0.510, reward_bound=0.229, batch=220\n",
      "14020: loss=0.083, reward_mean=0.430, reward_bound=0.314, batch=223\n",
      "14021: loss=0.084, reward_mean=0.480, reward_bound=0.349, batch=225\n",
      "14022: loss=0.084, reward_mean=0.460, reward_bound=0.356, batch=227\n",
      "14023: loss=0.084, reward_mean=0.440, reward_bound=0.380, batch=229\n",
      "14024: loss=0.084, reward_mean=0.420, reward_bound=0.387, batch=225\n",
      "14025: loss=0.084, reward_mean=0.450, reward_bound=0.396, batch=227\n",
      "14026: loss=0.084, reward_mean=0.570, reward_bound=0.414, batch=229\n",
      "14027: loss=0.085, reward_mean=0.370, reward_bound=0.405, batch=230\n",
      "14028: loss=0.084, reward_mean=0.370, reward_bound=0.430, batch=223\n",
      "14029: loss=0.083, reward_mean=0.410, reward_bound=0.459, batch=226\n",
      "14030: loss=0.084, reward_mean=0.360, reward_bound=0.368, batch=228\n",
      "14031: loss=0.083, reward_mean=0.480, reward_bound=0.387, batch=227\n",
      "14032: loss=0.083, reward_mean=0.360, reward_bound=0.349, batch=228\n",
      "14033: loss=0.083, reward_mean=0.510, reward_bound=0.430, batch=228\n",
      "14034: loss=0.082, reward_mean=0.440, reward_bound=0.353, batch=229\n",
      "14035: loss=0.082, reward_mean=0.390, reward_bound=0.387, batch=229\n",
      "14036: loss=0.084, reward_mean=0.560, reward_bound=0.430, batch=229\n",
      "14037: loss=0.083, reward_mean=0.420, reward_bound=0.450, batch=230\n",
      "14038: loss=0.080, reward_mean=0.350, reward_bound=0.478, batch=222\n",
      "14039: loss=0.080, reward_mean=0.460, reward_bound=0.400, batch=225\n",
      "14040: loss=0.080, reward_mean=0.450, reward_bound=0.387, batch=226\n",
      "14041: loss=0.080, reward_mean=0.470, reward_bound=0.430, batch=227\n",
      "14042: loss=0.079, reward_mean=0.440, reward_bound=0.469, batch=229\n",
      "14043: loss=0.079, reward_mean=0.510, reward_bound=0.360, batch=230\n",
      "14044: loss=0.080, reward_mean=0.450, reward_bound=0.418, batch=231\n",
      "14045: loss=0.080, reward_mean=0.430, reward_bound=0.478, batch=224\n",
      "14046: loss=0.080, reward_mean=0.520, reward_bound=0.478, batch=226\n",
      "14047: loss=0.080, reward_mean=0.450, reward_bound=0.478, batch=226\n",
      "14048: loss=0.080, reward_mean=0.470, reward_bound=0.433, batch=228\n",
      "14049: loss=0.079, reward_mean=0.400, reward_bound=0.435, batch=229\n",
      "14050: loss=0.079, reward_mean=0.470, reward_bound=0.381, batch=230\n",
      "14051: loss=0.079, reward_mean=0.440, reward_bound=0.365, batch=231\n",
      "14052: loss=0.079, reward_mean=0.420, reward_bound=0.387, batch=231\n",
      "14053: loss=0.079, reward_mean=0.440, reward_bound=0.430, batch=231\n",
      "14054: loss=0.079, reward_mean=0.400, reward_bound=0.430, batch=231\n",
      "14055: loss=0.080, reward_mean=0.440, reward_bound=0.478, batch=228\n",
      "14056: loss=0.079, reward_mean=0.420, reward_bound=0.357, batch=229\n",
      "14057: loss=0.082, reward_mean=0.450, reward_bound=0.478, batch=231\n",
      "14058: loss=0.079, reward_mean=0.460, reward_bound=0.478, batch=229\n",
      "14059: loss=0.079, reward_mean=0.490, reward_bound=0.478, batch=231\n",
      "14060: loss=0.080, reward_mean=0.560, reward_bound=0.478, batch=231\n",
      "14062: loss=0.073, reward_mean=0.510, reward_bound=0.000, batch=51\n",
      "14063: loss=0.066, reward_mean=0.430, reward_bound=0.000, batch=94\n",
      "14064: loss=0.071, reward_mean=0.400, reward_bound=0.000, batch=134\n",
      "14065: loss=0.073, reward_mean=0.500, reward_bound=0.005, batch=164\n",
      "14066: loss=0.073, reward_mean=0.410, reward_bound=0.011, batch=184\n",
      "14067: loss=0.071, reward_mean=0.430, reward_bound=0.020, batch=194\n",
      "14068: loss=0.082, reward_mean=0.430, reward_bound=0.034, batch=197\n",
      "14069: loss=0.081, reward_mean=0.430, reward_bound=0.052, batch=207\n",
      "14070: loss=0.082, reward_mean=0.490, reward_bound=0.072, batch=213\n",
      "14071: loss=0.077, reward_mean=0.470, reward_bound=0.089, batch=214\n",
      "14072: loss=0.078, reward_mean=0.420, reward_bound=0.109, batch=196\n",
      "14073: loss=0.082, reward_mean=0.410, reward_bound=0.122, batch=202\n",
      "14074: loss=0.081, reward_mean=0.450, reward_bound=0.135, batch=207\n",
      "14075: loss=0.082, reward_mean=0.460, reward_bound=0.150, batch=210\n",
      "14076: loss=0.081, reward_mean=0.470, reward_bound=0.167, batch=198\n",
      "14077: loss=0.083, reward_mean=0.520, reward_bound=0.185, batch=188\n",
      "14078: loss=0.084, reward_mean=0.400, reward_bound=0.137, batch=201\n",
      "14079: loss=0.083, reward_mean=0.400, reward_bound=0.167, batch=210\n",
      "14080: loss=0.083, reward_mean=0.590, reward_bound=0.206, batch=222\n",
      "14081: loss=0.084, reward_mean=0.440, reward_bound=0.206, batch=233\n",
      "14082: loss=0.085, reward_mean=0.450, reward_bound=0.206, batch=222\n",
      "14083: loss=0.088, reward_mean=0.400, reward_bound=0.229, batch=195\n",
      "14084: loss=0.091, reward_mean=0.440, reward_bound=0.206, batch=205\n",
      "14085: loss=0.091, reward_mean=0.450, reward_bound=0.229, batch=212\n",
      "14086: loss=0.087, reward_mean=0.440, reward_bound=0.254, batch=192\n",
      "14087: loss=0.085, reward_mean=0.430, reward_bound=0.109, batch=203\n",
      "14088: loss=0.086, reward_mean=0.450, reward_bound=0.185, batch=208\n",
      "14089: loss=0.084, reward_mean=0.450, reward_bound=0.208, batch=215\n",
      "14090: loss=0.084, reward_mean=0.330, reward_bound=0.229, batch=215\n",
      "14091: loss=0.083, reward_mean=0.400, reward_bound=0.254, batch=215\n",
      "14092: loss=0.084, reward_mean=0.450, reward_bound=0.282, batch=178\n",
      "14093: loss=0.083, reward_mean=0.390, reward_bound=0.123, batch=194\n",
      "14094: loss=0.082, reward_mean=0.390, reward_bound=0.098, batch=205\n",
      "14095: loss=0.083, reward_mean=0.480, reward_bound=0.138, batch=213\n",
      "14096: loss=0.084, reward_mean=0.440, reward_bound=0.167, batch=218\n",
      "14097: loss=0.080, reward_mean=0.520, reward_bound=0.185, batch=220\n",
      "14098: loss=0.078, reward_mean=0.500, reward_bound=0.222, batch=224\n",
      "14099: loss=0.080, reward_mean=0.500, reward_bound=0.254, batch=226\n",
      "14100: loss=0.082, reward_mean=0.440, reward_bound=0.282, batch=220\n",
      "14101: loss=0.084, reward_mean=0.440, reward_bound=0.314, batch=166\n",
      "14102: loss=0.089, reward_mean=0.460, reward_bound=0.061, batch=186\n",
      "14103: loss=0.088, reward_mean=0.520, reward_bound=0.115, batch=200\n",
      "14104: loss=0.091, reward_mean=0.390, reward_bound=0.150, batch=205\n",
      "14105: loss=0.090, reward_mean=0.390, reward_bound=0.167, batch=209\n",
      "14106: loss=0.092, reward_mean=0.470, reward_bound=0.185, batch=215\n",
      "14107: loss=0.090, reward_mean=0.460, reward_bound=0.206, batch=218\n",
      "14108: loss=0.090, reward_mean=0.500, reward_bound=0.229, batch=220\n",
      "14109: loss=0.089, reward_mean=0.450, reward_bound=0.240, batch=224\n",
      "14110: loss=0.085, reward_mean=0.480, reward_bound=0.254, batch=223\n",
      "14111: loss=0.084, reward_mean=0.460, reward_bound=0.282, batch=219\n",
      "14112: loss=0.085, reward_mean=0.450, reward_bound=0.314, batch=209\n",
      "14113: loss=0.085, reward_mean=0.420, reward_bound=0.263, batch=216\n",
      "14114: loss=0.083, reward_mean=0.390, reward_bound=0.241, batch=221\n",
      "14115: loss=0.084, reward_mean=0.440, reward_bound=0.314, batch=224\n",
      "14116: loss=0.079, reward_mean=0.370, reward_bound=0.349, batch=166\n",
      "14117: loss=0.075, reward_mean=0.420, reward_bound=0.058, batch=185\n",
      "14118: loss=0.079, reward_mean=0.510, reward_bound=0.122, batch=196\n",
      "14119: loss=0.077, reward_mean=0.550, reward_bound=0.143, batch=207\n",
      "14120: loss=0.079, reward_mean=0.400, reward_bound=0.185, batch=208\n",
      "14121: loss=0.077, reward_mean=0.440, reward_bound=0.208, batch=215\n",
      "14122: loss=0.078, reward_mean=0.600, reward_bound=0.234, batch=220\n",
      "14123: loss=0.077, reward_mean=0.410, reward_bound=0.254, batch=222\n",
      "14124: loss=0.077, reward_mean=0.540, reward_bound=0.282, batch=217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14125: loss=0.079, reward_mean=0.430, reward_bound=0.314, batch=205\n",
      "14126: loss=0.079, reward_mean=0.380, reward_bound=0.229, batch=212\n",
      "14127: loss=0.077, reward_mean=0.400, reward_bound=0.292, batch=218\n",
      "14128: loss=0.076, reward_mean=0.380, reward_bound=0.257, batch=222\n",
      "14129: loss=0.078, reward_mean=0.360, reward_bound=0.314, batch=222\n",
      "14130: loss=0.078, reward_mean=0.420, reward_bound=0.349, batch=214\n",
      "14131: loss=0.080, reward_mean=0.490, reward_bound=0.311, batch=220\n",
      "14132: loss=0.080, reward_mean=0.470, reward_bound=0.314, batch=222\n",
      "14133: loss=0.080, reward_mean=0.440, reward_bound=0.349, batch=224\n",
      "14134: loss=0.079, reward_mean=0.410, reward_bound=0.384, batch=227\n",
      "14135: loss=0.083, reward_mean=0.450, reward_bound=0.387, batch=154\n",
      "14136: loss=0.080, reward_mean=0.410, reward_bound=0.071, batch=178\n",
      "14137: loss=0.077, reward_mean=0.500, reward_bound=0.098, batch=192\n",
      "14138: loss=0.077, reward_mean=0.390, reward_bound=0.122, batch=198\n",
      "14139: loss=0.078, reward_mean=0.490, reward_bound=0.150, batch=205\n",
      "14140: loss=0.077, reward_mean=0.400, reward_bound=0.170, batch=213\n",
      "14141: loss=0.078, reward_mean=0.440, reward_bound=0.185, batch=214\n",
      "14142: loss=0.078, reward_mean=0.470, reward_bound=0.206, batch=211\n",
      "14143: loss=0.081, reward_mean=0.430, reward_bound=0.229, batch=210\n",
      "14144: loss=0.082, reward_mean=0.440, reward_bound=0.254, batch=214\n",
      "14145: loss=0.083, reward_mean=0.330, reward_bound=0.280, batch=220\n",
      "14146: loss=0.080, reward_mean=0.450, reward_bound=0.282, batch=213\n",
      "14147: loss=0.080, reward_mean=0.530, reward_bound=0.244, batch=219\n",
      "14148: loss=0.080, reward_mean=0.430, reward_bound=0.314, batch=209\n",
      "14149: loss=0.078, reward_mean=0.470, reward_bound=0.265, batch=216\n",
      "14150: loss=0.078, reward_mean=0.520, reward_bound=0.314, batch=220\n",
      "14151: loss=0.080, reward_mean=0.510, reward_bound=0.349, batch=206\n",
      "14152: loss=0.081, reward_mean=0.410, reward_bound=0.314, batch=211\n",
      "14153: loss=0.080, reward_mean=0.430, reward_bound=0.254, batch=216\n",
      "14154: loss=0.080, reward_mean=0.530, reward_bound=0.282, batch=218\n",
      "14155: loss=0.080, reward_mean=0.470, reward_bound=0.317, batch=222\n",
      "14156: loss=0.080, reward_mean=0.500, reward_bound=0.349, batch=219\n",
      "14157: loss=0.081, reward_mean=0.470, reward_bound=0.328, batch=223\n",
      "14158: loss=0.081, reward_mean=0.460, reward_bound=0.372, batch=226\n",
      "14159: loss=0.081, reward_mean=0.380, reward_bound=0.335, batch=228\n",
      "14160: loss=0.081, reward_mean=0.420, reward_bound=0.387, batch=197\n",
      "14161: loss=0.083, reward_mean=0.440, reward_bound=0.206, batch=207\n",
      "14162: loss=0.085, reward_mean=0.420, reward_bound=0.272, batch=215\n",
      "14163: loss=0.080, reward_mean=0.440, reward_bound=0.314, batch=217\n",
      "14164: loss=0.082, reward_mean=0.480, reward_bound=0.277, batch=222\n",
      "14165: loss=0.082, reward_mean=0.430, reward_bound=0.236, batch=225\n",
      "14166: loss=0.081, reward_mean=0.390, reward_bound=0.314, batch=226\n",
      "14167: loss=0.083, reward_mean=0.480, reward_bound=0.349, batch=223\n",
      "14168: loss=0.084, reward_mean=0.440, reward_bound=0.387, batch=212\n",
      "14169: loss=0.084, reward_mean=0.450, reward_bound=0.263, batch=218\n",
      "14170: loss=0.083, reward_mean=0.380, reward_bound=0.282, batch=221\n",
      "14171: loss=0.084, reward_mean=0.460, reward_bound=0.349, batch=223\n",
      "14172: loss=0.084, reward_mean=0.480, reward_bound=0.314, batch=224\n",
      "14173: loss=0.084, reward_mean=0.340, reward_bound=0.311, batch=227\n",
      "14174: loss=0.084, reward_mean=0.530, reward_bound=0.342, batch=229\n",
      "14175: loss=0.084, reward_mean=0.470, reward_bound=0.387, batch=222\n",
      "14176: loss=0.084, reward_mean=0.550, reward_bound=0.400, batch=225\n",
      "14177: loss=0.086, reward_mean=0.490, reward_bound=0.430, batch=120\n",
      "14178: loss=0.084, reward_mean=0.410, reward_bound=0.011, batch=154\n",
      "14179: loss=0.083, reward_mean=0.410, reward_bound=0.031, batch=178\n",
      "14180: loss=0.076, reward_mean=0.440, reward_bound=0.052, batch=193\n",
      "14181: loss=0.081, reward_mean=0.400, reward_bound=0.072, batch=202\n",
      "14182: loss=0.083, reward_mean=0.410, reward_bound=0.098, batch=210\n",
      "14183: loss=0.079, reward_mean=0.420, reward_bound=0.122, batch=215\n",
      "14184: loss=0.079, reward_mean=0.430, reward_bound=0.135, batch=212\n",
      "14185: loss=0.080, reward_mean=0.490, reward_bound=0.167, batch=210\n",
      "14186: loss=0.079, reward_mean=0.430, reward_bound=0.185, batch=214\n",
      "14187: loss=0.077, reward_mean=0.550, reward_bound=0.206, batch=217\n",
      "14188: loss=0.075, reward_mean=0.440, reward_bound=0.229, batch=211\n",
      "14189: loss=0.077, reward_mean=0.370, reward_bound=0.185, batch=216\n",
      "14190: loss=0.078, reward_mean=0.440, reward_bound=0.229, batch=220\n",
      "14191: loss=0.082, reward_mean=0.460, reward_bound=0.254, batch=207\n",
      "14192: loss=0.084, reward_mean=0.440, reward_bound=0.220, batch=215\n",
      "14193: loss=0.088, reward_mean=0.460, reward_bound=0.282, batch=199\n",
      "14194: loss=0.085, reward_mean=0.470, reward_bound=0.314, batch=184\n",
      "14195: loss=0.085, reward_mean=0.530, reward_bound=0.165, batch=199\n",
      "14196: loss=0.081, reward_mean=0.420, reward_bound=0.215, batch=209\n",
      "14197: loss=0.083, reward_mean=0.370, reward_bound=0.229, batch=214\n",
      "14198: loss=0.083, reward_mean=0.460, reward_bound=0.254, batch=214\n",
      "14199: loss=0.084, reward_mean=0.390, reward_bound=0.282, batch=214\n",
      "14200: loss=0.084, reward_mean=0.350, reward_bound=0.206, batch=219\n",
      "14201: loss=0.085, reward_mean=0.510, reward_bound=0.314, batch=215\n",
      "14202: loss=0.085, reward_mean=0.450, reward_bound=0.246, batch=220\n",
      "14203: loss=0.086, reward_mean=0.470, reward_bound=0.254, batch=223\n",
      "14204: loss=0.084, reward_mean=0.430, reward_bound=0.314, batch=223\n",
      "14205: loss=0.085, reward_mean=0.390, reward_bound=0.335, batch=226\n",
      "14206: loss=0.085, reward_mean=0.530, reward_bound=0.349, batch=198\n",
      "14207: loss=0.086, reward_mean=0.390, reward_bound=0.185, batch=205\n",
      "14208: loss=0.087, reward_mean=0.500, reward_bound=0.206, batch=212\n",
      "14209: loss=0.088, reward_mean=0.460, reward_bound=0.236, batch=218\n",
      "14210: loss=0.086, reward_mean=0.490, reward_bound=0.254, batch=219\n",
      "14211: loss=0.087, reward_mean=0.470, reward_bound=0.254, batch=221\n",
      "14212: loss=0.088, reward_mean=0.510, reward_bound=0.282, batch=220\n",
      "14213: loss=0.088, reward_mean=0.470, reward_bound=0.314, batch=217\n",
      "14214: loss=0.089, reward_mean=0.480, reward_bound=0.314, batch=220\n",
      "14215: loss=0.087, reward_mean=0.440, reward_bound=0.349, batch=213\n",
      "14216: loss=0.087, reward_mean=0.520, reward_bound=0.271, batch=219\n",
      "14217: loss=0.086, reward_mean=0.470, reward_bound=0.314, batch=220\n",
      "14218: loss=0.084, reward_mean=0.350, reward_bound=0.387, batch=186\n",
      "14219: loss=0.088, reward_mean=0.400, reward_bound=0.196, batch=200\n",
      "14220: loss=0.086, reward_mean=0.520, reward_bound=0.200, batch=210\n",
      "14221: loss=0.087, reward_mean=0.450, reward_bound=0.229, batch=210\n",
      "14222: loss=0.085, reward_mean=0.390, reward_bound=0.222, batch=217\n",
      "14223: loss=0.088, reward_mean=0.440, reward_bound=0.229, batch=219\n",
      "14224: loss=0.086, reward_mean=0.400, reward_bound=0.254, batch=219\n",
      "14225: loss=0.087, reward_mean=0.430, reward_bound=0.282, batch=222\n",
      "14226: loss=0.085, reward_mean=0.470, reward_bound=0.314, batch=215\n",
      "14227: loss=0.086, reward_mean=0.370, reward_bound=0.314, batch=218\n",
      "14228: loss=0.087, reward_mean=0.480, reward_bound=0.349, batch=214\n",
      "14229: loss=0.087, reward_mean=0.430, reward_bound=0.254, batch=218\n",
      "14230: loss=0.087, reward_mean=0.390, reward_bound=0.211, batch=222\n",
      "14231: loss=0.086, reward_mean=0.500, reward_bound=0.292, batch=225\n",
      "14232: loss=0.086, reward_mean=0.450, reward_bound=0.314, batch=226\n",
      "14233: loss=0.086, reward_mean=0.450, reward_bound=0.349, batch=225\n",
      "14234: loss=0.084, reward_mean=0.530, reward_bound=0.387, batch=219\n",
      "14235: loss=0.083, reward_mean=0.480, reward_bound=0.282, batch=222\n",
      "14236: loss=0.085, reward_mean=0.450, reward_bound=0.360, batch=225\n",
      "14237: loss=0.084, reward_mean=0.450, reward_bound=0.314, batch=226\n",
      "14238: loss=0.085, reward_mean=0.480, reward_bound=0.368, batch=228\n",
      "14239: loss=0.085, reward_mean=0.350, reward_bound=0.353, batch=229\n",
      "14240: loss=0.085, reward_mean=0.450, reward_bound=0.387, batch=228\n",
      "14241: loss=0.085, reward_mean=0.430, reward_bound=0.430, batch=168\n",
      "14242: loss=0.095, reward_mean=0.390, reward_bound=0.102, batch=187\n",
      "14243: loss=0.087, reward_mean=0.450, reward_bound=0.135, batch=199\n",
      "14244: loss=0.090, reward_mean=0.430, reward_bound=0.167, batch=205\n",
      "14245: loss=0.089, reward_mean=0.420, reward_bound=0.138, batch=213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14246: loss=0.084, reward_mean=0.410, reward_bound=0.185, batch=218\n",
      "14247: loss=0.080, reward_mean=0.430, reward_bound=0.206, batch=221\n",
      "14248: loss=0.085, reward_mean=0.440, reward_bound=0.254, batch=216\n",
      "14249: loss=0.085, reward_mean=0.490, reward_bound=0.282, batch=216\n",
      "14250: loss=0.085, reward_mean=0.530, reward_bound=0.314, batch=207\n",
      "14251: loss=0.085, reward_mean=0.440, reward_bound=0.254, batch=214\n",
      "14252: loss=0.085, reward_mean=0.350, reward_bound=0.282, batch=218\n",
      "14253: loss=0.084, reward_mean=0.440, reward_bound=0.282, batch=221\n",
      "14254: loss=0.087, reward_mean=0.470, reward_bound=0.314, batch=223\n",
      "14255: loss=0.088, reward_mean=0.440, reward_bound=0.349, batch=212\n",
      "14256: loss=0.087, reward_mean=0.440, reward_bound=0.254, batch=217\n",
      "14257: loss=0.087, reward_mean=0.530, reward_bound=0.308, batch=222\n",
      "14258: loss=0.087, reward_mean=0.490, reward_bound=0.292, batch=225\n",
      "14259: loss=0.089, reward_mean=0.460, reward_bound=0.321, batch=227\n",
      "14260: loss=0.090, reward_mean=0.480, reward_bound=0.349, batch=227\n",
      "14261: loss=0.086, reward_mean=0.430, reward_bound=0.387, batch=205\n",
      "14262: loss=0.085, reward_mean=0.410, reward_bound=0.321, batch=213\n",
      "14263: loss=0.084, reward_mean=0.450, reward_bound=0.220, batch=219\n",
      "14264: loss=0.086, reward_mean=0.450, reward_bound=0.282, batch=221\n",
      "14265: loss=0.087, reward_mean=0.440, reward_bound=0.314, batch=224\n",
      "14266: loss=0.089, reward_mean=0.340, reward_bound=0.349, batch=225\n",
      "14267: loss=0.086, reward_mean=0.470, reward_bound=0.387, batch=220\n",
      "14268: loss=0.087, reward_mean=0.430, reward_bound=0.254, batch=223\n",
      "14269: loss=0.087, reward_mean=0.450, reward_bound=0.314, batch=225\n",
      "14270: loss=0.087, reward_mean=0.420, reward_bound=0.289, batch=227\n",
      "14271: loss=0.087, reward_mean=0.500, reward_bound=0.342, batch=229\n",
      "14272: loss=0.085, reward_mean=0.510, reward_bound=0.349, batch=229\n",
      "14273: loss=0.084, reward_mean=0.510, reward_bound=0.430, batch=199\n",
      "14274: loss=0.083, reward_mean=0.350, reward_bound=0.141, batch=209\n",
      "14275: loss=0.082, reward_mean=0.430, reward_bound=0.254, batch=215\n",
      "14276: loss=0.084, reward_mean=0.510, reward_bound=0.282, batch=219\n",
      "14277: loss=0.084, reward_mean=0.490, reward_bound=0.282, batch=221\n",
      "14278: loss=0.087, reward_mean=0.460, reward_bound=0.314, batch=222\n",
      "14279: loss=0.084, reward_mean=0.500, reward_bound=0.349, batch=213\n",
      "14280: loss=0.086, reward_mean=0.420, reward_bound=0.314, batch=218\n",
      "14281: loss=0.086, reward_mean=0.480, reward_bound=0.349, batch=221\n",
      "14282: loss=0.087, reward_mean=0.370, reward_bound=0.314, batch=223\n",
      "14283: loss=0.087, reward_mean=0.410, reward_bound=0.349, batch=225\n",
      "14284: loss=0.088, reward_mean=0.450, reward_bound=0.356, batch=227\n",
      "14285: loss=0.087, reward_mean=0.440, reward_bound=0.387, batch=225\n",
      "14286: loss=0.085, reward_mean=0.360, reward_bound=0.430, batch=219\n",
      "14287: loss=0.086, reward_mean=0.560, reward_bound=0.364, batch=223\n",
      "14288: loss=0.087, reward_mean=0.510, reward_bound=0.372, batch=226\n",
      "14289: loss=0.087, reward_mean=0.390, reward_bound=0.368, batch=228\n",
      "14290: loss=0.087, reward_mean=0.390, reward_bound=0.387, batch=226\n",
      "14291: loss=0.086, reward_mean=0.430, reward_bound=0.454, batch=228\n",
      "14292: loss=0.086, reward_mean=0.390, reward_bound=0.478, batch=232\n",
      "14293: loss=0.092, reward_mean=0.420, reward_bound=0.478, batch=105\n",
      "14294: loss=0.071, reward_mean=0.540, reward_bound=0.015, batch=143\n",
      "14295: loss=0.069, reward_mean=0.400, reward_bound=0.018, batch=170\n",
      "14296: loss=0.074, reward_mean=0.510, reward_bound=0.056, batch=189\n",
      "14297: loss=0.075, reward_mean=0.490, reward_bound=0.065, batch=201\n",
      "14298: loss=0.078, reward_mean=0.480, reward_bound=0.089, batch=209\n",
      "14299: loss=0.082, reward_mean=0.420, reward_bound=0.109, batch=212\n",
      "14300: loss=0.083, reward_mean=0.540, reward_bound=0.135, batch=216\n",
      "14301: loss=0.080, reward_mean=0.520, reward_bound=0.167, batch=212\n",
      "14302: loss=0.080, reward_mean=0.420, reward_bound=0.185, batch=206\n",
      "14303: loss=0.076, reward_mean=0.490, reward_bound=0.206, batch=205\n",
      "14304: loss=0.077, reward_mean=0.390, reward_bound=0.229, batch=198\n",
      "14305: loss=0.077, reward_mean=0.420, reward_bound=0.152, batch=208\n",
      "14306: loss=0.081, reward_mean=0.580, reward_bound=0.254, batch=198\n",
      "14307: loss=0.082, reward_mean=0.360, reward_bound=0.171, batch=208\n",
      "14308: loss=0.080, reward_mean=0.410, reward_bound=0.231, batch=215\n",
      "14309: loss=0.083, reward_mean=0.410, reward_bound=0.206, batch=219\n",
      "14310: loss=0.083, reward_mean=0.430, reward_bound=0.254, batch=219\n",
      "14311: loss=0.083, reward_mean=0.470, reward_bound=0.282, batch=197\n",
      "14312: loss=0.086, reward_mean=0.420, reward_bound=0.150, batch=207\n",
      "14313: loss=0.086, reward_mean=0.460, reward_bound=0.185, batch=213\n",
      "14314: loss=0.084, reward_mean=0.510, reward_bound=0.206, batch=215\n",
      "14315: loss=0.085, reward_mean=0.460, reward_bound=0.254, batch=217\n",
      "14316: loss=0.086, reward_mean=0.390, reward_bound=0.220, batch=222\n",
      "14317: loss=0.084, reward_mean=0.440, reward_bound=0.282, batch=218\n",
      "14318: loss=0.085, reward_mean=0.430, reward_bound=0.257, batch=222\n",
      "14319: loss=0.084, reward_mean=0.520, reward_bound=0.314, batch=201\n",
      "14320: loss=0.084, reward_mean=0.490, reward_bound=0.206, batch=210\n",
      "14321: loss=0.085, reward_mean=0.350, reward_bound=0.185, batch=216\n",
      "14322: loss=0.082, reward_mean=0.380, reward_bound=0.229, batch=218\n",
      "14323: loss=0.083, reward_mean=0.470, reward_bound=0.282, batch=219\n",
      "14324: loss=0.084, reward_mean=0.520, reward_bound=0.295, batch=223\n",
      "14325: loss=0.086, reward_mean=0.450, reward_bound=0.301, batch=226\n",
      "14326: loss=0.085, reward_mean=0.380, reward_bound=0.271, batch=228\n",
      "14327: loss=0.086, reward_mean=0.370, reward_bound=0.349, batch=194\n",
      "14328: loss=0.088, reward_mean=0.420, reward_bound=0.229, batch=205\n",
      "14329: loss=0.088, reward_mean=0.380, reward_bound=0.254, batch=211\n",
      "14330: loss=0.087, reward_mean=0.480, reward_bound=0.254, batch=215\n",
      "14331: loss=0.085, reward_mean=0.490, reward_bound=0.282, batch=213\n",
      "14332: loss=0.084, reward_mean=0.540, reward_bound=0.314, batch=215\n",
      "14333: loss=0.084, reward_mean=0.500, reward_bound=0.260, batch=220\n",
      "14334: loss=0.083, reward_mean=0.520, reward_bound=0.314, batch=222\n",
      "14335: loss=0.085, reward_mean=0.450, reward_bound=0.349, batch=220\n",
      "14336: loss=0.084, reward_mean=0.480, reward_bound=0.229, batch=223\n",
      "14337: loss=0.084, reward_mean=0.560, reward_bound=0.372, batch=226\n",
      "14338: loss=0.083, reward_mean=0.510, reward_bound=0.368, batch=228\n",
      "14339: loss=0.085, reward_mean=0.460, reward_bound=0.387, batch=192\n",
      "14340: loss=0.084, reward_mean=0.450, reward_bound=0.172, batch=204\n",
      "14341: loss=0.083, reward_mean=0.500, reward_bound=0.226, batch=213\n",
      "14342: loss=0.083, reward_mean=0.480, reward_bound=0.254, batch=216\n",
      "14343: loss=0.084, reward_mean=0.520, reward_bound=0.282, batch=217\n",
      "14344: loss=0.086, reward_mean=0.380, reward_bound=0.314, batch=214\n",
      "14345: loss=0.087, reward_mean=0.430, reward_bound=0.206, batch=219\n",
      "14346: loss=0.087, reward_mean=0.370, reward_bound=0.229, batch=222\n",
      "14347: loss=0.087, reward_mean=0.490, reward_bound=0.282, batch=224\n",
      "14348: loss=0.087, reward_mean=0.480, reward_bound=0.314, batch=226\n",
      "14349: loss=0.088, reward_mean=0.460, reward_bound=0.349, batch=215\n",
      "14350: loss=0.088, reward_mean=0.460, reward_bound=0.260, batch=220\n",
      "14351: loss=0.088, reward_mean=0.430, reward_bound=0.304, batch=224\n",
      "14352: loss=0.089, reward_mean=0.450, reward_bound=0.349, batch=225\n",
      "14353: loss=0.086, reward_mean=0.490, reward_bound=0.387, batch=215\n",
      "14354: loss=0.089, reward_mean=0.460, reward_bound=0.229, batch=218\n",
      "14355: loss=0.086, reward_mean=0.450, reward_bound=0.349, batch=219\n",
      "14356: loss=0.086, reward_mean=0.410, reward_bound=0.295, batch=223\n",
      "14357: loss=0.088, reward_mean=0.430, reward_bound=0.314, batch=225\n",
      "14358: loss=0.086, reward_mean=0.420, reward_bound=0.349, batch=225\n",
      "14359: loss=0.086, reward_mean=0.430, reward_bound=0.387, batch=225\n",
      "14360: loss=0.085, reward_mean=0.430, reward_bound=0.396, batch=227\n",
      "14361: loss=0.087, reward_mean=0.590, reward_bound=0.430, batch=180\n",
      "14362: loss=0.086, reward_mean=0.520, reward_bound=0.162, batch=196\n",
      "14363: loss=0.085, reward_mean=0.510, reward_bound=0.206, batch=205\n",
      "14364: loss=0.086, reward_mean=0.440, reward_bound=0.167, batch=212\n",
      "14365: loss=0.088, reward_mean=0.460, reward_bound=0.229, batch=214\n",
      "14366: loss=0.087, reward_mean=0.470, reward_bound=0.254, batch=215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14367: loss=0.086, reward_mean=0.360, reward_bound=0.260, batch=220\n",
      "14368: loss=0.086, reward_mean=0.420, reward_bound=0.282, batch=221\n",
      "14369: loss=0.087, reward_mean=0.440, reward_bound=0.314, batch=218\n",
      "14370: loss=0.087, reward_mean=0.470, reward_bound=0.314, batch=221\n",
      "14371: loss=0.086, reward_mean=0.410, reward_bound=0.349, batch=211\n",
      "14372: loss=0.087, reward_mean=0.510, reward_bound=0.282, batch=217\n",
      "14373: loss=0.091, reward_mean=0.500, reward_bound=0.277, batch=222\n",
      "14374: loss=0.088, reward_mean=0.440, reward_bound=0.282, batch=224\n",
      "14375: loss=0.087, reward_mean=0.340, reward_bound=0.204, batch=227\n",
      "14376: loss=0.088, reward_mean=0.380, reward_bound=0.314, batch=225\n",
      "14377: loss=0.086, reward_mean=0.430, reward_bound=0.356, batch=227\n",
      "14378: loss=0.091, reward_mean=0.400, reward_bound=0.387, batch=207\n",
      "14379: loss=0.092, reward_mean=0.340, reward_bound=0.182, batch=215\n",
      "14380: loss=0.092, reward_mean=0.430, reward_bound=0.260, batch=220\n",
      "14381: loss=0.092, reward_mean=0.430, reward_bound=0.247, batch=224\n",
      "14382: loss=0.093, reward_mean=0.480, reward_bound=0.314, batch=225\n",
      "14383: loss=0.092, reward_mean=0.470, reward_bound=0.349, batch=220\n",
      "14384: loss=0.093, reward_mean=0.380, reward_bound=0.314, batch=223\n",
      "14385: loss=0.095, reward_mean=0.410, reward_bound=0.314, batch=225\n",
      "14386: loss=0.096, reward_mean=0.490, reward_bound=0.321, batch=227\n",
      "14387: loss=0.095, reward_mean=0.370, reward_bound=0.342, batch=229\n",
      "14388: loss=0.095, reward_mean=0.440, reward_bound=0.349, batch=228\n",
      "14389: loss=0.093, reward_mean=0.430, reward_bound=0.387, batch=222\n",
      "14390: loss=0.093, reward_mean=0.480, reward_bound=0.400, batch=225\n",
      "14391: loss=0.092, reward_mean=0.340, reward_bound=0.387, batch=226\n",
      "14392: loss=0.092, reward_mean=0.460, reward_bound=0.331, batch=228\n",
      "14393: loss=0.089, reward_mean=0.400, reward_bound=0.430, batch=205\n",
      "14394: loss=0.090, reward_mean=0.450, reward_bound=0.206, batch=212\n",
      "14395: loss=0.088, reward_mean=0.420, reward_bound=0.254, batch=216\n",
      "14396: loss=0.088, reward_mean=0.510, reward_bound=0.314, batch=220\n",
      "14397: loss=0.088, reward_mean=0.400, reward_bound=0.338, batch=224\n",
      "14398: loss=0.088, reward_mean=0.470, reward_bound=0.282, batch=226\n",
      "14399: loss=0.089, reward_mean=0.400, reward_bound=0.349, batch=219\n",
      "14400: loss=0.089, reward_mean=0.380, reward_bound=0.265, batch=223\n",
      "14401: loss=0.087, reward_mean=0.530, reward_bound=0.301, batch=226\n",
      "14402: loss=0.089, reward_mean=0.510, reward_bound=0.368, batch=228\n",
      "14403: loss=0.090, reward_mean=0.460, reward_bound=0.387, batch=220\n",
      "14404: loss=0.089, reward_mean=0.450, reward_bound=0.274, batch=224\n",
      "14405: loss=0.089, reward_mean=0.420, reward_bound=0.311, batch=227\n",
      "14406: loss=0.090, reward_mean=0.340, reward_bound=0.342, batch=229\n",
      "14407: loss=0.091, reward_mean=0.420, reward_bound=0.387, batch=229\n",
      "14408: loss=0.091, reward_mean=0.540, reward_bound=0.387, batch=229\n",
      "14409: loss=0.089, reward_mean=0.480, reward_bound=0.430, batch=215\n",
      "14410: loss=0.088, reward_mean=0.410, reward_bound=0.321, batch=220\n",
      "14411: loss=0.088, reward_mean=0.500, reward_bound=0.387, batch=222\n",
      "14412: loss=0.088, reward_mean=0.490, reward_bound=0.387, batch=223\n",
      "14413: loss=0.090, reward_mean=0.330, reward_bound=0.413, batch=226\n",
      "14414: loss=0.089, reward_mean=0.510, reward_bound=0.409, batch=228\n",
      "14415: loss=0.090, reward_mean=0.510, reward_bound=0.430, batch=224\n",
      "14416: loss=0.089, reward_mean=0.480, reward_bound=0.345, batch=227\n",
      "14417: loss=0.090, reward_mean=0.420, reward_bound=0.349, batch=228\n",
      "14418: loss=0.088, reward_mean=0.480, reward_bound=0.392, batch=229\n",
      "14419: loss=0.090, reward_mean=0.460, reward_bound=0.430, batch=226\n",
      "14420: loss=0.089, reward_mean=0.500, reward_bound=0.368, batch=228\n",
      "14421: loss=0.089, reward_mean=0.440, reward_bound=0.392, batch=229\n",
      "14422: loss=0.090, reward_mean=0.450, reward_bound=0.430, batch=227\n",
      "14423: loss=0.090, reward_mean=0.490, reward_bound=0.469, batch=229\n",
      "14424: loss=0.090, reward_mean=0.280, reward_bound=0.387, batch=229\n",
      "14425: loss=0.090, reward_mean=0.480, reward_bound=0.405, batch=230\n",
      "14426: loss=0.090, reward_mean=0.440, reward_bound=0.376, batch=231\n",
      "14427: loss=0.091, reward_mean=0.490, reward_bound=0.430, batch=231\n",
      "14428: loss=0.088, reward_mean=0.390, reward_bound=0.478, batch=154\n",
      "14429: loss=0.090, reward_mean=0.460, reward_bound=0.072, batch=176\n",
      "14430: loss=0.089, reward_mean=0.370, reward_bound=0.061, batch=193\n",
      "14431: loss=0.091, reward_mean=0.270, reward_bound=0.089, batch=203\n",
      "14432: loss=0.090, reward_mean=0.490, reward_bound=0.130, batch=212\n",
      "14433: loss=0.093, reward_mean=0.390, reward_bound=0.150, batch=212\n",
      "14434: loss=0.089, reward_mean=0.430, reward_bound=0.185, batch=210\n",
      "14435: loss=0.089, reward_mean=0.430, reward_bound=0.194, batch=217\n",
      "14436: loss=0.092, reward_mean=0.490, reward_bound=0.206, batch=221\n",
      "14437: loss=0.095, reward_mean=0.430, reward_bound=0.229, batch=216\n",
      "14438: loss=0.095, reward_mean=0.490, reward_bound=0.254, batch=210\n",
      "14439: loss=0.095, reward_mean=0.490, reward_bound=0.206, batch=219\n",
      "14440: loss=0.095, reward_mean=0.490, reward_bound=0.225, batch=223\n",
      "14441: loss=0.094, reward_mean=0.480, reward_bound=0.254, batch=225\n",
      "14442: loss=0.093, reward_mean=0.540, reward_bound=0.282, batch=224\n",
      "14443: loss=0.093, reward_mean=0.480, reward_bound=0.314, batch=210\n",
      "14444: loss=0.093, reward_mean=0.430, reward_bound=0.304, batch=217\n",
      "14445: loss=0.091, reward_mean=0.480, reward_bound=0.349, batch=202\n",
      "14446: loss=0.093, reward_mean=0.460, reward_bound=0.254, batch=210\n",
      "14447: loss=0.095, reward_mean=0.380, reward_bound=0.274, batch=217\n",
      "14448: loss=0.093, reward_mean=0.430, reward_bound=0.282, batch=220\n",
      "14449: loss=0.093, reward_mean=0.350, reward_bound=0.254, batch=223\n",
      "14450: loss=0.094, reward_mean=0.400, reward_bound=0.335, batch=226\n",
      "14451: loss=0.095, reward_mean=0.410, reward_bound=0.316, batch=228\n",
      "14452: loss=0.093, reward_mean=0.420, reward_bound=0.349, batch=221\n",
      "14453: loss=0.092, reward_mean=0.430, reward_bound=0.387, batch=197\n",
      "14454: loss=0.090, reward_mean=0.450, reward_bound=0.147, batch=208\n",
      "14455: loss=0.092, reward_mean=0.400, reward_bound=0.169, batch=215\n",
      "14456: loss=0.091, reward_mean=0.520, reward_bound=0.260, batch=220\n",
      "14457: loss=0.094, reward_mean=0.450, reward_bound=0.282, batch=221\n",
      "14458: loss=0.093, reward_mean=0.400, reward_bound=0.314, batch=222\n",
      "14459: loss=0.092, reward_mean=0.440, reward_bound=0.349, batch=216\n",
      "14460: loss=0.092, reward_mean=0.370, reward_bound=0.176, batch=221\n",
      "14461: loss=0.090, reward_mean=0.450, reward_bound=0.349, batch=222\n",
      "14462: loss=0.092, reward_mean=0.460, reward_bound=0.387, batch=213\n",
      "14463: loss=0.092, reward_mean=0.490, reward_bound=0.301, batch=219\n",
      "14464: loss=0.093, reward_mean=0.570, reward_bound=0.314, batch=222\n",
      "14465: loss=0.093, reward_mean=0.460, reward_bound=0.349, batch=222\n",
      "14466: loss=0.093, reward_mean=0.540, reward_bound=0.387, batch=222\n",
      "14467: loss=0.093, reward_mean=0.430, reward_bound=0.292, batch=225\n",
      "14468: loss=0.094, reward_mean=0.440, reward_bound=0.314, batch=226\n",
      "14469: loss=0.094, reward_mean=0.440, reward_bound=0.241, batch=228\n",
      "14470: loss=0.093, reward_mean=0.550, reward_bound=0.289, batch=229\n",
      "14471: loss=0.094, reward_mean=0.370, reward_bound=0.405, batch=230\n",
      "14472: loss=0.094, reward_mean=0.490, reward_bound=0.418, batch=231\n",
      "14473: loss=0.096, reward_mean=0.380, reward_bound=0.430, batch=195\n",
      "14474: loss=0.096, reward_mean=0.500, reward_bound=0.194, batch=206\n",
      "14475: loss=0.097, reward_mean=0.430, reward_bound=0.217, batch=214\n",
      "14476: loss=0.098, reward_mean=0.350, reward_bound=0.252, batch=220\n",
      "14477: loss=0.095, reward_mean=0.480, reward_bound=0.254, batch=221\n",
      "14478: loss=0.096, reward_mean=0.400, reward_bound=0.282, batch=222\n",
      "14479: loss=0.097, reward_mean=0.510, reward_bound=0.314, batch=219\n",
      "14480: loss=0.097, reward_mean=0.370, reward_bound=0.349, batch=219\n",
      "14481: loss=0.098, reward_mean=0.500, reward_bound=0.387, batch=218\n",
      "14482: loss=0.097, reward_mean=0.440, reward_bound=0.282, batch=221\n",
      "14483: loss=0.097, reward_mean=0.350, reward_bound=0.314, batch=223\n",
      "14484: loss=0.097, reward_mean=0.540, reward_bound=0.349, batch=223\n",
      "14485: loss=0.096, reward_mean=0.380, reward_bound=0.372, batch=226\n",
      "14486: loss=0.096, reward_mean=0.490, reward_bound=0.387, batch=226\n",
      "14487: loss=0.095, reward_mean=0.430, reward_bound=0.268, batch=228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14488: loss=0.095, reward_mean=0.380, reward_bound=0.392, batch=229\n",
      "14489: loss=0.096, reward_mean=0.380, reward_bound=0.328, batch=230\n",
      "14490: loss=0.097, reward_mean=0.370, reward_bound=0.430, batch=211\n",
      "14491: loss=0.097, reward_mean=0.500, reward_bound=0.349, batch=216\n",
      "14492: loss=0.096, reward_mean=0.460, reward_bound=0.230, batch=221\n",
      "14493: loss=0.095, reward_mean=0.440, reward_bound=0.282, batch=223\n",
      "14494: loss=0.097, reward_mean=0.490, reward_bound=0.349, batch=221\n",
      "14495: loss=0.096, reward_mean=0.450, reward_bound=0.349, batch=224\n",
      "14496: loss=0.097, reward_mean=0.490, reward_bound=0.280, batch=227\n",
      "14497: loss=0.097, reward_mean=0.340, reward_bound=0.282, batch=228\n",
      "14498: loss=0.098, reward_mean=0.440, reward_bound=0.353, batch=229\n",
      "14499: loss=0.097, reward_mean=0.480, reward_bound=0.387, batch=222\n",
      "14500: loss=0.097, reward_mean=0.460, reward_bound=0.360, batch=225\n",
      "14501: loss=0.095, reward_mean=0.390, reward_bound=0.387, batch=226\n",
      "14502: loss=0.095, reward_mean=0.500, reward_bound=0.409, batch=228\n",
      "14503: loss=0.095, reward_mean=0.420, reward_bound=0.392, batch=229\n",
      "14504: loss=0.097, reward_mean=0.480, reward_bound=0.430, batch=221\n",
      "14505: loss=0.098, reward_mean=0.410, reward_bound=0.254, batch=223\n",
      "14506: loss=0.098, reward_mean=0.550, reward_bound=0.372, batch=226\n",
      "14507: loss=0.098, reward_mean=0.460, reward_bound=0.387, batch=225\n",
      "14508: loss=0.098, reward_mean=0.520, reward_bound=0.349, batch=226\n",
      "14509: loss=0.099, reward_mean=0.420, reward_bound=0.409, batch=228\n",
      "14510: loss=0.098, reward_mean=0.500, reward_bound=0.430, batch=228\n",
      "14511: loss=0.098, reward_mean=0.410, reward_bound=0.387, batch=228\n",
      "14512: loss=0.098, reward_mean=0.460, reward_bound=0.435, batch=229\n",
      "14513: loss=0.098, reward_mean=0.450, reward_bound=0.360, batch=230\n",
      "14514: loss=0.098, reward_mean=0.380, reward_bound=0.430, batch=230\n",
      "14515: loss=0.098, reward_mean=0.420, reward_bound=0.451, batch=231\n",
      "14516: loss=0.093, reward_mean=0.410, reward_bound=0.478, batch=183\n",
      "14517: loss=0.096, reward_mean=0.540, reward_bound=0.198, batch=198\n",
      "14518: loss=0.092, reward_mean=0.370, reward_bound=0.187, batch=208\n",
      "14519: loss=0.093, reward_mean=0.360, reward_bound=0.206, batch=213\n",
      "14520: loss=0.094, reward_mean=0.440, reward_bound=0.206, batch=218\n",
      "14521: loss=0.091, reward_mean=0.460, reward_bound=0.229, batch=217\n",
      "14522: loss=0.092, reward_mean=0.460, reward_bound=0.249, batch=222\n",
      "14523: loss=0.091, reward_mean=0.410, reward_bound=0.263, batch=225\n",
      "14524: loss=0.092, reward_mean=0.480, reward_bound=0.282, batch=217\n",
      "14525: loss=0.093, reward_mean=0.450, reward_bound=0.314, batch=213\n",
      "14526: loss=0.092, reward_mean=0.440, reward_bound=0.349, batch=208\n",
      "14527: loss=0.094, reward_mean=0.430, reward_bound=0.231, batch=215\n",
      "14528: loss=0.092, reward_mean=0.420, reward_bound=0.314, batch=217\n",
      "14529: loss=0.092, reward_mean=0.490, reward_bound=0.308, batch=222\n",
      "14530: loss=0.091, reward_mean=0.390, reward_bound=0.263, batch=225\n",
      "14531: loss=0.091, reward_mean=0.460, reward_bound=0.314, batch=225\n",
      "14532: loss=0.095, reward_mean=0.410, reward_bound=0.349, batch=225\n",
      "14533: loss=0.094, reward_mean=0.470, reward_bound=0.387, batch=216\n",
      "14534: loss=0.092, reward_mean=0.410, reward_bound=0.430, batch=205\n",
      "14535: loss=0.093, reward_mean=0.470, reward_bound=0.179, batch=213\n",
      "14536: loss=0.092, reward_mean=0.570, reward_bound=0.254, batch=217\n",
      "14537: loss=0.091, reward_mean=0.380, reward_bound=0.282, batch=220\n",
      "14538: loss=0.090, reward_mean=0.400, reward_bound=0.314, batch=220\n",
      "14539: loss=0.091, reward_mean=0.480, reward_bound=0.349, batch=223\n",
      "14540: loss=0.091, reward_mean=0.560, reward_bound=0.335, batch=226\n",
      "14541: loss=0.090, reward_mean=0.310, reward_bound=0.268, batch=228\n",
      "14542: loss=0.092, reward_mean=0.490, reward_bound=0.387, batch=224\n",
      "14543: loss=0.092, reward_mean=0.460, reward_bound=0.384, batch=227\n",
      "14544: loss=0.092, reward_mean=0.460, reward_bound=0.430, batch=217\n",
      "14545: loss=0.091, reward_mean=0.400, reward_bound=0.314, batch=220\n",
      "14546: loss=0.091, reward_mean=0.500, reward_bound=0.314, batch=223\n",
      "14547: loss=0.093, reward_mean=0.480, reward_bound=0.349, batch=224\n",
      "14548: loss=0.092, reward_mean=0.390, reward_bound=0.345, batch=227\n",
      "14549: loss=0.093, reward_mean=0.480, reward_bound=0.387, batch=224\n",
      "14550: loss=0.092, reward_mean=0.440, reward_bound=0.426, batch=227\n",
      "14551: loss=0.092, reward_mean=0.470, reward_bound=0.380, batch=229\n",
      "14552: loss=0.092, reward_mean=0.460, reward_bound=0.387, batch=228\n",
      "14553: loss=0.092, reward_mean=0.430, reward_bound=0.430, batch=219\n",
      "14554: loss=0.091, reward_mean=0.410, reward_bound=0.328, batch=223\n",
      "14555: loss=0.090, reward_mean=0.470, reward_bound=0.387, batch=225\n",
      "14556: loss=0.090, reward_mean=0.500, reward_bound=0.375, batch=227\n",
      "14557: loss=0.090, reward_mean=0.510, reward_bound=0.387, batch=228\n",
      "14558: loss=0.090, reward_mean=0.500, reward_bound=0.435, batch=229\n",
      "14559: loss=0.090, reward_mean=0.450, reward_bound=0.430, batch=229\n",
      "14560: loss=0.089, reward_mean=0.500, reward_bound=0.478, batch=231\n",
      "14561: loss=0.089, reward_mean=0.450, reward_bound=0.430, batch=231\n",
      "14562: loss=0.092, reward_mean=0.410, reward_bound=0.478, batch=208\n",
      "14563: loss=0.095, reward_mean=0.430, reward_bound=0.229, batch=214\n",
      "14564: loss=0.093, reward_mean=0.410, reward_bound=0.282, batch=219\n",
      "14565: loss=0.094, reward_mean=0.370, reward_bound=0.314, batch=222\n",
      "14566: loss=0.093, reward_mean=0.450, reward_bound=0.349, batch=221\n",
      "14567: loss=0.092, reward_mean=0.450, reward_bound=0.349, batch=223\n",
      "14568: loss=0.091, reward_mean=0.460, reward_bound=0.387, batch=222\n",
      "14569: loss=0.090, reward_mean=0.530, reward_bound=0.282, batch=224\n",
      "14570: loss=0.092, reward_mean=0.440, reward_bound=0.384, batch=227\n",
      "14571: loss=0.092, reward_mean=0.450, reward_bound=0.380, batch=229\n",
      "14572: loss=0.093, reward_mean=0.490, reward_bound=0.405, batch=230\n",
      "14573: loss=0.093, reward_mean=0.460, reward_bound=0.418, batch=231\n",
      "14574: loss=0.093, reward_mean=0.440, reward_bound=0.430, batch=220\n",
      "14575: loss=0.093, reward_mean=0.520, reward_bound=0.329, batch=224\n",
      "14576: loss=0.093, reward_mean=0.410, reward_bound=0.349, batch=225\n",
      "14577: loss=0.092, reward_mean=0.500, reward_bound=0.253, batch=227\n",
      "14578: loss=0.093, reward_mean=0.380, reward_bound=0.349, batch=228\n",
      "14579: loss=0.094, reward_mean=0.470, reward_bound=0.392, batch=229\n",
      "14580: loss=0.095, reward_mean=0.480, reward_bound=0.430, batch=226\n",
      "14581: loss=0.095, reward_mean=0.420, reward_bound=0.331, batch=228\n",
      "14582: loss=0.095, reward_mean=0.420, reward_bound=0.353, batch=229\n",
      "14583: loss=0.094, reward_mean=0.370, reward_bound=0.405, batch=230\n",
      "14584: loss=0.094, reward_mean=0.460, reward_bound=0.418, batch=231\n",
      "14585: loss=0.094, reward_mean=0.460, reward_bound=0.430, batch=231\n",
      "14586: loss=0.091, reward_mean=0.510, reward_bound=0.478, batch=222\n",
      "14587: loss=0.091, reward_mean=0.420, reward_bound=0.430, batch=223\n",
      "14588: loss=0.090, reward_mean=0.470, reward_bound=0.387, batch=225\n",
      "14589: loss=0.091, reward_mean=0.480, reward_bound=0.321, batch=227\n",
      "14590: loss=0.090, reward_mean=0.450, reward_bound=0.349, batch=228\n",
      "14591: loss=0.090, reward_mean=0.400, reward_bound=0.430, batch=225\n",
      "14592: loss=0.090, reward_mean=0.450, reward_bound=0.387, batch=226\n",
      "14593: loss=0.090, reward_mean=0.410, reward_bound=0.430, batch=227\n",
      "14594: loss=0.089, reward_mean=0.460, reward_bound=0.380, batch=229\n",
      "14595: loss=0.089, reward_mean=0.510, reward_bound=0.430, batch=229\n",
      "14596: loss=0.089, reward_mean=0.420, reward_bound=0.349, batch=229\n",
      "14597: loss=0.090, reward_mean=0.370, reward_bound=0.405, batch=230\n",
      "14598: loss=0.091, reward_mean=0.510, reward_bound=0.464, batch=231\n",
      "14599: loss=0.091, reward_mean=0.400, reward_bound=0.430, batch=231\n",
      "14600: loss=0.091, reward_mean=0.420, reward_bound=0.387, batch=231\n",
      "14601: loss=0.091, reward_mean=0.460, reward_bound=0.478, batch=223\n",
      "14602: loss=0.091, reward_mean=0.510, reward_bound=0.335, batch=226\n",
      "14603: loss=0.090, reward_mean=0.430, reward_bound=0.368, batch=228\n",
      "14604: loss=0.091, reward_mean=0.480, reward_bound=0.387, batch=227\n",
      "14605: loss=0.090, reward_mean=0.470, reward_bound=0.349, batch=228\n",
      "14606: loss=0.091, reward_mean=0.350, reward_bound=0.392, batch=229\n",
      "14607: loss=0.091, reward_mean=0.480, reward_bound=0.342, batch=230\n",
      "14608: loss=0.090, reward_mean=0.410, reward_bound=0.338, batch=231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14609: loss=0.090, reward_mean=0.450, reward_bound=0.430, batch=228\n",
      "14610: loss=0.091, reward_mean=0.400, reward_bound=0.392, batch=229\n",
      "14611: loss=0.091, reward_mean=0.450, reward_bound=0.450, batch=230\n",
      "14612: loss=0.091, reward_mean=0.430, reward_bound=0.430, batch=230\n",
      "14613: loss=0.091, reward_mean=0.470, reward_bound=0.464, batch=231\n",
      "14614: loss=0.091, reward_mean=0.470, reward_bound=0.478, batch=226\n",
      "14615: loss=0.091, reward_mean=0.500, reward_bound=0.478, batch=227\n",
      "14616: loss=0.092, reward_mean=0.410, reward_bound=0.330, batch=229\n",
      "14617: loss=0.092, reward_mean=0.480, reward_bound=0.405, batch=230\n",
      "14618: loss=0.091, reward_mean=0.430, reward_bound=0.430, batch=230\n",
      "14619: loss=0.091, reward_mean=0.350, reward_bound=0.464, batch=231\n",
      "14620: loss=0.092, reward_mean=0.480, reward_bound=0.478, batch=230\n",
      "14621: loss=0.092, reward_mean=0.320, reward_bound=0.387, batch=230\n",
      "14622: loss=0.092, reward_mean=0.480, reward_bound=0.478, batch=230\n",
      "14623: loss=0.092, reward_mean=0.460, reward_bound=0.464, batch=231\n",
      "14624: loss=0.092, reward_mean=0.480, reward_bound=0.478, batch=230\n",
      "14625: loss=0.092, reward_mean=0.490, reward_bound=0.418, batch=231\n",
      "14626: loss=0.092, reward_mean=0.580, reward_bound=0.478, batch=230\n",
      "14627: loss=0.092, reward_mean=0.460, reward_bound=0.488, batch=231\n",
      "14628: loss=0.092, reward_mean=0.420, reward_bound=0.478, batch=231\n",
      "14629: loss=0.092, reward_mean=0.450, reward_bound=0.430, batch=231\n",
      "14630: loss=0.092, reward_mean=0.380, reward_bound=0.387, batch=231\n",
      "14631: loss=0.092, reward_mean=0.420, reward_bound=0.387, batch=231\n",
      "14632: loss=0.092, reward_mean=0.420, reward_bound=0.478, batch=231\n",
      "14633: loss=0.092, reward_mean=0.410, reward_bound=0.387, batch=231\n",
      "14635: loss=0.078, reward_mean=0.370, reward_bound=0.000, batch=37\n",
      "14636: loss=0.077, reward_mean=0.500, reward_bound=0.000, batch=87\n",
      "14637: loss=0.079, reward_mean=0.490, reward_bound=0.001, batch=131\n",
      "14638: loss=0.082, reward_mean=0.470, reward_bound=0.007, batch=160\n",
      "14639: loss=0.086, reward_mean=0.520, reward_bound=0.025, batch=181\n",
      "14640: loss=0.091, reward_mean=0.450, reward_bound=0.042, batch=192\n",
      "14641: loss=0.093, reward_mean=0.380, reward_bound=0.052, batch=196\n",
      "14642: loss=0.092, reward_mean=0.510, reward_bound=0.065, batch=202\n",
      "14643: loss=0.091, reward_mean=0.440, reward_bound=0.080, batch=202\n",
      "14644: loss=0.092, reward_mean=0.460, reward_bound=0.098, batch=203\n",
      "14645: loss=0.094, reward_mean=0.530, reward_bound=0.109, batch=204\n",
      "14646: loss=0.092, reward_mean=0.450, reward_bound=0.122, batch=204\n",
      "14647: loss=0.090, reward_mean=0.360, reward_bound=0.135, batch=204\n",
      "14648: loss=0.094, reward_mean=0.500, reward_bound=0.150, batch=205\n",
      "14649: loss=0.096, reward_mean=0.490, reward_bound=0.167, batch=200\n",
      "14650: loss=0.093, reward_mean=0.450, reward_bound=0.185, batch=188\n",
      "14651: loss=0.095, reward_mean=0.390, reward_bound=0.137, batch=201\n",
      "14652: loss=0.092, reward_mean=0.530, reward_bound=0.185, batch=207\n",
      "14653: loss=0.095, reward_mean=0.400, reward_bound=0.206, batch=191\n",
      "14654: loss=0.098, reward_mean=0.440, reward_bound=0.185, batch=203\n",
      "14655: loss=0.095, reward_mean=0.450, reward_bound=0.206, batch=208\n",
      "14656: loss=0.097, reward_mean=0.480, reward_bound=0.229, batch=179\n",
      "14657: loss=0.095, reward_mean=0.450, reward_bound=0.126, batch=195\n",
      "14658: loss=0.095, reward_mean=0.460, reward_bound=0.167, batch=202\n",
      "14659: loss=0.097, reward_mean=0.480, reward_bound=0.206, batch=215\n",
      "14660: loss=0.097, reward_mean=0.460, reward_bound=0.206, batch=215\n",
      "14661: loss=0.097, reward_mean=0.410, reward_bound=0.254, batch=177\n",
      "14662: loss=0.092, reward_mean=0.490, reward_bound=0.119, batch=194\n",
      "14663: loss=0.092, reward_mean=0.410, reward_bound=0.109, batch=204\n",
      "14664: loss=0.093, reward_mean=0.420, reward_bound=0.135, batch=211\n",
      "14665: loss=0.095, reward_mean=0.510, reward_bound=0.185, batch=217\n",
      "14666: loss=0.098, reward_mean=0.550, reward_bound=0.229, batch=214\n",
      "14667: loss=0.100, reward_mean=0.510, reward_bound=0.254, batch=212\n",
      "14668: loss=0.104, reward_mean=0.390, reward_bound=0.282, batch=179\n",
      "14669: loss=0.100, reward_mean=0.520, reward_bound=0.174, batch=195\n",
      "14670: loss=0.101, reward_mean=0.490, reward_bound=0.185, batch=201\n",
      "14671: loss=0.101, reward_mean=0.460, reward_bound=0.229, batch=203\n",
      "14672: loss=0.101, reward_mean=0.540, reward_bound=0.271, batch=212\n",
      "14673: loss=0.100, reward_mean=0.490, reward_bound=0.263, batch=218\n",
      "14674: loss=0.102, reward_mean=0.540, reward_bound=0.282, batch=216\n",
      "14675: loss=0.103, reward_mean=0.380, reward_bound=0.314, batch=172\n",
      "14676: loss=0.099, reward_mean=0.530, reward_bound=0.098, batch=189\n",
      "14677: loss=0.099, reward_mean=0.430, reward_bound=0.141, batch=202\n",
      "14678: loss=0.098, reward_mean=0.410, reward_bound=0.167, batch=209\n",
      "14679: loss=0.100, reward_mean=0.390, reward_bound=0.185, batch=215\n",
      "14680: loss=0.102, reward_mean=0.470, reward_bound=0.229, batch=213\n",
      "14681: loss=0.103, reward_mean=0.540, reward_bound=0.254, batch=213\n",
      "14682: loss=0.103, reward_mean=0.410, reward_bound=0.254, batch=218\n",
      "14683: loss=0.104, reward_mean=0.320, reward_bound=0.282, batch=219\n",
      "14684: loss=0.105, reward_mean=0.390, reward_bound=0.314, batch=212\n",
      "14685: loss=0.107, reward_mean=0.460, reward_bound=0.349, batch=148\n",
      "14686: loss=0.106, reward_mean=0.500, reward_bound=0.090, batch=173\n",
      "14687: loss=0.105, reward_mean=0.480, reward_bound=0.122, batch=189\n",
      "14688: loss=0.107, reward_mean=0.450, reward_bound=0.150, batch=201\n",
      "14689: loss=0.103, reward_mean=0.500, reward_bound=0.167, batch=203\n",
      "14690: loss=0.103, reward_mean=0.450, reward_bound=0.185, batch=208\n",
      "14691: loss=0.104, reward_mean=0.420, reward_bound=0.187, batch=215\n",
      "14692: loss=0.104, reward_mean=0.450, reward_bound=0.229, batch=207\n",
      "14693: loss=0.109, reward_mean=0.480, reward_bound=0.254, batch=200\n",
      "14694: loss=0.109, reward_mean=0.460, reward_bound=0.150, batch=209\n",
      "14695: loss=0.107, reward_mean=0.400, reward_bound=0.206, batch=215\n",
      "14696: loss=0.106, reward_mean=0.450, reward_bound=0.254, batch=216\n",
      "14697: loss=0.106, reward_mean=0.420, reward_bound=0.282, batch=202\n",
      "14698: loss=0.107, reward_mean=0.440, reward_bound=0.229, batch=209\n",
      "14699: loss=0.107, reward_mean=0.380, reward_bound=0.239, batch=216\n",
      "14700: loss=0.106, reward_mean=0.470, reward_bound=0.254, batch=220\n",
      "14701: loss=0.106, reward_mean=0.420, reward_bound=0.282, batch=220\n",
      "14702: loss=0.107, reward_mean=0.340, reward_bound=0.266, batch=224\n",
      "14703: loss=0.108, reward_mean=0.480, reward_bound=0.311, batch=227\n",
      "14704: loss=0.107, reward_mean=0.490, reward_bound=0.302, batch=229\n",
      "14705: loss=0.109, reward_mean=0.430, reward_bound=0.314, batch=213\n",
      "14706: loss=0.108, reward_mean=0.410, reward_bound=0.254, batch=218\n",
      "14707: loss=0.109, reward_mean=0.460, reward_bound=0.282, batch=221\n",
      "14708: loss=0.109, reward_mean=0.390, reward_bound=0.314, batch=223\n",
      "14709: loss=0.109, reward_mean=0.460, reward_bound=0.335, batch=226\n",
      "14710: loss=0.108, reward_mean=0.460, reward_bound=0.331, batch=228\n",
      "14711: loss=0.109, reward_mean=0.480, reward_bound=0.349, batch=205\n",
      "14712: loss=0.108, reward_mean=0.390, reward_bound=0.254, batch=210\n",
      "14713: loss=0.109, reward_mean=0.460, reward_bound=0.254, batch=216\n",
      "14714: loss=0.108, reward_mean=0.410, reward_bound=0.282, batch=218\n",
      "14715: loss=0.108, reward_mean=0.360, reward_bound=0.152, batch=222\n",
      "14716: loss=0.108, reward_mean=0.390, reward_bound=0.272, batch=225\n",
      "14717: loss=0.109, reward_mean=0.500, reward_bound=0.349, batch=223\n",
      "14718: loss=0.109, reward_mean=0.340, reward_bound=0.282, batch=225\n",
      "14719: loss=0.107, reward_mean=0.440, reward_bound=0.387, batch=143\n",
      "14720: loss=0.110, reward_mean=0.400, reward_bound=0.041, batch=170\n",
      "14721: loss=0.112, reward_mean=0.460, reward_bound=0.096, batch=189\n",
      "14722: loss=0.106, reward_mean=0.430, reward_bound=0.122, batch=201\n",
      "14723: loss=0.103, reward_mean=0.420, reward_bound=0.150, batch=208\n",
      "14724: loss=0.102, reward_mean=0.450, reward_bound=0.167, batch=209\n",
      "14725: loss=0.102, reward_mean=0.460, reward_bound=0.185, batch=214\n",
      "14726: loss=0.104, reward_mean=0.450, reward_bound=0.206, batch=214\n",
      "14727: loss=0.109, reward_mean=0.430, reward_bound=0.229, batch=213\n",
      "14728: loss=0.108, reward_mean=0.340, reward_bound=0.229, batch=218\n",
      "14729: loss=0.106, reward_mean=0.470, reward_bound=0.254, batch=214\n",
      "14730: loss=0.107, reward_mean=0.440, reward_bound=0.254, batch=219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14731: loss=0.105, reward_mean=0.530, reward_bound=0.282, batch=202\n",
      "14732: loss=0.103, reward_mean=0.400, reward_bound=0.172, batch=211\n",
      "14733: loss=0.106, reward_mean=0.450, reward_bound=0.185, batch=217\n",
      "14734: loss=0.103, reward_mean=0.410, reward_bound=0.206, batch=221\n",
      "14735: loss=0.104, reward_mean=0.480, reward_bound=0.254, batch=224\n",
      "14736: loss=0.105, reward_mean=0.520, reward_bound=0.282, batch=226\n",
      "14737: loss=0.108, reward_mean=0.550, reward_bound=0.314, batch=209\n",
      "14738: loss=0.110, reward_mean=0.500, reward_bound=0.265, batch=216\n",
      "14739: loss=0.109, reward_mean=0.420, reward_bound=0.314, batch=220\n",
      "14740: loss=0.108, reward_mean=0.510, reward_bound=0.274, batch=224\n",
      "14741: loss=0.109, reward_mean=0.500, reward_bound=0.282, batch=225\n",
      "14742: loss=0.108, reward_mean=0.490, reward_bound=0.349, batch=196\n",
      "14743: loss=0.106, reward_mean=0.480, reward_bound=0.268, batch=207\n",
      "14744: loss=0.107, reward_mean=0.470, reward_bound=0.229, batch=214\n",
      "14745: loss=0.106, reward_mean=0.390, reward_bound=0.229, batch=219\n",
      "14746: loss=0.107, reward_mean=0.420, reward_bound=0.254, batch=221\n",
      "14747: loss=0.107, reward_mean=0.390, reward_bound=0.282, batch=223\n",
      "14748: loss=0.106, reward_mean=0.500, reward_bound=0.314, batch=220\n",
      "14749: loss=0.107, reward_mean=0.490, reward_bound=0.338, batch=224\n",
      "14750: loss=0.106, reward_mean=0.480, reward_bound=0.342, batch=227\n",
      "14751: loss=0.105, reward_mean=0.470, reward_bound=0.380, batch=229\n",
      "14752: loss=0.106, reward_mean=0.430, reward_bound=0.387, batch=195\n",
      "14753: loss=0.105, reward_mean=0.420, reward_bound=0.135, batch=205\n",
      "14754: loss=0.107, reward_mean=0.440, reward_bound=0.189, batch=213\n",
      "14755: loss=0.106, reward_mean=0.560, reward_bound=0.254, batch=216\n",
      "14756: loss=0.104, reward_mean=0.460, reward_bound=0.254, batch=220\n",
      "14757: loss=0.106, reward_mean=0.370, reward_bound=0.282, batch=218\n",
      "14758: loss=0.107, reward_mean=0.460, reward_bound=0.282, batch=221\n",
      "14759: loss=0.107, reward_mean=0.490, reward_bound=0.282, batch=224\n",
      "14760: loss=0.107, reward_mean=0.460, reward_bound=0.314, batch=218\n",
      "14761: loss=0.107, reward_mean=0.450, reward_bound=0.349, batch=215\n",
      "14762: loss=0.107, reward_mean=0.350, reward_bound=0.314, batch=219\n",
      "14763: loss=0.106, reward_mean=0.450, reward_bound=0.265, batch=223\n",
      "14764: loss=0.107, reward_mean=0.440, reward_bound=0.314, batch=225\n",
      "14765: loss=0.109, reward_mean=0.480, reward_bound=0.349, batch=226\n",
      "14766: loss=0.109, reward_mean=0.370, reward_bound=0.316, batch=228\n",
      "14767: loss=0.106, reward_mean=0.430, reward_bound=0.387, batch=222\n",
      "14768: loss=0.107, reward_mean=0.320, reward_bound=0.272, batch=225\n",
      "14769: loss=0.107, reward_mean=0.420, reward_bound=0.349, batch=225\n",
      "14770: loss=0.107, reward_mean=0.380, reward_bound=0.289, batch=227\n",
      "14771: loss=0.106, reward_mean=0.430, reward_bound=0.380, batch=229\n",
      "14772: loss=0.107, reward_mean=0.510, reward_bound=0.387, batch=229\n",
      "14773: loss=0.106, reward_mean=0.430, reward_bound=0.405, batch=230\n",
      "14774: loss=0.106, reward_mean=0.490, reward_bound=0.406, batch=231\n",
      "14775: loss=0.108, reward_mean=0.370, reward_bound=0.430, batch=116\n",
      "14776: loss=0.111, reward_mean=0.480, reward_bound=0.038, batch=149\n",
      "14777: loss=0.110, reward_mean=0.500, reward_bound=0.065, batch=170\n",
      "14778: loss=0.108, reward_mean=0.520, reward_bound=0.077, batch=189\n",
      "14779: loss=0.105, reward_mean=0.410, reward_bound=0.098, batch=200\n",
      "14780: loss=0.103, reward_mean=0.390, reward_bound=0.122, batch=200\n",
      "14781: loss=0.104, reward_mean=0.360, reward_bound=0.135, batch=208\n",
      "14782: loss=0.108, reward_mean=0.370, reward_bound=0.167, batch=209\n",
      "14783: loss=0.108, reward_mean=0.410, reward_bound=0.157, batch=216\n",
      "14784: loss=0.107, reward_mean=0.460, reward_bound=0.206, batch=210\n",
      "14785: loss=0.107, reward_mean=0.450, reward_bound=0.229, batch=207\n",
      "14786: loss=0.107, reward_mean=0.400, reward_bound=0.167, batch=214\n",
      "14787: loss=0.104, reward_mean=0.490, reward_bound=0.229, batch=219\n",
      "14788: loss=0.107, reward_mean=0.420, reward_bound=0.254, batch=203\n",
      "14789: loss=0.107, reward_mean=0.420, reward_bound=0.254, batch=211\n",
      "14790: loss=0.106, reward_mean=0.410, reward_bound=0.282, batch=196\n",
      "14791: loss=0.106, reward_mean=0.330, reward_bound=0.167, batch=205\n",
      "14792: loss=0.106, reward_mean=0.470, reward_bound=0.210, batch=213\n",
      "14793: loss=0.104, reward_mean=0.610, reward_bound=0.254, batch=216\n",
      "14794: loss=0.104, reward_mean=0.430, reward_bound=0.282, batch=220\n",
      "14795: loss=0.108, reward_mean=0.410, reward_bound=0.314, batch=194\n",
      "14796: loss=0.106, reward_mean=0.510, reward_bound=0.254, batch=205\n",
      "14797: loss=0.107, reward_mean=0.580, reward_bound=0.260, batch=213\n",
      "14798: loss=0.110, reward_mean=0.480, reward_bound=0.282, batch=217\n",
      "14799: loss=0.109, reward_mean=0.470, reward_bound=0.302, batch=222\n",
      "14800: loss=0.110, reward_mean=0.410, reward_bound=0.292, batch=225\n",
      "14801: loss=0.110, reward_mean=0.400, reward_bound=0.289, batch=227\n",
      "14802: loss=0.110, reward_mean=0.410, reward_bound=0.314, batch=228\n",
      "14803: loss=0.111, reward_mean=0.390, reward_bound=0.349, batch=198\n",
      "14804: loss=0.114, reward_mean=0.450, reward_bound=0.187, batch=208\n",
      "14805: loss=0.109, reward_mean=0.480, reward_bound=0.231, batch=215\n",
      "14806: loss=0.110, reward_mean=0.510, reward_bound=0.254, batch=217\n",
      "14807: loss=0.110, reward_mean=0.430, reward_bound=0.206, batch=221\n",
      "14808: loss=0.110, reward_mean=0.470, reward_bound=0.282, batch=221\n",
      "14809: loss=0.110, reward_mean=0.460, reward_bound=0.254, batch=224\n",
      "14810: loss=0.108, reward_mean=0.390, reward_bound=0.314, batch=223\n",
      "14811: loss=0.109, reward_mean=0.370, reward_bound=0.301, batch=226\n",
      "14812: loss=0.109, reward_mean=0.400, reward_bound=0.349, batch=220\n",
      "14813: loss=0.109, reward_mean=0.420, reward_bound=0.314, batch=222\n",
      "14814: loss=0.109, reward_mean=0.470, reward_bound=0.349, batch=224\n",
      "14815: loss=0.108, reward_mean=0.400, reward_bound=0.308, batch=227\n",
      "14816: loss=0.104, reward_mean=0.530, reward_bound=0.387, batch=185\n",
      "14817: loss=0.104, reward_mean=0.500, reward_bound=0.167, batch=198\n",
      "14818: loss=0.100, reward_mean=0.460, reward_bound=0.206, batch=207\n",
      "14819: loss=0.100, reward_mean=0.380, reward_bound=0.202, batch=215\n",
      "14820: loss=0.098, reward_mean=0.470, reward_bound=0.254, batch=219\n",
      "14821: loss=0.099, reward_mean=0.430, reward_bound=0.265, batch=223\n",
      "14822: loss=0.099, reward_mean=0.480, reward_bound=0.282, batch=223\n",
      "14823: loss=0.101, reward_mean=0.470, reward_bound=0.314, batch=212\n",
      "14824: loss=0.101, reward_mean=0.400, reward_bound=0.254, batch=217\n",
      "14825: loss=0.101, reward_mean=0.480, reward_bound=0.314, batch=219\n",
      "14826: loss=0.101, reward_mean=0.420, reward_bound=0.254, batch=222\n",
      "14827: loss=0.101, reward_mean=0.480, reward_bound=0.324, batch=225\n",
      "14828: loss=0.101, reward_mean=0.440, reward_bound=0.349, batch=218\n",
      "14829: loss=0.100, reward_mean=0.470, reward_bound=0.314, batch=221\n",
      "14830: loss=0.102, reward_mean=0.480, reward_bound=0.387, batch=207\n",
      "14831: loss=0.107, reward_mean=0.390, reward_bound=0.282, batch=214\n",
      "14832: loss=0.107, reward_mean=0.330, reward_bound=0.226, batch=220\n",
      "14833: loss=0.109, reward_mean=0.300, reward_bound=0.304, batch=224\n",
      "14834: loss=0.108, reward_mean=0.490, reward_bound=0.314, batch=222\n",
      "14835: loss=0.103, reward_mean=0.480, reward_bound=0.349, batch=220\n",
      "14836: loss=0.104, reward_mean=0.500, reward_bound=0.338, batch=224\n",
      "14837: loss=0.104, reward_mean=0.450, reward_bound=0.280, batch=227\n",
      "14838: loss=0.103, reward_mean=0.460, reward_bound=0.314, batch=228\n",
      "14839: loss=0.102, reward_mean=0.340, reward_bound=0.353, batch=229\n",
      "14840: loss=0.103, reward_mean=0.490, reward_bound=0.387, batch=223\n",
      "14841: loss=0.102, reward_mean=0.440, reward_bound=0.387, batch=225\n",
      "14842: loss=0.102, reward_mean=0.480, reward_bound=0.430, batch=173\n",
      "14843: loss=0.097, reward_mean=0.440, reward_bound=0.105, batch=191\n",
      "14844: loss=0.097, reward_mean=0.440, reward_bound=0.122, batch=200\n",
      "14845: loss=0.099, reward_mean=0.440, reward_bound=0.167, batch=208\n",
      "14846: loss=0.097, reward_mean=0.400, reward_bound=0.206, batch=210\n",
      "14847: loss=0.099, reward_mean=0.470, reward_bound=0.229, batch=216\n",
      "14848: loss=0.098, reward_mean=0.510, reward_bound=0.282, batch=220\n",
      "14849: loss=0.098, reward_mean=0.460, reward_bound=0.274, batch=224\n",
      "14850: loss=0.100, reward_mean=0.410, reward_bound=0.314, batch=213\n",
      "14851: loss=0.100, reward_mean=0.440, reward_bound=0.349, batch=210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14852: loss=0.099, reward_mean=0.440, reward_bound=0.274, batch=217\n",
      "14853: loss=0.102, reward_mean=0.430, reward_bound=0.277, batch=222\n",
      "14854: loss=0.100, reward_mean=0.390, reward_bound=0.292, batch=225\n",
      "14855: loss=0.100, reward_mean=0.290, reward_bound=0.314, batch=225\n",
      "14856: loss=0.099, reward_mean=0.460, reward_bound=0.349, batch=225\n",
      "14857: loss=0.099, reward_mean=0.450, reward_bound=0.329, batch=227\n",
      "14858: loss=0.099, reward_mean=0.400, reward_bound=0.380, batch=229\n",
      "14859: loss=0.101, reward_mean=0.430, reward_bound=0.387, batch=214\n",
      "14860: loss=0.101, reward_mean=0.390, reward_bound=0.303, batch=220\n",
      "14861: loss=0.101, reward_mean=0.410, reward_bound=0.314, batch=222\n",
      "14862: loss=0.100, reward_mean=0.450, reward_bound=0.263, batch=225\n",
      "14863: loss=0.100, reward_mean=0.400, reward_bound=0.349, batch=226\n",
      "14864: loss=0.100, reward_mean=0.430, reward_bound=0.349, batch=227\n",
      "14865: loss=0.100, reward_mean=0.460, reward_bound=0.387, batch=226\n",
      "14866: loss=0.099, reward_mean=0.430, reward_bound=0.331, batch=228\n",
      "14867: loss=0.099, reward_mean=0.470, reward_bound=0.392, batch=229\n",
      "14868: loss=0.101, reward_mean=0.430, reward_bound=0.430, batch=203\n",
      "14869: loss=0.099, reward_mean=0.510, reward_bound=0.220, batch=212\n",
      "14870: loss=0.098, reward_mean=0.430, reward_bound=0.206, batch=220\n",
      "14871: loss=0.097, reward_mean=0.420, reward_bound=0.229, batch=223\n",
      "14872: loss=0.098, reward_mean=0.430, reward_bound=0.282, batch=225\n",
      "14873: loss=0.098, reward_mean=0.400, reward_bound=0.314, batch=220\n",
      "14874: loss=0.098, reward_mean=0.450, reward_bound=0.314, batch=223\n",
      "14875: loss=0.103, reward_mean=0.470, reward_bound=0.349, batch=221\n",
      "14876: loss=0.103, reward_mean=0.390, reward_bound=0.254, batch=224\n",
      "14877: loss=0.103, reward_mean=0.460, reward_bound=0.384, batch=227\n",
      "14878: loss=0.101, reward_mean=0.420, reward_bound=0.387, batch=222\n",
      "14879: loss=0.101, reward_mean=0.350, reward_bound=0.387, batch=223\n",
      "14880: loss=0.101, reward_mean=0.520, reward_bound=0.413, batch=226\n",
      "14881: loss=0.101, reward_mean=0.430, reward_bound=0.409, batch=228\n",
      "14882: loss=0.103, reward_mean=0.540, reward_bound=0.430, batch=219\n",
      "14883: loss=0.102, reward_mean=0.340, reward_bound=0.324, batch=223\n",
      "14884: loss=0.102, reward_mean=0.450, reward_bound=0.387, batch=222\n",
      "14885: loss=0.103, reward_mean=0.440, reward_bound=0.272, batch=225\n",
      "14886: loss=0.101, reward_mean=0.430, reward_bound=0.349, batch=226\n",
      "14887: loss=0.101, reward_mean=0.320, reward_bound=0.331, batch=228\n",
      "14888: loss=0.101, reward_mean=0.500, reward_bound=0.353, batch=229\n",
      "14889: loss=0.101, reward_mean=0.390, reward_bound=0.387, batch=228\n",
      "14890: loss=0.102, reward_mean=0.440, reward_bound=0.325, batch=229\n",
      "14891: loss=0.102, reward_mean=0.340, reward_bound=0.430, batch=224\n",
      "14892: loss=0.101, reward_mean=0.440, reward_bound=0.254, batch=226\n",
      "14893: loss=0.102, reward_mean=0.440, reward_bound=0.409, batch=228\n",
      "14894: loss=0.102, reward_mean=0.390, reward_bound=0.430, batch=228\n",
      "14895: loss=0.102, reward_mean=0.460, reward_bound=0.362, batch=229\n",
      "14896: loss=0.102, reward_mean=0.550, reward_bound=0.430, batch=229\n",
      "14897: loss=0.102, reward_mean=0.490, reward_bound=0.401, batch=230\n",
      "14898: loss=0.087, reward_mean=0.380, reward_bound=0.478, batch=91\n",
      "14899: loss=0.095, reward_mean=0.400, reward_bound=0.000, batch=131\n",
      "14900: loss=0.094, reward_mean=0.430, reward_bound=0.031, batch=159\n",
      "14901: loss=0.090, reward_mean=0.470, reward_bound=0.047, batch=177\n",
      "14902: loss=0.094, reward_mean=0.410, reward_bound=0.072, batch=191\n",
      "14903: loss=0.086, reward_mean=0.460, reward_bound=0.098, batch=203\n",
      "14904: loss=0.088, reward_mean=0.510, reward_bound=0.122, batch=202\n",
      "14905: loss=0.089, reward_mean=0.400, reward_bound=0.150, batch=204\n",
      "14906: loss=0.089, reward_mean=0.470, reward_bound=0.167, batch=207\n",
      "14907: loss=0.087, reward_mean=0.520, reward_bound=0.185, batch=207\n",
      "14908: loss=0.089, reward_mean=0.350, reward_bound=0.198, batch=215\n",
      "14909: loss=0.093, reward_mean=0.440, reward_bound=0.206, batch=219\n",
      "14910: loss=0.095, reward_mean=0.420, reward_bound=0.229, batch=210\n",
      "14911: loss=0.099, reward_mean=0.510, reward_bound=0.254, batch=195\n",
      "14912: loss=0.098, reward_mean=0.450, reward_bound=0.210, batch=206\n",
      "14913: loss=0.098, reward_mean=0.390, reward_bound=0.150, batch=213\n",
      "14914: loss=0.099, reward_mean=0.470, reward_bound=0.198, batch=219\n",
      "14915: loss=0.093, reward_mean=0.460, reward_bound=0.282, batch=197\n",
      "14916: loss=0.092, reward_mean=0.450, reward_bound=0.185, batch=207\n",
      "14917: loss=0.092, reward_mean=0.460, reward_bound=0.229, batch=214\n",
      "14918: loss=0.096, reward_mean=0.460, reward_bound=0.249, batch=220\n",
      "14919: loss=0.099, reward_mean=0.470, reward_bound=0.254, batch=223\n",
      "14920: loss=0.098, reward_mean=0.550, reward_bound=0.282, batch=225\n",
      "14921: loss=0.100, reward_mean=0.460, reward_bound=0.314, batch=199\n",
      "14922: loss=0.099, reward_mean=0.390, reward_bound=0.157, batch=209\n",
      "14923: loss=0.096, reward_mean=0.420, reward_bound=0.229, batch=214\n",
      "14924: loss=0.098, reward_mean=0.460, reward_bound=0.282, batch=214\n",
      "14925: loss=0.099, reward_mean=0.370, reward_bound=0.314, batch=217\n",
      "14926: loss=0.100, reward_mean=0.410, reward_bound=0.308, batch=222\n",
      "14927: loss=0.097, reward_mean=0.490, reward_bound=0.349, batch=189\n",
      "14928: loss=0.097, reward_mean=0.430, reward_bound=0.174, batch=202\n",
      "14929: loss=0.096, reward_mean=0.480, reward_bound=0.185, batch=210\n",
      "14930: loss=0.097, reward_mean=0.500, reward_bound=0.229, batch=216\n",
      "14931: loss=0.098, reward_mean=0.450, reward_bound=0.254, batch=215\n",
      "14932: loss=0.099, reward_mean=0.380, reward_bound=0.189, batch=220\n",
      "14933: loss=0.100, reward_mean=0.500, reward_bound=0.282, batch=221\n",
      "14934: loss=0.100, reward_mean=0.460, reward_bound=0.314, batch=219\n",
      "14935: loss=0.100, reward_mean=0.450, reward_bound=0.282, batch=222\n",
      "14936: loss=0.096, reward_mean=0.380, reward_bound=0.349, batch=217\n",
      "14937: loss=0.095, reward_mean=0.490, reward_bound=0.380, batch=222\n",
      "14938: loss=0.096, reward_mean=0.430, reward_bound=0.324, batch=225\n",
      "14939: loss=0.097, reward_mean=0.490, reward_bound=0.349, batch=225\n",
      "14940: loss=0.096, reward_mean=0.490, reward_bound=0.387, batch=179\n",
      "14941: loss=0.094, reward_mean=0.480, reward_bound=0.157, batch=195\n",
      "14942: loss=0.092, reward_mean=0.440, reward_bound=0.189, batch=206\n",
      "14943: loss=0.092, reward_mean=0.390, reward_bound=0.176, batch=214\n",
      "14944: loss=0.092, reward_mean=0.480, reward_bound=0.206, batch=216\n",
      "14945: loss=0.091, reward_mean=0.410, reward_bound=0.254, batch=215\n",
      "14946: loss=0.091, reward_mean=0.440, reward_bound=0.240, batch=220\n",
      "14947: loss=0.092, reward_mean=0.470, reward_bound=0.282, batch=212\n",
      "14948: loss=0.090, reward_mean=0.430, reward_bound=0.191, batch=218\n",
      "14949: loss=0.092, reward_mean=0.440, reward_bound=0.286, batch=222\n",
      "14950: loss=0.095, reward_mean=0.380, reward_bound=0.314, batch=218\n",
      "14951: loss=0.094, reward_mean=0.470, reward_bound=0.289, batch=222\n",
      "14952: loss=0.094, reward_mean=0.470, reward_bound=0.349, batch=209\n",
      "14953: loss=0.095, reward_mean=0.420, reward_bound=0.265, batch=216\n",
      "14954: loss=0.096, reward_mean=0.410, reward_bound=0.282, batch=220\n",
      "14955: loss=0.095, reward_mean=0.440, reward_bound=0.274, batch=224\n",
      "14956: loss=0.095, reward_mean=0.440, reward_bound=0.282, batch=226\n",
      "14957: loss=0.093, reward_mean=0.330, reward_bound=0.368, batch=228\n",
      "14958: loss=0.093, reward_mean=0.380, reward_bound=0.387, batch=214\n",
      "14959: loss=0.092, reward_mean=0.460, reward_bound=0.349, batch=218\n",
      "14960: loss=0.092, reward_mean=0.520, reward_bound=0.349, batch=220\n",
      "14961: loss=0.091, reward_mean=0.420, reward_bound=0.314, batch=223\n",
      "14962: loss=0.093, reward_mean=0.500, reward_bound=0.335, batch=226\n",
      "14963: loss=0.093, reward_mean=0.430, reward_bound=0.331, batch=228\n",
      "14964: loss=0.093, reward_mean=0.420, reward_bound=0.349, batch=227\n",
      "14965: loss=0.093, reward_mean=0.500, reward_bound=0.387, batch=224\n",
      "14966: loss=0.093, reward_mean=0.540, reward_bound=0.426, batch=227\n",
      "14967: loss=0.092, reward_mean=0.480, reward_bound=0.414, batch=229\n",
      "14968: loss=0.092, reward_mean=0.460, reward_bound=0.405, batch=230\n",
      "14969: loss=0.095, reward_mean=0.440, reward_bound=0.430, batch=176\n",
      "14970: loss=0.092, reward_mean=0.540, reward_bound=0.196, batch=193\n",
      "14971: loss=0.097, reward_mean=0.450, reward_bound=0.206, batch=202\n",
      "14972: loss=0.096, reward_mean=0.370, reward_bound=0.236, batch=211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14973: loss=0.096, reward_mean=0.450, reward_bound=0.254, batch=213\n",
      "14974: loss=0.094, reward_mean=0.460, reward_bound=0.282, batch=208\n",
      "14975: loss=0.093, reward_mean=0.530, reward_bound=0.282, batch=213\n",
      "14976: loss=0.095, reward_mean=0.420, reward_bound=0.314, batch=207\n",
      "14977: loss=0.095, reward_mean=0.440, reward_bound=0.150, batch=214\n",
      "14978: loss=0.093, reward_mean=0.370, reward_bound=0.229, batch=219\n",
      "14979: loss=0.092, reward_mean=0.510, reward_bound=0.282, batch=220\n",
      "14980: loss=0.095, reward_mean=0.440, reward_bound=0.314, batch=219\n",
      "14981: loss=0.096, reward_mean=0.470, reward_bound=0.349, batch=214\n",
      "14982: loss=0.095, reward_mean=0.390, reward_bound=0.206, batch=219\n",
      "14983: loss=0.096, reward_mean=0.450, reward_bound=0.239, batch=223\n",
      "14984: loss=0.095, reward_mean=0.480, reward_bound=0.301, batch=226\n",
      "14985: loss=0.099, reward_mean=0.490, reward_bound=0.314, batch=226\n",
      "14986: loss=0.096, reward_mean=0.470, reward_bound=0.349, batch=226\n",
      "14987: loss=0.096, reward_mean=0.440, reward_bound=0.368, batch=228\n",
      "14988: loss=0.095, reward_mean=0.460, reward_bound=0.387, batch=209\n",
      "14989: loss=0.098, reward_mean=0.410, reward_bound=0.203, batch=216\n",
      "14990: loss=0.095, reward_mean=0.540, reward_bound=0.282, batch=220\n",
      "14991: loss=0.096, reward_mean=0.450, reward_bound=0.314, batch=223\n",
      "14992: loss=0.095, reward_mean=0.480, reward_bound=0.271, batch=226\n",
      "14993: loss=0.096, reward_mean=0.460, reward_bound=0.349, batch=226\n",
      "14994: loss=0.097, reward_mean=0.500, reward_bound=0.387, batch=226\n",
      "14995: loss=0.097, reward_mean=0.400, reward_bound=0.430, batch=205\n",
      "14996: loss=0.097, reward_mean=0.410, reward_bound=0.138, batch=213\n",
      "14997: loss=0.097, reward_mean=0.400, reward_bound=0.220, batch=219\n",
      "14998: loss=0.097, reward_mean=0.460, reward_bound=0.239, batch=223\n",
      "14999: loss=0.097, reward_mean=0.400, reward_bound=0.282, batch=223\n",
      "15000: loss=0.097, reward_mean=0.380, reward_bound=0.290, batch=226\n",
      "15001: loss=0.096, reward_mean=0.480, reward_bound=0.314, batch=227\n",
      "15002: loss=0.097, reward_mean=0.360, reward_bound=0.349, batch=228\n",
      "15003: loss=0.098, reward_mean=0.550, reward_bound=0.387, batch=227\n",
      "15004: loss=0.098, reward_mean=0.450, reward_bound=0.380, batch=229\n",
      "15005: loss=0.097, reward_mean=0.450, reward_bound=0.387, batch=229\n",
      "15006: loss=0.097, reward_mean=0.430, reward_bound=0.405, batch=230\n",
      "15007: loss=0.098, reward_mean=0.370, reward_bound=0.386, batch=231\n",
      "15008: loss=0.097, reward_mean=0.410, reward_bound=0.430, batch=216\n",
      "15009: loss=0.096, reward_mean=0.430, reward_bound=0.314, batch=220\n",
      "15010: loss=0.097, reward_mean=0.410, reward_bound=0.282, batch=223\n",
      "15011: loss=0.097, reward_mean=0.470, reward_bound=0.314, batch=225\n",
      "15012: loss=0.095, reward_mean=0.430, reward_bound=0.349, batch=226\n",
      "15013: loss=0.097, reward_mean=0.450, reward_bound=0.387, batch=225\n",
      "15014: loss=0.096, reward_mean=0.510, reward_bound=0.356, batch=227\n",
      "15015: loss=0.098, reward_mean=0.450, reward_bound=0.422, batch=229\n",
      "15016: loss=0.098, reward_mean=0.460, reward_bound=0.430, batch=226\n",
      "15017: loss=0.098, reward_mean=0.400, reward_bound=0.387, batch=227\n",
      "15018: loss=0.098, reward_mean=0.430, reward_bound=0.422, batch=229\n",
      "15019: loss=0.098, reward_mean=0.520, reward_bound=0.430, batch=227\n",
      "15020: loss=0.098, reward_mean=0.390, reward_bound=0.469, batch=229\n",
      "15021: loss=0.099, reward_mean=0.440, reward_bound=0.364, batch=230\n",
      "15022: loss=0.097, reward_mean=0.530, reward_bound=0.418, batch=231\n",
      "15023: loss=0.093, reward_mean=0.480, reward_bound=0.478, batch=149\n",
      "15024: loss=0.093, reward_mean=0.470, reward_bound=0.061, batch=174\n",
      "15025: loss=0.095, reward_mean=0.420, reward_bound=0.058, batch=191\n",
      "15026: loss=0.094, reward_mean=0.450, reward_bound=0.089, batch=203\n",
      "15027: loss=0.094, reward_mean=0.510, reward_bound=0.122, batch=208\n",
      "15028: loss=0.089, reward_mean=0.420, reward_bound=0.150, batch=210\n",
      "15029: loss=0.091, reward_mean=0.490, reward_bound=0.180, batch=217\n",
      "15030: loss=0.090, reward_mean=0.430, reward_bound=0.206, batch=211\n",
      "15031: loss=0.091, reward_mean=0.500, reward_bound=0.229, batch=212\n",
      "15032: loss=0.092, reward_mean=0.460, reward_bound=0.254, batch=207\n",
      "15033: loss=0.091, reward_mean=0.410, reward_bound=0.206, batch=214\n",
      "15034: loss=0.088, reward_mean=0.500, reward_bound=0.282, batch=205\n",
      "15035: loss=0.088, reward_mean=0.370, reward_bound=0.194, batch=213\n",
      "15036: loss=0.092, reward_mean=0.380, reward_bound=0.244, batch=219\n",
      "15037: loss=0.094, reward_mean=0.510, reward_bound=0.314, batch=210\n",
      "15038: loss=0.095, reward_mean=0.360, reward_bound=0.229, batch=216\n",
      "15039: loss=0.096, reward_mean=0.520, reward_bound=0.314, batch=215\n",
      "15040: loss=0.097, reward_mean=0.510, reward_bound=0.349, batch=199\n",
      "15041: loss=0.101, reward_mean=0.440, reward_bound=0.185, batch=206\n",
      "15042: loss=0.098, reward_mean=0.510, reward_bound=0.268, batch=214\n",
      "15043: loss=0.097, reward_mean=0.400, reward_bound=0.282, batch=217\n",
      "15044: loss=0.099, reward_mean=0.510, reward_bound=0.167, batch=221\n",
      "15045: loss=0.097, reward_mean=0.480, reward_bound=0.314, batch=222\n",
      "15046: loss=0.096, reward_mean=0.460, reward_bound=0.349, batch=224\n",
      "15047: loss=0.095, reward_mean=0.530, reward_bound=0.349, batch=226\n",
      "15048: loss=0.096, reward_mean=0.400, reward_bound=0.368, batch=228\n",
      "15049: loss=0.093, reward_mean=0.400, reward_bound=0.387, batch=196\n",
      "15050: loss=0.093, reward_mean=0.510, reward_bound=0.206, batch=206\n",
      "15051: loss=0.096, reward_mean=0.430, reward_bound=0.198, batch=214\n",
      "15052: loss=0.091, reward_mean=0.420, reward_bound=0.254, batch=218\n",
      "15053: loss=0.090, reward_mean=0.510, reward_bound=0.282, batch=219\n",
      "15054: loss=0.089, reward_mean=0.470, reward_bound=0.314, batch=217\n",
      "15055: loss=0.091, reward_mean=0.490, reward_bound=0.277, batch=222\n",
      "15056: loss=0.092, reward_mean=0.490, reward_bound=0.314, batch=224\n",
      "15057: loss=0.090, reward_mean=0.430, reward_bound=0.349, batch=216\n",
      "15058: loss=0.088, reward_mean=0.480, reward_bound=0.331, batch=221\n",
      "15059: loss=0.089, reward_mean=0.410, reward_bound=0.314, batch=223\n",
      "15060: loss=0.088, reward_mean=0.490, reward_bound=0.301, batch=226\n",
      "15061: loss=0.088, reward_mean=0.390, reward_bound=0.349, batch=227\n",
      "15062: loss=0.088, reward_mean=0.410, reward_bound=0.349, batch=227\n",
      "15063: loss=0.090, reward_mean=0.450, reward_bound=0.387, batch=218\n",
      "15064: loss=0.090, reward_mean=0.380, reward_bound=0.317, batch=222\n",
      "15065: loss=0.090, reward_mean=0.390, reward_bound=0.314, batch=224\n",
      "15066: loss=0.089, reward_mean=0.470, reward_bound=0.282, batch=226\n",
      "15067: loss=0.090, reward_mean=0.520, reward_bound=0.387, batch=226\n",
      "15068: loss=0.090, reward_mean=0.480, reward_bound=0.409, batch=228\n",
      "15069: loss=0.086, reward_mean=0.440, reward_bound=0.430, batch=190\n",
      "15070: loss=0.085, reward_mean=0.490, reward_bound=0.180, batch=203\n",
      "15071: loss=0.087, reward_mean=0.450, reward_bound=0.185, batch=211\n",
      "15072: loss=0.087, reward_mean=0.520, reward_bound=0.229, batch=214\n",
      "15073: loss=0.087, reward_mean=0.490, reward_bound=0.254, batch=214\n",
      "15074: loss=0.088, reward_mean=0.410, reward_bound=0.223, batch=220\n",
      "15075: loss=0.086, reward_mean=0.380, reward_bound=0.247, batch=224\n",
      "15076: loss=0.085, reward_mean=0.360, reward_bound=0.280, batch=227\n",
      "15077: loss=0.086, reward_mean=0.460, reward_bound=0.314, batch=223\n",
      "15078: loss=0.086, reward_mean=0.350, reward_bound=0.290, batch=226\n",
      "15079: loss=0.091, reward_mean=0.380, reward_bound=0.349, batch=214\n",
      "15080: loss=0.091, reward_mean=0.430, reward_bound=0.252, batch=220\n",
      "15081: loss=0.092, reward_mean=0.390, reward_bound=0.282, batch=223\n",
      "15082: loss=0.092, reward_mean=0.420, reward_bound=0.301, batch=226\n",
      "15083: loss=0.092, reward_mean=0.440, reward_bound=0.298, batch=228\n",
      "15084: loss=0.092, reward_mean=0.440, reward_bound=0.317, batch=229\n",
      "15085: loss=0.090, reward_mean=0.470, reward_bound=0.349, batch=223\n",
      "15086: loss=0.088, reward_mean=0.440, reward_bound=0.387, batch=216\n",
      "15087: loss=0.087, reward_mean=0.440, reward_bound=0.387, batch=219\n",
      "15088: loss=0.086, reward_mean=0.430, reward_bound=0.364, batch=223\n",
      "15089: loss=0.086, reward_mean=0.470, reward_bound=0.372, batch=226\n",
      "15090: loss=0.087, reward_mean=0.370, reward_bound=0.387, batch=225\n",
      "15091: loss=0.086, reward_mean=0.500, reward_bound=0.430, batch=208\n",
      "15092: loss=0.085, reward_mean=0.470, reward_bound=0.185, batch=214\n",
      "15093: loss=0.086, reward_mean=0.420, reward_bound=0.280, batch=220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15094: loss=0.082, reward_mean=0.540, reward_bound=0.282, batch=219\n",
      "15095: loss=0.085, reward_mean=0.490, reward_bound=0.349, batch=219\n",
      "15096: loss=0.087, reward_mean=0.470, reward_bound=0.387, batch=218\n",
      "15097: loss=0.088, reward_mean=0.520, reward_bound=0.289, batch=222\n",
      "15098: loss=0.088, reward_mean=0.460, reward_bound=0.282, batch=224\n",
      "15099: loss=0.089, reward_mean=0.410, reward_bound=0.349, batch=226\n",
      "15100: loss=0.089, reward_mean=0.480, reward_bound=0.331, batch=228\n",
      "15101: loss=0.089, reward_mean=0.410, reward_bound=0.349, batch=228\n",
      "15102: loss=0.089, reward_mean=0.380, reward_bound=0.353, batch=229\n",
      "15103: loss=0.087, reward_mean=0.480, reward_bound=0.387, batch=226\n",
      "15104: loss=0.088, reward_mean=0.410, reward_bound=0.368, batch=228\n",
      "15105: loss=0.088, reward_mean=0.410, reward_bound=0.353, batch=229\n",
      "15106: loss=0.086, reward_mean=0.540, reward_bound=0.430, batch=222\n",
      "15107: loss=0.090, reward_mean=0.600, reward_bound=0.478, batch=173\n",
      "15108: loss=0.095, reward_mean=0.370, reward_bound=0.098, batch=191\n",
      "15109: loss=0.089, reward_mean=0.400, reward_bound=0.150, batch=201\n",
      "15110: loss=0.087, reward_mean=0.440, reward_bound=0.206, batch=206\n",
      "15111: loss=0.086, reward_mean=0.430, reward_bound=0.196, batch=214\n",
      "15112: loss=0.087, reward_mean=0.450, reward_bound=0.229, batch=217\n",
      "15113: loss=0.092, reward_mean=0.480, reward_bound=0.254, batch=219\n",
      "15114: loss=0.095, reward_mean=0.460, reward_bound=0.282, batch=212\n",
      "15115: loss=0.091, reward_mean=0.500, reward_bound=0.314, batch=209\n",
      "15116: loss=0.094, reward_mean=0.440, reward_bound=0.215, batch=216\n",
      "15117: loss=0.092, reward_mean=0.440, reward_bound=0.241, batch=221\n",
      "15118: loss=0.094, reward_mean=0.350, reward_bound=0.349, batch=213\n",
      "15119: loss=0.098, reward_mean=0.460, reward_bound=0.185, batch=217\n",
      "15120: loss=0.099, reward_mean=0.520, reward_bound=0.308, batch=222\n",
      "15121: loss=0.098, reward_mean=0.460, reward_bound=0.314, batch=222\n",
      "15122: loss=0.097, reward_mean=0.490, reward_bound=0.349, batch=223\n",
      "15123: loss=0.091, reward_mean=0.450, reward_bound=0.387, batch=210\n",
      "15124: loss=0.090, reward_mean=0.380, reward_bound=0.185, batch=216\n",
      "15125: loss=0.094, reward_mean=0.530, reward_bound=0.314, batch=220\n",
      "15126: loss=0.091, reward_mean=0.450, reward_bound=0.349, batch=219\n",
      "15127: loss=0.091, reward_mean=0.380, reward_bound=0.314, batch=221\n",
      "15128: loss=0.092, reward_mean=0.410, reward_bound=0.314, batch=222\n",
      "15129: loss=0.092, reward_mean=0.450, reward_bound=0.349, batch=224\n",
      "15130: loss=0.090, reward_mean=0.340, reward_bound=0.384, batch=227\n",
      "15131: loss=0.090, reward_mean=0.450, reward_bound=0.380, batch=229\n",
      "15132: loss=0.091, reward_mean=0.450, reward_bound=0.387, batch=228\n",
      "15133: loss=0.090, reward_mean=0.450, reward_bound=0.430, batch=205\n",
      "15134: loss=0.089, reward_mean=0.490, reward_bound=0.216, batch=213\n",
      "15135: loss=0.087, reward_mean=0.450, reward_bound=0.254, batch=218\n",
      "15136: loss=0.086, reward_mean=0.470, reward_bound=0.349, batch=221\n",
      "15137: loss=0.087, reward_mean=0.550, reward_bound=0.349, batch=223\n",
      "15138: loss=0.086, reward_mean=0.400, reward_bound=0.349, batch=225\n",
      "15139: loss=0.086, reward_mean=0.470, reward_bound=0.387, batch=222\n",
      "15140: loss=0.086, reward_mean=0.440, reward_bound=0.263, batch=225\n",
      "15141: loss=0.085, reward_mean=0.480, reward_bound=0.314, batch=225\n",
      "15142: loss=0.086, reward_mean=0.460, reward_bound=0.387, batch=225\n",
      "15143: loss=0.085, reward_mean=0.460, reward_bound=0.396, batch=227\n",
      "15144: loss=0.086, reward_mean=0.540, reward_bound=0.422, batch=229\n",
      "15145: loss=0.087, reward_mean=0.470, reward_bound=0.381, batch=230\n",
      "15146: loss=0.086, reward_mean=0.420, reward_bound=0.395, batch=231\n",
      "15147: loss=0.087, reward_mean=0.390, reward_bound=0.430, batch=218\n",
      "15148: loss=0.087, reward_mean=0.400, reward_bound=0.208, batch=222\n",
      "15149: loss=0.086, reward_mean=0.410, reward_bound=0.314, batch=224\n",
      "15150: loss=0.088, reward_mean=0.460, reward_bound=0.349, batch=225\n",
      "15151: loss=0.087, reward_mean=0.410, reward_bound=0.387, batch=226\n",
      "15152: loss=0.087, reward_mean=0.510, reward_bound=0.430, batch=224\n",
      "15153: loss=0.090, reward_mean=0.430, reward_bound=0.426, batch=227\n",
      "15154: loss=0.091, reward_mean=0.460, reward_bound=0.302, batch=229\n",
      "15155: loss=0.090, reward_mean=0.540, reward_bound=0.405, batch=230\n",
      "15156: loss=0.089, reward_mean=0.490, reward_bound=0.418, batch=231\n",
      "15157: loss=0.088, reward_mean=0.450, reward_bound=0.430, batch=224\n",
      "15158: loss=0.088, reward_mean=0.470, reward_bound=0.345, batch=227\n",
      "15159: loss=0.087, reward_mean=0.380, reward_bound=0.430, batch=228\n",
      "15160: loss=0.086, reward_mean=0.410, reward_bound=0.435, batch=229\n",
      "15161: loss=0.086, reward_mean=0.480, reward_bound=0.450, batch=230\n",
      "15162: loss=0.086, reward_mean=0.430, reward_bound=0.365, batch=231\n",
      "15163: loss=0.086, reward_mean=0.380, reward_bound=0.430, batch=231\n",
      "15164: loss=0.085, reward_mean=0.390, reward_bound=0.478, batch=192\n",
      "15165: loss=0.089, reward_mean=0.380, reward_bound=0.167, batch=202\n",
      "15166: loss=0.087, reward_mean=0.320, reward_bound=0.113, batch=211\n",
      "15167: loss=0.091, reward_mean=0.420, reward_bound=0.206, batch=216\n",
      "15168: loss=0.086, reward_mean=0.460, reward_bound=0.229, batch=215\n",
      "15169: loss=0.087, reward_mean=0.470, reward_bound=0.254, batch=214\n",
      "15170: loss=0.088, reward_mean=0.520, reward_bound=0.282, batch=216\n",
      "15171: loss=0.089, reward_mean=0.490, reward_bound=0.314, batch=218\n",
      "15172: loss=0.089, reward_mean=0.450, reward_bound=0.317, batch=222\n",
      "15173: loss=0.091, reward_mean=0.460, reward_bound=0.349, batch=216\n",
      "15174: loss=0.091, reward_mean=0.550, reward_bound=0.349, batch=220\n",
      "15175: loss=0.090, reward_mean=0.400, reward_bound=0.387, batch=220\n",
      "15176: loss=0.092, reward_mean=0.420, reward_bound=0.247, batch=224\n",
      "15177: loss=0.092, reward_mean=0.390, reward_bound=0.349, batch=226\n",
      "15178: loss=0.089, reward_mean=0.430, reward_bound=0.387, batch=223\n",
      "15179: loss=0.090, reward_mean=0.490, reward_bound=0.372, batch=226\n",
      "15180: loss=0.090, reward_mean=0.370, reward_bound=0.349, batch=227\n",
      "15181: loss=0.089, reward_mean=0.530, reward_bound=0.387, batch=228\n",
      "15182: loss=0.086, reward_mean=0.500, reward_bound=0.430, batch=213\n",
      "15183: loss=0.087, reward_mean=0.410, reward_bound=0.254, batch=217\n",
      "15184: loss=0.085, reward_mean=0.490, reward_bound=0.282, batch=221\n",
      "15185: loss=0.086, reward_mean=0.420, reward_bound=0.314, batch=224\n",
      "15186: loss=0.085, reward_mean=0.440, reward_bound=0.314, batch=226\n",
      "15187: loss=0.084, reward_mean=0.490, reward_bound=0.349, batch=224\n",
      "15188: loss=0.084, reward_mean=0.400, reward_bound=0.387, batch=221\n",
      "15189: loss=0.083, reward_mean=0.410, reward_bound=0.314, batch=224\n",
      "15190: loss=0.083, reward_mean=0.490, reward_bound=0.349, batch=225\n",
      "15191: loss=0.084, reward_mean=0.470, reward_bound=0.356, batch=227\n",
      "15192: loss=0.083, reward_mean=0.480, reward_bound=0.380, batch=229\n",
      "15193: loss=0.083, reward_mean=0.400, reward_bound=0.349, batch=229\n",
      "15194: loss=0.084, reward_mean=0.420, reward_bound=0.364, batch=230\n",
      "15195: loss=0.084, reward_mean=0.450, reward_bound=0.387, batch=229\n",
      "15196: loss=0.084, reward_mean=0.460, reward_bound=0.405, batch=230\n",
      "15197: loss=0.084, reward_mean=0.430, reward_bound=0.430, batch=220\n",
      "15198: loss=0.084, reward_mean=0.480, reward_bound=0.338, batch=224\n",
      "15199: loss=0.085, reward_mean=0.450, reward_bound=0.384, batch=227\n",
      "15200: loss=0.084, reward_mean=0.490, reward_bound=0.387, batch=228\n",
      "15201: loss=0.083, reward_mean=0.490, reward_bound=0.357, batch=229\n",
      "15202: loss=0.083, reward_mean=0.460, reward_bound=0.430, batch=225\n",
      "15203: loss=0.083, reward_mean=0.430, reward_bound=0.406, batch=227\n",
      "15204: loss=0.082, reward_mean=0.450, reward_bound=0.282, batch=228\n",
      "15205: loss=0.082, reward_mean=0.340, reward_bound=0.392, batch=229\n",
      "15206: loss=0.082, reward_mean=0.450, reward_bound=0.450, batch=230\n",
      "15207: loss=0.082, reward_mean=0.470, reward_bound=0.418, batch=231\n",
      "15208: loss=0.082, reward_mean=0.420, reward_bound=0.387, batch=231\n",
      "15209: loss=0.082, reward_mean=0.450, reward_bound=0.387, batch=231\n",
      "15210: loss=0.084, reward_mean=0.400, reward_bound=0.478, batch=213\n",
      "15211: loss=0.085, reward_mean=0.570, reward_bound=0.387, batch=218\n",
      "15212: loss=0.086, reward_mean=0.420, reward_bound=0.282, batch=221\n",
      "15213: loss=0.087, reward_mean=0.500, reward_bound=0.254, batch=223\n",
      "15214: loss=0.085, reward_mean=0.410, reward_bound=0.335, batch=226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15215: loss=0.085, reward_mean=0.430, reward_bound=0.368, batch=228\n",
      "15216: loss=0.085, reward_mean=0.470, reward_bound=0.430, batch=223\n",
      "15217: loss=0.085, reward_mean=0.500, reward_bound=0.244, batch=226\n",
      "15218: loss=0.087, reward_mean=0.440, reward_bound=0.351, batch=228\n",
      "15219: loss=0.087, reward_mean=0.490, reward_bound=0.392, batch=229\n",
      "15220: loss=0.085, reward_mean=0.550, reward_bound=0.430, batch=224\n",
      "15221: loss=0.085, reward_mean=0.370, reward_bound=0.469, batch=227\n",
      "15222: loss=0.085, reward_mean=0.450, reward_bound=0.380, batch=229\n",
      "15223: loss=0.084, reward_mean=0.440, reward_bound=0.450, batch=230\n",
      "15224: loss=0.084, reward_mean=0.420, reward_bound=0.365, batch=231\n",
      "15225: loss=0.084, reward_mean=0.440, reward_bound=0.387, batch=230\n",
      "15226: loss=0.084, reward_mean=0.490, reward_bound=0.478, batch=223\n",
      "15227: loss=0.084, reward_mean=0.470, reward_bound=0.387, batch=224\n",
      "15228: loss=0.084, reward_mean=0.420, reward_bound=0.280, batch=227\n",
      "15229: loss=0.086, reward_mean=0.390, reward_bound=0.349, batch=228\n",
      "15230: loss=0.087, reward_mean=0.450, reward_bound=0.286, batch=229\n",
      "15231: loss=0.086, reward_mean=0.350, reward_bound=0.381, batch=230\n",
      "15232: loss=0.084, reward_mean=0.470, reward_bound=0.430, batch=226\n",
      "15233: loss=0.084, reward_mean=0.420, reward_bound=0.387, batch=227\n",
      "15234: loss=0.085, reward_mean=0.430, reward_bound=0.387, batch=228\n",
      "15235: loss=0.086, reward_mean=0.380, reward_bound=0.357, batch=229\n",
      "15236: loss=0.087, reward_mean=0.370, reward_bound=0.342, batch=230\n",
      "15237: loss=0.086, reward_mean=0.480, reward_bound=0.464, batch=231\n",
      "15238: loss=0.084, reward_mean=0.430, reward_bound=0.478, batch=225\n",
      "15239: loss=0.083, reward_mean=0.520, reward_bound=0.430, batch=226\n",
      "15240: loss=0.083, reward_mean=0.400, reward_bound=0.349, batch=227\n",
      "15241: loss=0.084, reward_mean=0.480, reward_bound=0.422, batch=229\n",
      "15242: loss=0.084, reward_mean=0.500, reward_bound=0.349, batch=229\n",
      "15243: loss=0.085, reward_mean=0.490, reward_bound=0.405, batch=230\n",
      "15244: loss=0.084, reward_mean=0.490, reward_bound=0.478, batch=226\n",
      "15245: loss=0.084, reward_mean=0.430, reward_bound=0.387, batch=227\n",
      "15246: loss=0.084, reward_mean=0.390, reward_bound=0.387, batch=228\n",
      "15247: loss=0.083, reward_mean=0.410, reward_bound=0.478, batch=230\n",
      "15248: loss=0.083, reward_mean=0.430, reward_bound=0.464, batch=231\n",
      "15249: loss=0.084, reward_mean=0.440, reward_bound=0.478, batch=228\n",
      "15250: loss=0.084, reward_mean=0.410, reward_bound=0.435, batch=229\n",
      "15251: loss=0.083, reward_mean=0.470, reward_bound=0.478, batch=231\n",
      "15252: loss=0.084, reward_mean=0.460, reward_bound=0.478, batch=229\n",
      "15253: loss=0.083, reward_mean=0.370, reward_bound=0.424, batch=230\n",
      "15254: loss=0.083, reward_mean=0.410, reward_bound=0.464, batch=231\n",
      "15255: loss=0.083, reward_mean=0.510, reward_bound=0.478, batch=230\n",
      "15256: loss=0.083, reward_mean=0.460, reward_bound=0.515, batch=231\n",
      "15257: loss=0.083, reward_mean=0.500, reward_bound=0.478, batch=231\n",
      "15258: loss=0.083, reward_mean=0.530, reward_bound=0.478, batch=231\n",
      "15259: loss=0.083, reward_mean=0.300, reward_bound=0.478, batch=231\n",
      "15260: loss=0.083, reward_mean=0.360, reward_bound=0.478, batch=231\n",
      "15261: loss=0.083, reward_mean=0.410, reward_bound=0.430, batch=231\n",
      "15262: loss=0.083, reward_mean=0.530, reward_bound=0.478, batch=231\n",
      "15263: loss=0.083, reward_mean=0.450, reward_bound=0.478, batch=231\n",
      "15265: loss=0.074, reward_mean=0.420, reward_bound=0.000, batch=42\n",
      "15266: loss=0.076, reward_mean=0.430, reward_bound=0.000, batch=85\n",
      "15267: loss=0.082, reward_mean=0.540, reward_bound=0.002, batch=129\n",
      "15268: loss=0.083, reward_mean=0.460, reward_bound=0.008, batch=160\n",
      "15269: loss=0.082, reward_mean=0.400, reward_bound=0.022, batch=182\n",
      "15270: loss=0.087, reward_mean=0.500, reward_bound=0.042, batch=193\n",
      "15271: loss=0.089, reward_mean=0.460, reward_bound=0.058, batch=199\n",
      "15272: loss=0.090, reward_mean=0.470, reward_bound=0.072, batch=208\n",
      "15273: loss=0.092, reward_mean=0.480, reward_bound=0.089, batch=213\n",
      "15274: loss=0.094, reward_mean=0.320, reward_bound=0.098, batch=208\n",
      "15275: loss=0.097, reward_mean=0.450, reward_bound=0.109, batch=204\n",
      "15276: loss=0.099, reward_mean=0.540, reward_bound=0.135, batch=202\n",
      "15277: loss=0.098, reward_mean=0.380, reward_bound=0.150, batch=199\n",
      "15278: loss=0.095, reward_mean=0.350, reward_bound=0.167, batch=186\n",
      "15279: loss=0.095, reward_mean=0.430, reward_bound=0.115, batch=200\n",
      "15280: loss=0.098, reward_mean=0.410, reward_bound=0.167, batch=209\n",
      "15281: loss=0.101, reward_mean=0.450, reward_bound=0.185, batch=206\n",
      "15282: loss=0.101, reward_mean=0.490, reward_bound=0.206, batch=193\n",
      "15283: loss=0.101, reward_mean=0.520, reward_bound=0.206, batch=204\n",
      "15284: loss=0.104, reward_mean=0.430, reward_bound=0.229, batch=179\n",
      "15285: loss=0.103, reward_mean=0.430, reward_bound=0.109, batch=194\n",
      "15286: loss=0.103, reward_mean=0.400, reward_bound=0.135, batch=202\n",
      "15287: loss=0.102, reward_mean=0.480, reward_bound=0.191, batch=211\n",
      "15288: loss=0.099, reward_mean=0.450, reward_bound=0.229, batch=212\n",
      "15289: loss=0.100, reward_mean=0.480, reward_bound=0.254, batch=185\n",
      "15290: loss=0.102, reward_mean=0.480, reward_bound=0.170, batch=199\n",
      "15291: loss=0.105, reward_mean=0.520, reward_bound=0.167, batch=208\n",
      "15292: loss=0.105, reward_mean=0.470, reward_bound=0.229, batch=213\n",
      "15293: loss=0.104, reward_mean=0.350, reward_bound=0.171, batch=219\n",
      "15294: loss=0.103, reward_mean=0.500, reward_bound=0.215, batch=223\n",
      "15295: loss=0.105, reward_mean=0.450, reward_bound=0.254, batch=225\n",
      "15296: loss=0.103, reward_mean=0.360, reward_bound=0.282, batch=181\n",
      "15297: loss=0.104, reward_mean=0.430, reward_bound=0.122, batch=192\n",
      "15298: loss=0.102, reward_mean=0.480, reward_bound=0.167, batch=201\n",
      "15299: loss=0.101, reward_mean=0.480, reward_bound=0.150, batch=210\n",
      "15300: loss=0.103, reward_mean=0.460, reward_bound=0.206, batch=223\n",
      "15301: loss=0.103, reward_mean=0.490, reward_bound=0.206, batch=223\n",
      "15302: loss=0.102, reward_mean=0.430, reward_bound=0.229, batch=224\n",
      "15303: loss=0.103, reward_mean=0.490, reward_bound=0.254, batch=224\n",
      "15304: loss=0.102, reward_mean=0.530, reward_bound=0.282, batch=224\n",
      "15305: loss=0.098, reward_mean=0.480, reward_bound=0.314, batch=169\n",
      "15306: loss=0.098, reward_mean=0.440, reward_bound=0.148, batch=188\n",
      "15307: loss=0.097, reward_mean=0.430, reward_bound=0.135, batch=200\n",
      "15308: loss=0.096, reward_mean=0.480, reward_bound=0.167, batch=208\n",
      "15309: loss=0.092, reward_mean=0.390, reward_bound=0.206, batch=208\n",
      "15310: loss=0.095, reward_mean=0.450, reward_bound=0.229, batch=208\n",
      "15311: loss=0.095, reward_mean=0.490, reward_bound=0.254, batch=209\n",
      "15312: loss=0.094, reward_mean=0.460, reward_bound=0.282, batch=210\n",
      "15313: loss=0.093, reward_mean=0.440, reward_bound=0.247, batch=217\n",
      "15314: loss=0.094, reward_mean=0.470, reward_bound=0.277, batch=222\n",
      "15315: loss=0.096, reward_mean=0.430, reward_bound=0.282, batch=223\n",
      "15316: loss=0.095, reward_mean=0.420, reward_bound=0.314, batch=216\n",
      "15317: loss=0.094, reward_mean=0.610, reward_bound=0.331, batch=221\n",
      "15318: loss=0.095, reward_mean=0.470, reward_bound=0.314, batch=222\n",
      "15319: loss=0.091, reward_mean=0.450, reward_bound=0.349, batch=168\n",
      "15320: loss=0.091, reward_mean=0.550, reward_bound=0.169, batch=187\n",
      "15321: loss=0.091, reward_mean=0.480, reward_bound=0.122, batch=199\n",
      "15322: loss=0.087, reward_mean=0.470, reward_bound=0.206, batch=205\n",
      "15323: loss=0.090, reward_mean=0.490, reward_bound=0.229, batch=207\n",
      "15324: loss=0.091, reward_mean=0.470, reward_bound=0.206, batch=214\n",
      "15325: loss=0.090, reward_mean=0.450, reward_bound=0.252, batch=220\n",
      "15326: loss=0.089, reward_mean=0.500, reward_bound=0.254, batch=219\n",
      "15327: loss=0.089, reward_mean=0.370, reward_bound=0.282, batch=217\n",
      "15328: loss=0.091, reward_mean=0.380, reward_bound=0.308, batch=222\n",
      "15329: loss=0.089, reward_mean=0.500, reward_bound=0.314, batch=210\n",
      "15330: loss=0.088, reward_mean=0.450, reward_bound=0.338, batch=217\n",
      "15331: loss=0.090, reward_mean=0.550, reward_bound=0.349, batch=213\n",
      "15332: loss=0.088, reward_mean=0.500, reward_bound=0.290, batch=219\n",
      "15333: loss=0.087, reward_mean=0.410, reward_bound=0.265, batch=223\n",
      "15334: loss=0.086, reward_mean=0.400, reward_bound=0.282, batch=225\n",
      "15335: loss=0.087, reward_mean=0.420, reward_bound=0.314, batch=223\n",
      "15336: loss=0.088, reward_mean=0.440, reward_bound=0.349, batch=223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15337: loss=0.088, reward_mean=0.480, reward_bound=0.301, batch=226\n",
      "15338: loss=0.089, reward_mean=0.430, reward_bound=0.349, batch=227\n",
      "15339: loss=0.090, reward_mean=0.380, reward_bound=0.277, batch=229\n",
      "15340: loss=0.088, reward_mean=0.350, reward_bound=0.387, batch=150\n",
      "15341: loss=0.089, reward_mean=0.460, reward_bound=0.086, batch=175\n",
      "15342: loss=0.088, reward_mean=0.420, reward_bound=0.109, batch=193\n",
      "15343: loss=0.089, reward_mean=0.460, reward_bound=0.130, batch=205\n",
      "15344: loss=0.083, reward_mean=0.510, reward_bound=0.150, batch=211\n",
      "15345: loss=0.083, reward_mean=0.500, reward_bound=0.167, batch=212\n",
      "15346: loss=0.087, reward_mean=0.370, reward_bound=0.185, batch=215\n",
      "15347: loss=0.084, reward_mean=0.400, reward_bound=0.206, batch=215\n",
      "15348: loss=0.087, reward_mean=0.390, reward_bound=0.229, batch=214\n",
      "15349: loss=0.085, reward_mean=0.400, reward_bound=0.229, batch=217\n",
      "15350: loss=0.091, reward_mean=0.440, reward_bound=0.254, batch=211\n",
      "15351: loss=0.091, reward_mean=0.370, reward_bound=0.282, batch=206\n",
      "15352: loss=0.089, reward_mean=0.470, reward_bound=0.176, batch=214\n",
      "15353: loss=0.090, reward_mean=0.450, reward_bound=0.229, batch=219\n",
      "15354: loss=0.087, reward_mean=0.450, reward_bound=0.314, batch=205\n",
      "15355: loss=0.086, reward_mean=0.460, reward_bound=0.254, batch=211\n",
      "15356: loss=0.089, reward_mean=0.450, reward_bound=0.254, batch=217\n",
      "15357: loss=0.088, reward_mean=0.450, reward_bound=0.254, batch=221\n",
      "15358: loss=0.088, reward_mean=0.450, reward_bound=0.282, batch=220\n",
      "15359: loss=0.092, reward_mean=0.530, reward_bound=0.349, batch=212\n",
      "15360: loss=0.091, reward_mean=0.460, reward_bound=0.324, batch=218\n",
      "15361: loss=0.093, reward_mean=0.560, reward_bound=0.349, batch=221\n",
      "15362: loss=0.087, reward_mean=0.410, reward_bound=0.387, batch=200\n",
      "15363: loss=0.088, reward_mean=0.480, reward_bound=0.254, batch=209\n",
      "15364: loss=0.086, reward_mean=0.450, reward_bound=0.282, batch=215\n",
      "15365: loss=0.086, reward_mean=0.450, reward_bound=0.282, batch=218\n",
      "15366: loss=0.088, reward_mean=0.500, reward_bound=0.286, batch=222\n",
      "15367: loss=0.089, reward_mean=0.510, reward_bound=0.292, batch=225\n",
      "15368: loss=0.087, reward_mean=0.430, reward_bound=0.314, batch=221\n",
      "15369: loss=0.087, reward_mean=0.460, reward_bound=0.349, batch=224\n",
      "15370: loss=0.088, reward_mean=0.450, reward_bound=0.384, batch=227\n",
      "15371: loss=0.087, reward_mean=0.480, reward_bound=0.387, batch=221\n",
      "15372: loss=0.087, reward_mean=0.430, reward_bound=0.349, batch=223\n",
      "15373: loss=0.086, reward_mean=0.430, reward_bound=0.413, batch=226\n",
      "15374: loss=0.088, reward_mean=0.430, reward_bound=0.430, batch=114\n",
      "15375: loss=0.078, reward_mean=0.450, reward_bound=0.012, batch=150\n",
      "15376: loss=0.087, reward_mean=0.520, reward_bound=0.047, batch=174\n",
      "15377: loss=0.087, reward_mean=0.460, reward_bound=0.065, batch=188\n",
      "15378: loss=0.088, reward_mean=0.390, reward_bound=0.081, batch=201\n",
      "15379: loss=0.084, reward_mean=0.380, reward_bound=0.109, batch=205\n",
      "15380: loss=0.083, reward_mean=0.410, reward_bound=0.112, batch=213\n",
      "15381: loss=0.083, reward_mean=0.490, reward_bound=0.144, batch=219\n",
      "15382: loss=0.081, reward_mean=0.480, reward_bound=0.167, batch=216\n",
      "15383: loss=0.082, reward_mean=0.430, reward_bound=0.185, batch=218\n",
      "15384: loss=0.084, reward_mean=0.390, reward_bound=0.206, batch=204\n",
      "15385: loss=0.081, reward_mean=0.420, reward_bound=0.229, batch=202\n",
      "15386: loss=0.080, reward_mean=0.470, reward_bound=0.229, batch=209\n",
      "15387: loss=0.078, reward_mean=0.450, reward_bound=0.254, batch=202\n",
      "15388: loss=0.078, reward_mean=0.560, reward_bound=0.213, batch=211\n",
      "15389: loss=0.078, reward_mean=0.550, reward_bound=0.229, batch=216\n",
      "15390: loss=0.087, reward_mean=0.470, reward_bound=0.282, batch=196\n",
      "15391: loss=0.086, reward_mean=0.510, reward_bound=0.196, batch=207\n",
      "15392: loss=0.088, reward_mean=0.520, reward_bound=0.229, batch=214\n",
      "15393: loss=0.089, reward_mean=0.440, reward_bound=0.254, batch=216\n",
      "15394: loss=0.088, reward_mean=0.410, reward_bound=0.268, batch=221\n",
      "15395: loss=0.090, reward_mean=0.340, reward_bound=0.282, batch=215\n",
      "15396: loss=0.091, reward_mean=0.480, reward_bound=0.289, batch=220\n",
      "15397: loss=0.091, reward_mean=0.430, reward_bound=0.282, batch=223\n",
      "15398: loss=0.089, reward_mean=0.450, reward_bound=0.314, batch=205\n",
      "15399: loss=0.089, reward_mean=0.430, reward_bound=0.240, batch=213\n",
      "15400: loss=0.089, reward_mean=0.450, reward_bound=0.244, batch=219\n",
      "15401: loss=0.089, reward_mean=0.530, reward_bound=0.282, batch=221\n",
      "15402: loss=0.088, reward_mean=0.460, reward_bound=0.314, batch=221\n",
      "15403: loss=0.087, reward_mean=0.470, reward_bound=0.349, batch=193\n",
      "15404: loss=0.086, reward_mean=0.490, reward_bound=0.206, batch=203\n",
      "15405: loss=0.083, reward_mean=0.480, reward_bound=0.167, batch=211\n",
      "15406: loss=0.083, reward_mean=0.470, reward_bound=0.229, batch=216\n",
      "15407: loss=0.085, reward_mean=0.480, reward_bound=0.254, batch=220\n",
      "15408: loss=0.087, reward_mean=0.490, reward_bound=0.282, batch=223\n",
      "15409: loss=0.088, reward_mean=0.470, reward_bound=0.314, batch=222\n",
      "15410: loss=0.087, reward_mean=0.480, reward_bound=0.324, batch=225\n",
      "15411: loss=0.087, reward_mean=0.450, reward_bound=0.349, batch=218\n",
      "15412: loss=0.085, reward_mean=0.460, reward_bound=0.229, batch=221\n",
      "15413: loss=0.085, reward_mean=0.470, reward_bound=0.314, batch=223\n",
      "15414: loss=0.086, reward_mean=0.410, reward_bound=0.349, batch=224\n",
      "15415: loss=0.087, reward_mean=0.450, reward_bound=0.345, batch=227\n",
      "15416: loss=0.087, reward_mean=0.460, reward_bound=0.302, batch=229\n",
      "15417: loss=0.094, reward_mean=0.520, reward_bound=0.387, batch=195\n",
      "15418: loss=0.096, reward_mean=0.450, reward_bound=0.175, batch=206\n",
      "15419: loss=0.097, reward_mean=0.370, reward_bound=0.143, batch=214\n",
      "15420: loss=0.096, reward_mean=0.440, reward_bound=0.254, batch=216\n",
      "15421: loss=0.098, reward_mean=0.470, reward_bound=0.282, batch=215\n",
      "15422: loss=0.098, reward_mean=0.410, reward_bound=0.314, batch=219\n",
      "15423: loss=0.099, reward_mean=0.380, reward_bound=0.349, batch=216\n",
      "15424: loss=0.099, reward_mean=0.480, reward_bound=0.331, batch=221\n",
      "15425: loss=0.098, reward_mean=0.450, reward_bound=0.349, batch=222\n",
      "15426: loss=0.098, reward_mean=0.400, reward_bound=0.254, batch=225\n",
      "15427: loss=0.095, reward_mean=0.410, reward_bound=0.387, batch=221\n",
      "15428: loss=0.095, reward_mean=0.460, reward_bound=0.387, batch=223\n",
      "15429: loss=0.095, reward_mean=0.440, reward_bound=0.387, batch=225\n",
      "15430: loss=0.091, reward_mean=0.500, reward_bound=0.430, batch=174\n",
      "15431: loss=0.089, reward_mean=0.430, reward_bound=0.150, batch=191\n",
      "15432: loss=0.092, reward_mean=0.390, reward_bound=0.167, batch=202\n",
      "15433: loss=0.093, reward_mean=0.370, reward_bound=0.185, batch=208\n",
      "15434: loss=0.089, reward_mean=0.420, reward_bound=0.206, batch=212\n",
      "15435: loss=0.089, reward_mean=0.440, reward_bound=0.229, batch=216\n",
      "15436: loss=0.091, reward_mean=0.430, reward_bound=0.254, batch=214\n",
      "15437: loss=0.092, reward_mean=0.500, reward_bound=0.282, batch=212\n",
      "15438: loss=0.093, reward_mean=0.480, reward_bound=0.263, batch=218\n",
      "15439: loss=0.092, reward_mean=0.430, reward_bound=0.282, batch=220\n",
      "15440: loss=0.092, reward_mean=0.450, reward_bound=0.314, batch=214\n",
      "15441: loss=0.089, reward_mean=0.410, reward_bound=0.280, batch=220\n",
      "15442: loss=0.091, reward_mean=0.500, reward_bound=0.282, batch=219\n",
      "15443: loss=0.092, reward_mean=0.390, reward_bound=0.282, batch=222\n",
      "15444: loss=0.094, reward_mean=0.460, reward_bound=0.324, batch=225\n",
      "15445: loss=0.092, reward_mean=0.450, reward_bound=0.349, batch=212\n",
      "15446: loss=0.093, reward_mean=0.500, reward_bound=0.314, batch=218\n",
      "15447: loss=0.095, reward_mean=0.490, reward_bound=0.321, batch=222\n",
      "15448: loss=0.092, reward_mean=0.460, reward_bound=0.387, batch=210\n",
      "15449: loss=0.090, reward_mean=0.530, reward_bound=0.314, batch=216\n",
      "15450: loss=0.090, reward_mean=0.490, reward_bound=0.349, batch=219\n",
      "15451: loss=0.089, reward_mean=0.330, reward_bound=0.282, batch=221\n",
      "15452: loss=0.088, reward_mean=0.390, reward_bound=0.282, batch=224\n",
      "15453: loss=0.089, reward_mean=0.480, reward_bound=0.314, batch=225\n",
      "15454: loss=0.093, reward_mean=0.440, reward_bound=0.387, batch=222\n",
      "15455: loss=0.093, reward_mean=0.420, reward_bound=0.387, batch=224\n",
      "15456: loss=0.095, reward_mean=0.380, reward_bound=0.345, batch=227\n",
      "15457: loss=0.094, reward_mean=0.470, reward_bound=0.414, batch=229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15458: loss=0.093, reward_mean=0.470, reward_bound=0.430, batch=210\n",
      "15459: loss=0.093, reward_mean=0.440, reward_bound=0.254, batch=215\n",
      "15460: loss=0.095, reward_mean=0.430, reward_bound=0.321, batch=220\n",
      "15461: loss=0.094, reward_mean=0.350, reward_bound=0.266, batch=224\n",
      "15462: loss=0.096, reward_mean=0.430, reward_bound=0.311, batch=227\n",
      "15463: loss=0.097, reward_mean=0.420, reward_bound=0.308, batch=229\n",
      "15464: loss=0.097, reward_mean=0.490, reward_bound=0.295, batch=230\n",
      "15465: loss=0.096, reward_mean=0.440, reward_bound=0.338, batch=231\n",
      "15466: loss=0.092, reward_mean=0.360, reward_bound=0.349, batch=227\n",
      "15467: loss=0.093, reward_mean=0.550, reward_bound=0.387, batch=225\n",
      "15468: loss=0.093, reward_mean=0.400, reward_bound=0.314, batch=226\n",
      "15469: loss=0.093, reward_mean=0.440, reward_bound=0.349, batch=227\n",
      "15470: loss=0.093, reward_mean=0.370, reward_bound=0.335, batch=229\n",
      "15471: loss=0.093, reward_mean=0.410, reward_bound=0.314, batch=229\n",
      "15472: loss=0.093, reward_mean=0.450, reward_bound=0.349, batch=229\n",
      "15473: loss=0.093, reward_mean=0.380, reward_bound=0.430, batch=224\n",
      "15474: loss=0.094, reward_mean=0.460, reward_bound=0.314, batch=226\n",
      "15475: loss=0.094, reward_mean=0.460, reward_bound=0.349, batch=226\n",
      "15476: loss=0.094, reward_mean=0.430, reward_bound=0.454, batch=228\n",
      "15477: loss=0.094, reward_mean=0.440, reward_bound=0.430, batch=228\n",
      "15478: loss=0.093, reward_mean=0.500, reward_bound=0.478, batch=232\n",
      "15479: loss=0.084, reward_mean=0.490, reward_bound=0.478, batch=80\n",
      "15480: loss=0.075, reward_mean=0.400, reward_bound=0.000, batch=120\n",
      "15481: loss=0.083, reward_mean=0.470, reward_bound=0.014, batch=154\n",
      "15482: loss=0.082, reward_mean=0.460, reward_bound=0.028, batch=176\n",
      "15483: loss=0.086, reward_mean=0.520, reward_bound=0.052, batch=190\n",
      "15484: loss=0.089, reward_mean=0.460, reward_bound=0.080, batch=202\n",
      "15485: loss=0.087, reward_mean=0.460, reward_bound=0.098, batch=204\n",
      "15486: loss=0.088, reward_mean=0.480, reward_bound=0.109, batch=209\n",
      "15487: loss=0.091, reward_mean=0.490, reward_bound=0.135, batch=211\n",
      "15488: loss=0.089, reward_mean=0.520, reward_bound=0.150, batch=213\n",
      "15489: loss=0.092, reward_mean=0.500, reward_bound=0.167, batch=215\n",
      "15490: loss=0.093, reward_mean=0.460, reward_bound=0.185, batch=208\n",
      "15491: loss=0.096, reward_mean=0.450, reward_bound=0.206, batch=200\n",
      "15492: loss=0.098, reward_mean=0.370, reward_bound=0.162, batch=210\n",
      "15493: loss=0.095, reward_mean=0.530, reward_bound=0.229, batch=201\n",
      "15494: loss=0.096, reward_mean=0.480, reward_bound=0.254, batch=187\n",
      "15495: loss=0.098, reward_mean=0.320, reward_bound=0.150, batch=200\n",
      "15496: loss=0.099, reward_mean=0.490, reward_bound=0.206, batch=211\n",
      "15497: loss=0.102, reward_mean=0.400, reward_bound=0.229, batch=214\n",
      "15498: loss=0.103, reward_mean=0.400, reward_bound=0.252, batch=220\n",
      "15499: loss=0.102, reward_mean=0.380, reward_bound=0.247, batch=224\n",
      "15500: loss=0.100, reward_mean=0.350, reward_bound=0.254, batch=225\n",
      "15501: loss=0.100, reward_mean=0.460, reward_bound=0.282, batch=203\n",
      "15502: loss=0.101, reward_mean=0.390, reward_bound=0.185, batch=211\n",
      "15503: loss=0.098, reward_mean=0.350, reward_bound=0.254, batch=217\n",
      "15504: loss=0.098, reward_mean=0.520, reward_bound=0.282, batch=220\n",
      "15505: loss=0.095, reward_mean=0.500, reward_bound=0.314, batch=189\n",
      "15506: loss=0.095, reward_mean=0.420, reward_bound=0.185, batch=201\n",
      "15507: loss=0.099, reward_mean=0.520, reward_bound=0.229, batch=206\n",
      "15508: loss=0.099, reward_mean=0.480, reward_bound=0.196, batch=214\n",
      "15509: loss=0.098, reward_mean=0.490, reward_bound=0.254, batch=217\n",
      "15510: loss=0.097, reward_mean=0.410, reward_bound=0.282, batch=215\n",
      "15511: loss=0.097, reward_mean=0.390, reward_bound=0.289, batch=220\n",
      "15512: loss=0.096, reward_mean=0.520, reward_bound=0.304, batch=224\n",
      "15513: loss=0.094, reward_mean=0.460, reward_bound=0.314, batch=225\n",
      "15514: loss=0.095, reward_mean=0.440, reward_bound=0.349, batch=188\n",
      "15515: loss=0.094, reward_mean=0.510, reward_bound=0.229, batch=200\n",
      "15516: loss=0.095, reward_mean=0.470, reward_bound=0.206, batch=212\n",
      "15517: loss=0.095, reward_mean=0.460, reward_bound=0.191, batch=218\n",
      "15518: loss=0.095, reward_mean=0.490, reward_bound=0.254, batch=216\n",
      "15519: loss=0.093, reward_mean=0.360, reward_bound=0.282, batch=219\n",
      "15520: loss=0.094, reward_mean=0.500, reward_bound=0.314, batch=215\n",
      "15521: loss=0.094, reward_mean=0.380, reward_bound=0.321, batch=220\n",
      "15522: loss=0.095, reward_mean=0.440, reward_bound=0.349, batch=211\n",
      "15523: loss=0.095, reward_mean=0.490, reward_bound=0.254, batch=216\n",
      "15524: loss=0.094, reward_mean=0.430, reward_bound=0.314, batch=220\n",
      "15525: loss=0.092, reward_mean=0.390, reward_bound=0.240, batch=224\n",
      "15526: loss=0.092, reward_mean=0.370, reward_bound=0.345, batch=227\n",
      "15527: loss=0.094, reward_mean=0.330, reward_bound=0.349, batch=227\n",
      "15528: loss=0.090, reward_mean=0.410, reward_bound=0.387, batch=179\n",
      "15529: loss=0.089, reward_mean=0.450, reward_bound=0.167, batch=194\n",
      "15530: loss=0.090, reward_mean=0.510, reward_bound=0.185, batch=205\n",
      "15531: loss=0.090, reward_mean=0.370, reward_bound=0.167, batch=212\n",
      "15532: loss=0.089, reward_mean=0.390, reward_bound=0.213, batch=218\n",
      "15533: loss=0.090, reward_mean=0.400, reward_bound=0.229, batch=219\n",
      "15534: loss=0.089, reward_mean=0.390, reward_bound=0.254, batch=221\n",
      "15535: loss=0.092, reward_mean=0.420, reward_bound=0.314, batch=210\n",
      "15536: loss=0.091, reward_mean=0.350, reward_bound=0.274, batch=217\n",
      "15537: loss=0.092, reward_mean=0.440, reward_bound=0.314, batch=220\n",
      "15538: loss=0.088, reward_mean=0.390, reward_bound=0.349, batch=209\n",
      "15539: loss=0.088, reward_mean=0.460, reward_bound=0.239, batch=216\n",
      "15540: loss=0.090, reward_mean=0.470, reward_bound=0.314, batch=220\n",
      "15541: loss=0.089, reward_mean=0.500, reward_bound=0.349, batch=218\n",
      "15542: loss=0.089, reward_mean=0.470, reward_bound=0.387, batch=211\n",
      "15543: loss=0.090, reward_mean=0.380, reward_bound=0.282, batch=217\n",
      "15544: loss=0.089, reward_mean=0.400, reward_bound=0.229, batch=221\n",
      "15545: loss=0.090, reward_mean=0.390, reward_bound=0.254, batch=223\n",
      "15546: loss=0.090, reward_mean=0.480, reward_bound=0.301, batch=226\n",
      "15547: loss=0.089, reward_mean=0.420, reward_bound=0.314, batch=225\n",
      "15548: loss=0.089, reward_mean=0.330, reward_bound=0.227, batch=227\n",
      "15549: loss=0.088, reward_mean=0.380, reward_bound=0.349, batch=225\n",
      "15550: loss=0.088, reward_mean=0.450, reward_bound=0.303, batch=227\n",
      "15551: loss=0.087, reward_mean=0.460, reward_bound=0.387, batch=222\n",
      "15552: loss=0.087, reward_mean=0.470, reward_bound=0.373, batch=225\n",
      "15553: loss=0.081, reward_mean=0.460, reward_bound=0.430, batch=164\n",
      "15554: loss=0.078, reward_mean=0.500, reward_bound=0.079, batch=185\n",
      "15555: loss=0.084, reward_mean=0.410, reward_bound=0.098, batch=195\n",
      "15556: loss=0.084, reward_mean=0.380, reward_bound=0.122, batch=204\n",
      "15557: loss=0.085, reward_mean=0.450, reward_bound=0.150, batch=210\n",
      "15558: loss=0.093, reward_mean=0.490, reward_bound=0.167, batch=216\n",
      "15559: loss=0.096, reward_mean=0.430, reward_bound=0.185, batch=219\n",
      "15560: loss=0.095, reward_mean=0.420, reward_bound=0.229, batch=208\n",
      "15561: loss=0.095, reward_mean=0.400, reward_bound=0.231, batch=215\n",
      "15562: loss=0.092, reward_mean=0.360, reward_bound=0.254, batch=210\n",
      "15563: loss=0.091, reward_mean=0.450, reward_bound=0.247, batch=217\n",
      "15564: loss=0.090, reward_mean=0.470, reward_bound=0.254, batch=220\n",
      "15565: loss=0.082, reward_mean=0.500, reward_bound=0.282, batch=216\n",
      "15566: loss=0.079, reward_mean=0.490, reward_bound=0.314, batch=209\n",
      "15567: loss=0.080, reward_mean=0.410, reward_bound=0.295, batch=216\n",
      "15568: loss=0.080, reward_mean=0.460, reward_bound=0.331, batch=221\n",
      "15569: loss=0.082, reward_mean=0.430, reward_bound=0.349, batch=211\n",
      "15570: loss=0.081, reward_mean=0.360, reward_bound=0.282, batch=217\n",
      "15571: loss=0.082, reward_mean=0.450, reward_bound=0.342, batch=222\n",
      "15572: loss=0.082, reward_mean=0.520, reward_bound=0.349, batch=223\n",
      "15573: loss=0.080, reward_mean=0.400, reward_bound=0.387, batch=207\n",
      "15574: loss=0.080, reward_mean=0.390, reward_bound=0.185, batch=213\n",
      "15575: loss=0.079, reward_mean=0.530, reward_bound=0.301, batch=219\n",
      "15576: loss=0.080, reward_mean=0.480, reward_bound=0.314, batch=222\n",
      "15577: loss=0.080, reward_mean=0.460, reward_bound=0.324, batch=225\n",
      "15578: loss=0.080, reward_mean=0.470, reward_bound=0.349, batch=225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15579: loss=0.079, reward_mean=0.460, reward_bound=0.387, batch=216\n",
      "15580: loss=0.078, reward_mean=0.500, reward_bound=0.314, batch=219\n",
      "15581: loss=0.078, reward_mean=0.440, reward_bound=0.349, batch=222\n",
      "15582: loss=0.081, reward_mean=0.430, reward_bound=0.387, batch=224\n",
      "15583: loss=0.083, reward_mean=0.450, reward_bound=0.430, batch=199\n",
      "15584: loss=0.082, reward_mean=0.350, reward_bound=0.203, batch=209\n",
      "15585: loss=0.081, reward_mean=0.450, reward_bound=0.203, batch=216\n",
      "15586: loss=0.084, reward_mean=0.450, reward_bound=0.254, batch=220\n",
      "15587: loss=0.083, reward_mean=0.400, reward_bound=0.282, batch=218\n",
      "15588: loss=0.082, reward_mean=0.400, reward_bound=0.257, batch=222\n",
      "15589: loss=0.083, reward_mean=0.460, reward_bound=0.314, batch=223\n",
      "15590: loss=0.083, reward_mean=0.440, reward_bound=0.335, batch=226\n",
      "15591: loss=0.085, reward_mean=0.430, reward_bound=0.349, batch=217\n",
      "15592: loss=0.084, reward_mean=0.410, reward_bound=0.282, batch=220\n",
      "15593: loss=0.083, reward_mean=0.480, reward_bound=0.296, batch=224\n",
      "15594: loss=0.085, reward_mean=0.430, reward_bound=0.311, batch=227\n",
      "15595: loss=0.087, reward_mean=0.460, reward_bound=0.314, batch=227\n",
      "15596: loss=0.087, reward_mean=0.450, reward_bound=0.335, batch=229\n",
      "15597: loss=0.086, reward_mean=0.500, reward_bound=0.349, batch=228\n",
      "15598: loss=0.086, reward_mean=0.460, reward_bound=0.387, batch=221\n",
      "15599: loss=0.085, reward_mean=0.480, reward_bound=0.282, batch=224\n",
      "15600: loss=0.085, reward_mean=0.540, reward_bound=0.430, batch=213\n",
      "15601: loss=0.084, reward_mean=0.420, reward_bound=0.314, batch=217\n",
      "15602: loss=0.084, reward_mean=0.400, reward_bound=0.314, batch=221\n",
      "15603: loss=0.083, reward_mean=0.360, reward_bound=0.349, batch=222\n",
      "15604: loss=0.084, reward_mean=0.470, reward_bound=0.387, batch=218\n",
      "15605: loss=0.083, reward_mean=0.370, reward_bound=0.208, batch=222\n",
      "15606: loss=0.084, reward_mean=0.340, reward_bound=0.349, batch=222\n",
      "15607: loss=0.084, reward_mean=0.390, reward_bound=0.349, batch=224\n",
      "15608: loss=0.085, reward_mean=0.400, reward_bound=0.349, batch=226\n",
      "15609: loss=0.084, reward_mean=0.490, reward_bound=0.349, batch=227\n",
      "15610: loss=0.083, reward_mean=0.450, reward_bound=0.387, batch=228\n",
      "15611: loss=0.084, reward_mean=0.370, reward_bound=0.430, batch=218\n",
      "15612: loss=0.084, reward_mean=0.430, reward_bound=0.353, batch=222\n",
      "15613: loss=0.086, reward_mean=0.430, reward_bound=0.400, batch=225\n",
      "15614: loss=0.087, reward_mean=0.500, reward_bound=0.396, batch=227\n",
      "15615: loss=0.084, reward_mean=0.430, reward_bound=0.430, batch=226\n",
      "15616: loss=0.085, reward_mean=0.420, reward_bound=0.478, batch=144\n",
      "15617: loss=0.078, reward_mean=0.440, reward_bound=0.108, batch=171\n",
      "15618: loss=0.079, reward_mean=0.480, reward_bound=0.122, batch=186\n",
      "15619: loss=0.081, reward_mean=0.470, reward_bound=0.135, batch=198\n",
      "15620: loss=0.084, reward_mean=0.540, reward_bound=0.167, batch=207\n",
      "15621: loss=0.088, reward_mean=0.420, reward_bound=0.185, batch=205\n",
      "15622: loss=0.088, reward_mean=0.440, reward_bound=0.170, batch=213\n",
      "15623: loss=0.090, reward_mean=0.460, reward_bound=0.206, batch=212\n",
      "15624: loss=0.088, reward_mean=0.570, reward_bound=0.229, batch=215\n",
      "15625: loss=0.091, reward_mean=0.420, reward_bound=0.254, batch=209\n",
      "15626: loss=0.092, reward_mean=0.360, reward_bound=0.194, batch=216\n",
      "15627: loss=0.090, reward_mean=0.420, reward_bound=0.217, batch=221\n",
      "15628: loss=0.091, reward_mean=0.420, reward_bound=0.229, batch=224\n",
      "15629: loss=0.091, reward_mean=0.370, reward_bound=0.282, batch=211\n",
      "15630: loss=0.090, reward_mean=0.440, reward_bound=0.229, batch=217\n",
      "15631: loss=0.091, reward_mean=0.490, reward_bound=0.308, batch=222\n",
      "15632: loss=0.089, reward_mean=0.490, reward_bound=0.314, batch=208\n",
      "15633: loss=0.090, reward_mean=0.380, reward_bound=0.229, batch=214\n",
      "15634: loss=0.089, reward_mean=0.490, reward_bound=0.311, batch=220\n",
      "15635: loss=0.094, reward_mean=0.440, reward_bound=0.314, batch=222\n",
      "15636: loss=0.094, reward_mean=0.450, reward_bound=0.349, batch=207\n",
      "15637: loss=0.092, reward_mean=0.390, reward_bound=0.224, batch=215\n",
      "15638: loss=0.092, reward_mean=0.500, reward_bound=0.282, batch=219\n",
      "15639: loss=0.094, reward_mean=0.530, reward_bound=0.314, batch=222\n",
      "15640: loss=0.094, reward_mean=0.450, reward_bound=0.324, batch=225\n",
      "15641: loss=0.095, reward_mean=0.480, reward_bound=0.321, batch=227\n",
      "15642: loss=0.096, reward_mean=0.490, reward_bound=0.349, batch=227\n",
      "15643: loss=0.093, reward_mean=0.460, reward_bound=0.387, batch=193\n",
      "15644: loss=0.092, reward_mean=0.360, reward_bound=0.144, batch=205\n",
      "15645: loss=0.095, reward_mean=0.350, reward_bound=0.150, batch=209\n",
      "15646: loss=0.097, reward_mean=0.470, reward_bound=0.203, batch=216\n",
      "15647: loss=0.096, reward_mean=0.450, reward_bound=0.229, batch=220\n",
      "15648: loss=0.098, reward_mean=0.550, reward_bound=0.282, batch=222\n",
      "15649: loss=0.099, reward_mean=0.430, reward_bound=0.314, batch=223\n",
      "15650: loss=0.097, reward_mean=0.430, reward_bound=0.349, batch=216\n",
      "15651: loss=0.096, reward_mean=0.410, reward_bound=0.282, batch=220\n",
      "15652: loss=0.097, reward_mean=0.460, reward_bound=0.329, batch=224\n",
      "15653: loss=0.097, reward_mean=0.350, reward_bound=0.349, batch=225\n",
      "15654: loss=0.094, reward_mean=0.390, reward_bound=0.387, batch=214\n",
      "15655: loss=0.094, reward_mean=0.550, reward_bound=0.345, batch=220\n",
      "15656: loss=0.094, reward_mean=0.340, reward_bound=0.254, batch=223\n",
      "15657: loss=0.095, reward_mean=0.370, reward_bound=0.290, batch=226\n",
      "15658: loss=0.096, reward_mean=0.440, reward_bound=0.314, batch=224\n",
      "15659: loss=0.094, reward_mean=0.560, reward_bound=0.349, batch=224\n",
      "15660: loss=0.095, reward_mean=0.480, reward_bound=0.380, batch=227\n",
      "15661: loss=0.095, reward_mean=0.480, reward_bound=0.387, batch=223\n",
      "15662: loss=0.096, reward_mean=0.430, reward_bound=0.314, batch=225\n",
      "15663: loss=0.094, reward_mean=0.480, reward_bound=0.387, batch=225\n",
      "15664: loss=0.091, reward_mean=0.530, reward_bound=0.430, batch=187\n",
      "15665: loss=0.087, reward_mean=0.440, reward_bound=0.119, batch=201\n",
      "15666: loss=0.089, reward_mean=0.390, reward_bound=0.185, batch=209\n",
      "15667: loss=0.086, reward_mean=0.480, reward_bound=0.229, batch=215\n",
      "15668: loss=0.085, reward_mean=0.440, reward_bound=0.254, batch=213\n",
      "15669: loss=0.091, reward_mean=0.430, reward_bound=0.282, batch=211\n",
      "15670: loss=0.092, reward_mean=0.430, reward_bound=0.229, batch=217\n",
      "15671: loss=0.092, reward_mean=0.460, reward_bound=0.282, batch=220\n",
      "15672: loss=0.093, reward_mean=0.560, reward_bound=0.314, batch=217\n",
      "15673: loss=0.092, reward_mean=0.420, reward_bound=0.349, batch=214\n",
      "15674: loss=0.089, reward_mean=0.420, reward_bound=0.245, batch=220\n",
      "15675: loss=0.090, reward_mean=0.400, reward_bound=0.254, batch=223\n",
      "15676: loss=0.092, reward_mean=0.460, reward_bound=0.301, batch=226\n",
      "15677: loss=0.092, reward_mean=0.490, reward_bound=0.349, batch=224\n",
      "15678: loss=0.092, reward_mean=0.470, reward_bound=0.384, batch=227\n",
      "15679: loss=0.092, reward_mean=0.450, reward_bound=0.282, batch=228\n",
      "15680: loss=0.089, reward_mean=0.400, reward_bound=0.387, batch=216\n",
      "15681: loss=0.090, reward_mean=0.370, reward_bound=0.298, batch=221\n",
      "15682: loss=0.089, reward_mean=0.440, reward_bound=0.314, batch=223\n",
      "15683: loss=0.088, reward_mean=0.400, reward_bound=0.335, batch=226\n",
      "15684: loss=0.088, reward_mean=0.470, reward_bound=0.349, batch=227\n",
      "15685: loss=0.088, reward_mean=0.450, reward_bound=0.380, batch=229\n",
      "15686: loss=0.089, reward_mean=0.430, reward_bound=0.387, batch=228\n",
      "15687: loss=0.088, reward_mean=0.360, reward_bound=0.357, batch=229\n",
      "15688: loss=0.088, reward_mean=0.430, reward_bound=0.405, batch=230\n",
      "15689: loss=0.090, reward_mean=0.490, reward_bound=0.430, batch=208\n",
      "15690: loss=0.090, reward_mean=0.420, reward_bound=0.234, batch=215\n",
      "15691: loss=0.090, reward_mean=0.460, reward_bound=0.289, batch=220\n",
      "15692: loss=0.090, reward_mean=0.400, reward_bound=0.288, batch=224\n",
      "15693: loss=0.090, reward_mean=0.460, reward_bound=0.311, batch=227\n",
      "15694: loss=0.091, reward_mean=0.450, reward_bound=0.349, batch=222\n",
      "15695: loss=0.090, reward_mean=0.420, reward_bound=0.360, batch=225\n",
      "15696: loss=0.090, reward_mean=0.550, reward_bound=0.387, batch=217\n",
      "15697: loss=0.089, reward_mean=0.470, reward_bound=0.308, batch=222\n",
      "15698: loss=0.089, reward_mean=0.500, reward_bound=0.292, batch=225\n",
      "15699: loss=0.089, reward_mean=0.440, reward_bound=0.314, batch=226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15700: loss=0.088, reward_mean=0.500, reward_bound=0.349, batch=225\n",
      "15701: loss=0.088, reward_mean=0.410, reward_bound=0.349, batch=225\n",
      "15702: loss=0.089, reward_mean=0.470, reward_bound=0.387, batch=224\n",
      "15703: loss=0.089, reward_mean=0.460, reward_bound=0.387, batch=226\n",
      "15704: loss=0.090, reward_mean=0.450, reward_bound=0.368, batch=228\n",
      "15705: loss=0.089, reward_mean=0.480, reward_bound=0.387, batch=228\n",
      "15706: loss=0.091, reward_mean=0.460, reward_bound=0.430, batch=220\n",
      "15707: loss=0.091, reward_mean=0.480, reward_bound=0.349, batch=222\n",
      "15708: loss=0.090, reward_mean=0.430, reward_bound=0.292, batch=225\n",
      "15709: loss=0.090, reward_mean=0.380, reward_bound=0.349, batch=226\n",
      "15710: loss=0.091, reward_mean=0.560, reward_bound=0.387, batch=225\n",
      "15711: loss=0.091, reward_mean=0.430, reward_bound=0.365, batch=227\n",
      "15712: loss=0.090, reward_mean=0.280, reward_bound=0.422, batch=229\n",
      "15713: loss=0.090, reward_mean=0.440, reward_bound=0.430, batch=226\n",
      "15714: loss=0.091, reward_mean=0.380, reward_bound=0.298, batch=228\n",
      "15715: loss=0.090, reward_mean=0.440, reward_bound=0.435, batch=229\n",
      "15716: loss=0.089, reward_mean=0.490, reward_bound=0.478, batch=231\n",
      "15717: loss=0.087, reward_mean=0.420, reward_bound=0.478, batch=172\n",
      "15718: loss=0.087, reward_mean=0.440, reward_bound=0.167, batch=188\n",
      "15719: loss=0.087, reward_mean=0.490, reward_bound=0.208, batch=201\n",
      "15720: loss=0.085, reward_mean=0.450, reward_bound=0.185, batch=210\n",
      "15721: loss=0.084, reward_mean=0.420, reward_bound=0.229, batch=212\n",
      "15722: loss=0.083, reward_mean=0.380, reward_bound=0.236, batch=218\n",
      "15723: loss=0.085, reward_mean=0.520, reward_bound=0.282, batch=213\n",
      "15724: loss=0.086, reward_mean=0.450, reward_bound=0.301, batch=219\n",
      "15725: loss=0.085, reward_mean=0.530, reward_bound=0.314, batch=215\n",
      "15726: loss=0.084, reward_mean=0.440, reward_bound=0.349, batch=206\n",
      "15727: loss=0.086, reward_mean=0.390, reward_bound=0.135, batch=213\n",
      "15728: loss=0.088, reward_mean=0.440, reward_bound=0.206, batch=218\n",
      "15729: loss=0.086, reward_mean=0.450, reward_bound=0.254, batch=221\n",
      "15730: loss=0.087, reward_mean=0.430, reward_bound=0.282, batch=222\n",
      "15731: loss=0.086, reward_mean=0.530, reward_bound=0.324, batch=225\n",
      "15732: loss=0.085, reward_mean=0.480, reward_bound=0.349, batch=221\n",
      "15733: loss=0.086, reward_mean=0.480, reward_bound=0.387, batch=208\n",
      "15734: loss=0.088, reward_mean=0.400, reward_bound=0.229, batch=214\n",
      "15735: loss=0.088, reward_mean=0.400, reward_bound=0.204, batch=220\n",
      "15736: loss=0.087, reward_mean=0.430, reward_bound=0.222, batch=224\n",
      "15737: loss=0.085, reward_mean=0.400, reward_bound=0.252, batch=227\n",
      "15738: loss=0.085, reward_mean=0.440, reward_bound=0.277, batch=229\n",
      "15739: loss=0.082, reward_mean=0.530, reward_bound=0.295, batch=230\n",
      "15740: loss=0.082, reward_mean=0.550, reward_bound=0.314, batch=230\n",
      "15741: loss=0.084, reward_mean=0.430, reward_bound=0.349, batch=222\n",
      "15742: loss=0.083, reward_mean=0.350, reward_bound=0.336, batch=225\n",
      "15743: loss=0.083, reward_mean=0.460, reward_bound=0.314, batch=226\n",
      "15744: loss=0.084, reward_mean=0.340, reward_bound=0.387, batch=220\n",
      "15745: loss=0.084, reward_mean=0.430, reward_bound=0.314, batch=223\n",
      "15746: loss=0.085, reward_mean=0.480, reward_bound=0.387, batch=225\n",
      "15747: loss=0.084, reward_mean=0.460, reward_bound=0.387, batch=226\n",
      "15748: loss=0.084, reward_mean=0.460, reward_bound=0.372, batch=228\n",
      "15749: loss=0.085, reward_mean=0.440, reward_bound=0.357, batch=229\n",
      "15750: loss=0.085, reward_mean=0.440, reward_bound=0.349, batch=229\n",
      "15751: loss=0.083, reward_mean=0.530, reward_bound=0.430, batch=205\n",
      "15752: loss=0.081, reward_mean=0.430, reward_bound=0.282, batch=212\n",
      "15753: loss=0.082, reward_mean=0.490, reward_bound=0.314, batch=216\n",
      "15754: loss=0.081, reward_mean=0.580, reward_bound=0.349, batch=217\n",
      "15755: loss=0.084, reward_mean=0.460, reward_bound=0.308, batch=222\n",
      "15756: loss=0.084, reward_mean=0.490, reward_bound=0.349, batch=223\n",
      "15757: loss=0.083, reward_mean=0.370, reward_bound=0.290, batch=226\n",
      "15758: loss=0.083, reward_mean=0.440, reward_bound=0.298, batch=228\n",
      "15759: loss=0.082, reward_mean=0.460, reward_bound=0.317, batch=229\n",
      "15760: loss=0.082, reward_mean=0.390, reward_bound=0.349, batch=228\n",
      "15761: loss=0.087, reward_mean=0.450, reward_bound=0.387, batch=226\n",
      "15762: loss=0.086, reward_mean=0.430, reward_bound=0.430, batch=218\n",
      "15763: loss=0.085, reward_mean=0.440, reward_bound=0.349, batch=220\n",
      "15764: loss=0.087, reward_mean=0.500, reward_bound=0.304, batch=224\n",
      "15765: loss=0.087, reward_mean=0.570, reward_bound=0.314, batch=225\n",
      "15766: loss=0.087, reward_mean=0.550, reward_bound=0.387, batch=226\n",
      "15767: loss=0.087, reward_mean=0.410, reward_bound=0.409, batch=228\n",
      "15768: loss=0.087, reward_mean=0.420, reward_bound=0.430, batch=224\n",
      "15769: loss=0.087, reward_mean=0.510, reward_bound=0.426, batch=227\n",
      "15770: loss=0.086, reward_mean=0.430, reward_bound=0.414, batch=229\n",
      "15771: loss=0.086, reward_mean=0.510, reward_bound=0.450, batch=230\n",
      "15772: loss=0.086, reward_mean=0.450, reward_bound=0.464, batch=231\n",
      "15773: loss=0.087, reward_mean=0.410, reward_bound=0.478, batch=199\n",
      "15774: loss=0.083, reward_mean=0.510, reward_bound=0.229, batch=208\n",
      "15775: loss=0.085, reward_mean=0.510, reward_bound=0.282, batch=214\n",
      "15776: loss=0.085, reward_mean=0.430, reward_bound=0.277, batch=220\n",
      "15777: loss=0.084, reward_mean=0.400, reward_bound=0.304, batch=224\n",
      "15778: loss=0.085, reward_mean=0.400, reward_bound=0.314, batch=222\n",
      "15779: loss=0.083, reward_mean=0.400, reward_bound=0.349, batch=221\n",
      "15780: loss=0.083, reward_mean=0.420, reward_bound=0.349, batch=222\n",
      "15781: loss=0.082, reward_mean=0.490, reward_bound=0.282, batch=224\n",
      "15782: loss=0.081, reward_mean=0.370, reward_bound=0.345, batch=227\n",
      "15783: loss=0.082, reward_mean=0.460, reward_bound=0.380, batch=229\n",
      "15784: loss=0.083, reward_mean=0.400, reward_bound=0.387, batch=221\n",
      "15785: loss=0.083, reward_mean=0.440, reward_bound=0.387, batch=224\n",
      "15786: loss=0.084, reward_mean=0.480, reward_bound=0.380, batch=227\n",
      "15787: loss=0.083, reward_mean=0.490, reward_bound=0.349, batch=228\n",
      "15788: loss=0.082, reward_mean=0.450, reward_bound=0.392, batch=229\n",
      "15789: loss=0.085, reward_mean=0.470, reward_bound=0.430, batch=216\n",
      "15790: loss=0.083, reward_mean=0.440, reward_bound=0.241, batch=221\n",
      "15791: loss=0.085, reward_mean=0.320, reward_bound=0.254, batch=224\n",
      "15792: loss=0.086, reward_mean=0.440, reward_bound=0.282, batch=225\n",
      "15793: loss=0.085, reward_mean=0.490, reward_bound=0.349, batch=225\n",
      "15794: loss=0.087, reward_mean=0.520, reward_bound=0.387, batch=224\n",
      "15795: loss=0.085, reward_mean=0.400, reward_bound=0.430, batch=224\n",
      "15796: loss=0.086, reward_mean=0.430, reward_bound=0.349, batch=226\n",
      "15797: loss=0.085, reward_mean=0.520, reward_bound=0.387, batch=227\n",
      "15798: loss=0.084, reward_mean=0.510, reward_bound=0.469, batch=229\n",
      "15799: loss=0.084, reward_mean=0.520, reward_bound=0.424, batch=230\n",
      "15800: loss=0.084, reward_mean=0.440, reward_bound=0.387, batch=230\n",
      "15801: loss=0.085, reward_mean=0.460, reward_bound=0.376, batch=231\n",
      "15802: loss=0.087, reward_mean=0.620, reward_bound=0.478, batch=214\n",
      "15803: loss=0.088, reward_mean=0.450, reward_bound=0.229, batch=219\n",
      "15804: loss=0.086, reward_mean=0.500, reward_bound=0.295, batch=223\n",
      "15805: loss=0.087, reward_mean=0.350, reward_bound=0.314, batch=224\n",
      "15806: loss=0.086, reward_mean=0.490, reward_bound=0.277, batch=227\n",
      "15807: loss=0.086, reward_mean=0.520, reward_bound=0.314, batch=228\n",
      "15808: loss=0.087, reward_mean=0.460, reward_bound=0.349, batch=227\n",
      "15809: loss=0.087, reward_mean=0.440, reward_bound=0.349, batch=228\n",
      "15810: loss=0.088, reward_mean=0.510, reward_bound=0.387, batch=223\n",
      "15811: loss=0.088, reward_mean=0.470, reward_bound=0.372, batch=226\n",
      "15812: loss=0.090, reward_mean=0.440, reward_bound=0.368, batch=228\n",
      "15813: loss=0.089, reward_mean=0.390, reward_bound=0.387, batch=227\n",
      "15814: loss=0.089, reward_mean=0.440, reward_bound=0.422, batch=229\n",
      "15815: loss=0.089, reward_mean=0.460, reward_bound=0.405, batch=230\n",
      "15816: loss=0.089, reward_mean=0.350, reward_bound=0.376, batch=231\n",
      "15817: loss=0.089, reward_mean=0.330, reward_bound=0.387, batch=230\n",
      "15818: loss=0.089, reward_mean=0.440, reward_bound=0.386, batch=231\n",
      "15819: loss=0.087, reward_mean=0.460, reward_bound=0.430, batch=221\n",
      "15820: loss=0.086, reward_mean=0.490, reward_bound=0.314, batch=224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15821: loss=0.086, reward_mean=0.450, reward_bound=0.314, batch=226\n",
      "15822: loss=0.087, reward_mean=0.520, reward_bound=0.368, batch=228\n",
      "15823: loss=0.087, reward_mean=0.350, reward_bound=0.387, batch=227\n",
      "15824: loss=0.087, reward_mean=0.480, reward_bound=0.430, batch=226\n",
      "15825: loss=0.088, reward_mean=0.360, reward_bound=0.433, batch=228\n",
      "15826: loss=0.089, reward_mean=0.450, reward_bound=0.478, batch=232\n",
      "15827: loss=0.087, reward_mean=0.410, reward_bound=0.478, batch=223\n",
      "15828: loss=0.086, reward_mean=0.440, reward_bound=0.314, batch=224\n",
      "15829: loss=0.086, reward_mean=0.440, reward_bound=0.282, batch=226\n",
      "15830: loss=0.086, reward_mean=0.420, reward_bound=0.387, batch=226\n",
      "15831: loss=0.086, reward_mean=0.450, reward_bound=0.268, batch=228\n",
      "15832: loss=0.087, reward_mean=0.420, reward_bound=0.353, batch=229\n",
      "15833: loss=0.087, reward_mean=0.580, reward_bound=0.405, batch=230\n",
      "15834: loss=0.087, reward_mean=0.520, reward_bound=0.387, batch=230\n",
      "15835: loss=0.088, reward_mean=0.420, reward_bound=0.430, batch=226\n",
      "15836: loss=0.089, reward_mean=0.500, reward_bound=0.314, batch=227\n",
      "15837: loss=0.089, reward_mean=0.440, reward_bound=0.387, batch=228\n",
      "15838: loss=0.088, reward_mean=0.500, reward_bound=0.478, batch=231\n",
      "15839: loss=0.088, reward_mean=0.420, reward_bound=0.387, batch=231\n",
      "15840: loss=0.086, reward_mean=0.450, reward_bound=0.478, batch=228\n",
      "15841: loss=0.085, reward_mean=0.470, reward_bound=0.353, batch=229\n",
      "15842: loss=0.086, reward_mean=0.440, reward_bound=0.424, batch=230\n",
      "15843: loss=0.086, reward_mean=0.500, reward_bound=0.478, batch=230\n",
      "15844: loss=0.086, reward_mean=0.440, reward_bound=0.451, batch=231\n",
      "15846: loss=0.087, reward_mean=0.410, reward_bound=0.000, batch=41\n",
      "15847: loss=0.082, reward_mean=0.450, reward_bound=0.000, batch=86\n",
      "15848: loss=0.081, reward_mean=0.410, reward_bound=0.000, batch=127\n",
      "15849: loss=0.085, reward_mean=0.440, reward_bound=0.003, batch=159\n",
      "15850: loss=0.085, reward_mean=0.470, reward_bound=0.011, batch=181\n",
      "15851: loss=0.080, reward_mean=0.410, reward_bound=0.023, batch=193\n",
      "15852: loss=0.084, reward_mean=0.340, reward_bound=0.033, batch=205\n",
      "15853: loss=0.084, reward_mean=0.430, reward_bound=0.047, batch=210\n",
      "15854: loss=0.089, reward_mean=0.430, reward_bound=0.058, batch=214\n",
      "15855: loss=0.089, reward_mean=0.480, reward_bound=0.072, batch=208\n",
      "15856: loss=0.083, reward_mean=0.570, reward_bound=0.089, batch=213\n",
      "15857: loss=0.080, reward_mean=0.380, reward_bound=0.105, batch=219\n",
      "15858: loss=0.088, reward_mean=0.470, reward_bound=0.109, batch=216\n",
      "15859: loss=0.084, reward_mean=0.500, reward_bound=0.122, batch=219\n",
      "15860: loss=0.084, reward_mean=0.500, reward_bound=0.135, batch=216\n",
      "15861: loss=0.085, reward_mean=0.450, reward_bound=0.150, batch=217\n",
      "15862: loss=0.085, reward_mean=0.550, reward_bound=0.167, batch=208\n",
      "15863: loss=0.085, reward_mean=0.420, reward_bound=0.185, batch=190\n",
      "15864: loss=0.088, reward_mean=0.370, reward_bound=0.106, batch=203\n",
      "15865: loss=0.086, reward_mean=0.370, reward_bound=0.160, batch=212\n",
      "15866: loss=0.085, reward_mean=0.340, reward_bound=0.185, batch=217\n",
      "15867: loss=0.087, reward_mean=0.470, reward_bound=0.206, batch=203\n",
      "15868: loss=0.093, reward_mean=0.540, reward_bound=0.229, batch=189\n",
      "15869: loss=0.094, reward_mean=0.410, reward_bound=0.150, batch=201\n",
      "15870: loss=0.095, reward_mean=0.390, reward_bound=0.206, batch=208\n",
      "15871: loss=0.094, reward_mean=0.500, reward_bound=0.231, batch=215\n",
      "15872: loss=0.095, reward_mean=0.400, reward_bound=0.254, batch=191\n",
      "15873: loss=0.093, reward_mean=0.440, reward_bound=0.185, batch=202\n",
      "15874: loss=0.092, reward_mean=0.440, reward_bound=0.206, batch=212\n",
      "15875: loss=0.094, reward_mean=0.440, reward_bound=0.206, batch=221\n",
      "15876: loss=0.094, reward_mean=0.370, reward_bound=0.254, batch=219\n",
      "15877: loss=0.091, reward_mean=0.420, reward_bound=0.282, batch=179\n",
      "15878: loss=0.093, reward_mean=0.410, reward_bound=0.109, batch=194\n",
      "15879: loss=0.090, reward_mean=0.410, reward_bound=0.134, batch=206\n",
      "15880: loss=0.088, reward_mean=0.410, reward_bound=0.135, batch=213\n",
      "15881: loss=0.088, reward_mean=0.570, reward_bound=0.206, batch=215\n",
      "15882: loss=0.091, reward_mean=0.550, reward_bound=0.254, batch=213\n",
      "15883: loss=0.092, reward_mean=0.390, reward_bound=0.206, batch=216\n",
      "15884: loss=0.092, reward_mean=0.450, reward_bound=0.282, batch=212\n",
      "15885: loss=0.092, reward_mean=0.380, reward_bound=0.229, batch=217\n",
      "15886: loss=0.092, reward_mean=0.420, reward_bound=0.277, batch=222\n",
      "15887: loss=0.092, reward_mean=0.490, reward_bound=0.282, batch=224\n",
      "15888: loss=0.090, reward_mean=0.520, reward_bound=0.314, batch=187\n",
      "15889: loss=0.090, reward_mean=0.400, reward_bound=0.206, batch=200\n",
      "15890: loss=0.091, reward_mean=0.400, reward_bound=0.229, batch=207\n",
      "15891: loss=0.090, reward_mean=0.350, reward_bound=0.249, batch=215\n",
      "15892: loss=0.090, reward_mean=0.490, reward_bound=0.254, batch=214\n",
      "15893: loss=0.090, reward_mean=0.390, reward_bound=0.254, batch=218\n",
      "15894: loss=0.091, reward_mean=0.510, reward_bound=0.282, batch=221\n",
      "15895: loss=0.090, reward_mean=0.370, reward_bound=0.254, batch=223\n",
      "15896: loss=0.089, reward_mean=0.450, reward_bound=0.314, batch=217\n",
      "15897: loss=0.088, reward_mean=0.460, reward_bound=0.342, batch=222\n",
      "15898: loss=0.091, reward_mean=0.430, reward_bound=0.349, batch=163\n",
      "15899: loss=0.088, reward_mean=0.400, reward_bound=0.085, batch=184\n",
      "15900: loss=0.089, reward_mean=0.490, reward_bound=0.135, batch=197\n",
      "15901: loss=0.091, reward_mean=0.440, reward_bound=0.150, batch=207\n",
      "15902: loss=0.088, reward_mean=0.510, reward_bound=0.185, batch=212\n",
      "15903: loss=0.087, reward_mean=0.480, reward_bound=0.206, batch=221\n",
      "15904: loss=0.088, reward_mean=0.450, reward_bound=0.229, batch=221\n",
      "15905: loss=0.087, reward_mean=0.400, reward_bound=0.254, batch=222\n",
      "15906: loss=0.091, reward_mean=0.480, reward_bound=0.282, batch=210\n",
      "15907: loss=0.089, reward_mean=0.370, reward_bound=0.167, batch=216\n",
      "15908: loss=0.090, reward_mean=0.480, reward_bound=0.254, batch=219\n",
      "15909: loss=0.091, reward_mean=0.400, reward_bound=0.282, batch=221\n",
      "15910: loss=0.091, reward_mean=0.430, reward_bound=0.314, batch=215\n",
      "15911: loss=0.089, reward_mean=0.480, reward_bound=0.321, batch=220\n",
      "15912: loss=0.089, reward_mean=0.460, reward_bound=0.314, batch=223\n",
      "15913: loss=0.090, reward_mean=0.480, reward_bound=0.244, batch=226\n",
      "15914: loss=0.089, reward_mean=0.450, reward_bound=0.314, batch=227\n",
      "15915: loss=0.091, reward_mean=0.470, reward_bound=0.349, batch=217\n",
      "15916: loss=0.090, reward_mean=0.340, reward_bound=0.249, batch=222\n",
      "15917: loss=0.089, reward_mean=0.500, reward_bound=0.282, batch=222\n",
      "15918: loss=0.091, reward_mean=0.450, reward_bound=0.324, batch=225\n",
      "15919: loss=0.090, reward_mean=0.430, reward_bound=0.289, batch=227\n",
      "15920: loss=0.091, reward_mean=0.450, reward_bound=0.349, batch=226\n",
      "15921: loss=0.091, reward_mean=0.390, reward_bound=0.314, batch=227\n",
      "15922: loss=0.096, reward_mean=0.490, reward_bound=0.387, batch=143\n",
      "15923: loss=0.087, reward_mean=0.510, reward_bound=0.077, batch=170\n",
      "15924: loss=0.095, reward_mean=0.500, reward_bound=0.109, batch=187\n",
      "15925: loss=0.094, reward_mean=0.510, reward_bound=0.135, batch=199\n",
      "15926: loss=0.096, reward_mean=0.520, reward_bound=0.167, batch=205\n",
      "15927: loss=0.098, reward_mean=0.370, reward_bound=0.185, batch=206\n",
      "15928: loss=0.097, reward_mean=0.410, reward_bound=0.206, batch=212\n",
      "15929: loss=0.098, reward_mean=0.420, reward_bound=0.229, batch=207\n",
      "15930: loss=0.096, reward_mean=0.450, reward_bound=0.254, batch=202\n",
      "15931: loss=0.094, reward_mean=0.460, reward_bound=0.282, batch=200\n",
      "15932: loss=0.096, reward_mean=0.360, reward_bound=0.274, batch=210\n",
      "15933: loss=0.096, reward_mean=0.560, reward_bound=0.266, batch=217\n",
      "15934: loss=0.097, reward_mean=0.470, reward_bound=0.254, batch=220\n",
      "15935: loss=0.097, reward_mean=0.400, reward_bound=0.274, batch=224\n",
      "15936: loss=0.096, reward_mean=0.350, reward_bound=0.282, batch=223\n",
      "15937: loss=0.096, reward_mean=0.550, reward_bound=0.314, batch=212\n",
      "15938: loss=0.097, reward_mean=0.480, reward_bound=0.314, batch=216\n",
      "15939: loss=0.097, reward_mean=0.410, reward_bound=0.314, batch=220\n",
      "15940: loss=0.098, reward_mean=0.460, reward_bound=0.329, batch=224\n",
      "15941: loss=0.097, reward_mean=0.460, reward_bound=0.349, batch=197\n",
      "15942: loss=0.096, reward_mean=0.460, reward_bound=0.185, batch=207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15943: loss=0.094, reward_mean=0.460, reward_bound=0.224, batch=215\n",
      "15944: loss=0.096, reward_mean=0.510, reward_bound=0.282, batch=216\n",
      "15945: loss=0.097, reward_mean=0.340, reward_bound=0.282, batch=218\n",
      "15946: loss=0.098, reward_mean=0.540, reward_bound=0.314, batch=217\n",
      "15947: loss=0.098, reward_mean=0.390, reward_bound=0.224, batch=222\n",
      "15948: loss=0.098, reward_mean=0.460, reward_bound=0.282, batch=224\n",
      "15949: loss=0.097, reward_mean=0.400, reward_bound=0.311, batch=227\n",
      "15950: loss=0.097, reward_mean=0.470, reward_bound=0.308, batch=229\n",
      "15951: loss=0.094, reward_mean=0.390, reward_bound=0.349, batch=220\n",
      "15952: loss=0.093, reward_mean=0.460, reward_bound=0.349, batch=223\n",
      "15953: loss=0.093, reward_mean=0.420, reward_bound=0.358, batch=226\n",
      "15954: loss=0.093, reward_mean=0.530, reward_bound=0.387, batch=195\n",
      "15955: loss=0.093, reward_mean=0.390, reward_bound=0.141, batch=206\n",
      "15956: loss=0.093, reward_mean=0.460, reward_bound=0.217, batch=214\n",
      "15957: loss=0.093, reward_mean=0.410, reward_bound=0.229, batch=218\n",
      "15958: loss=0.094, reward_mean=0.490, reward_bound=0.282, batch=220\n",
      "15959: loss=0.093, reward_mean=0.320, reward_bound=0.229, batch=223\n",
      "15960: loss=0.093, reward_mean=0.430, reward_bound=0.282, batch=224\n",
      "15961: loss=0.092, reward_mean=0.560, reward_bound=0.349, batch=215\n",
      "15962: loss=0.092, reward_mean=0.460, reward_bound=0.273, batch=220\n",
      "15963: loss=0.092, reward_mean=0.450, reward_bound=0.274, batch=224\n",
      "15964: loss=0.092, reward_mean=0.400, reward_bound=0.314, batch=226\n",
      "15965: loss=0.092, reward_mean=0.410, reward_bound=0.349, batch=224\n",
      "15966: loss=0.092, reward_mean=0.460, reward_bound=0.311, batch=227\n",
      "15967: loss=0.090, reward_mean=0.460, reward_bound=0.314, batch=228\n",
      "15968: loss=0.091, reward_mean=0.420, reward_bound=0.349, batch=227\n",
      "15969: loss=0.090, reward_mean=0.420, reward_bound=0.387, batch=218\n",
      "15970: loss=0.090, reward_mean=0.400, reward_bound=0.282, batch=221\n",
      "15971: loss=0.090, reward_mean=0.440, reward_bound=0.314, batch=224\n",
      "15972: loss=0.089, reward_mean=0.400, reward_bound=0.345, batch=227\n",
      "15973: loss=0.090, reward_mean=0.440, reward_bound=0.349, batch=226\n",
      "15974: loss=0.091, reward_mean=0.400, reward_bound=0.387, batch=227\n",
      "15975: loss=0.090, reward_mean=0.450, reward_bound=0.422, batch=229\n",
      "15976: loss=0.090, reward_mean=0.410, reward_bound=0.405, batch=230\n",
      "15977: loss=0.084, reward_mean=0.500, reward_bound=0.430, batch=127\n",
      "15978: loss=0.087, reward_mean=0.460, reward_bound=0.028, batch=158\n",
      "15979: loss=0.091, reward_mean=0.500, reward_bound=0.058, batch=178\n",
      "15980: loss=0.086, reward_mean=0.400, reward_bound=0.089, batch=191\n",
      "15981: loss=0.094, reward_mean=0.460, reward_bound=0.122, batch=197\n",
      "15982: loss=0.096, reward_mean=0.450, reward_bound=0.135, batch=205\n",
      "15983: loss=0.094, reward_mean=0.480, reward_bound=0.167, batch=202\n",
      "15984: loss=0.094, reward_mean=0.520, reward_bound=0.185, batch=210\n",
      "15985: loss=0.091, reward_mean=0.460, reward_bound=0.206, batch=220\n",
      "15986: loss=0.093, reward_mean=0.510, reward_bound=0.206, batch=237\n",
      "15987: loss=0.093, reward_mean=0.410, reward_bound=0.206, batch=231\n",
      "15988: loss=0.094, reward_mean=0.450, reward_bound=0.229, batch=226\n",
      "15989: loss=0.097, reward_mean=0.510, reward_bound=0.254, batch=213\n",
      "15990: loss=0.098, reward_mean=0.320, reward_bound=0.198, batch=219\n",
      "15991: loss=0.092, reward_mean=0.480, reward_bound=0.282, batch=199\n",
      "15992: loss=0.091, reward_mean=0.400, reward_bound=0.167, batch=208\n",
      "15993: loss=0.093, reward_mean=0.520, reward_bound=0.229, batch=214\n",
      "15994: loss=0.093, reward_mean=0.380, reward_bound=0.229, batch=219\n",
      "15995: loss=0.093, reward_mean=0.400, reward_bound=0.254, batch=219\n",
      "15996: loss=0.093, reward_mean=0.380, reward_bound=0.239, batch=223\n",
      "15997: loss=0.093, reward_mean=0.480, reward_bound=0.282, batch=224\n",
      "15998: loss=0.091, reward_mean=0.470, reward_bound=0.314, batch=201\n",
      "15999: loss=0.091, reward_mean=0.380, reward_bound=0.167, batch=209\n",
      "16000: loss=0.091, reward_mean=0.480, reward_bound=0.278, batch=216\n",
      "16001: loss=0.091, reward_mean=0.470, reward_bound=0.268, batch=221\n",
      "16002: loss=0.092, reward_mean=0.450, reward_bound=0.254, batch=224\n",
      "16003: loss=0.089, reward_mean=0.470, reward_bound=0.314, batch=222\n",
      "16004: loss=0.092, reward_mean=0.500, reward_bound=0.349, batch=203\n",
      "16005: loss=0.092, reward_mean=0.460, reward_bound=0.220, batch=212\n",
      "16006: loss=0.093, reward_mean=0.440, reward_bound=0.236, batch=218\n",
      "16007: loss=0.092, reward_mean=0.450, reward_bound=0.282, batch=221\n",
      "16008: loss=0.091, reward_mean=0.490, reward_bound=0.314, batch=219\n",
      "16009: loss=0.091, reward_mean=0.430, reward_bound=0.278, batch=223\n",
      "16010: loss=0.089, reward_mean=0.330, reward_bound=0.301, batch=226\n",
      "16011: loss=0.091, reward_mean=0.440, reward_bound=0.314, batch=224\n",
      "16012: loss=0.094, reward_mean=0.460, reward_bound=0.349, batch=219\n",
      "16013: loss=0.092, reward_mean=0.560, reward_bound=0.387, batch=190\n",
      "16014: loss=0.088, reward_mean=0.380, reward_bound=0.112, batch=203\n",
      "16015: loss=0.092, reward_mean=0.570, reward_bound=0.167, batch=211\n",
      "16016: loss=0.090, reward_mean=0.360, reward_bound=0.206, batch=217\n",
      "16017: loss=0.089, reward_mean=0.450, reward_bound=0.229, batch=218\n",
      "16018: loss=0.086, reward_mean=0.420, reward_bound=0.254, batch=215\n",
      "16019: loss=0.089, reward_mean=0.440, reward_bound=0.282, batch=213\n",
      "16020: loss=0.087, reward_mean=0.490, reward_bound=0.244, batch=219\n",
      "16021: loss=0.087, reward_mean=0.510, reward_bound=0.254, batch=220\n",
      "16022: loss=0.091, reward_mean=0.470, reward_bound=0.314, batch=213\n",
      "16023: loss=0.091, reward_mean=0.450, reward_bound=0.244, batch=219\n",
      "16024: loss=0.090, reward_mean=0.490, reward_bound=0.278, batch=223\n",
      "16025: loss=0.091, reward_mean=0.440, reward_bound=0.335, batch=226\n",
      "16026: loss=0.090, reward_mean=0.430, reward_bound=0.349, batch=220\n",
      "16027: loss=0.091, reward_mean=0.470, reward_bound=0.338, batch=224\n",
      "16028: loss=0.092, reward_mean=0.360, reward_bound=0.308, batch=227\n",
      "16029: loss=0.092, reward_mean=0.480, reward_bound=0.349, batch=225\n",
      "16030: loss=0.097, reward_mean=0.440, reward_bound=0.387, batch=212\n",
      "16031: loss=0.097, reward_mean=0.360, reward_bound=0.292, batch=218\n",
      "16032: loss=0.099, reward_mean=0.480, reward_bound=0.349, batch=218\n",
      "16033: loss=0.099, reward_mean=0.460, reward_bound=0.289, batch=222\n",
      "16034: loss=0.100, reward_mean=0.370, reward_bound=0.220, batch=225\n",
      "16035: loss=0.098, reward_mean=0.390, reward_bound=0.289, batch=227\n",
      "16036: loss=0.099, reward_mean=0.460, reward_bound=0.314, batch=228\n",
      "16037: loss=0.098, reward_mean=0.520, reward_bound=0.387, batch=224\n",
      "16038: loss=0.098, reward_mean=0.430, reward_bound=0.426, batch=227\n",
      "16039: loss=0.097, reward_mean=0.440, reward_bound=0.342, batch=229\n",
      "16040: loss=0.098, reward_mean=0.470, reward_bound=0.405, batch=230\n",
      "16041: loss=0.088, reward_mean=0.400, reward_bound=0.430, batch=173\n",
      "16042: loss=0.093, reward_mean=0.460, reward_bound=0.190, batch=191\n",
      "16043: loss=0.091, reward_mean=0.440, reward_bound=0.206, batch=203\n",
      "16044: loss=0.089, reward_mean=0.390, reward_bound=0.229, batch=206\n",
      "16045: loss=0.086, reward_mean=0.310, reward_bound=0.176, batch=214\n",
      "16046: loss=0.086, reward_mean=0.430, reward_bound=0.185, batch=218\n",
      "16047: loss=0.089, reward_mean=0.480, reward_bound=0.254, batch=216\n",
      "16048: loss=0.091, reward_mean=0.430, reward_bound=0.282, batch=209\n",
      "16049: loss=0.089, reward_mean=0.570, reward_bound=0.314, batch=209\n",
      "16050: loss=0.091, reward_mean=0.460, reward_bound=0.295, batch=216\n",
      "16051: loss=0.090, reward_mean=0.370, reward_bound=0.196, batch=221\n",
      "16052: loss=0.093, reward_mean=0.440, reward_bound=0.254, batch=224\n",
      "16053: loss=0.089, reward_mean=0.410, reward_bound=0.314, batch=225\n",
      "16054: loss=0.086, reward_mean=0.490, reward_bound=0.349, batch=210\n",
      "16055: loss=0.083, reward_mean=0.440, reward_bound=0.200, batch=217\n",
      "16056: loss=0.086, reward_mean=0.460, reward_bound=0.254, batch=221\n",
      "16057: loss=0.085, reward_mean=0.430, reward_bound=0.349, batch=224\n",
      "16058: loss=0.086, reward_mean=0.460, reward_bound=0.349, batch=226\n",
      "16059: loss=0.092, reward_mean=0.500, reward_bound=0.387, batch=202\n",
      "16060: loss=0.091, reward_mean=0.320, reward_bound=0.185, batch=209\n",
      "16061: loss=0.094, reward_mean=0.490, reward_bound=0.314, batch=214\n",
      "16062: loss=0.093, reward_mean=0.450, reward_bound=0.277, batch=220\n",
      "16063: loss=0.091, reward_mean=0.390, reward_bound=0.282, batch=223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16064: loss=0.090, reward_mean=0.410, reward_bound=0.314, batch=224\n",
      "16065: loss=0.090, reward_mean=0.420, reward_bound=0.349, batch=218\n",
      "16066: loss=0.090, reward_mean=0.440, reward_bound=0.353, batch=222\n",
      "16067: loss=0.091, reward_mean=0.450, reward_bound=0.349, batch=224\n",
      "16068: loss=0.092, reward_mean=0.500, reward_bound=0.349, batch=226\n",
      "16069: loss=0.091, reward_mean=0.430, reward_bound=0.349, batch=227\n",
      "16070: loss=0.092, reward_mean=0.450, reward_bound=0.330, batch=229\n",
      "16071: loss=0.091, reward_mean=0.430, reward_bound=0.387, batch=223\n",
      "16072: loss=0.090, reward_mean=0.390, reward_bound=0.384, batch=226\n",
      "16073: loss=0.091, reward_mean=0.440, reward_bound=0.430, batch=203\n",
      "16074: loss=0.088, reward_mean=0.360, reward_bound=0.185, batch=210\n",
      "16075: loss=0.090, reward_mean=0.520, reward_bound=0.229, batch=213\n",
      "16076: loss=0.093, reward_mean=0.510, reward_bound=0.301, batch=219\n",
      "16077: loss=0.093, reward_mean=0.400, reward_bound=0.314, batch=220\n",
      "16078: loss=0.092, reward_mean=0.440, reward_bound=0.216, batch=224\n",
      "16079: loss=0.095, reward_mean=0.460, reward_bound=0.349, batch=219\n",
      "16080: loss=0.094, reward_mean=0.480, reward_bound=0.364, batch=223\n",
      "16081: loss=0.092, reward_mean=0.490, reward_bound=0.387, batch=220\n",
      "16082: loss=0.094, reward_mean=0.430, reward_bound=0.304, batch=224\n",
      "16083: loss=0.094, reward_mean=0.390, reward_bound=0.314, batch=225\n",
      "16084: loss=0.093, reward_mean=0.470, reward_bound=0.387, batch=225\n",
      "16085: loss=0.093, reward_mean=0.510, reward_bound=0.349, batch=226\n",
      "16086: loss=0.093, reward_mean=0.420, reward_bound=0.368, batch=228\n",
      "16087: loss=0.094, reward_mean=0.410, reward_bound=0.392, batch=229\n",
      "16088: loss=0.093, reward_mean=0.470, reward_bound=0.360, batch=230\n",
      "16089: loss=0.091, reward_mean=0.520, reward_bound=0.430, batch=220\n",
      "16090: loss=0.090, reward_mean=0.500, reward_bound=0.349, batch=223\n",
      "16091: loss=0.090, reward_mean=0.520, reward_bound=0.349, batch=225\n",
      "16092: loss=0.091, reward_mean=0.450, reward_bound=0.329, batch=227\n",
      "16093: loss=0.093, reward_mean=0.530, reward_bound=0.387, batch=224\n",
      "16094: loss=0.092, reward_mean=0.510, reward_bound=0.387, batch=226\n",
      "16095: loss=0.092, reward_mean=0.340, reward_bound=0.390, batch=228\n",
      "16096: loss=0.092, reward_mean=0.450, reward_bound=0.430, batch=224\n",
      "16097: loss=0.091, reward_mean=0.480, reward_bound=0.416, batch=227\n",
      "16098: loss=0.092, reward_mean=0.390, reward_bound=0.277, batch=229\n",
      "16099: loss=0.092, reward_mean=0.320, reward_bound=0.250, batch=230\n",
      "16100: loss=0.091, reward_mean=0.440, reward_bound=0.338, batch=231\n",
      "16101: loss=0.091, reward_mean=0.360, reward_bound=0.387, batch=231\n",
      "16102: loss=0.091, reward_mean=0.490, reward_bound=0.254, batch=231\n",
      "16103: loss=0.091, reward_mean=0.470, reward_bound=0.430, batch=231\n",
      "16104: loss=0.091, reward_mean=0.410, reward_bound=0.430, batch=231\n",
      "16105: loss=0.091, reward_mean=0.420, reward_bound=0.430, batch=231\n",
      "16106: loss=0.091, reward_mean=0.490, reward_bound=0.430, batch=231\n",
      "16107: loss=0.076, reward_mean=0.390, reward_bound=0.478, batch=97\n",
      "16108: loss=0.071, reward_mean=0.440, reward_bound=0.002, batch=138\n",
      "16109: loss=0.070, reward_mean=0.490, reward_bound=0.020, batch=162\n",
      "16110: loss=0.071, reward_mean=0.490, reward_bound=0.058, batch=182\n",
      "16111: loss=0.075, reward_mean=0.400, reward_bound=0.072, batch=193\n",
      "16112: loss=0.077, reward_mean=0.370, reward_bound=0.089, batch=204\n",
      "16113: loss=0.075, reward_mean=0.420, reward_bound=0.122, batch=207\n",
      "16114: loss=0.075, reward_mean=0.430, reward_bound=0.135, batch=213\n",
      "16115: loss=0.078, reward_mean=0.520, reward_bound=0.167, batch=210\n",
      "16116: loss=0.075, reward_mean=0.420, reward_bound=0.185, batch=205\n",
      "16117: loss=0.074, reward_mean=0.560, reward_bound=0.206, batch=207\n",
      "16118: loss=0.072, reward_mean=0.410, reward_bound=0.229, batch=196\n",
      "16119: loss=0.071, reward_mean=0.410, reward_bound=0.207, batch=207\n",
      "16120: loss=0.073, reward_mean=0.460, reward_bound=0.254, batch=195\n",
      "16121: loss=0.073, reward_mean=0.430, reward_bound=0.234, batch=206\n",
      "16122: loss=0.073, reward_mean=0.490, reward_bound=0.254, batch=211\n",
      "16123: loss=0.080, reward_mean=0.430, reward_bound=0.282, batch=195\n",
      "16124: loss=0.079, reward_mean=0.420, reward_bound=0.206, batch=204\n",
      "16125: loss=0.077, reward_mean=0.410, reward_bound=0.229, batch=211\n",
      "16126: loss=0.078, reward_mean=0.360, reward_bound=0.254, batch=215\n",
      "16127: loss=0.077, reward_mean=0.350, reward_bound=0.254, batch=219\n",
      "16128: loss=0.078, reward_mean=0.420, reward_bound=0.282, batch=210\n",
      "16129: loss=0.079, reward_mean=0.410, reward_bound=0.222, batch=217\n",
      "16130: loss=0.078, reward_mean=0.370, reward_bound=0.229, batch=219\n",
      "16131: loss=0.077, reward_mean=0.470, reward_bound=0.282, batch=222\n",
      "16132: loss=0.083, reward_mean=0.530, reward_bound=0.314, batch=195\n",
      "16133: loss=0.085, reward_mean=0.440, reward_bound=0.206, batch=204\n",
      "16134: loss=0.082, reward_mean=0.480, reward_bound=0.282, batch=212\n",
      "16135: loss=0.082, reward_mean=0.490, reward_bound=0.206, batch=220\n",
      "16136: loss=0.083, reward_mean=0.410, reward_bound=0.206, batch=225\n",
      "16137: loss=0.084, reward_mean=0.450, reward_bound=0.289, batch=227\n",
      "16138: loss=0.086, reward_mean=0.470, reward_bound=0.314, batch=227\n",
      "16139: loss=0.086, reward_mean=0.370, reward_bound=0.282, batch=228\n",
      "16140: loss=0.089, reward_mean=0.410, reward_bound=0.349, batch=189\n",
      "16141: loss=0.086, reward_mean=0.450, reward_bound=0.215, batch=202\n",
      "16142: loss=0.088, reward_mean=0.420, reward_bound=0.150, batch=210\n",
      "16143: loss=0.087, reward_mean=0.400, reward_bound=0.180, batch=217\n",
      "16144: loss=0.087, reward_mean=0.530, reward_bound=0.229, batch=221\n",
      "16145: loss=0.086, reward_mean=0.470, reward_bound=0.282, batch=220\n",
      "16146: loss=0.086, reward_mean=0.400, reward_bound=0.274, batch=224\n",
      "16147: loss=0.085, reward_mean=0.420, reward_bound=0.277, batch=227\n",
      "16148: loss=0.086, reward_mean=0.480, reward_bound=0.314, batch=217\n",
      "16149: loss=0.088, reward_mean=0.490, reward_bound=0.349, batch=212\n",
      "16150: loss=0.089, reward_mean=0.380, reward_bound=0.172, batch=218\n",
      "16151: loss=0.087, reward_mean=0.400, reward_bound=0.254, batch=220\n",
      "16152: loss=0.087, reward_mean=0.490, reward_bound=0.314, batch=222\n",
      "16153: loss=0.087, reward_mean=0.520, reward_bound=0.263, batch=225\n",
      "16154: loss=0.087, reward_mean=0.490, reward_bound=0.349, batch=222\n",
      "16155: loss=0.084, reward_mean=0.440, reward_bound=0.387, batch=181\n",
      "16156: loss=0.078, reward_mean=0.370, reward_bound=0.135, batch=196\n",
      "16157: loss=0.081, reward_mean=0.400, reward_bound=0.150, batch=206\n",
      "16158: loss=0.079, reward_mean=0.390, reward_bound=0.185, batch=209\n",
      "16159: loss=0.081, reward_mean=0.410, reward_bound=0.229, batch=213\n",
      "16160: loss=0.084, reward_mean=0.410, reward_bound=0.198, batch=219\n",
      "16161: loss=0.083, reward_mean=0.450, reward_bound=0.254, batch=217\n",
      "16162: loss=0.084, reward_mean=0.490, reward_bound=0.282, batch=214\n",
      "16163: loss=0.084, reward_mean=0.490, reward_bound=0.314, batch=210\n",
      "16164: loss=0.084, reward_mean=0.410, reward_bound=0.206, batch=218\n",
      "16165: loss=0.083, reward_mean=0.460, reward_bound=0.314, batch=221\n",
      "16166: loss=0.082, reward_mean=0.420, reward_bound=0.282, batch=224\n",
      "16167: loss=0.083, reward_mean=0.510, reward_bound=0.282, batch=226\n",
      "16168: loss=0.081, reward_mean=0.420, reward_bound=0.349, batch=216\n",
      "16169: loss=0.080, reward_mean=0.470, reward_bound=0.349, batch=220\n",
      "16170: loss=0.081, reward_mean=0.490, reward_bound=0.349, batch=222\n",
      "16171: loss=0.084, reward_mean=0.490, reward_bound=0.387, batch=206\n",
      "16172: loss=0.082, reward_mean=0.510, reward_bound=0.268, batch=214\n",
      "16173: loss=0.084, reward_mean=0.480, reward_bound=0.282, batch=218\n",
      "16174: loss=0.082, reward_mean=0.460, reward_bound=0.349, batch=215\n",
      "16175: loss=0.082, reward_mean=0.470, reward_bound=0.321, batch=220\n",
      "16176: loss=0.084, reward_mean=0.400, reward_bound=0.387, batch=219\n",
      "16177: loss=0.083, reward_mean=0.480, reward_bound=0.387, batch=222\n",
      "16178: loss=0.083, reward_mean=0.490, reward_bound=0.400, batch=225\n",
      "16179: loss=0.083, reward_mean=0.520, reward_bound=0.430, batch=163\n",
      "16180: loss=0.078, reward_mean=0.430, reward_bound=0.062, batch=184\n",
      "16181: loss=0.078, reward_mean=0.370, reward_bound=0.080, batch=198\n",
      "16182: loss=0.079, reward_mean=0.420, reward_bound=0.122, batch=207\n",
      "16183: loss=0.080, reward_mean=0.480, reward_bound=0.150, batch=213\n",
      "16184: loss=0.081, reward_mean=0.470, reward_bound=0.206, batch=218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16185: loss=0.085, reward_mean=0.510, reward_bound=0.229, batch=216\n",
      "16186: loss=0.082, reward_mean=0.450, reward_bound=0.254, batch=214\n",
      "16187: loss=0.079, reward_mean=0.400, reward_bound=0.224, batch=220\n",
      "16188: loss=0.083, reward_mean=0.470, reward_bound=0.247, batch=224\n",
      "16189: loss=0.084, reward_mean=0.460, reward_bound=0.282, batch=224\n",
      "16190: loss=0.084, reward_mean=0.450, reward_bound=0.280, batch=227\n",
      "16191: loss=0.078, reward_mean=0.420, reward_bound=0.314, batch=210\n",
      "16192: loss=0.079, reward_mean=0.390, reward_bound=0.282, batch=213\n",
      "16193: loss=0.077, reward_mean=0.430, reward_bound=0.229, batch=218\n",
      "16194: loss=0.077, reward_mean=0.470, reward_bound=0.254, batch=221\n",
      "16195: loss=0.078, reward_mean=0.410, reward_bound=0.254, batch=224\n",
      "16196: loss=0.076, reward_mean=0.460, reward_bound=0.314, batch=226\n",
      "16197: loss=0.075, reward_mean=0.430, reward_bound=0.349, batch=211\n",
      "16198: loss=0.077, reward_mean=0.500, reward_bound=0.229, batch=217\n",
      "16199: loss=0.076, reward_mean=0.490, reward_bound=0.314, batch=219\n",
      "16200: loss=0.075, reward_mean=0.410, reward_bound=0.314, batch=222\n",
      "16201: loss=0.076, reward_mean=0.400, reward_bound=0.314, batch=224\n",
      "16202: loss=0.074, reward_mean=0.490, reward_bound=0.384, batch=227\n",
      "16203: loss=0.078, reward_mean=0.490, reward_bound=0.387, batch=205\n",
      "16204: loss=0.076, reward_mean=0.540, reward_bound=0.254, batch=212\n",
      "16205: loss=0.078, reward_mean=0.490, reward_bound=0.282, batch=214\n",
      "16206: loss=0.080, reward_mean=0.500, reward_bound=0.311, batch=220\n",
      "16207: loss=0.078, reward_mean=0.510, reward_bound=0.314, batch=223\n",
      "16208: loss=0.079, reward_mean=0.320, reward_bound=0.271, batch=226\n",
      "16209: loss=0.077, reward_mean=0.480, reward_bound=0.331, batch=228\n",
      "16210: loss=0.079, reward_mean=0.480, reward_bound=0.349, batch=225\n",
      "16211: loss=0.079, reward_mean=0.350, reward_bound=0.321, batch=227\n",
      "16212: loss=0.080, reward_mean=0.370, reward_bound=0.380, batch=229\n",
      "16213: loss=0.080, reward_mean=0.500, reward_bound=0.387, batch=222\n",
      "16214: loss=0.082, reward_mean=0.440, reward_bound=0.430, batch=201\n",
      "16215: loss=0.079, reward_mean=0.500, reward_bound=0.314, batch=210\n",
      "16216: loss=0.080, reward_mean=0.510, reward_bound=0.296, batch=217\n",
      "16217: loss=0.080, reward_mean=0.400, reward_bound=0.277, batch=222\n",
      "16218: loss=0.080, reward_mean=0.570, reward_bound=0.314, batch=222\n",
      "16219: loss=0.085, reward_mean=0.400, reward_bound=0.349, batch=219\n",
      "16220: loss=0.084, reward_mean=0.460, reward_bound=0.282, batch=222\n",
      "16221: loss=0.085, reward_mean=0.420, reward_bound=0.349, batch=223\n",
      "16222: loss=0.084, reward_mean=0.390, reward_bound=0.387, batch=219\n",
      "16223: loss=0.084, reward_mean=0.430, reward_bound=0.387, batch=222\n",
      "16224: loss=0.084, reward_mean=0.440, reward_bound=0.360, batch=225\n",
      "16225: loss=0.085, reward_mean=0.410, reward_bound=0.387, batch=226\n",
      "16226: loss=0.085, reward_mean=0.400, reward_bound=0.387, batch=226\n",
      "16227: loss=0.087, reward_mean=0.490, reward_bound=0.368, batch=228\n",
      "16228: loss=0.082, reward_mean=0.370, reward_bound=0.430, batch=213\n",
      "16229: loss=0.079, reward_mean=0.480, reward_bound=0.198, batch=219\n",
      "16230: loss=0.078, reward_mean=0.480, reward_bound=0.239, batch=223\n",
      "16231: loss=0.079, reward_mean=0.420, reward_bound=0.244, batch=226\n",
      "16232: loss=0.081, reward_mean=0.440, reward_bound=0.314, batch=226\n",
      "16233: loss=0.081, reward_mean=0.460, reward_bound=0.349, batch=225\n",
      "16234: loss=0.082, reward_mean=0.540, reward_bound=0.356, batch=227\n",
      "16235: loss=0.082, reward_mean=0.440, reward_bound=0.373, batch=229\n",
      "16236: loss=0.084, reward_mean=0.380, reward_bound=0.387, batch=226\n",
      "16237: loss=0.082, reward_mean=0.460, reward_bound=0.430, batch=219\n",
      "16238: loss=0.082, reward_mean=0.440, reward_bound=0.250, batch=223\n",
      "16239: loss=0.086, reward_mean=0.470, reward_bound=0.301, batch=226\n",
      "16240: loss=0.082, reward_mean=0.410, reward_bound=0.349, batch=224\n",
      "16241: loss=0.082, reward_mean=0.450, reward_bound=0.384, batch=227\n",
      "16242: loss=0.082, reward_mean=0.420, reward_bound=0.387, batch=228\n",
      "16243: loss=0.081, reward_mean=0.480, reward_bound=0.430, batch=225\n",
      "16244: loss=0.080, reward_mean=0.430, reward_bound=0.478, batch=140\n",
      "16245: loss=0.088, reward_mean=0.470, reward_bound=0.070, batch=168\n",
      "16246: loss=0.087, reward_mean=0.460, reward_bound=0.089, batch=184\n",
      "16247: loss=0.088, reward_mean=0.450, reward_bound=0.109, batch=198\n",
      "16248: loss=0.087, reward_mean=0.370, reward_bound=0.122, batch=205\n",
      "16249: loss=0.081, reward_mean=0.480, reward_bound=0.150, batch=201\n",
      "16250: loss=0.081, reward_mean=0.440, reward_bound=0.167, batch=210\n",
      "16251: loss=0.088, reward_mean=0.390, reward_bound=0.185, batch=204\n",
      "16252: loss=0.091, reward_mean=0.480, reward_bound=0.206, batch=205\n",
      "16253: loss=0.093, reward_mean=0.390, reward_bound=0.210, batch=213\n",
      "16254: loss=0.092, reward_mean=0.440, reward_bound=0.229, batch=209\n",
      "16255: loss=0.093, reward_mean=0.340, reward_bound=0.185, batch=215\n",
      "16256: loss=0.092, reward_mean=0.360, reward_bound=0.210, batch=220\n",
      "16257: loss=0.091, reward_mean=0.440, reward_bound=0.254, batch=214\n",
      "16258: loss=0.090, reward_mean=0.430, reward_bound=0.275, batch=220\n",
      "16259: loss=0.092, reward_mean=0.550, reward_bound=0.282, batch=211\n",
      "16260: loss=0.090, reward_mean=0.430, reward_bound=0.229, batch=216\n",
      "16261: loss=0.093, reward_mean=0.450, reward_bound=0.254, batch=220\n",
      "16262: loss=0.092, reward_mean=0.450, reward_bound=0.314, batch=205\n",
      "16263: loss=0.091, reward_mean=0.470, reward_bound=0.229, batch=212\n",
      "16264: loss=0.092, reward_mean=0.390, reward_bound=0.282, batch=216\n",
      "16265: loss=0.092, reward_mean=0.530, reward_bound=0.268, batch=221\n",
      "16266: loss=0.092, reward_mean=0.510, reward_bound=0.314, batch=224\n",
      "16267: loss=0.089, reward_mean=0.370, reward_bound=0.349, batch=205\n",
      "16268: loss=0.088, reward_mean=0.390, reward_bound=0.206, batch=212\n",
      "16269: loss=0.086, reward_mean=0.390, reward_bound=0.263, batch=218\n",
      "16270: loss=0.090, reward_mean=0.400, reward_bound=0.314, batch=219\n",
      "16271: loss=0.090, reward_mean=0.450, reward_bound=0.265, batch=223\n",
      "16272: loss=0.090, reward_mean=0.330, reward_bound=0.282, batch=225\n",
      "16273: loss=0.090, reward_mean=0.390, reward_bound=0.321, batch=227\n",
      "16274: loss=0.089, reward_mean=0.450, reward_bound=0.349, batch=225\n",
      "16275: loss=0.091, reward_mean=0.380, reward_bound=0.387, batch=200\n",
      "16276: loss=0.091, reward_mean=0.480, reward_bound=0.247, batch=210\n",
      "16277: loss=0.091, reward_mean=0.470, reward_bound=0.167, batch=216\n",
      "16278: loss=0.090, reward_mean=0.420, reward_bound=0.207, batch=221\n",
      "16279: loss=0.093, reward_mean=0.410, reward_bound=0.254, batch=223\n",
      "16280: loss=0.091, reward_mean=0.490, reward_bound=0.282, batch=225\n",
      "16281: loss=0.089, reward_mean=0.510, reward_bound=0.314, batch=224\n",
      "16282: loss=0.088, reward_mean=0.440, reward_bound=0.345, batch=227\n",
      "16283: loss=0.089, reward_mean=0.420, reward_bound=0.349, batch=222\n",
      "16284: loss=0.088, reward_mean=0.430, reward_bound=0.387, batch=218\n",
      "16285: loss=0.088, reward_mean=0.430, reward_bound=0.289, batch=222\n",
      "16286: loss=0.090, reward_mean=0.480, reward_bound=0.302, batch=225\n",
      "16287: loss=0.091, reward_mean=0.390, reward_bound=0.321, batch=227\n",
      "16288: loss=0.088, reward_mean=0.440, reward_bound=0.349, batch=226\n",
      "16289: loss=0.088, reward_mean=0.430, reward_bound=0.387, batch=227\n",
      "16290: loss=0.087, reward_mean=0.450, reward_bound=0.407, batch=229\n",
      "16291: loss=0.087, reward_mean=0.420, reward_bound=0.364, batch=230\n",
      "16292: loss=0.087, reward_mean=0.580, reward_bound=0.376, batch=231\n",
      "16293: loss=0.078, reward_mean=0.460, reward_bound=0.430, batch=186\n",
      "16294: loss=0.079, reward_mean=0.540, reward_bound=0.254, batch=198\n",
      "16295: loss=0.080, reward_mean=0.470, reward_bound=0.282, batch=204\n",
      "16296: loss=0.079, reward_mean=0.420, reward_bound=0.229, batch=211\n",
      "16297: loss=0.081, reward_mean=0.520, reward_bound=0.254, batch=214\n",
      "16298: loss=0.079, reward_mean=0.460, reward_bound=0.204, batch=220\n",
      "16299: loss=0.081, reward_mean=0.370, reward_bound=0.247, batch=224\n",
      "16300: loss=0.082, reward_mean=0.500, reward_bound=0.282, batch=224\n",
      "16301: loss=0.082, reward_mean=0.410, reward_bound=0.314, batch=220\n",
      "16302: loss=0.082, reward_mean=0.470, reward_bound=0.314, batch=223\n",
      "16303: loss=0.079, reward_mean=0.400, reward_bound=0.349, batch=213\n",
      "16304: loss=0.080, reward_mean=0.460, reward_bound=0.282, batch=218\n",
      "16305: loss=0.078, reward_mean=0.410, reward_bound=0.314, batch=220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16306: loss=0.077, reward_mean=0.470, reward_bound=0.254, batch=223\n",
      "16307: loss=0.078, reward_mean=0.390, reward_bound=0.349, batch=225\n",
      "16308: loss=0.080, reward_mean=0.440, reward_bound=0.387, batch=218\n",
      "16309: loss=0.080, reward_mean=0.480, reward_bound=0.353, batch=222\n",
      "16310: loss=0.081, reward_mean=0.470, reward_bound=0.349, batch=224\n",
      "16311: loss=0.081, reward_mean=0.410, reward_bound=0.311, batch=227\n",
      "16312: loss=0.081, reward_mean=0.440, reward_bound=0.314, batch=228\n",
      "16313: loss=0.080, reward_mean=0.430, reward_bound=0.349, batch=227\n",
      "16314: loss=0.079, reward_mean=0.560, reward_bound=0.373, batch=229\n",
      "16315: loss=0.079, reward_mean=0.420, reward_bound=0.387, batch=229\n",
      "16316: loss=0.076, reward_mean=0.390, reward_bound=0.430, batch=209\n",
      "16317: loss=0.076, reward_mean=0.440, reward_bound=0.295, batch=216\n",
      "16318: loss=0.076, reward_mean=0.500, reward_bound=0.349, batch=216\n",
      "16319: loss=0.074, reward_mean=0.420, reward_bound=0.368, batch=221\n",
      "16320: loss=0.074, reward_mean=0.390, reward_bound=0.314, batch=224\n",
      "16321: loss=0.074, reward_mean=0.450, reward_bound=0.349, batch=226\n",
      "16322: loss=0.073, reward_mean=0.390, reward_bound=0.387, batch=221\n",
      "16323: loss=0.075, reward_mean=0.470, reward_bound=0.314, batch=224\n",
      "16324: loss=0.074, reward_mean=0.460, reward_bound=0.349, batch=226\n",
      "16325: loss=0.072, reward_mean=0.490, reward_bound=0.387, batch=226\n",
      "16326: loss=0.073, reward_mean=0.450, reward_bound=0.298, batch=228\n",
      "16327: loss=0.072, reward_mean=0.370, reward_bound=0.349, batch=226\n",
      "16328: loss=0.073, reward_mean=0.450, reward_bound=0.390, batch=228\n",
      "16329: loss=0.073, reward_mean=0.460, reward_bound=0.392, batch=229\n",
      "16330: loss=0.075, reward_mean=0.460, reward_bound=0.430, batch=222\n",
      "16331: loss=0.075, reward_mean=0.470, reward_bound=0.445, batch=225\n",
      "16332: loss=0.075, reward_mean=0.420, reward_bound=0.321, batch=227\n",
      "16333: loss=0.074, reward_mean=0.400, reward_bound=0.380, batch=229\n",
      "16334: loss=0.074, reward_mean=0.450, reward_bound=0.328, batch=230\n",
      "16335: loss=0.075, reward_mean=0.390, reward_bound=0.387, batch=230\n",
      "16336: loss=0.074, reward_mean=0.460, reward_bound=0.430, batch=229\n",
      "16337: loss=0.074, reward_mean=0.460, reward_bound=0.450, batch=230\n",
      "16338: loss=0.074, reward_mean=0.370, reward_bound=0.439, batch=231\n",
      "16339: loss=0.075, reward_mean=0.450, reward_bound=0.478, batch=180\n",
      "16340: loss=0.072, reward_mean=0.420, reward_bound=0.146, batch=196\n",
      "16341: loss=0.069, reward_mean=0.420, reward_bound=0.167, batch=205\n",
      "16342: loss=0.072, reward_mean=0.450, reward_bound=0.185, batch=211\n",
      "16343: loss=0.074, reward_mean=0.510, reward_bound=0.229, batch=215\n",
      "16344: loss=0.076, reward_mean=0.520, reward_bound=0.282, batch=213\n",
      "16345: loss=0.074, reward_mean=0.410, reward_bound=0.301, batch=219\n",
      "16346: loss=0.072, reward_mean=0.340, reward_bound=0.215, batch=223\n",
      "16347: loss=0.074, reward_mean=0.400, reward_bound=0.254, batch=225\n",
      "16348: loss=0.071, reward_mean=0.460, reward_bound=0.314, batch=219\n",
      "16349: loss=0.075, reward_mean=0.460, reward_bound=0.349, batch=209\n",
      "16350: loss=0.077, reward_mean=0.470, reward_bound=0.239, batch=216\n",
      "16351: loss=0.079, reward_mean=0.440, reward_bound=0.217, batch=221\n",
      "16352: loss=0.080, reward_mean=0.460, reward_bound=0.254, batch=222\n",
      "16353: loss=0.079, reward_mean=0.390, reward_bound=0.229, batch=224\n",
      "16354: loss=0.074, reward_mean=0.580, reward_bound=0.314, batch=225\n",
      "16355: loss=0.077, reward_mean=0.450, reward_bound=0.387, batch=208\n",
      "16356: loss=0.075, reward_mean=0.430, reward_bound=0.234, batch=215\n",
      "16357: loss=0.074, reward_mean=0.430, reward_bound=0.289, batch=220\n",
      "16358: loss=0.075, reward_mean=0.410, reward_bound=0.314, batch=220\n",
      "16359: loss=0.076, reward_mean=0.480, reward_bound=0.349, batch=221\n",
      "16360: loss=0.075, reward_mean=0.450, reward_bound=0.349, batch=224\n",
      "16361: loss=0.074, reward_mean=0.430, reward_bound=0.342, batch=227\n",
      "16362: loss=0.074, reward_mean=0.510, reward_bound=0.349, batch=228\n",
      "16363: loss=0.074, reward_mean=0.510, reward_bound=0.353, batch=229\n",
      "16364: loss=0.072, reward_mean=0.400, reward_bound=0.387, batch=226\n",
      "16365: loss=0.073, reward_mean=0.350, reward_bound=0.351, batch=228\n",
      "16366: loss=0.073, reward_mean=0.450, reward_bound=0.387, batch=228\n",
      "16367: loss=0.073, reward_mean=0.410, reward_bound=0.430, batch=210\n",
      "16368: loss=0.073, reward_mean=0.470, reward_bound=0.254, batch=216\n",
      "16369: loss=0.074, reward_mean=0.380, reward_bound=0.256, batch=221\n",
      "16370: loss=0.074, reward_mean=0.390, reward_bound=0.229, batch=224\n",
      "16371: loss=0.072, reward_mean=0.350, reward_bound=0.280, batch=227\n",
      "16372: loss=0.071, reward_mean=0.350, reward_bound=0.282, batch=226\n",
      "16373: loss=0.072, reward_mean=0.410, reward_bound=0.349, batch=220\n",
      "16374: loss=0.073, reward_mean=0.460, reward_bound=0.296, batch=224\n",
      "16375: loss=0.073, reward_mean=0.490, reward_bound=0.314, batch=225\n",
      "16376: loss=0.071, reward_mean=0.430, reward_bound=0.349, batch=224\n",
      "16377: loss=0.070, reward_mean=0.430, reward_bound=0.387, batch=222\n",
      "16378: loss=0.070, reward_mean=0.410, reward_bound=0.400, batch=225\n",
      "16379: loss=0.070, reward_mean=0.450, reward_bound=0.349, batch=226\n",
      "16380: loss=0.069, reward_mean=0.440, reward_bound=0.241, batch=228\n",
      "16381: loss=0.070, reward_mean=0.480, reward_bound=0.387, batch=228\n",
      "16382: loss=0.070, reward_mean=0.480, reward_bound=0.392, batch=229\n",
      "16383: loss=0.070, reward_mean=0.440, reward_bound=0.430, batch=223\n",
      "16384: loss=0.073, reward_mean=0.460, reward_bound=0.372, batch=226\n",
      "16385: loss=0.073, reward_mean=0.490, reward_bound=0.409, batch=228\n",
      "16386: loss=0.074, reward_mean=0.410, reward_bound=0.392, batch=229\n",
      "16387: loss=0.073, reward_mean=0.450, reward_bound=0.405, batch=230\n",
      "16388: loss=0.071, reward_mean=0.480, reward_bound=0.430, batch=230\n",
      "16389: loss=0.071, reward_mean=0.400, reward_bound=0.451, batch=231\n",
      "16390: loss=0.073, reward_mean=0.490, reward_bound=0.478, batch=196\n",
      "16391: loss=0.074, reward_mean=0.430, reward_bound=0.144, batch=207\n",
      "16392: loss=0.077, reward_mean=0.460, reward_bound=0.229, batch=213\n",
      "16393: loss=0.079, reward_mean=0.370, reward_bound=0.244, batch=219\n",
      "16394: loss=0.082, reward_mean=0.530, reward_bound=0.282, batch=218\n",
      "16395: loss=0.084, reward_mean=0.470, reward_bound=0.314, batch=216\n",
      "16396: loss=0.083, reward_mean=0.610, reward_bound=0.331, batch=221\n",
      "16397: loss=0.080, reward_mean=0.410, reward_bound=0.349, batch=218\n",
      "16398: loss=0.080, reward_mean=0.470, reward_bound=0.282, batch=220\n",
      "16399: loss=0.078, reward_mean=0.420, reward_bound=0.387, batch=219\n",
      "16400: loss=0.077, reward_mean=0.460, reward_bound=0.282, batch=222\n",
      "16401: loss=0.077, reward_mean=0.430, reward_bound=0.324, batch=225\n",
      "16402: loss=0.077, reward_mean=0.520, reward_bound=0.356, batch=227\n",
      "16403: loss=0.079, reward_mean=0.460, reward_bound=0.387, batch=226\n",
      "16404: loss=0.075, reward_mean=0.380, reward_bound=0.430, batch=215\n",
      "16405: loss=0.074, reward_mean=0.470, reward_bound=0.234, batch=220\n",
      "16406: loss=0.075, reward_mean=0.410, reward_bound=0.349, batch=220\n",
      "16407: loss=0.077, reward_mean=0.430, reward_bound=0.329, batch=224\n",
      "16408: loss=0.078, reward_mean=0.450, reward_bound=0.349, batch=226\n",
      "16409: loss=0.076, reward_mean=0.480, reward_bound=0.387, batch=224\n",
      "16410: loss=0.075, reward_mean=0.480, reward_bound=0.422, batch=227\n",
      "16411: loss=0.074, reward_mean=0.390, reward_bound=0.422, batch=229\n",
      "16412: loss=0.074, reward_mean=0.440, reward_bound=0.430, batch=226\n",
      "16413: loss=0.074, reward_mean=0.420, reward_bound=0.387, batch=227\n",
      "16414: loss=0.074, reward_mean=0.380, reward_bound=0.373, batch=229\n",
      "16415: loss=0.075, reward_mean=0.390, reward_bound=0.387, batch=228\n",
      "16416: loss=0.074, reward_mean=0.410, reward_bound=0.392, batch=229\n",
      "16417: loss=0.074, reward_mean=0.460, reward_bound=0.430, batch=226\n",
      "16418: loss=0.073, reward_mean=0.430, reward_bound=0.409, batch=228\n",
      "16419: loss=0.074, reward_mean=0.450, reward_bound=0.430, batch=227\n",
      "16420: loss=0.075, reward_mean=0.360, reward_bound=0.380, batch=229\n",
      "16421: loss=0.075, reward_mean=0.490, reward_bound=0.405, batch=230\n",
      "16422: loss=0.075, reward_mean=0.460, reward_bound=0.418, batch=231\n",
      "16423: loss=0.074, reward_mean=0.380, reward_bound=0.430, batch=229\n",
      "16424: loss=0.075, reward_mean=0.430, reward_bound=0.450, batch=230\n",
      "16425: loss=0.072, reward_mean=0.420, reward_bound=0.478, batch=213\n",
      "16426: loss=0.073, reward_mean=0.470, reward_bound=0.314, batch=217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16427: loss=0.073, reward_mean=0.520, reward_bound=0.277, batch=222\n",
      "16428: loss=0.073, reward_mean=0.460, reward_bound=0.349, batch=221\n",
      "16429: loss=0.075, reward_mean=0.360, reward_bound=0.314, batch=224\n",
      "16430: loss=0.074, reward_mean=0.440, reward_bound=0.380, batch=227\n",
      "16431: loss=0.071, reward_mean=0.500, reward_bound=0.387, batch=226\n",
      "16432: loss=0.071, reward_mean=0.450, reward_bound=0.368, batch=228\n",
      "16433: loss=0.071, reward_mean=0.370, reward_bound=0.387, batch=228\n",
      "16434: loss=0.072, reward_mean=0.460, reward_bound=0.430, batch=217\n",
      "16435: loss=0.071, reward_mean=0.440, reward_bound=0.277, batch=222\n",
      "16436: loss=0.070, reward_mean=0.430, reward_bound=0.292, batch=225\n",
      "16437: loss=0.072, reward_mean=0.440, reward_bound=0.314, batch=224\n",
      "16438: loss=0.074, reward_mean=0.390, reward_bound=0.349, batch=225\n",
      "16439: loss=0.074, reward_mean=0.520, reward_bound=0.349, batch=226\n",
      "16440: loss=0.074, reward_mean=0.420, reward_bound=0.368, batch=228\n",
      "16441: loss=0.072, reward_mean=0.480, reward_bound=0.430, batch=224\n",
      "16442: loss=0.073, reward_mean=0.520, reward_bound=0.384, batch=227\n",
      "16443: loss=0.071, reward_mean=0.430, reward_bound=0.422, batch=229\n",
      "16444: loss=0.071, reward_mean=0.410, reward_bound=0.349, batch=229\n",
      "16445: loss=0.073, reward_mean=0.390, reward_bound=0.430, batch=227\n",
      "16446: loss=0.073, reward_mean=0.460, reward_bound=0.387, batch=227\n",
      "16447: loss=0.074, reward_mean=0.470, reward_bound=0.452, batch=229\n",
      "16448: loss=0.074, reward_mean=0.440, reward_bound=0.349, batch=229\n",
      "16449: loss=0.074, reward_mean=0.440, reward_bound=0.430, batch=229\n",
      "16450: loss=0.075, reward_mean=0.440, reward_bound=0.478, batch=231\n",
      "16451: loss=0.075, reward_mean=0.490, reward_bound=0.430, batch=231\n",
      "16452: loss=0.072, reward_mean=0.560, reward_bound=0.478, batch=224\n",
      "16453: loss=0.071, reward_mean=0.450, reward_bound=0.426, batch=227\n",
      "16454: loss=0.071, reward_mean=0.390, reward_bound=0.314, batch=228\n",
      "16455: loss=0.072, reward_mean=0.360, reward_bound=0.430, batch=225\n",
      "16456: loss=0.072, reward_mean=0.400, reward_bound=0.314, batch=226\n",
      "16457: loss=0.071, reward_mean=0.420, reward_bound=0.454, batch=228\n",
      "16458: loss=0.071, reward_mean=0.460, reward_bound=0.435, batch=229\n",
      "16459: loss=0.071, reward_mean=0.400, reward_bound=0.405, batch=230\n",
      "16460: loss=0.071, reward_mean=0.490, reward_bound=0.464, batch=231\n",
      "16461: loss=0.073, reward_mean=0.450, reward_bound=0.478, batch=226\n",
      "16462: loss=0.073, reward_mean=0.510, reward_bound=0.349, batch=226\n",
      "16463: loss=0.073, reward_mean=0.440, reward_bound=0.254, batch=227\n",
      "16464: loss=0.074, reward_mean=0.480, reward_bound=0.414, batch=229\n",
      "16465: loss=0.074, reward_mean=0.470, reward_bound=0.387, batch=229\n",
      "16466: loss=0.073, reward_mean=0.450, reward_bound=0.328, batch=230\n",
      "16467: loss=0.073, reward_mean=0.480, reward_bound=0.430, batch=228\n",
      "16468: loss=0.072, reward_mean=0.450, reward_bound=0.397, batch=229\n",
      "16469: loss=0.072, reward_mean=0.370, reward_bound=0.478, batch=231\n",
      "16470: loss=0.073, reward_mean=0.430, reward_bound=0.478, batch=229\n",
      "16471: loss=0.072, reward_mean=0.410, reward_bound=0.401, batch=230\n",
      "16472: loss=0.072, reward_mean=0.460, reward_bound=0.515, batch=231\n",
      "16473: loss=0.072, reward_mean=0.400, reward_bound=0.478, batch=231\n",
      "16474: loss=0.072, reward_mean=0.550, reward_bound=0.478, batch=231\n",
      "16475: loss=0.072, reward_mean=0.470, reward_bound=0.430, batch=231\n",
      "16477: loss=0.053, reward_mean=0.430, reward_bound=0.000, batch=43\n",
      "16478: loss=0.061, reward_mean=0.460, reward_bound=0.000, batch=89\n",
      "16479: loss=0.065, reward_mean=0.400, reward_bound=0.000, batch=129\n",
      "16480: loss=0.066, reward_mean=0.500, reward_bound=0.004, batch=160\n",
      "16481: loss=0.070, reward_mean=0.510, reward_bound=0.020, batch=179\n",
      "16482: loss=0.069, reward_mean=0.390, reward_bound=0.028, batch=192\n",
      "16483: loss=0.070, reward_mean=0.530, reward_bound=0.052, batch=199\n",
      "16484: loss=0.071, reward_mean=0.510, reward_bound=0.065, batch=204\n",
      "16485: loss=0.069, reward_mean=0.480, reward_bound=0.080, batch=207\n",
      "16486: loss=0.069, reward_mean=0.380, reward_bound=0.089, batch=221\n",
      "16487: loss=0.071, reward_mean=0.430, reward_bound=0.098, batch=217\n",
      "16488: loss=0.070, reward_mean=0.440, reward_bound=0.122, batch=210\n",
      "16489: loss=0.073, reward_mean=0.440, reward_bound=0.135, batch=214\n",
      "16490: loss=0.070, reward_mean=0.420, reward_bound=0.150, batch=204\n",
      "16491: loss=0.072, reward_mean=0.530, reward_bound=0.167, batch=198\n",
      "16492: loss=0.075, reward_mean=0.460, reward_bound=0.185, batch=188\n",
      "16493: loss=0.072, reward_mean=0.430, reward_bound=0.206, batch=170\n",
      "16494: loss=0.074, reward_mean=0.360, reward_bound=0.080, batch=188\n",
      "16495: loss=0.072, reward_mean=0.430, reward_bound=0.123, batch=201\n",
      "16496: loss=0.073, reward_mean=0.500, reward_bound=0.167, batch=208\n",
      "16497: loss=0.072, reward_mean=0.510, reward_bound=0.206, batch=211\n",
      "16498: loss=0.078, reward_mean=0.370, reward_bound=0.229, batch=192\n",
      "16499: loss=0.077, reward_mean=0.470, reward_bound=0.191, batch=204\n",
      "16500: loss=0.076, reward_mean=0.470, reward_bound=0.204, batch=213\n",
      "16501: loss=0.075, reward_mean=0.400, reward_bound=0.206, batch=217\n",
      "16502: loss=0.075, reward_mean=0.440, reward_bound=0.229, batch=220\n",
      "16503: loss=0.077, reward_mean=0.540, reward_bound=0.254, batch=187\n",
      "16504: loss=0.081, reward_mean=0.500, reward_bound=0.150, batch=200\n",
      "16505: loss=0.081, reward_mean=0.370, reward_bound=0.150, batch=209\n",
      "16506: loss=0.078, reward_mean=0.490, reward_bound=0.206, batch=215\n",
      "16507: loss=0.077, reward_mean=0.440, reward_bound=0.229, batch=218\n",
      "16508: loss=0.074, reward_mean=0.520, reward_bound=0.282, batch=170\n",
      "16509: loss=0.073, reward_mean=0.470, reward_bound=0.089, batch=186\n",
      "16510: loss=0.072, reward_mean=0.470, reward_bound=0.115, batch=200\n",
      "16511: loss=0.070, reward_mean=0.450, reward_bound=0.146, batch=210\n",
      "16512: loss=0.071, reward_mean=0.450, reward_bound=0.167, batch=215\n",
      "16513: loss=0.071, reward_mean=0.440, reward_bound=0.185, batch=219\n",
      "16514: loss=0.069, reward_mean=0.330, reward_bound=0.206, batch=218\n",
      "16515: loss=0.071, reward_mean=0.360, reward_bound=0.229, batch=219\n",
      "16516: loss=0.070, reward_mean=0.390, reward_bound=0.254, batch=212\n",
      "16517: loss=0.068, reward_mean=0.350, reward_bound=0.213, batch=218\n",
      "16518: loss=0.068, reward_mean=0.480, reward_bound=0.257, batch=222\n",
      "16519: loss=0.068, reward_mean=0.410, reward_bound=0.263, batch=225\n",
      "16520: loss=0.068, reward_mean=0.380, reward_bound=0.282, batch=225\n",
      "16521: loss=0.076, reward_mean=0.450, reward_bound=0.314, batch=168\n",
      "16522: loss=0.074, reward_mean=0.460, reward_bound=0.123, batch=187\n",
      "16523: loss=0.074, reward_mean=0.430, reward_bound=0.132, batch=201\n",
      "16524: loss=0.078, reward_mean=0.420, reward_bound=0.150, batch=209\n",
      "16525: loss=0.075, reward_mean=0.530, reward_bound=0.185, batch=214\n",
      "16526: loss=0.074, reward_mean=0.370, reward_bound=0.206, batch=217\n",
      "16527: loss=0.074, reward_mean=0.430, reward_bound=0.229, batch=221\n",
      "16528: loss=0.075, reward_mean=0.450, reward_bound=0.254, batch=217\n",
      "16529: loss=0.074, reward_mean=0.510, reward_bound=0.282, batch=211\n",
      "16530: loss=0.076, reward_mean=0.430, reward_bound=0.314, batch=204\n",
      "16531: loss=0.074, reward_mean=0.380, reward_bound=0.204, batch=213\n",
      "16532: loss=0.074, reward_mean=0.440, reward_bound=0.206, batch=218\n",
      "16533: loss=0.077, reward_mean=0.540, reward_bound=0.229, batch=221\n",
      "16534: loss=0.079, reward_mean=0.500, reward_bound=0.254, batch=219\n",
      "16535: loss=0.078, reward_mean=0.390, reward_bound=0.282, batch=222\n",
      "16536: loss=0.076, reward_mean=0.480, reward_bound=0.349, batch=161\n",
      "16537: loss=0.073, reward_mean=0.420, reward_bound=0.052, batch=182\n",
      "16538: loss=0.077, reward_mean=0.450, reward_bound=0.109, batch=192\n",
      "16539: loss=0.074, reward_mean=0.400, reward_bound=0.150, batch=202\n",
      "16540: loss=0.075, reward_mean=0.510, reward_bound=0.167, batch=208\n",
      "16541: loss=0.073, reward_mean=0.460, reward_bound=0.185, batch=214\n",
      "16542: loss=0.072, reward_mean=0.390, reward_bound=0.206, batch=212\n",
      "16543: loss=0.070, reward_mean=0.500, reward_bound=0.236, batch=218\n",
      "16544: loss=0.070, reward_mean=0.520, reward_bound=0.254, batch=213\n",
      "16545: loss=0.070, reward_mean=0.390, reward_bound=0.271, batch=219\n",
      "16546: loss=0.073, reward_mean=0.400, reward_bound=0.282, batch=212\n",
      "16547: loss=0.072, reward_mean=0.420, reward_bound=0.229, batch=216\n",
      "16548: loss=0.072, reward_mean=0.510, reward_bound=0.314, batch=212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16549: loss=0.072, reward_mean=0.520, reward_bound=0.254, batch=215\n",
      "16550: loss=0.071, reward_mean=0.420, reward_bound=0.314, batch=218\n",
      "16551: loss=0.076, reward_mean=0.480, reward_bound=0.349, batch=203\n",
      "16552: loss=0.076, reward_mean=0.360, reward_bound=0.178, batch=212\n",
      "16553: loss=0.073, reward_mean=0.450, reward_bound=0.206, batch=221\n",
      "16554: loss=0.073, reward_mean=0.470, reward_bound=0.206, batch=224\n",
      "16555: loss=0.073, reward_mean=0.370, reward_bound=0.280, batch=227\n",
      "16556: loss=0.073, reward_mean=0.450, reward_bound=0.282, batch=227\n",
      "16557: loss=0.073, reward_mean=0.410, reward_bound=0.314, batch=227\n",
      "16558: loss=0.074, reward_mean=0.490, reward_bound=0.349, batch=222\n",
      "16559: loss=0.068, reward_mean=0.540, reward_bound=0.387, batch=145\n",
      "16560: loss=0.074, reward_mean=0.400, reward_bound=0.031, batch=169\n",
      "16561: loss=0.071, reward_mean=0.520, reward_bound=0.089, batch=185\n",
      "16562: loss=0.070, reward_mean=0.560, reward_bound=0.153, batch=199\n",
      "16563: loss=0.070, reward_mean=0.470, reward_bound=0.167, batch=206\n",
      "16564: loss=0.072, reward_mean=0.410, reward_bound=0.185, batch=212\n",
      "16565: loss=0.073, reward_mean=0.440, reward_bound=0.206, batch=221\n",
      "16566: loss=0.070, reward_mean=0.430, reward_bound=0.206, batch=213\n",
      "16567: loss=0.069, reward_mean=0.410, reward_bound=0.229, batch=208\n",
      "16568: loss=0.069, reward_mean=0.380, reward_bound=0.211, batch=215\n",
      "16569: loss=0.071, reward_mean=0.490, reward_bound=0.254, batch=218\n",
      "16570: loss=0.069, reward_mean=0.430, reward_bound=0.234, batch=222\n",
      "16571: loss=0.068, reward_mean=0.520, reward_bound=0.282, batch=206\n",
      "16572: loss=0.069, reward_mean=0.430, reward_bound=0.229, batch=212\n",
      "16573: loss=0.068, reward_mean=0.480, reward_bound=0.292, batch=218\n",
      "16574: loss=0.073, reward_mean=0.430, reward_bound=0.314, batch=206\n",
      "16575: loss=0.074, reward_mean=0.470, reward_bound=0.254, batch=213\n",
      "16576: loss=0.071, reward_mean=0.490, reward_bound=0.301, batch=219\n",
      "16577: loss=0.072, reward_mean=0.490, reward_bound=0.314, batch=222\n",
      "16578: loss=0.070, reward_mean=0.380, reward_bound=0.349, batch=202\n",
      "16579: loss=0.071, reward_mean=0.460, reward_bound=0.254, batch=210\n",
      "16580: loss=0.069, reward_mean=0.420, reward_bound=0.274, batch=217\n",
      "16581: loss=0.068, reward_mean=0.420, reward_bound=0.282, batch=221\n",
      "16582: loss=0.071, reward_mean=0.510, reward_bound=0.314, batch=221\n",
      "16583: loss=0.070, reward_mean=0.370, reward_bound=0.349, batch=224\n",
      "16584: loss=0.070, reward_mean=0.460, reward_bound=0.349, batch=225\n",
      "16585: loss=0.070, reward_mean=0.380, reward_bound=0.356, batch=227\n",
      "16586: loss=0.070, reward_mean=0.390, reward_bound=0.380, batch=229\n",
      "16587: loss=0.069, reward_mean=0.440, reward_bound=0.387, batch=205\n",
      "16588: loss=0.071, reward_mean=0.510, reward_bound=0.260, batch=213\n",
      "16589: loss=0.072, reward_mean=0.530, reward_bound=0.282, batch=217\n",
      "16590: loss=0.073, reward_mean=0.530, reward_bound=0.282, batch=219\n",
      "16591: loss=0.070, reward_mean=0.510, reward_bound=0.328, batch=223\n",
      "16592: loss=0.068, reward_mean=0.540, reward_bound=0.349, batch=221\n",
      "16593: loss=0.067, reward_mean=0.430, reward_bound=0.314, batch=224\n",
      "16594: loss=0.068, reward_mean=0.550, reward_bound=0.387, batch=222\n",
      "16595: loss=0.069, reward_mean=0.380, reward_bound=0.254, batch=225\n",
      "16596: loss=0.069, reward_mean=0.440, reward_bound=0.387, batch=224\n",
      "16597: loss=0.071, reward_mean=0.510, reward_bound=0.430, batch=128\n",
      "16598: loss=0.064, reward_mean=0.430, reward_bound=0.028, batch=159\n",
      "16599: loss=0.061, reward_mean=0.430, reward_bound=0.058, batch=178\n",
      "16600: loss=0.066, reward_mean=0.470, reward_bound=0.081, batch=194\n",
      "16601: loss=0.068, reward_mean=0.490, reward_bound=0.122, batch=200\n",
      "16602: loss=0.070, reward_mean=0.450, reward_bound=0.135, batch=208\n",
      "16603: loss=0.068, reward_mean=0.360, reward_bound=0.150, batch=214\n",
      "16604: loss=0.066, reward_mean=0.420, reward_bound=0.185, batch=211\n",
      "16605: loss=0.069, reward_mean=0.360, reward_bound=0.206, batch=209\n",
      "16606: loss=0.071, reward_mean=0.430, reward_bound=0.229, batch=207\n",
      "16607: loss=0.072, reward_mean=0.440, reward_bound=0.202, batch=215\n",
      "16608: loss=0.071, reward_mean=0.490, reward_bound=0.210, batch=220\n",
      "16609: loss=0.071, reward_mean=0.400, reward_bound=0.229, batch=222\n",
      "16610: loss=0.072, reward_mean=0.330, reward_bound=0.254, batch=211\n",
      "16611: loss=0.074, reward_mean=0.520, reward_bound=0.282, batch=201\n",
      "16612: loss=0.074, reward_mean=0.430, reward_bound=0.206, batch=210\n",
      "16613: loss=0.075, reward_mean=0.430, reward_bound=0.222, batch=217\n",
      "16614: loss=0.073, reward_mean=0.400, reward_bound=0.229, batch=220\n",
      "16615: loss=0.072, reward_mean=0.440, reward_bound=0.254, batch=223\n",
      "16616: loss=0.070, reward_mean=0.500, reward_bound=0.282, batch=224\n",
      "16617: loss=0.068, reward_mean=0.550, reward_bound=0.314, batch=212\n",
      "16618: loss=0.068, reward_mean=0.420, reward_bound=0.314, batch=217\n",
      "16619: loss=0.067, reward_mean=0.390, reward_bound=0.282, batch=221\n",
      "16620: loss=0.066, reward_mean=0.480, reward_bound=0.314, batch=224\n",
      "16621: loss=0.069, reward_mean=0.500, reward_bound=0.349, batch=207\n",
      "16622: loss=0.068, reward_mean=0.470, reward_bound=0.277, batch=215\n",
      "16623: loss=0.068, reward_mean=0.400, reward_bound=0.234, batch=220\n",
      "16624: loss=0.065, reward_mean=0.510, reward_bound=0.282, batch=223\n",
      "16625: loss=0.065, reward_mean=0.540, reward_bound=0.314, batch=224\n",
      "16626: loss=0.064, reward_mean=0.400, reward_bound=0.305, batch=227\n",
      "16627: loss=0.064, reward_mean=0.430, reward_bound=0.302, batch=229\n",
      "16628: loss=0.067, reward_mean=0.450, reward_bound=0.349, batch=226\n",
      "16629: loss=0.069, reward_mean=0.390, reward_bound=0.321, batch=228\n",
      "16630: loss=0.068, reward_mean=0.490, reward_bound=0.387, batch=196\n",
      "16631: loss=0.065, reward_mean=0.470, reward_bound=0.158, batch=207\n",
      "16632: loss=0.064, reward_mean=0.420, reward_bound=0.206, batch=214\n",
      "16633: loss=0.068, reward_mean=0.460, reward_bound=0.254, batch=218\n",
      "16634: loss=0.066, reward_mean=0.360, reward_bound=0.282, batch=214\n",
      "16635: loss=0.065, reward_mean=0.500, reward_bound=0.311, batch=220\n",
      "16636: loss=0.068, reward_mean=0.480, reward_bound=0.349, batch=217\n",
      "16637: loss=0.067, reward_mean=0.530, reward_bound=0.349, batch=221\n",
      "16638: loss=0.067, reward_mean=0.530, reward_bound=0.282, batch=224\n",
      "16639: loss=0.067, reward_mean=0.430, reward_bound=0.384, batch=227\n",
      "16640: loss=0.067, reward_mean=0.550, reward_bound=0.387, batch=221\n",
      "16641: loss=0.068, reward_mean=0.370, reward_bound=0.254, batch=224\n",
      "16642: loss=0.066, reward_mean=0.490, reward_bound=0.349, batch=226\n",
      "16643: loss=0.066, reward_mean=0.410, reward_bound=0.387, batch=227\n",
      "16644: loss=0.066, reward_mean=0.440, reward_bound=0.387, batch=228\n",
      "16645: loss=0.065, reward_mean=0.390, reward_bound=0.430, batch=187\n",
      "16646: loss=0.066, reward_mean=0.440, reward_bound=0.202, batch=201\n",
      "16647: loss=0.064, reward_mean=0.400, reward_bound=0.206, batch=209\n",
      "16648: loss=0.061, reward_mean=0.420, reward_bound=0.229, batch=215\n",
      "16649: loss=0.061, reward_mean=0.510, reward_bound=0.254, batch=219\n",
      "16650: loss=0.059, reward_mean=0.430, reward_bound=0.282, batch=215\n",
      "16651: loss=0.061, reward_mean=0.440, reward_bound=0.314, batch=210\n",
      "16652: loss=0.062, reward_mean=0.420, reward_bound=0.274, batch=217\n",
      "16653: loss=0.068, reward_mean=0.400, reward_bound=0.277, batch=222\n",
      "16654: loss=0.067, reward_mean=0.410, reward_bound=0.324, batch=225\n",
      "16655: loss=0.069, reward_mean=0.400, reward_bound=0.349, batch=222\n",
      "16656: loss=0.068, reward_mean=0.460, reward_bound=0.282, batch=223\n",
      "16657: loss=0.069, reward_mean=0.500, reward_bound=0.349, batch=225\n",
      "16658: loss=0.069, reward_mean=0.460, reward_bound=0.387, batch=210\n",
      "16659: loss=0.068, reward_mean=0.550, reward_bound=0.365, batch=217\n",
      "16660: loss=0.069, reward_mean=0.270, reward_bound=0.314, batch=219\n",
      "16661: loss=0.068, reward_mean=0.420, reward_bound=0.314, batch=221\n",
      "16662: loss=0.069, reward_mean=0.440, reward_bound=0.229, batch=223\n",
      "16663: loss=0.068, reward_mean=0.520, reward_bound=0.314, batch=225\n",
      "16664: loss=0.069, reward_mean=0.400, reward_bound=0.387, batch=221\n",
      "16665: loss=0.068, reward_mean=0.530, reward_bound=0.349, batch=224\n",
      "16666: loss=0.069, reward_mean=0.480, reward_bound=0.380, batch=227\n",
      "16667: loss=0.068, reward_mean=0.420, reward_bound=0.387, batch=228\n",
      "16668: loss=0.065, reward_mean=0.380, reward_bound=0.430, batch=211\n",
      "16669: loss=0.067, reward_mean=0.350, reward_bound=0.185, batch=217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16670: loss=0.064, reward_mean=0.380, reward_bound=0.277, batch=222\n",
      "16671: loss=0.067, reward_mean=0.310, reward_bound=0.292, batch=225\n",
      "16672: loss=0.065, reward_mean=0.390, reward_bound=0.314, batch=222\n",
      "16673: loss=0.063, reward_mean=0.470, reward_bound=0.349, batch=222\n",
      "16674: loss=0.063, reward_mean=0.440, reward_bound=0.324, batch=225\n",
      "16675: loss=0.062, reward_mean=0.480, reward_bound=0.349, batch=226\n",
      "16676: loss=0.065, reward_mean=0.440, reward_bound=0.387, batch=224\n",
      "16677: loss=0.064, reward_mean=0.400, reward_bound=0.426, batch=227\n",
      "16678: loss=0.064, reward_mean=0.450, reward_bound=0.430, batch=221\n",
      "16679: loss=0.064, reward_mean=0.460, reward_bound=0.314, batch=223\n",
      "16680: loss=0.063, reward_mean=0.330, reward_bound=0.271, batch=226\n",
      "16681: loss=0.062, reward_mean=0.410, reward_bound=0.316, batch=228\n",
      "16682: loss=0.062, reward_mean=0.480, reward_bound=0.349, batch=228\n",
      "16683: loss=0.062, reward_mean=0.520, reward_bound=0.317, batch=229\n",
      "16684: loss=0.063, reward_mean=0.450, reward_bound=0.387, batch=228\n",
      "16685: loss=0.064, reward_mean=0.520, reward_bound=0.430, batch=224\n",
      "16686: loss=0.064, reward_mean=0.350, reward_bound=0.280, batch=227\n",
      "16687: loss=0.063, reward_mean=0.370, reward_bound=0.314, batch=228\n",
      "16688: loss=0.064, reward_mean=0.430, reward_bound=0.478, batch=231\n",
      "16689: loss=0.043, reward_mean=0.420, reward_bound=0.478, batch=79\n",
      "16690: loss=0.057, reward_mean=0.480, reward_bound=0.008, batch=125\n",
      "16691: loss=0.055, reward_mean=0.450, reward_bound=0.020, batch=156\n",
      "16692: loss=0.056, reward_mean=0.550, reward_bound=0.033, batch=179\n",
      "16693: loss=0.054, reward_mean=0.360, reward_bound=0.038, batch=192\n",
      "16694: loss=0.053, reward_mean=0.470, reward_bound=0.067, batch=204\n",
      "16695: loss=0.054, reward_mean=0.450, reward_bound=0.089, batch=212\n",
      "16696: loss=0.047, reward_mean=0.450, reward_bound=0.122, batch=209\n",
      "16697: loss=0.048, reward_mean=0.520, reward_bound=0.135, batch=208\n",
      "16698: loss=0.051, reward_mean=0.390, reward_bound=0.150, batch=209\n",
      "16699: loss=0.049, reward_mean=0.370, reward_bound=0.167, batch=213\n",
      "16700: loss=0.052, reward_mean=0.480, reward_bound=0.185, batch=212\n",
      "16701: loss=0.051, reward_mean=0.480, reward_bound=0.206, batch=224\n",
      "16702: loss=0.054, reward_mean=0.470, reward_bound=0.206, batch=208\n",
      "16703: loss=0.053, reward_mean=0.480, reward_bound=0.229, batch=201\n",
      "16704: loss=0.055, reward_mean=0.460, reward_bound=0.254, batch=193\n",
      "16705: loss=0.056, reward_mean=0.420, reward_bound=0.167, batch=204\n",
      "16706: loss=0.054, reward_mean=0.400, reward_bound=0.226, batch=213\n",
      "16707: loss=0.054, reward_mean=0.500, reward_bound=0.229, batch=215\n",
      "16708: loss=0.055, reward_mean=0.420, reward_bound=0.254, batch=219\n",
      "16709: loss=0.054, reward_mean=0.490, reward_bound=0.265, batch=223\n",
      "16710: loss=0.053, reward_mean=0.410, reward_bound=0.271, batch=226\n",
      "16711: loss=0.050, reward_mean=0.440, reward_bound=0.282, batch=202\n",
      "16712: loss=0.050, reward_mean=0.490, reward_bound=0.263, batch=211\n",
      "16713: loss=0.052, reward_mean=0.470, reward_bound=0.282, batch=217\n",
      "16714: loss=0.052, reward_mean=0.460, reward_bound=0.314, batch=189\n",
      "16715: loss=0.052, reward_mean=0.420, reward_bound=0.157, batch=202\n",
      "16716: loss=0.049, reward_mean=0.390, reward_bound=0.150, batch=210\n",
      "16717: loss=0.049, reward_mean=0.550, reward_bound=0.229, batch=216\n",
      "16718: loss=0.051, reward_mean=0.380, reward_bound=0.254, batch=211\n",
      "16719: loss=0.052, reward_mean=0.460, reward_bound=0.254, batch=217\n",
      "16720: loss=0.052, reward_mean=0.460, reward_bound=0.282, batch=215\n",
      "16721: loss=0.052, reward_mean=0.430, reward_bound=0.206, batch=219\n",
      "16722: loss=0.052, reward_mean=0.470, reward_bound=0.282, batch=222\n",
      "16723: loss=0.057, reward_mean=0.480, reward_bound=0.314, batch=218\n",
      "16724: loss=0.062, reward_mean=0.440, reward_bound=0.349, batch=191\n",
      "16725: loss=0.062, reward_mean=0.430, reward_bound=0.135, batch=202\n",
      "16726: loss=0.064, reward_mean=0.490, reward_bound=0.185, batch=209\n",
      "16727: loss=0.062, reward_mean=0.420, reward_bound=0.215, batch=216\n",
      "16728: loss=0.057, reward_mean=0.420, reward_bound=0.229, batch=219\n",
      "16729: loss=0.058, reward_mean=0.420, reward_bound=0.254, batch=222\n",
      "16730: loss=0.056, reward_mean=0.530, reward_bound=0.282, batch=220\n",
      "16731: loss=0.057, reward_mean=0.490, reward_bound=0.304, batch=224\n",
      "16732: loss=0.058, reward_mean=0.430, reward_bound=0.314, batch=220\n",
      "16733: loss=0.058, reward_mean=0.560, reward_bound=0.282, batch=222\n",
      "16734: loss=0.060, reward_mean=0.400, reward_bound=0.272, batch=225\n",
      "16735: loss=0.059, reward_mean=0.440, reward_bound=0.349, batch=211\n",
      "16736: loss=0.060, reward_mean=0.550, reward_bound=0.314, batch=217\n",
      "16737: loss=0.060, reward_mean=0.450, reward_bound=0.206, batch=221\n",
      "16738: loss=0.061, reward_mean=0.520, reward_bound=0.349, batch=224\n",
      "16739: loss=0.057, reward_mean=0.460, reward_bound=0.387, batch=169\n",
      "16740: loss=0.055, reward_mean=0.400, reward_bound=0.036, batch=188\n",
      "16741: loss=0.051, reward_mean=0.450, reward_bound=0.100, batch=201\n",
      "16742: loss=0.057, reward_mean=0.520, reward_bound=0.122, batch=209\n",
      "16743: loss=0.054, reward_mean=0.530, reward_bound=0.185, batch=213\n",
      "16744: loss=0.054, reward_mean=0.430, reward_bound=0.206, batch=216\n",
      "16745: loss=0.056, reward_mean=0.460, reward_bound=0.229, batch=219\n",
      "16746: loss=0.057, reward_mean=0.420, reward_bound=0.254, batch=220\n",
      "16747: loss=0.057, reward_mean=0.430, reward_bound=0.200, batch=224\n",
      "16748: loss=0.055, reward_mean=0.460, reward_bound=0.280, batch=227\n",
      "16749: loss=0.055, reward_mean=0.370, reward_bound=0.282, batch=220\n",
      "16750: loss=0.055, reward_mean=0.320, reward_bound=0.314, batch=210\n",
      "16751: loss=0.055, reward_mean=0.560, reward_bound=0.282, batch=216\n",
      "16752: loss=0.054, reward_mean=0.430, reward_bound=0.256, batch=221\n",
      "16753: loss=0.054, reward_mean=0.450, reward_bound=0.314, batch=221\n",
      "16754: loss=0.053, reward_mean=0.430, reward_bound=0.314, batch=224\n",
      "16755: loss=0.052, reward_mean=0.490, reward_bound=0.345, batch=227\n",
      "16756: loss=0.054, reward_mean=0.460, reward_bound=0.342, batch=229\n",
      "16757: loss=0.056, reward_mean=0.470, reward_bound=0.349, batch=214\n",
      "16758: loss=0.055, reward_mean=0.360, reward_bound=0.206, batch=219\n",
      "16759: loss=0.056, reward_mean=0.460, reward_bound=0.254, batch=222\n",
      "16760: loss=0.054, reward_mean=0.410, reward_bound=0.292, batch=225\n",
      "16761: loss=0.055, reward_mean=0.420, reward_bound=0.314, batch=225\n",
      "16762: loss=0.055, reward_mean=0.480, reward_bound=0.387, batch=207\n",
      "16763: loss=0.053, reward_mean=0.450, reward_bound=0.254, batch=214\n",
      "16764: loss=0.055, reward_mean=0.460, reward_bound=0.229, batch=219\n",
      "16765: loss=0.054, reward_mean=0.330, reward_bound=0.314, batch=220\n",
      "16766: loss=0.059, reward_mean=0.470, reward_bound=0.349, batch=222\n",
      "16767: loss=0.057, reward_mean=0.380, reward_bound=0.387, batch=220\n",
      "16768: loss=0.056, reward_mean=0.350, reward_bound=0.304, batch=224\n",
      "16769: loss=0.057, reward_mean=0.560, reward_bound=0.345, batch=227\n",
      "16770: loss=0.060, reward_mean=0.470, reward_bound=0.380, batch=229\n",
      "16771: loss=0.056, reward_mean=0.440, reward_bound=0.387, batch=227\n",
      "16772: loss=0.051, reward_mean=0.400, reward_bound=0.430, batch=167\n",
      "16773: loss=0.056, reward_mean=0.360, reward_bound=0.097, batch=187\n",
      "16774: loss=0.053, reward_mean=0.390, reward_bound=0.109, batch=203\n",
      "16775: loss=0.058, reward_mean=0.420, reward_bound=0.135, batch=207\n",
      "16776: loss=0.053, reward_mean=0.490, reward_bound=0.167, batch=212\n",
      "16777: loss=0.052, reward_mean=0.370, reward_bound=0.185, batch=217\n",
      "16778: loss=0.051, reward_mean=0.430, reward_bound=0.224, batch=222\n",
      "16779: loss=0.054, reward_mean=0.460, reward_bound=0.229, batch=222\n",
      "16780: loss=0.053, reward_mean=0.370, reward_bound=0.254, batch=213\n",
      "16781: loss=0.053, reward_mean=0.470, reward_bound=0.244, batch=219\n",
      "16782: loss=0.053, reward_mean=0.490, reward_bound=0.282, batch=214\n",
      "16783: loss=0.052, reward_mean=0.470, reward_bound=0.254, batch=219\n",
      "16784: loss=0.054, reward_mean=0.440, reward_bound=0.282, batch=222\n",
      "16785: loss=0.050, reward_mean=0.470, reward_bound=0.314, batch=214\n",
      "16786: loss=0.049, reward_mean=0.530, reward_bound=0.314, batch=219\n",
      "16787: loss=0.048, reward_mean=0.350, reward_bound=0.295, batch=223\n",
      "16788: loss=0.048, reward_mean=0.400, reward_bound=0.335, batch=226\n",
      "16789: loss=0.048, reward_mean=0.440, reward_bound=0.314, batch=227\n",
      "16790: loss=0.049, reward_mean=0.380, reward_bound=0.349, batch=212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16791: loss=0.048, reward_mean=0.380, reward_bound=0.236, batch=218\n",
      "16792: loss=0.051, reward_mean=0.390, reward_bound=0.257, batch=222\n",
      "16793: loss=0.049, reward_mean=0.300, reward_bound=0.282, batch=222\n",
      "16794: loss=0.054, reward_mean=0.450, reward_bound=0.387, batch=212\n",
      "16795: loss=0.056, reward_mean=0.410, reward_bound=0.324, batch=218\n",
      "16796: loss=0.056, reward_mean=0.450, reward_bound=0.349, batch=219\n",
      "16797: loss=0.055, reward_mean=0.500, reward_bound=0.405, batch=223\n",
      "16798: loss=0.054, reward_mean=0.490, reward_bound=0.387, batch=225\n",
      "16799: loss=0.053, reward_mean=0.500, reward_bound=0.430, batch=198\n",
      "16800: loss=0.051, reward_mean=0.420, reward_bound=0.152, batch=208\n",
      "16801: loss=0.053, reward_mean=0.430, reward_bound=0.229, batch=212\n",
      "16802: loss=0.051, reward_mean=0.430, reward_bound=0.254, batch=217\n",
      "16803: loss=0.049, reward_mean=0.430, reward_bound=0.178, batch=222\n",
      "16804: loss=0.052, reward_mean=0.480, reward_bound=0.254, batch=224\n",
      "16805: loss=0.049, reward_mean=0.460, reward_bound=0.282, batch=224\n",
      "16806: loss=0.051, reward_mean=0.440, reward_bound=0.314, batch=217\n",
      "16807: loss=0.050, reward_mean=0.360, reward_bound=0.229, batch=220\n",
      "16808: loss=0.051, reward_mean=0.490, reward_bound=0.349, batch=215\n",
      "16809: loss=0.051, reward_mean=0.390, reward_bound=0.266, batch=220\n",
      "16810: loss=0.050, reward_mean=0.490, reward_bound=0.349, batch=223\n",
      "16811: loss=0.052, reward_mean=0.500, reward_bound=0.387, batch=215\n",
      "16812: loss=0.052, reward_mean=0.380, reward_bound=0.260, batch=220\n",
      "16813: loss=0.052, reward_mean=0.390, reward_bound=0.282, batch=222\n",
      "16814: loss=0.053, reward_mean=0.430, reward_bound=0.349, batch=223\n",
      "16815: loss=0.053, reward_mean=0.530, reward_bound=0.358, batch=226\n",
      "16816: loss=0.052, reward_mean=0.460, reward_bound=0.368, batch=228\n",
      "16817: loss=0.051, reward_mean=0.470, reward_bound=0.387, batch=225\n",
      "16818: loss=0.052, reward_mean=0.460, reward_bound=0.430, batch=214\n",
      "16819: loss=0.050, reward_mean=0.550, reward_bound=0.226, batch=220\n",
      "16820: loss=0.053, reward_mean=0.510, reward_bound=0.254, batch=223\n",
      "16821: loss=0.053, reward_mean=0.460, reward_bound=0.314, batch=224\n",
      "16822: loss=0.054, reward_mean=0.420, reward_bound=0.345, batch=227\n",
      "16823: loss=0.053, reward_mean=0.450, reward_bound=0.342, batch=229\n",
      "16824: loss=0.053, reward_mean=0.450, reward_bound=0.349, batch=227\n",
      "16825: loss=0.052, reward_mean=0.430, reward_bound=0.387, batch=225\n",
      "16826: loss=0.052, reward_mean=0.410, reward_bound=0.430, batch=225\n",
      "16827: loss=0.052, reward_mean=0.410, reward_bound=0.440, batch=227\n",
      "16828: loss=0.051, reward_mean=0.520, reward_bound=0.469, batch=229\n",
      "16829: loss=0.052, reward_mean=0.550, reward_bound=0.478, batch=231\n",
      "16830: loss=0.041, reward_mean=0.410, reward_bound=0.478, batch=140\n",
      "16831: loss=0.038, reward_mean=0.350, reward_bound=0.030, batch=168\n",
      "16832: loss=0.038, reward_mean=0.410, reward_bound=0.053, batch=187\n",
      "16833: loss=0.038, reward_mean=0.390, reward_bound=0.089, batch=202\n",
      "16834: loss=0.037, reward_mean=0.480, reward_bound=0.109, batch=207\n",
      "16835: loss=0.036, reward_mean=0.530, reward_bound=0.135, batch=213\n",
      "16836: loss=0.035, reward_mean=0.460, reward_bound=0.167, batch=209\n",
      "16837: loss=0.036, reward_mean=0.430, reward_bound=0.185, batch=208\n",
      "16838: loss=0.039, reward_mean=0.480, reward_bound=0.206, batch=212\n",
      "16839: loss=0.041, reward_mean=0.430, reward_bound=0.229, batch=208\n",
      "16840: loss=0.046, reward_mean=0.480, reward_bound=0.254, batch=205\n",
      "16841: loss=0.044, reward_mean=0.440, reward_bound=0.210, batch=213\n",
      "16842: loss=0.044, reward_mean=0.540, reward_bound=0.282, batch=201\n",
      "16843: loss=0.042, reward_mean=0.530, reward_bound=0.254, batch=210\n",
      "16844: loss=0.041, reward_mean=0.460, reward_bound=0.282, batch=215\n",
      "16845: loss=0.040, reward_mean=0.480, reward_bound=0.282, batch=218\n",
      "16846: loss=0.036, reward_mean=0.510, reward_bound=0.314, batch=205\n",
      "16847: loss=0.039, reward_mean=0.450, reward_bound=0.282, batch=211\n",
      "16848: loss=0.038, reward_mean=0.400, reward_bound=0.229, batch=217\n",
      "16849: loss=0.037, reward_mean=0.410, reward_bound=0.277, batch=222\n",
      "16850: loss=0.037, reward_mean=0.390, reward_bound=0.282, batch=223\n",
      "16851: loss=0.035, reward_mean=0.380, reward_bound=0.314, batch=223\n",
      "16852: loss=0.038, reward_mean=0.450, reward_bound=0.335, batch=226\n",
      "16853: loss=0.040, reward_mean=0.350, reward_bound=0.349, batch=197\n",
      "16854: loss=0.040, reward_mean=0.440, reward_bound=0.185, batch=207\n",
      "16855: loss=0.038, reward_mean=0.500, reward_bound=0.224, batch=215\n",
      "16856: loss=0.038, reward_mean=0.470, reward_bound=0.229, batch=219\n",
      "16857: loss=0.038, reward_mean=0.360, reward_bound=0.282, batch=219\n",
      "16858: loss=0.038, reward_mean=0.450, reward_bound=0.314, batch=220\n",
      "16859: loss=0.039, reward_mean=0.540, reward_bound=0.349, batch=217\n",
      "16860: loss=0.039, reward_mean=0.480, reward_bound=0.349, batch=220\n",
      "16861: loss=0.040, reward_mean=0.420, reward_bound=0.338, batch=224\n",
      "16862: loss=0.039, reward_mean=0.460, reward_bound=0.345, batch=227\n",
      "16863: loss=0.038, reward_mean=0.460, reward_bound=0.387, batch=203\n",
      "16864: loss=0.038, reward_mean=0.420, reward_bound=0.206, batch=211\n",
      "16865: loss=0.039, reward_mean=0.490, reward_bound=0.314, batch=210\n",
      "16866: loss=0.040, reward_mean=0.500, reward_bound=0.254, batch=216\n",
      "16867: loss=0.039, reward_mean=0.550, reward_bound=0.298, batch=221\n",
      "16868: loss=0.041, reward_mean=0.400, reward_bound=0.314, batch=221\n",
      "16869: loss=0.040, reward_mean=0.430, reward_bound=0.314, batch=224\n",
      "16870: loss=0.042, reward_mean=0.400, reward_bound=0.311, batch=227\n",
      "16871: loss=0.040, reward_mean=0.490, reward_bound=0.342, batch=229\n",
      "16872: loss=0.041, reward_mean=0.470, reward_bound=0.349, batch=224\n",
      "16873: loss=0.040, reward_mean=0.460, reward_bound=0.282, batch=226\n",
      "16874: loss=0.040, reward_mean=0.480, reward_bound=0.331, batch=228\n",
      "16875: loss=0.040, reward_mean=0.510, reward_bound=0.353, batch=229\n",
      "16876: loss=0.039, reward_mean=0.440, reward_bound=0.387, batch=223\n",
      "16877: loss=0.037, reward_mean=0.420, reward_bound=0.430, batch=187\n",
      "16878: loss=0.042, reward_mean=0.450, reward_bound=0.135, batch=200\n",
      "16879: loss=0.038, reward_mean=0.430, reward_bound=0.150, batch=209\n",
      "16880: loss=0.039, reward_mean=0.390, reward_bound=0.185, batch=215\n",
      "16881: loss=0.041, reward_mean=0.460, reward_bound=0.229, batch=218\n",
      "16882: loss=0.040, reward_mean=0.380, reward_bound=0.254, batch=221\n",
      "16883: loss=0.041, reward_mean=0.380, reward_bound=0.282, batch=221\n",
      "16884: loss=0.039, reward_mean=0.400, reward_bound=0.314, batch=221\n",
      "16885: loss=0.039, reward_mean=0.390, reward_bound=0.314, batch=222\n",
      "16886: loss=0.043, reward_mean=0.430, reward_bound=0.349, batch=213\n",
      "16887: loss=0.043, reward_mean=0.430, reward_bound=0.220, batch=219\n",
      "16888: loss=0.045, reward_mean=0.490, reward_bound=0.278, batch=223\n",
      "16889: loss=0.044, reward_mean=0.420, reward_bound=0.301, batch=226\n",
      "16890: loss=0.040, reward_mean=0.480, reward_bound=0.314, batch=227\n",
      "16891: loss=0.041, reward_mean=0.410, reward_bound=0.349, batch=226\n",
      "16892: loss=0.042, reward_mean=0.440, reward_bound=0.351, batch=228\n",
      "16893: loss=0.041, reward_mean=0.370, reward_bound=0.387, batch=215\n",
      "16894: loss=0.044, reward_mean=0.440, reward_bound=0.266, batch=220\n",
      "16895: loss=0.041, reward_mean=0.390, reward_bound=0.314, batch=223\n",
      "16896: loss=0.041, reward_mean=0.390, reward_bound=0.349, batch=224\n",
      "16897: loss=0.043, reward_mean=0.460, reward_bound=0.311, batch=227\n",
      "16898: loss=0.041, reward_mean=0.460, reward_bound=0.349, batch=227\n",
      "16899: loss=0.040, reward_mean=0.460, reward_bound=0.373, batch=229\n",
      "16900: loss=0.040, reward_mean=0.400, reward_bound=0.349, batch=229\n",
      "16901: loss=0.040, reward_mean=0.470, reward_bound=0.387, batch=222\n",
      "16902: loss=0.041, reward_mean=0.420, reward_bound=0.314, batch=224\n",
      "16903: loss=0.041, reward_mean=0.440, reward_bound=0.384, batch=227\n",
      "16904: loss=0.041, reward_mean=0.490, reward_bound=0.422, batch=229\n",
      "16905: loss=0.041, reward_mean=0.500, reward_bound=0.387, batch=229\n",
      "16906: loss=0.034, reward_mean=0.520, reward_bound=0.430, batch=207\n",
      "16907: loss=0.033, reward_mean=0.460, reward_bound=0.254, batch=214\n",
      "16908: loss=0.036, reward_mean=0.410, reward_bound=0.280, batch=220\n",
      "16909: loss=0.034, reward_mean=0.470, reward_bound=0.282, batch=223\n",
      "16910: loss=0.034, reward_mean=0.360, reward_bound=0.314, batch=224\n",
      "16911: loss=0.034, reward_mean=0.350, reward_bound=0.349, batch=224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16912: loss=0.033, reward_mean=0.400, reward_bound=0.339, batch=227\n",
      "16913: loss=0.035, reward_mean=0.360, reward_bound=0.308, batch=229\n",
      "16914: loss=0.033, reward_mean=0.480, reward_bound=0.349, batch=229\n",
      "16915: loss=0.033, reward_mean=0.470, reward_bound=0.364, batch=230\n",
      "16916: loss=0.034, reward_mean=0.330, reward_bound=0.387, batch=224\n",
      "16917: loss=0.033, reward_mean=0.430, reward_bound=0.384, batch=227\n",
      "16918: loss=0.033, reward_mean=0.490, reward_bound=0.349, batch=228\n",
      "16919: loss=0.033, reward_mean=0.520, reward_bound=0.387, batch=228\n",
      "16920: loss=0.033, reward_mean=0.370, reward_bound=0.297, batch=229\n",
      "16921: loss=0.034, reward_mean=0.460, reward_bound=0.430, batch=222\n",
      "16922: loss=0.034, reward_mean=0.430, reward_bound=0.324, batch=225\n",
      "16923: loss=0.036, reward_mean=0.440, reward_bound=0.321, batch=227\n",
      "16924: loss=0.037, reward_mean=0.390, reward_bound=0.422, batch=229\n",
      "16925: loss=0.034, reward_mean=0.490, reward_bound=0.430, batch=223\n",
      "16926: loss=0.036, reward_mean=0.500, reward_bound=0.478, batch=178\n",
      "16927: loss=0.035, reward_mean=0.420, reward_bound=0.073, batch=194\n",
      "16928: loss=0.037, reward_mean=0.460, reward_bound=0.167, batch=203\n",
      "16929: loss=0.036, reward_mean=0.450, reward_bound=0.229, batch=210\n",
      "16930: loss=0.041, reward_mean=0.380, reward_bound=0.254, batch=215\n",
      "16931: loss=0.042, reward_mean=0.370, reward_bound=0.234, batch=220\n",
      "16932: loss=0.042, reward_mean=0.460, reward_bound=0.282, batch=212\n",
      "16933: loss=0.041, reward_mean=0.400, reward_bound=0.213, batch=218\n",
      "16934: loss=0.041, reward_mean=0.440, reward_bound=0.282, batch=219\n",
      "16935: loss=0.039, reward_mean=0.460, reward_bound=0.314, batch=211\n",
      "16936: loss=0.038, reward_mean=0.390, reward_bound=0.254, batch=217\n",
      "16937: loss=0.038, reward_mean=0.450, reward_bound=0.314, batch=218\n",
      "16938: loss=0.038, reward_mean=0.460, reward_bound=0.211, batch=222\n",
      "16939: loss=0.039, reward_mean=0.340, reward_bound=0.272, batch=225\n",
      "16940: loss=0.037, reward_mean=0.510, reward_bound=0.314, batch=226\n",
      "16941: loss=0.037, reward_mean=0.390, reward_bound=0.314, batch=227\n",
      "16942: loss=0.036, reward_mean=0.370, reward_bound=0.342, batch=229\n",
      "16943: loss=0.040, reward_mean=0.470, reward_bound=0.349, batch=211\n",
      "16944: loss=0.039, reward_mean=0.450, reward_bound=0.349, batch=213\n",
      "16945: loss=0.038, reward_mean=0.360, reward_bound=0.301, batch=219\n",
      "16946: loss=0.040, reward_mean=0.440, reward_bound=0.349, batch=221\n",
      "16947: loss=0.041, reward_mean=0.470, reward_bound=0.314, batch=224\n",
      "16948: loss=0.041, reward_mean=0.370, reward_bound=0.345, batch=227\n",
      "16949: loss=0.039, reward_mean=0.460, reward_bound=0.349, batch=228\n",
      "16950: loss=0.039, reward_mean=0.440, reward_bound=0.321, batch=229\n",
      "16951: loss=0.038, reward_mean=0.510, reward_bound=0.387, batch=210\n",
      "16952: loss=0.038, reward_mean=0.470, reward_bound=0.200, batch=217\n",
      "16953: loss=0.037, reward_mean=0.340, reward_bound=0.182, batch=222\n",
      "16954: loss=0.041, reward_mean=0.510, reward_bound=0.263, batch=225\n",
      "16955: loss=0.045, reward_mean=0.430, reward_bound=0.314, batch=225\n",
      "16956: loss=0.040, reward_mean=0.420, reward_bound=0.349, batch=222\n",
      "16957: loss=0.040, reward_mean=0.470, reward_bound=0.387, batch=221\n",
      "16958: loss=0.040, reward_mean=0.540, reward_bound=0.387, batch=224\n",
      "16959: loss=0.039, reward_mean=0.530, reward_bound=0.308, batch=227\n",
      "16960: loss=0.040, reward_mean=0.390, reward_bound=0.349, batch=227\n",
      "16961: loss=0.042, reward_mean=0.510, reward_bound=0.430, batch=203\n",
      "16962: loss=0.046, reward_mean=0.480, reward_bound=0.229, batch=210\n",
      "16963: loss=0.041, reward_mean=0.450, reward_bound=0.282, batch=215\n",
      "16964: loss=0.040, reward_mean=0.480, reward_bound=0.314, batch=219\n",
      "16965: loss=0.039, reward_mean=0.480, reward_bound=0.349, batch=216\n",
      "16966: loss=0.039, reward_mean=0.450, reward_bound=0.254, batch=220\n",
      "16967: loss=0.038, reward_mean=0.390, reward_bound=0.282, batch=223\n",
      "16968: loss=0.038, reward_mean=0.480, reward_bound=0.301, batch=226\n",
      "16969: loss=0.040, reward_mean=0.480, reward_bound=0.349, batch=226\n",
      "16970: loss=0.041, reward_mean=0.450, reward_bound=0.387, batch=219\n",
      "16971: loss=0.044, reward_mean=0.490, reward_bound=0.364, batch=223\n",
      "16972: loss=0.044, reward_mean=0.490, reward_bound=0.301, batch=226\n",
      "16973: loss=0.043, reward_mean=0.400, reward_bound=0.331, batch=228\n",
      "16974: loss=0.043, reward_mean=0.440, reward_bound=0.349, batch=228\n",
      "16975: loss=0.044, reward_mean=0.440, reward_bound=0.387, batch=224\n",
      "16976: loss=0.046, reward_mean=0.410, reward_bound=0.426, batch=227\n",
      "16977: loss=0.045, reward_mean=0.440, reward_bound=0.422, batch=229\n",
      "16978: loss=0.045, reward_mean=0.490, reward_bound=0.381, batch=230\n",
      "16979: loss=0.045, reward_mean=0.420, reward_bound=0.395, batch=231\n",
      "16980: loss=0.043, reward_mean=0.490, reward_bound=0.430, batch=218\n",
      "16981: loss=0.044, reward_mean=0.380, reward_bound=0.220, batch=222\n",
      "16982: loss=0.044, reward_mean=0.510, reward_bound=0.349, batch=224\n",
      "16983: loss=0.044, reward_mean=0.420, reward_bound=0.387, batch=225\n",
      "16984: loss=0.044, reward_mean=0.340, reward_bound=0.321, batch=227\n",
      "16985: loss=0.044, reward_mean=0.480, reward_bound=0.430, batch=225\n",
      "16986: loss=0.046, reward_mean=0.400, reward_bound=0.321, batch=227\n",
      "16987: loss=0.045, reward_mean=0.480, reward_bound=0.342, batch=229\n",
      "16988: loss=0.045, reward_mean=0.450, reward_bound=0.349, batch=228\n",
      "16989: loss=0.044, reward_mean=0.470, reward_bound=0.387, batch=228\n",
      "16990: loss=0.043, reward_mean=0.430, reward_bound=0.317, batch=229\n",
      "16991: loss=0.043, reward_mean=0.460, reward_bound=0.405, batch=230\n",
      "16992: loss=0.044, reward_mean=0.430, reward_bound=0.430, batch=229\n",
      "16993: loss=0.044, reward_mean=0.340, reward_bound=0.387, batch=229\n",
      "16994: loss=0.043, reward_mean=0.520, reward_bound=0.478, batch=232\n",
      "16995: loss=0.046, reward_mean=0.490, reward_bound=0.478, batch=205\n",
      "16996: loss=0.047, reward_mean=0.470, reward_bound=0.189, batch=213\n",
      "16997: loss=0.048, reward_mean=0.470, reward_bound=0.301, batch=219\n",
      "16998: loss=0.048, reward_mean=0.430, reward_bound=0.314, batch=219\n",
      "16999: loss=0.046, reward_mean=0.440, reward_bound=0.349, batch=215\n",
      "17000: loss=0.045, reward_mean=0.430, reward_bound=0.282, batch=219\n",
      "17001: loss=0.044, reward_mean=0.470, reward_bound=0.328, batch=223\n",
      "17002: loss=0.044, reward_mean=0.390, reward_bound=0.349, batch=225\n",
      "17003: loss=0.043, reward_mean=0.500, reward_bound=0.387, batch=220\n",
      "17004: loss=0.043, reward_mean=0.540, reward_bound=0.282, batch=223\n",
      "17005: loss=0.043, reward_mean=0.410, reward_bound=0.349, batch=223\n",
      "17006: loss=0.042, reward_mean=0.490, reward_bound=0.387, batch=224\n",
      "17007: loss=0.042, reward_mean=0.400, reward_bound=0.314, batch=225\n",
      "17008: loss=0.042, reward_mean=0.470, reward_bound=0.337, batch=227\n",
      "17009: loss=0.042, reward_mean=0.480, reward_bound=0.314, batch=227\n",
      "17010: loss=0.042, reward_mean=0.350, reward_bound=0.373, batch=229\n",
      "17011: loss=0.041, reward_mean=0.510, reward_bound=0.364, batch=230\n",
      "17012: loss=0.044, reward_mean=0.420, reward_bound=0.430, batch=219\n",
      "17013: loss=0.045, reward_mean=0.480, reward_bound=0.364, batch=223\n",
      "17014: loss=0.044, reward_mean=0.460, reward_bound=0.282, batch=225\n",
      "17015: loss=0.044, reward_mean=0.430, reward_bound=0.321, batch=227\n",
      "17016: loss=0.044, reward_mean=0.410, reward_bound=0.380, batch=229\n",
      "17017: loss=0.044, reward_mean=0.470, reward_bound=0.387, batch=226\n",
      "17018: loss=0.044, reward_mean=0.430, reward_bound=0.390, batch=228\n",
      "17019: loss=0.044, reward_mean=0.480, reward_bound=0.392, batch=229\n",
      "17020: loss=0.044, reward_mean=0.390, reward_bound=0.381, batch=230\n",
      "17021: loss=0.043, reward_mean=0.410, reward_bound=0.406, batch=231\n",
      "17022: loss=0.042, reward_mean=0.510, reward_bound=0.430, batch=227\n",
      "17023: loss=0.042, reward_mean=0.410, reward_bound=0.422, batch=229\n",
      "17024: loss=0.042, reward_mean=0.440, reward_bound=0.381, batch=230\n",
      "17025: loss=0.042, reward_mean=0.470, reward_bound=0.464, batch=231\n",
      "17026: loss=0.044, reward_mean=0.560, reward_bound=0.478, batch=216\n",
      "17027: loss=0.043, reward_mean=0.430, reward_bound=0.254, batch=220\n",
      "17028: loss=0.043, reward_mean=0.460, reward_bound=0.274, batch=224\n",
      "17029: loss=0.050, reward_mean=0.410, reward_bound=0.311, batch=227\n",
      "17030: loss=0.049, reward_mean=0.450, reward_bound=0.308, batch=229\n",
      "17031: loss=0.047, reward_mean=0.520, reward_bound=0.314, batch=228\n",
      "17032: loss=0.046, reward_mean=0.450, reward_bound=0.349, batch=227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17033: loss=0.046, reward_mean=0.440, reward_bound=0.387, batch=225\n",
      "17034: loss=0.046, reward_mean=0.390, reward_bound=0.321, batch=227\n",
      "17035: loss=0.049, reward_mean=0.460, reward_bound=0.342, batch=229\n",
      "17036: loss=0.049, reward_mean=0.380, reward_bound=0.364, batch=230\n",
      "17037: loss=0.049, reward_mean=0.380, reward_bound=0.387, batch=228\n",
      "17038: loss=0.049, reward_mean=0.560, reward_bound=0.387, batch=228\n",
      "17039: loss=0.046, reward_mean=0.410, reward_bound=0.430, batch=225\n",
      "17040: loss=0.046, reward_mean=0.430, reward_bound=0.356, batch=227\n",
      "17041: loss=0.045, reward_mean=0.340, reward_bound=0.308, batch=229\n",
      "17042: loss=0.045, reward_mean=0.480, reward_bound=0.405, batch=230\n",
      "17043: loss=0.045, reward_mean=0.420, reward_bound=0.464, batch=231\n",
      "17044: loss=0.045, reward_mean=0.590, reward_bound=0.430, batch=231\n",
      "17045: loss=0.045, reward_mean=0.420, reward_bound=0.430, batch=231\n",
      "17046: loss=0.045, reward_mean=0.480, reward_bound=0.430, batch=231\n",
      "17047: loss=0.047, reward_mean=0.470, reward_bound=0.478, batch=224\n",
      "17048: loss=0.050, reward_mean=0.450, reward_bound=0.345, batch=227\n",
      "17049: loss=0.046, reward_mean=0.490, reward_bound=0.349, batch=228\n",
      "17050: loss=0.046, reward_mean=0.520, reward_bound=0.387, batch=228\n",
      "17051: loss=0.046, reward_mean=0.440, reward_bound=0.430, batch=227\n",
      "17052: loss=0.048, reward_mean=0.550, reward_bound=0.422, batch=229\n",
      "17053: loss=0.046, reward_mean=0.440, reward_bound=0.430, batch=229\n",
      "17054: loss=0.046, reward_mean=0.460, reward_bound=0.430, batch=229\n",
      "17055: loss=0.046, reward_mean=0.440, reward_bound=0.478, batch=231\n",
      "17056: loss=0.046, reward_mean=0.420, reward_bound=0.387, batch=231\n",
      "17057: loss=0.046, reward_mean=0.430, reward_bound=0.387, batch=231\n",
      "17058: loss=0.046, reward_mean=0.490, reward_bound=0.478, batch=225\n",
      "17059: loss=0.046, reward_mean=0.420, reward_bound=0.349, batch=226\n",
      "17060: loss=0.046, reward_mean=0.380, reward_bound=0.387, batch=226\n",
      "17061: loss=0.046, reward_mean=0.400, reward_bound=0.314, batch=227\n",
      "17062: loss=0.046, reward_mean=0.470, reward_bound=0.422, batch=229\n",
      "17063: loss=0.048, reward_mean=0.430, reward_bound=0.430, batch=228\n",
      "17064: loss=0.048, reward_mean=0.420, reward_bound=0.484, batch=229\n",
      "17066: loss=0.035, reward_mean=0.430, reward_bound=0.000, batch=43\n",
      "17067: loss=0.038, reward_mean=0.420, reward_bound=0.000, batch=85\n",
      "17068: loss=0.045, reward_mean=0.490, reward_bound=0.001, batch=129\n",
      "17069: loss=0.049, reward_mean=0.470, reward_bound=0.005, batch=160\n",
      "17070: loss=0.047, reward_mean=0.410, reward_bound=0.016, batch=177\n",
      "17071: loss=0.050, reward_mean=0.470, reward_bound=0.028, batch=189\n",
      "17072: loss=0.049, reward_mean=0.420, reward_bound=0.038, batch=198\n",
      "17073: loss=0.046, reward_mean=0.450, reward_bound=0.052, batch=200\n",
      "17074: loss=0.050, reward_mean=0.460, reward_bound=0.065, batch=205\n",
      "17075: loss=0.052, reward_mean=0.450, reward_bound=0.098, batch=207\n",
      "17076: loss=0.051, reward_mean=0.430, reward_bound=0.109, batch=224\n",
      "17077: loss=0.056, reward_mean=0.490, reward_bound=0.109, batch=221\n",
      "17078: loss=0.052, reward_mean=0.460, reward_bound=0.122, batch=221\n",
      "17079: loss=0.055, reward_mean=0.410, reward_bound=0.135, batch=216\n",
      "17080: loss=0.056, reward_mean=0.390, reward_bound=0.150, batch=213\n",
      "17081: loss=0.055, reward_mean=0.390, reward_bound=0.167, batch=203\n",
      "17082: loss=0.060, reward_mean=0.430, reward_bound=0.185, batch=189\n",
      "17083: loss=0.059, reward_mean=0.420, reward_bound=0.194, batch=202\n",
      "17084: loss=0.056, reward_mean=0.470, reward_bound=0.206, batch=213\n",
      "17085: loss=0.056, reward_mean=0.500, reward_bound=0.206, batch=190\n",
      "17086: loss=0.057, reward_mean=0.400, reward_bound=0.127, batch=203\n",
      "17087: loss=0.057, reward_mean=0.450, reward_bound=0.150, batch=210\n",
      "17088: loss=0.056, reward_mean=0.340, reward_bound=0.200, batch=217\n",
      "17089: loss=0.056, reward_mean=0.460, reward_bound=0.229, batch=185\n",
      "17090: loss=0.056, reward_mean=0.430, reward_bound=0.185, batch=196\n",
      "17091: loss=0.059, reward_mean=0.390, reward_bound=0.229, batch=206\n",
      "17092: loss=0.055, reward_mean=0.470, reward_bound=0.254, batch=180\n",
      "17093: loss=0.056, reward_mean=0.440, reward_bound=0.138, batch=196\n",
      "17094: loss=0.055, reward_mean=0.430, reward_bound=0.143, batch=207\n",
      "17095: loss=0.054, reward_mean=0.450, reward_bound=0.185, batch=214\n",
      "17096: loss=0.054, reward_mean=0.420, reward_bound=0.206, batch=219\n",
      "17097: loss=0.054, reward_mean=0.460, reward_bound=0.229, batch=220\n",
      "17098: loss=0.055, reward_mean=0.500, reward_bound=0.254, batch=223\n",
      "17099: loss=0.057, reward_mean=0.430, reward_bound=0.282, batch=182\n",
      "17100: loss=0.056, reward_mean=0.410, reward_bound=0.126, batch=197\n",
      "17101: loss=0.057, reward_mean=0.440, reward_bound=0.167, batch=202\n",
      "17102: loss=0.057, reward_mean=0.450, reward_bound=0.167, batch=210\n",
      "17103: loss=0.056, reward_mean=0.480, reward_bound=0.222, batch=217\n",
      "17104: loss=0.056, reward_mean=0.480, reward_bound=0.229, batch=219\n",
      "17105: loss=0.056, reward_mean=0.450, reward_bound=0.254, batch=222\n",
      "17106: loss=0.051, reward_mean=0.510, reward_bound=0.314, batch=164\n",
      "17107: loss=0.053, reward_mean=0.480, reward_bound=0.078, batch=185\n",
      "17108: loss=0.055, reward_mean=0.450, reward_bound=0.098, batch=196\n",
      "17109: loss=0.057, reward_mean=0.440, reward_bound=0.109, batch=206\n",
      "17110: loss=0.057, reward_mean=0.560, reward_bound=0.150, batch=212\n",
      "17111: loss=0.052, reward_mean=0.420, reward_bound=0.185, batch=212\n",
      "17112: loss=0.052, reward_mean=0.460, reward_bound=0.206, batch=220\n",
      "17113: loss=0.049, reward_mean=0.390, reward_bound=0.229, batch=216\n",
      "17114: loss=0.051, reward_mean=0.480, reward_bound=0.254, batch=219\n",
      "17115: loss=0.057, reward_mean=0.380, reward_bound=0.282, batch=212\n",
      "17116: loss=0.055, reward_mean=0.450, reward_bound=0.314, batch=207\n",
      "17117: loss=0.053, reward_mean=0.500, reward_bound=0.308, batch=215\n",
      "17118: loss=0.052, reward_mean=0.450, reward_bound=0.289, batch=220\n",
      "17119: loss=0.053, reward_mean=0.420, reward_bound=0.338, batch=224\n",
      "17120: loss=0.052, reward_mean=0.460, reward_bound=0.349, batch=157\n",
      "17121: loss=0.054, reward_mean=0.460, reward_bound=0.065, batch=179\n",
      "17122: loss=0.053, reward_mean=0.440, reward_bound=0.075, batch=195\n",
      "17123: loss=0.054, reward_mean=0.460, reward_bound=0.112, batch=206\n",
      "17124: loss=0.051, reward_mean=0.500, reward_bound=0.158, batch=214\n",
      "17125: loss=0.053, reward_mean=0.410, reward_bound=0.167, batch=218\n",
      "17126: loss=0.050, reward_mean=0.520, reward_bound=0.206, batch=219\n",
      "17127: loss=0.046, reward_mean=0.470, reward_bound=0.239, batch=223\n",
      "17128: loss=0.049, reward_mean=0.420, reward_bound=0.254, batch=225\n",
      "17129: loss=0.050, reward_mean=0.440, reward_bound=0.282, batch=214\n",
      "17130: loss=0.052, reward_mean=0.500, reward_bound=0.229, batch=219\n",
      "17131: loss=0.053, reward_mean=0.470, reward_bound=0.282, batch=222\n",
      "17132: loss=0.053, reward_mean=0.380, reward_bound=0.254, batch=223\n",
      "17133: loss=0.052, reward_mean=0.490, reward_bound=0.314, batch=208\n",
      "17134: loss=0.053, reward_mean=0.460, reward_bound=0.282, batch=214\n",
      "17135: loss=0.052, reward_mean=0.410, reward_bound=0.314, batch=217\n",
      "17136: loss=0.053, reward_mean=0.470, reward_bound=0.308, batch=222\n",
      "17137: loss=0.052, reward_mean=0.380, reward_bound=0.314, batch=224\n",
      "17138: loss=0.052, reward_mean=0.430, reward_bound=0.349, batch=210\n",
      "17139: loss=0.053, reward_mean=0.490, reward_bound=0.254, batch=216\n",
      "17140: loss=0.051, reward_mean=0.380, reward_bound=0.268, batch=221\n",
      "17141: loss=0.051, reward_mean=0.470, reward_bound=0.282, batch=223\n",
      "17142: loss=0.052, reward_mean=0.550, reward_bound=0.314, batch=225\n",
      "17143: loss=0.052, reward_mean=0.520, reward_bound=0.349, batch=223\n",
      "17144: loss=0.040, reward_mean=0.460, reward_bound=0.387, batch=147\n",
      "17145: loss=0.035, reward_mean=0.370, reward_bound=0.042, batch=172\n",
      "17146: loss=0.041, reward_mean=0.430, reward_bound=0.082, batch=190\n",
      "17147: loss=0.040, reward_mean=0.390, reward_bound=0.096, batch=203\n",
      "17148: loss=0.041, reward_mean=0.470, reward_bound=0.150, batch=202\n",
      "17149: loss=0.041, reward_mean=0.440, reward_bound=0.167, batch=209\n",
      "17150: loss=0.041, reward_mean=0.420, reward_bound=0.185, batch=214\n",
      "17151: loss=0.044, reward_mean=0.380, reward_bound=0.204, batch=220\n",
      "17152: loss=0.047, reward_mean=0.450, reward_bound=0.222, batch=224\n",
      "17153: loss=0.046, reward_mean=0.360, reward_bound=0.229, batch=218\n",
      "17154: loss=0.047, reward_mean=0.330, reward_bound=0.229, batch=221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17155: loss=0.042, reward_mean=0.480, reward_bound=0.254, batch=217\n",
      "17156: loss=0.042, reward_mean=0.430, reward_bound=0.229, batch=221\n",
      "17157: loss=0.041, reward_mean=0.440, reward_bound=0.282, batch=216\n",
      "17158: loss=0.041, reward_mean=0.410, reward_bound=0.314, batch=205\n",
      "17159: loss=0.039, reward_mean=0.550, reward_bound=0.210, batch=213\n",
      "17160: loss=0.041, reward_mean=0.370, reward_bound=0.197, batch=219\n",
      "17161: loss=0.041, reward_mean=0.460, reward_bound=0.254, batch=220\n",
      "17162: loss=0.041, reward_mean=0.380, reward_bound=0.274, batch=224\n",
      "17163: loss=0.039, reward_mean=0.410, reward_bound=0.314, batch=226\n",
      "17164: loss=0.039, reward_mean=0.480, reward_bound=0.282, batch=227\n",
      "17165: loss=0.038, reward_mean=0.390, reward_bound=0.349, batch=203\n",
      "17166: loss=0.036, reward_mean=0.450, reward_bound=0.167, batch=211\n",
      "17167: loss=0.036, reward_mean=0.530, reward_bound=0.254, batch=216\n",
      "17168: loss=0.035, reward_mean=0.370, reward_bound=0.143, batch=221\n",
      "17169: loss=0.037, reward_mean=0.440, reward_bound=0.282, batch=220\n",
      "17170: loss=0.037, reward_mean=0.400, reward_bound=0.314, batch=220\n",
      "17171: loss=0.038, reward_mean=0.380, reward_bound=0.349, batch=216\n",
      "17172: loss=0.037, reward_mean=0.400, reward_bound=0.335, batch=221\n",
      "17173: loss=0.037, reward_mean=0.480, reward_bound=0.314, batch=223\n",
      "17174: loss=0.037, reward_mean=0.470, reward_bound=0.387, batch=203\n",
      "17175: loss=0.035, reward_mean=0.450, reward_bound=0.220, batch=212\n",
      "17176: loss=0.036, reward_mean=0.370, reward_bound=0.236, batch=218\n",
      "17177: loss=0.036, reward_mean=0.380, reward_bound=0.254, batch=221\n",
      "17178: loss=0.035, reward_mean=0.390, reward_bound=0.185, batch=224\n",
      "17179: loss=0.037, reward_mean=0.470, reward_bound=0.282, batch=224\n",
      "17180: loss=0.037, reward_mean=0.480, reward_bound=0.314, batch=225\n",
      "17181: loss=0.038, reward_mean=0.500, reward_bound=0.349, batch=224\n",
      "17182: loss=0.036, reward_mean=0.530, reward_bound=0.387, batch=221\n",
      "17183: loss=0.036, reward_mean=0.540, reward_bound=0.282, batch=224\n",
      "17184: loss=0.035, reward_mean=0.450, reward_bound=0.342, batch=227\n",
      "17185: loss=0.035, reward_mean=0.510, reward_bound=0.380, batch=229\n",
      "17186: loss=0.035, reward_mean=0.380, reward_bound=0.405, batch=230\n",
      "17187: loss=0.041, reward_mean=0.400, reward_bound=0.430, batch=126\n",
      "17188: loss=0.034, reward_mean=0.370, reward_bound=0.015, batch=157\n",
      "17189: loss=0.035, reward_mean=0.470, reward_bound=0.047, batch=178\n",
      "17190: loss=0.037, reward_mean=0.370, reward_bound=0.043, batch=194\n",
      "17191: loss=0.040, reward_mean=0.480, reward_bound=0.079, batch=206\n",
      "17192: loss=0.042, reward_mean=0.490, reward_bound=0.109, batch=209\n",
      "17193: loss=0.036, reward_mean=0.390, reward_bound=0.135, batch=213\n",
      "17194: loss=0.039, reward_mean=0.440, reward_bound=0.150, batch=216\n",
      "17195: loss=0.036, reward_mean=0.500, reward_bound=0.185, batch=216\n",
      "17196: loss=0.039, reward_mean=0.460, reward_bound=0.206, batch=217\n",
      "17197: loss=0.037, reward_mean=0.440, reward_bound=0.229, batch=213\n",
      "17198: loss=0.035, reward_mean=0.540, reward_bound=0.254, batch=208\n",
      "17199: loss=0.036, reward_mean=0.520, reward_bound=0.229, batch=213\n",
      "17200: loss=0.036, reward_mean=0.470, reward_bound=0.271, batch=219\n",
      "17201: loss=0.038, reward_mean=0.420, reward_bound=0.282, batch=200\n",
      "17202: loss=0.045, reward_mean=0.450, reward_bound=0.180, batch=210\n",
      "17203: loss=0.044, reward_mean=0.420, reward_bound=0.200, batch=217\n",
      "17204: loss=0.038, reward_mean=0.460, reward_bound=0.229, batch=219\n",
      "17205: loss=0.038, reward_mean=0.460, reward_bound=0.254, batch=220\n",
      "17206: loss=0.041, reward_mean=0.480, reward_bound=0.314, batch=202\n",
      "17207: loss=0.041, reward_mean=0.330, reward_bound=0.155, batch=211\n",
      "17208: loss=0.039, reward_mean=0.470, reward_bound=0.282, batch=214\n",
      "17209: loss=0.038, reward_mean=0.450, reward_bound=0.305, batch=220\n",
      "17210: loss=0.038, reward_mean=0.500, reward_bound=0.282, batch=223\n",
      "17211: loss=0.038, reward_mean=0.520, reward_bound=0.314, batch=225\n",
      "17212: loss=0.037, reward_mean=0.340, reward_bound=0.314, batch=226\n",
      "17213: loss=0.037, reward_mean=0.360, reward_bound=0.349, batch=206\n",
      "17214: loss=0.036, reward_mean=0.390, reward_bound=0.230, batch=214\n",
      "17215: loss=0.035, reward_mean=0.400, reward_bound=0.280, batch=220\n",
      "17216: loss=0.036, reward_mean=0.520, reward_bound=0.282, batch=222\n",
      "17217: loss=0.034, reward_mean=0.470, reward_bound=0.314, batch=224\n",
      "17218: loss=0.034, reward_mean=0.410, reward_bound=0.280, batch=227\n",
      "17219: loss=0.035, reward_mean=0.460, reward_bound=0.349, batch=223\n",
      "17220: loss=0.039, reward_mean=0.440, reward_bound=0.387, batch=189\n",
      "17221: loss=0.036, reward_mean=0.440, reward_bound=0.206, batch=201\n",
      "17222: loss=0.038, reward_mean=0.390, reward_bound=0.229, batch=210\n",
      "17223: loss=0.041, reward_mean=0.440, reward_bound=0.247, batch=217\n",
      "17224: loss=0.041, reward_mean=0.490, reward_bound=0.254, batch=217\n",
      "17225: loss=0.043, reward_mean=0.520, reward_bound=0.282, batch=220\n",
      "17226: loss=0.047, reward_mean=0.530, reward_bound=0.314, batch=220\n",
      "17227: loss=0.043, reward_mean=0.410, reward_bound=0.349, batch=214\n",
      "17228: loss=0.044, reward_mean=0.390, reward_bound=0.254, batch=217\n",
      "17229: loss=0.045, reward_mean=0.440, reward_bound=0.314, batch=220\n",
      "17230: loss=0.046, reward_mean=0.440, reward_bound=0.387, batch=215\n",
      "17231: loss=0.045, reward_mean=0.380, reward_bound=0.229, batch=219\n",
      "17232: loss=0.045, reward_mean=0.500, reward_bound=0.295, batch=223\n",
      "17233: loss=0.045, reward_mean=0.420, reward_bound=0.349, batch=224\n",
      "17234: loss=0.047, reward_mean=0.490, reward_bound=0.384, batch=227\n",
      "17235: loss=0.047, reward_mean=0.460, reward_bound=0.387, batch=222\n",
      "17236: loss=0.046, reward_mean=0.520, reward_bound=0.400, batch=225\n",
      "17237: loss=0.051, reward_mean=0.500, reward_bound=0.430, batch=184\n",
      "17238: loss=0.052, reward_mean=0.420, reward_bound=0.165, batch=199\n",
      "17239: loss=0.051, reward_mean=0.450, reward_bound=0.185, batch=208\n",
      "17240: loss=0.049, reward_mean=0.530, reward_bound=0.208, batch=215\n",
      "17241: loss=0.048, reward_mean=0.420, reward_bound=0.229, batch=216\n",
      "17242: loss=0.047, reward_mean=0.420, reward_bound=0.282, batch=214\n",
      "17243: loss=0.047, reward_mean=0.500, reward_bound=0.226, batch=220\n",
      "17244: loss=0.048, reward_mean=0.390, reward_bound=0.222, batch=224\n",
      "17245: loss=0.047, reward_mean=0.520, reward_bound=0.314, batch=219\n",
      "17246: loss=0.046, reward_mean=0.440, reward_bound=0.254, batch=222\n",
      "17247: loss=0.047, reward_mean=0.380, reward_bound=0.349, batch=217\n",
      "17248: loss=0.046, reward_mean=0.450, reward_bound=0.335, batch=222\n",
      "17249: loss=0.049, reward_mean=0.450, reward_bound=0.324, batch=225\n",
      "17250: loss=0.048, reward_mean=0.460, reward_bound=0.349, batch=225\n",
      "17251: loss=0.047, reward_mean=0.460, reward_bound=0.356, batch=227\n",
      "17252: loss=0.047, reward_mean=0.460, reward_bound=0.349, batch=228\n",
      "17253: loss=0.047, reward_mean=0.450, reward_bound=0.387, batch=213\n",
      "17254: loss=0.046, reward_mean=0.440, reward_bound=0.271, batch=219\n",
      "17255: loss=0.045, reward_mean=0.490, reward_bound=0.282, batch=222\n",
      "17256: loss=0.045, reward_mean=0.400, reward_bound=0.324, batch=225\n",
      "17257: loss=0.045, reward_mean=0.330, reward_bound=0.349, batch=226\n",
      "17258: loss=0.045, reward_mean=0.460, reward_bound=0.387, batch=226\n",
      "17259: loss=0.045, reward_mean=0.400, reward_bound=0.409, batch=228\n",
      "17260: loss=0.046, reward_mean=0.490, reward_bound=0.430, batch=213\n",
      "17261: loss=0.044, reward_mean=0.500, reward_bound=0.290, batch=219\n",
      "17262: loss=0.044, reward_mean=0.460, reward_bound=0.314, batch=220\n",
      "17263: loss=0.043, reward_mean=0.420, reward_bound=0.274, batch=224\n",
      "17264: loss=0.043, reward_mean=0.450, reward_bound=0.282, batch=226\n",
      "17265: loss=0.042, reward_mean=0.410, reward_bound=0.298, batch=228\n",
      "17266: loss=0.044, reward_mean=0.460, reward_bound=0.349, batch=224\n",
      "17267: loss=0.045, reward_mean=0.380, reward_bound=0.349, batch=225\n",
      "17268: loss=0.048, reward_mean=0.380, reward_bound=0.387, batch=220\n",
      "17269: loss=0.050, reward_mean=0.480, reward_bound=0.430, batch=220\n",
      "17270: loss=0.051, reward_mean=0.410, reward_bound=0.338, batch=224\n",
      "17271: loss=0.052, reward_mean=0.400, reward_bound=0.308, batch=227\n",
      "17272: loss=0.049, reward_mean=0.510, reward_bound=0.349, batch=226\n",
      "17273: loss=0.050, reward_mean=0.450, reward_bound=0.454, batch=228\n",
      "17274: loss=0.050, reward_mean=0.450, reward_bound=0.435, batch=229\n",
      "17275: loss=0.050, reward_mean=0.360, reward_bound=0.343, batch=230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17276: loss=0.050, reward_mean=0.440, reward_bound=0.418, batch=231\n",
      "17277: loss=0.050, reward_mean=0.400, reward_bound=0.430, batch=230\n",
      "17278: loss=0.050, reward_mean=0.350, reward_bound=0.464, batch=231\n",
      "17279: loss=0.057, reward_mean=0.420, reward_bound=0.478, batch=94\n",
      "17280: loss=0.052, reward_mean=0.350, reward_bound=0.000, batch=129\n",
      "17281: loss=0.048, reward_mean=0.440, reward_bound=0.007, batch=160\n",
      "17282: loss=0.050, reward_mean=0.330, reward_bound=0.020, batch=182\n",
      "17283: loss=0.054, reward_mean=0.440, reward_bound=0.044, batch=197\n",
      "17284: loss=0.050, reward_mean=0.420, reward_bound=0.070, batch=208\n",
      "17285: loss=0.050, reward_mean=0.430, reward_bound=0.098, batch=208\n",
      "17286: loss=0.050, reward_mean=0.410, reward_bound=0.122, batch=212\n",
      "17287: loss=0.052, reward_mean=0.500, reward_bound=0.135, batch=217\n",
      "17288: loss=0.054, reward_mean=0.480, reward_bound=0.163, batch=222\n",
      "17289: loss=0.056, reward_mean=0.480, reward_bound=0.167, batch=219\n",
      "17290: loss=0.056, reward_mean=0.430, reward_bound=0.185, batch=213\n",
      "17291: loss=0.057, reward_mean=0.360, reward_bound=0.206, batch=203\n",
      "17292: loss=0.060, reward_mean=0.410, reward_bound=0.229, batch=187\n",
      "17293: loss=0.057, reward_mean=0.430, reward_bound=0.198, batch=201\n",
      "17294: loss=0.057, reward_mean=0.440, reward_bound=0.229, batch=206\n",
      "17295: loss=0.055, reward_mean=0.430, reward_bound=0.217, batch=214\n",
      "17296: loss=0.053, reward_mean=0.440, reward_bound=0.252, batch=220\n",
      "17297: loss=0.053, reward_mean=0.440, reward_bound=0.254, batch=203\n",
      "17298: loss=0.051, reward_mean=0.490, reward_bound=0.229, batch=211\n",
      "17299: loss=0.051, reward_mean=0.400, reward_bound=0.254, batch=214\n",
      "17300: loss=0.050, reward_mean=0.360, reward_bound=0.249, batch=220\n",
      "17301: loss=0.051, reward_mean=0.500, reward_bound=0.282, batch=205\n",
      "17302: loss=0.051, reward_mean=0.540, reward_bound=0.229, batch=212\n",
      "17303: loss=0.050, reward_mean=0.450, reward_bound=0.282, batch=215\n",
      "17304: loss=0.051, reward_mean=0.470, reward_bound=0.314, batch=200\n",
      "17305: loss=0.049, reward_mean=0.410, reward_bound=0.229, batch=208\n",
      "17306: loss=0.053, reward_mean=0.510, reward_bound=0.254, batch=214\n",
      "17307: loss=0.055, reward_mean=0.400, reward_bound=0.282, batch=219\n",
      "17308: loss=0.054, reward_mean=0.490, reward_bound=0.295, batch=223\n",
      "17309: loss=0.054, reward_mean=0.450, reward_bound=0.301, batch=226\n",
      "17310: loss=0.051, reward_mean=0.410, reward_bound=0.314, batch=224\n",
      "17311: loss=0.053, reward_mean=0.420, reward_bound=0.349, batch=194\n",
      "17312: loss=0.055, reward_mean=0.520, reward_bound=0.150, batch=205\n",
      "17313: loss=0.058, reward_mean=0.380, reward_bound=0.189, batch=213\n",
      "17314: loss=0.056, reward_mean=0.340, reward_bound=0.206, batch=217\n",
      "17315: loss=0.054, reward_mean=0.360, reward_bound=0.249, batch=222\n",
      "17316: loss=0.053, reward_mean=0.390, reward_bound=0.254, batch=224\n",
      "17317: loss=0.052, reward_mean=0.350, reward_bound=0.282, batch=223\n",
      "17318: loss=0.053, reward_mean=0.530, reward_bound=0.282, batch=224\n",
      "17319: loss=0.049, reward_mean=0.450, reward_bound=0.314, batch=216\n",
      "17320: loss=0.049, reward_mean=0.440, reward_bound=0.314, batch=220\n",
      "17321: loss=0.049, reward_mean=0.360, reward_bound=0.349, batch=219\n",
      "17322: loss=0.050, reward_mean=0.430, reward_bound=0.349, batch=222\n",
      "17323: loss=0.050, reward_mean=0.400, reward_bound=0.360, batch=225\n",
      "17324: loss=0.049, reward_mean=0.480, reward_bound=0.356, batch=227\n",
      "17325: loss=0.052, reward_mean=0.460, reward_bound=0.387, batch=186\n",
      "17326: loss=0.051, reward_mean=0.460, reward_bound=0.128, batch=200\n",
      "17327: loss=0.055, reward_mean=0.370, reward_bound=0.200, batch=210\n",
      "17328: loss=0.057, reward_mean=0.440, reward_bound=0.222, batch=217\n",
      "17329: loss=0.051, reward_mean=0.420, reward_bound=0.229, batch=217\n",
      "17330: loss=0.053, reward_mean=0.430, reward_bound=0.254, batch=217\n",
      "17331: loss=0.053, reward_mean=0.370, reward_bound=0.267, batch=222\n",
      "17332: loss=0.053, reward_mean=0.490, reward_bound=0.282, batch=217\n",
      "17333: loss=0.052, reward_mean=0.460, reward_bound=0.254, batch=221\n",
      "17334: loss=0.052, reward_mean=0.490, reward_bound=0.314, batch=217\n",
      "17335: loss=0.054, reward_mean=0.460, reward_bound=0.308, batch=222\n",
      "17336: loss=0.053, reward_mean=0.430, reward_bound=0.292, batch=225\n",
      "17337: loss=0.055, reward_mean=0.500, reward_bound=0.321, batch=227\n",
      "17338: loss=0.055, reward_mean=0.430, reward_bound=0.349, batch=221\n",
      "17339: loss=0.056, reward_mean=0.430, reward_bound=0.314, batch=224\n",
      "17340: loss=0.055, reward_mean=0.430, reward_bound=0.345, batch=227\n",
      "17341: loss=0.055, reward_mean=0.430, reward_bound=0.349, batch=228\n",
      "17342: loss=0.051, reward_mean=0.430, reward_bound=0.387, batch=217\n",
      "17343: loss=0.050, reward_mean=0.440, reward_bound=0.380, batch=222\n",
      "17344: loss=0.053, reward_mean=0.450, reward_bound=0.360, batch=225\n",
      "17345: loss=0.054, reward_mean=0.450, reward_bound=0.387, batch=226\n",
      "17346: loss=0.054, reward_mean=0.420, reward_bound=0.289, batch=228\n",
      "17347: loss=0.057, reward_mean=0.470, reward_bound=0.353, batch=229\n",
      "17348: loss=0.057, reward_mean=0.510, reward_bound=0.349, batch=229\n",
      "17349: loss=0.056, reward_mean=0.440, reward_bound=0.430, batch=166\n",
      "17350: loss=0.054, reward_mean=0.430, reward_bound=0.095, batch=186\n",
      "17351: loss=0.058, reward_mean=0.430, reward_bound=0.109, batch=197\n",
      "17352: loss=0.060, reward_mean=0.410, reward_bound=0.119, batch=208\n",
      "17353: loss=0.060, reward_mean=0.450, reward_bound=0.167, batch=211\n",
      "17354: loss=0.057, reward_mean=0.450, reward_bound=0.185, batch=217\n",
      "17355: loss=0.058, reward_mean=0.440, reward_bound=0.206, batch=217\n",
      "17356: loss=0.062, reward_mean=0.430, reward_bound=0.229, batch=220\n",
      "17357: loss=0.061, reward_mean=0.350, reward_bound=0.254, batch=216\n",
      "17358: loss=0.060, reward_mean=0.440, reward_bound=0.268, batch=221\n",
      "17359: loss=0.055, reward_mean=0.380, reward_bound=0.282, batch=212\n",
      "17360: loss=0.056, reward_mean=0.380, reward_bound=0.314, batch=203\n",
      "17361: loss=0.059, reward_mean=0.420, reward_bound=0.144, batch=212\n",
      "17362: loss=0.059, reward_mean=0.530, reward_bound=0.191, batch=218\n",
      "17363: loss=0.058, reward_mean=0.450, reward_bound=0.206, batch=220\n",
      "17364: loss=0.059, reward_mean=0.470, reward_bound=0.282, batch=217\n",
      "17365: loss=0.063, reward_mean=0.340, reward_bound=0.259, batch=222\n",
      "17366: loss=0.060, reward_mean=0.500, reward_bound=0.349, batch=212\n",
      "17367: loss=0.059, reward_mean=0.510, reward_bound=0.254, batch=217\n",
      "17368: loss=0.059, reward_mean=0.430, reward_bound=0.282, batch=219\n",
      "17369: loss=0.058, reward_mean=0.440, reward_bound=0.314, batch=221\n",
      "17370: loss=0.058, reward_mean=0.420, reward_bound=0.282, batch=224\n",
      "17371: loss=0.057, reward_mean=0.530, reward_bound=0.384, batch=227\n",
      "17372: loss=0.057, reward_mean=0.500, reward_bound=0.387, batch=207\n",
      "17373: loss=0.055, reward_mean=0.460, reward_bound=0.302, batch=215\n",
      "17374: loss=0.055, reward_mean=0.510, reward_bound=0.314, batch=218\n",
      "17375: loss=0.053, reward_mean=0.380, reward_bound=0.154, batch=222\n",
      "17376: loss=0.055, reward_mean=0.420, reward_bound=0.282, batch=223\n",
      "17377: loss=0.056, reward_mean=0.480, reward_bound=0.349, batch=220\n",
      "17378: loss=0.055, reward_mean=0.430, reward_bound=0.314, batch=223\n",
      "17379: loss=0.057, reward_mean=0.450, reward_bound=0.349, batch=225\n",
      "17380: loss=0.056, reward_mean=0.390, reward_bound=0.356, batch=227\n",
      "17381: loss=0.058, reward_mean=0.480, reward_bound=0.387, batch=221\n",
      "17382: loss=0.059, reward_mean=0.420, reward_bound=0.349, batch=224\n",
      "17383: loss=0.058, reward_mean=0.380, reward_bound=0.384, batch=227\n",
      "17384: loss=0.059, reward_mean=0.330, reward_bound=0.380, batch=229\n",
      "17385: loss=0.058, reward_mean=0.410, reward_bound=0.387, batch=227\n",
      "17386: loss=0.058, reward_mean=0.440, reward_bound=0.314, batch=228\n",
      "17387: loss=0.059, reward_mean=0.530, reward_bound=0.430, batch=205\n",
      "17388: loss=0.058, reward_mean=0.410, reward_bound=0.189, batch=213\n",
      "17389: loss=0.060, reward_mean=0.550, reward_bound=0.254, batch=218\n",
      "17390: loss=0.062, reward_mean=0.480, reward_bound=0.314, batch=219\n",
      "17391: loss=0.064, reward_mean=0.480, reward_bound=0.295, batch=223\n",
      "17392: loss=0.058, reward_mean=0.510, reward_bound=0.387, batch=218\n",
      "17393: loss=0.057, reward_mean=0.440, reward_bound=0.353, batch=222\n",
      "17394: loss=0.056, reward_mean=0.510, reward_bound=0.349, batch=224\n",
      "17395: loss=0.058, reward_mean=0.470, reward_bound=0.387, batch=224\n",
      "17396: loss=0.057, reward_mean=0.470, reward_bound=0.349, batch=226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17397: loss=0.057, reward_mean=0.430, reward_bound=0.430, batch=215\n",
      "17398: loss=0.056, reward_mean=0.470, reward_bound=0.329, batch=220\n",
      "17399: loss=0.055, reward_mean=0.430, reward_bound=0.304, batch=224\n",
      "17400: loss=0.054, reward_mean=0.450, reward_bound=0.384, batch=227\n",
      "17401: loss=0.055, reward_mean=0.480, reward_bound=0.387, batch=226\n",
      "17402: loss=0.057, reward_mean=0.380, reward_bound=0.331, batch=228\n",
      "17403: loss=0.054, reward_mean=0.480, reward_bound=0.392, batch=229\n",
      "17404: loss=0.055, reward_mean=0.450, reward_bound=0.430, batch=224\n",
      "17405: loss=0.054, reward_mean=0.430, reward_bound=0.345, batch=227\n",
      "17406: loss=0.054, reward_mean=0.420, reward_bound=0.349, batch=228\n",
      "17407: loss=0.056, reward_mean=0.480, reward_bound=0.392, batch=229\n",
      "17408: loss=0.056, reward_mean=0.510, reward_bound=0.405, batch=230\n",
      "17409: loss=0.057, reward_mean=0.420, reward_bound=0.430, batch=230\n",
      "17410: loss=0.050, reward_mean=0.500, reward_bound=0.478, batch=146\n",
      "17411: loss=0.052, reward_mean=0.450, reward_bound=0.080, batch=171\n",
      "17412: loss=0.051, reward_mean=0.470, reward_bound=0.109, batch=183\n",
      "17413: loss=0.053, reward_mean=0.490, reward_bound=0.150, batch=197\n",
      "17414: loss=0.052, reward_mean=0.340, reward_bound=0.150, batch=207\n",
      "17415: loss=0.050, reward_mean=0.540, reward_bound=0.167, batch=211\n",
      "17416: loss=0.047, reward_mean=0.400, reward_bound=0.185, batch=210\n",
      "17417: loss=0.054, reward_mean=0.400, reward_bound=0.206, batch=218\n",
      "17418: loss=0.050, reward_mean=0.430, reward_bound=0.206, batch=214\n",
      "17419: loss=0.051, reward_mean=0.450, reward_bound=0.229, batch=214\n",
      "17420: loss=0.051, reward_mean=0.430, reward_bound=0.252, batch=220\n",
      "17421: loss=0.053, reward_mean=0.400, reward_bound=0.254, batch=213\n",
      "17422: loss=0.056, reward_mean=0.450, reward_bound=0.282, batch=205\n",
      "17423: loss=0.057, reward_mean=0.440, reward_bound=0.260, batch=213\n",
      "17424: loss=0.057, reward_mean=0.560, reward_bound=0.282, batch=218\n",
      "17425: loss=0.059, reward_mean=0.430, reward_bound=0.314, batch=204\n",
      "17426: loss=0.056, reward_mean=0.460, reward_bound=0.229, batch=212\n",
      "17427: loss=0.057, reward_mean=0.500, reward_bound=0.314, batch=217\n",
      "17428: loss=0.057, reward_mean=0.490, reward_bound=0.349, batch=201\n",
      "17429: loss=0.059, reward_mean=0.360, reward_bound=0.167, batch=209\n",
      "17430: loss=0.057, reward_mean=0.490, reward_bound=0.239, batch=216\n",
      "17431: loss=0.055, reward_mean=0.420, reward_bound=0.282, batch=214\n",
      "17432: loss=0.057, reward_mean=0.410, reward_bound=0.277, batch=220\n",
      "17433: loss=0.056, reward_mean=0.500, reward_bound=0.338, batch=224\n",
      "17434: loss=0.054, reward_mean=0.430, reward_bound=0.349, batch=225\n",
      "17435: loss=0.059, reward_mean=0.460, reward_bound=0.387, batch=195\n",
      "17436: loss=0.060, reward_mean=0.430, reward_bound=0.206, batch=205\n",
      "17437: loss=0.059, reward_mean=0.440, reward_bound=0.254, batch=210\n",
      "17438: loss=0.056, reward_mean=0.520, reward_bound=0.282, batch=214\n",
      "17439: loss=0.054, reward_mean=0.440, reward_bound=0.226, batch=220\n",
      "17440: loss=0.055, reward_mean=0.410, reward_bound=0.274, batch=224\n",
      "17441: loss=0.057, reward_mean=0.390, reward_bound=0.314, batch=221\n",
      "17442: loss=0.056, reward_mean=0.470, reward_bound=0.282, batch=224\n",
      "17443: loss=0.060, reward_mean=0.450, reward_bound=0.314, batch=226\n",
      "17444: loss=0.058, reward_mean=0.470, reward_bound=0.349, batch=215\n",
      "17445: loss=0.059, reward_mean=0.480, reward_bound=0.254, batch=219\n",
      "17446: loss=0.060, reward_mean=0.470, reward_bound=0.314, batch=222\n",
      "17447: loss=0.059, reward_mean=0.440, reward_bound=0.292, batch=225\n",
      "17448: loss=0.058, reward_mean=0.420, reward_bound=0.246, batch=227\n",
      "17449: loss=0.062, reward_mean=0.470, reward_bound=0.349, batch=226\n",
      "17450: loss=0.063, reward_mean=0.440, reward_bound=0.351, batch=228\n",
      "17451: loss=0.061, reward_mean=0.390, reward_bound=0.387, batch=218\n",
      "17452: loss=0.060, reward_mean=0.370, reward_bound=0.257, batch=222\n",
      "17453: loss=0.061, reward_mean=0.440, reward_bound=0.292, batch=225\n",
      "17454: loss=0.061, reward_mean=0.460, reward_bound=0.349, batch=226\n",
      "17455: loss=0.060, reward_mean=0.410, reward_bound=0.409, batch=228\n",
      "17456: loss=0.060, reward_mean=0.480, reward_bound=0.357, batch=229\n",
      "17457: loss=0.054, reward_mean=0.440, reward_bound=0.430, batch=188\n",
      "17458: loss=0.057, reward_mean=0.420, reward_bound=0.150, batch=200\n",
      "17459: loss=0.051, reward_mean=0.420, reward_bound=0.185, batch=206\n",
      "17460: loss=0.054, reward_mean=0.420, reward_bound=0.241, batch=214\n",
      "17461: loss=0.053, reward_mean=0.530, reward_bound=0.254, batch=219\n",
      "17462: loss=0.056, reward_mean=0.420, reward_bound=0.254, batch=222\n",
      "17463: loss=0.054, reward_mean=0.510, reward_bound=0.314, batch=214\n",
      "17464: loss=0.054, reward_mean=0.410, reward_bound=0.345, batch=220\n",
      "17465: loss=0.057, reward_mean=0.460, reward_bound=0.349, batch=211\n",
      "17466: loss=0.060, reward_mean=0.480, reward_bound=0.349, batch=215\n",
      "17467: loss=0.058, reward_mean=0.470, reward_bound=0.321, batch=220\n",
      "17468: loss=0.059, reward_mean=0.460, reward_bound=0.274, batch=224\n",
      "17469: loss=0.058, reward_mean=0.480, reward_bound=0.254, batch=226\n",
      "17470: loss=0.060, reward_mean=0.400, reward_bound=0.282, batch=227\n",
      "17471: loss=0.060, reward_mean=0.390, reward_bound=0.349, batch=225\n",
      "17472: loss=0.058, reward_mean=0.460, reward_bound=0.387, batch=216\n",
      "17473: loss=0.059, reward_mean=0.400, reward_bound=0.349, batch=218\n",
      "17474: loss=0.059, reward_mean=0.500, reward_bound=0.282, batch=220\n",
      "17475: loss=0.061, reward_mean=0.450, reward_bound=0.314, batch=221\n",
      "17476: loss=0.062, reward_mean=0.410, reward_bound=0.430, batch=200\n",
      "17477: loss=0.062, reward_mean=0.390, reward_bound=0.200, batch=210\n",
      "17478: loss=0.066, reward_mean=0.510, reward_bound=0.206, batch=225\n",
      "17479: loss=0.062, reward_mean=0.390, reward_bound=0.206, batch=224\n",
      "17480: loss=0.063, reward_mean=0.480, reward_bound=0.282, batch=222\n",
      "17481: loss=0.065, reward_mean=0.450, reward_bound=0.314, batch=224\n",
      "17482: loss=0.064, reward_mean=0.410, reward_bound=0.349, batch=220\n",
      "17483: loss=0.063, reward_mean=0.330, reward_bound=0.349, batch=223\n",
      "17484: loss=0.061, reward_mean=0.500, reward_bound=0.387, batch=219\n",
      "17485: loss=0.060, reward_mean=0.520, reward_bound=0.343, batch=223\n",
      "17486: loss=0.061, reward_mean=0.420, reward_bound=0.387, batch=225\n",
      "17487: loss=0.061, reward_mean=0.440, reward_bound=0.349, batch=226\n",
      "17488: loss=0.062, reward_mean=0.440, reward_bound=0.409, batch=228\n",
      "17489: loss=0.061, reward_mean=0.500, reward_bound=0.430, batch=217\n",
      "17490: loss=0.060, reward_mean=0.410, reward_bound=0.254, batch=221\n",
      "17491: loss=0.061, reward_mean=0.470, reward_bound=0.314, batch=224\n",
      "17492: loss=0.062, reward_mean=0.410, reward_bound=0.345, batch=227\n",
      "17493: loss=0.062, reward_mean=0.440, reward_bound=0.349, batch=223\n",
      "17494: loss=0.065, reward_mean=0.410, reward_bound=0.387, batch=223\n",
      "17495: loss=0.064, reward_mean=0.490, reward_bound=0.349, batch=225\n",
      "17496: loss=0.065, reward_mean=0.370, reward_bound=0.430, batch=222\n",
      "17497: loss=0.066, reward_mean=0.530, reward_bound=0.349, batch=224\n",
      "17498: loss=0.065, reward_mean=0.450, reward_bound=0.311, batch=227\n",
      "17499: loss=0.065, reward_mean=0.500, reward_bound=0.349, batch=228\n",
      "17500: loss=0.065, reward_mean=0.470, reward_bound=0.353, batch=229\n",
      "17501: loss=0.065, reward_mean=0.410, reward_bound=0.387, batch=229\n",
      "17502: loss=0.065, reward_mean=0.490, reward_bound=0.430, batch=229\n",
      "17503: loss=0.065, reward_mean=0.420, reward_bound=0.387, batch=229\n",
      "17504: loss=0.065, reward_mean=0.470, reward_bound=0.387, batch=229\n",
      "17505: loss=0.065, reward_mean=0.460, reward_bound=0.450, batch=230\n",
      "17506: loss=0.064, reward_mean=0.440, reward_bound=0.376, batch=231\n",
      "17507: loss=0.064, reward_mean=0.430, reward_bound=0.430, batch=231\n",
      "17508: loss=0.055, reward_mean=0.490, reward_bound=0.478, batch=176\n",
      "17509: loss=0.056, reward_mean=0.470, reward_bound=0.122, batch=192\n",
      "17510: loss=0.054, reward_mean=0.480, reward_bound=0.167, batch=200\n",
      "17511: loss=0.054, reward_mean=0.420, reward_bound=0.185, batch=207\n",
      "17512: loss=0.052, reward_mean=0.450, reward_bound=0.229, batch=209\n",
      "17513: loss=0.050, reward_mean=0.340, reward_bound=0.175, batch=216\n",
      "17514: loss=0.050, reward_mean=0.450, reward_bound=0.254, batch=216\n",
      "17515: loss=0.054, reward_mean=0.460, reward_bound=0.282, batch=219\n",
      "17516: loss=0.057, reward_mean=0.430, reward_bound=0.314, batch=211\n",
      "17517: loss=0.055, reward_mean=0.470, reward_bound=0.206, batch=217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17518: loss=0.053, reward_mean=0.360, reward_bound=0.249, batch=222\n",
      "17519: loss=0.054, reward_mean=0.460, reward_bound=0.263, batch=225\n",
      "17520: loss=0.055, reward_mean=0.420, reward_bound=0.282, batch=224\n",
      "17521: loss=0.056, reward_mean=0.390, reward_bound=0.349, batch=209\n",
      "17522: loss=0.057, reward_mean=0.420, reward_bound=0.174, batch=216\n",
      "17523: loss=0.058, reward_mean=0.510, reward_bound=0.268, batch=221\n",
      "17524: loss=0.055, reward_mean=0.510, reward_bound=0.314, batch=223\n",
      "17525: loss=0.057, reward_mean=0.480, reward_bound=0.349, batch=219\n",
      "17526: loss=0.059, reward_mean=0.460, reward_bound=0.265, batch=223\n",
      "17527: loss=0.057, reward_mean=0.470, reward_bound=0.387, batch=206\n",
      "17528: loss=0.055, reward_mean=0.400, reward_bound=0.225, batch=214\n",
      "17529: loss=0.056, reward_mean=0.480, reward_bound=0.314, batch=219\n",
      "17530: loss=0.056, reward_mean=0.420, reward_bound=0.349, batch=222\n",
      "17531: loss=0.055, reward_mean=0.400, reward_bound=0.324, batch=225\n",
      "17532: loss=0.056, reward_mean=0.400, reward_bound=0.349, batch=226\n",
      "17533: loss=0.056, reward_mean=0.400, reward_bound=0.387, batch=225\n",
      "17534: loss=0.057, reward_mean=0.520, reward_bound=0.430, batch=202\n",
      "17535: loss=0.061, reward_mean=0.400, reward_bound=0.213, batch=211\n",
      "17536: loss=0.060, reward_mean=0.400, reward_bound=0.229, batch=211\n",
      "17537: loss=0.056, reward_mean=0.420, reward_bound=0.254, batch=217\n",
      "17538: loss=0.055, reward_mean=0.390, reward_bound=0.277, batch=222\n",
      "17539: loss=0.056, reward_mean=0.500, reward_bound=0.282, batch=224\n",
      "17540: loss=0.055, reward_mean=0.430, reward_bound=0.229, batch=226\n",
      "17541: loss=0.054, reward_mean=0.460, reward_bound=0.314, batch=221\n",
      "17542: loss=0.053, reward_mean=0.460, reward_bound=0.349, batch=218\n",
      "17543: loss=0.052, reward_mean=0.410, reward_bound=0.260, batch=222\n",
      "17544: loss=0.054, reward_mean=0.470, reward_bound=0.349, batch=224\n",
      "17545: loss=0.053, reward_mean=0.380, reward_bound=0.380, batch=227\n",
      "17546: loss=0.053, reward_mean=0.460, reward_bound=0.387, batch=219\n",
      "17547: loss=0.053, reward_mean=0.400, reward_bound=0.282, batch=222\n",
      "17548: loss=0.052, reward_mean=0.410, reward_bound=0.349, batch=224\n",
      "17549: loss=0.053, reward_mean=0.410, reward_bound=0.345, batch=227\n",
      "17550: loss=0.052, reward_mean=0.490, reward_bound=0.387, batch=227\n",
      "17551: loss=0.053, reward_mean=0.480, reward_bound=0.387, batch=228\n",
      "17552: loss=0.056, reward_mean=0.500, reward_bound=0.430, batch=219\n",
      "17553: loss=0.055, reward_mean=0.450, reward_bound=0.430, batch=220\n",
      "17554: loss=0.055, reward_mean=0.520, reward_bound=0.338, batch=224\n",
      "17555: loss=0.054, reward_mean=0.440, reward_bound=0.345, batch=227\n",
      "17556: loss=0.055, reward_mean=0.420, reward_bound=0.349, batch=228\n",
      "17557: loss=0.054, reward_mean=0.440, reward_bound=0.387, batch=228\n",
      "17558: loss=0.054, reward_mean=0.440, reward_bound=0.430, batch=226\n",
      "17559: loss=0.054, reward_mean=0.340, reward_bound=0.387, batch=227\n",
      "17560: loss=0.054, reward_mean=0.440, reward_bound=0.282, batch=228\n",
      "17561: loss=0.053, reward_mean=0.380, reward_bound=0.286, batch=229\n",
      "17562: loss=0.053, reward_mean=0.430, reward_bound=0.405, batch=230\n",
      "17563: loss=0.055, reward_mean=0.430, reward_bound=0.430, batch=230\n",
      "17564: loss=0.058, reward_mean=0.440, reward_bound=0.478, batch=199\n",
      "17565: loss=0.058, reward_mean=0.460, reward_bound=0.215, batch=209\n",
      "17566: loss=0.058, reward_mean=0.520, reward_bound=0.229, batch=214\n",
      "17567: loss=0.056, reward_mean=0.380, reward_bound=0.254, batch=216\n",
      "17568: loss=0.058, reward_mean=0.470, reward_bound=0.282, batch=220\n",
      "17569: loss=0.057, reward_mean=0.460, reward_bound=0.314, batch=220\n",
      "17570: loss=0.058, reward_mean=0.420, reward_bound=0.349, batch=219\n",
      "17571: loss=0.057, reward_mean=0.440, reward_bound=0.349, batch=222\n",
      "17572: loss=0.057, reward_mean=0.530, reward_bound=0.387, batch=213\n",
      "17573: loss=0.058, reward_mean=0.410, reward_bound=0.271, batch=219\n",
      "17574: loss=0.058, reward_mean=0.480, reward_bound=0.314, batch=221\n",
      "17575: loss=0.058, reward_mean=0.540, reward_bound=0.349, batch=223\n",
      "17576: loss=0.058, reward_mean=0.350, reward_bound=0.322, batch=226\n",
      "17577: loss=0.058, reward_mean=0.400, reward_bound=0.331, batch=228\n",
      "17578: loss=0.058, reward_mean=0.380, reward_bound=0.353, batch=229\n",
      "17579: loss=0.056, reward_mean=0.400, reward_bound=0.387, batch=224\n",
      "17580: loss=0.056, reward_mean=0.410, reward_bound=0.349, batch=226\n",
      "17581: loss=0.056, reward_mean=0.440, reward_bound=0.430, batch=215\n",
      "17582: loss=0.063, reward_mean=0.450, reward_bound=0.240, batch=220\n",
      "17583: loss=0.061, reward_mean=0.460, reward_bound=0.349, batch=223\n",
      "17584: loss=0.059, reward_mean=0.470, reward_bound=0.387, batch=221\n",
      "17585: loss=0.058, reward_mean=0.490, reward_bound=0.314, batch=224\n",
      "17586: loss=0.058, reward_mean=0.490, reward_bound=0.349, batch=225\n",
      "17587: loss=0.058, reward_mean=0.430, reward_bound=0.387, batch=224\n",
      "17588: loss=0.057, reward_mean=0.540, reward_bound=0.314, batch=226\n",
      "17589: loss=0.057, reward_mean=0.500, reward_bound=0.368, batch=228\n",
      "17590: loss=0.057, reward_mean=0.400, reward_bound=0.353, batch=229\n",
      "17591: loss=0.057, reward_mean=0.420, reward_bound=0.387, batch=228\n",
      "17592: loss=0.055, reward_mean=0.520, reward_bound=0.430, batch=220\n",
      "17593: loss=0.056, reward_mean=0.410, reward_bound=0.376, batch=224\n",
      "17594: loss=0.057, reward_mean=0.470, reward_bound=0.384, batch=227\n",
      "17595: loss=0.056, reward_mean=0.400, reward_bound=0.387, batch=225\n",
      "17596: loss=0.056, reward_mean=0.410, reward_bound=0.396, batch=227\n",
      "17597: loss=0.057, reward_mean=0.380, reward_bound=0.342, batch=229\n",
      "17598: loss=0.055, reward_mean=0.430, reward_bound=0.349, batch=229\n",
      "17599: loss=0.055, reward_mean=0.490, reward_bound=0.430, batch=224\n",
      "17600: loss=0.056, reward_mean=0.410, reward_bound=0.314, batch=226\n",
      "17601: loss=0.056, reward_mean=0.470, reward_bound=0.349, batch=227\n",
      "17602: loss=0.055, reward_mean=0.430, reward_bound=0.422, batch=229\n",
      "17603: loss=0.055, reward_mean=0.410, reward_bound=0.450, batch=230\n",
      "17604: loss=0.055, reward_mean=0.530, reward_bound=0.387, batch=230\n",
      "17605: loss=0.055, reward_mean=0.470, reward_bound=0.464, batch=231\n",
      "17606: loss=0.056, reward_mean=0.490, reward_bound=0.478, batch=212\n",
      "17607: loss=0.056, reward_mean=0.420, reward_bound=0.324, batch=218\n",
      "17608: loss=0.054, reward_mean=0.510, reward_bound=0.349, batch=220\n",
      "17609: loss=0.054, reward_mean=0.440, reward_bound=0.338, batch=224\n",
      "17610: loss=0.056, reward_mean=0.440, reward_bound=0.349, batch=225\n",
      "17611: loss=0.055, reward_mean=0.380, reward_bound=0.356, batch=227\n",
      "17612: loss=0.055, reward_mean=0.420, reward_bound=0.387, batch=221\n",
      "17613: loss=0.055, reward_mean=0.430, reward_bound=0.387, batch=223\n",
      "17614: loss=0.057, reward_mean=0.480, reward_bound=0.430, batch=222\n",
      "17615: loss=0.056, reward_mean=0.450, reward_bound=0.360, batch=225\n",
      "17616: loss=0.056, reward_mean=0.400, reward_bound=0.387, batch=225\n",
      "17617: loss=0.056, reward_mean=0.580, reward_bound=0.396, batch=227\n",
      "17618: loss=0.056, reward_mean=0.440, reward_bound=0.430, batch=227\n",
      "17619: loss=0.056, reward_mean=0.460, reward_bound=0.460, batch=229\n",
      "17620: loss=0.055, reward_mean=0.470, reward_bound=0.450, batch=230\n",
      "17621: loss=0.055, reward_mean=0.490, reward_bound=0.430, batch=230\n",
      "17622: loss=0.055, reward_mean=0.460, reward_bound=0.376, batch=231\n",
      "17623: loss=0.055, reward_mean=0.430, reward_bound=0.478, batch=223\n",
      "17624: loss=0.055, reward_mean=0.410, reward_bound=0.349, batch=225\n",
      "17625: loss=0.054, reward_mean=0.440, reward_bound=0.356, batch=227\n",
      "17626: loss=0.054, reward_mean=0.350, reward_bound=0.342, batch=229\n",
      "17627: loss=0.054, reward_mean=0.410, reward_bound=0.314, batch=229\n",
      "17628: loss=0.055, reward_mean=0.420, reward_bound=0.349, batch=229\n",
      "17629: loss=0.056, reward_mean=0.380, reward_bound=0.387, batch=229\n",
      "17630: loss=0.054, reward_mean=0.440, reward_bound=0.430, batch=229\n",
      "17631: loss=0.054, reward_mean=0.490, reward_bound=0.478, batch=231\n",
      "17632: loss=0.055, reward_mean=0.420, reward_bound=0.478, batch=227\n",
      "17633: loss=0.055, reward_mean=0.490, reward_bound=0.387, batch=228\n",
      "17634: loss=0.056, reward_mean=0.400, reward_bound=0.435, batch=229\n",
      "17635: loss=0.056, reward_mean=0.340, reward_bound=0.430, batch=229\n",
      "17636: loss=0.056, reward_mean=0.550, reward_bound=0.405, batch=230\n",
      "17637: loss=0.054, reward_mean=0.450, reward_bound=0.478, batch=229\n",
      "17638: loss=0.054, reward_mean=0.490, reward_bound=0.364, batch=230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17639: loss=0.054, reward_mean=0.450, reward_bound=0.387, batch=229\n",
      "17640: loss=0.054, reward_mean=0.420, reward_bound=0.500, batch=230\n",
      "17641: loss=0.054, reward_mean=0.570, reward_bound=0.376, batch=231\n",
      "17642: loss=0.054, reward_mean=0.520, reward_bound=0.478, batch=231\n",
      "17643: loss=0.054, reward_mean=0.370, reward_bound=0.478, batch=231\n",
      "17644: loss=0.054, reward_mean=0.480, reward_bound=0.478, batch=231\n",
      "17646: loss=0.040, reward_mean=0.460, reward_bound=0.000, batch=46\n",
      "17647: loss=0.037, reward_mean=0.520, reward_bound=0.000, batch=98\n",
      "17648: loss=0.043, reward_mean=0.490, reward_bound=0.001, batch=138\n",
      "17649: loss=0.049, reward_mean=0.510, reward_bound=0.006, batch=166\n",
      "17650: loss=0.050, reward_mean=0.420, reward_bound=0.015, batch=182\n",
      "17651: loss=0.049, reward_mean=0.530, reward_bound=0.029, batch=197\n",
      "17652: loss=0.054, reward_mean=0.480, reward_bound=0.047, batch=204\n",
      "17653: loss=0.052, reward_mean=0.480, reward_bound=0.065, batch=211\n",
      "17654: loss=0.051, reward_mean=0.390, reward_bound=0.080, batch=209\n",
      "17655: loss=0.053, reward_mean=0.550, reward_bound=0.098, batch=208\n",
      "17656: loss=0.053, reward_mean=0.380, reward_bound=0.109, batch=206\n",
      "17657: loss=0.052, reward_mean=0.410, reward_bound=0.122, batch=208\n",
      "17658: loss=0.048, reward_mean=0.460, reward_bound=0.135, batch=212\n",
      "17659: loss=0.050, reward_mean=0.330, reward_bound=0.150, batch=201\n",
      "17660: loss=0.046, reward_mean=0.370, reward_bound=0.167, batch=189\n",
      "17661: loss=0.046, reward_mean=0.430, reward_bound=0.114, batch=202\n",
      "17662: loss=0.049, reward_mean=0.390, reward_bound=0.150, batch=209\n",
      "17663: loss=0.046, reward_mean=0.510, reward_bound=0.167, batch=213\n",
      "17664: loss=0.049, reward_mean=0.490, reward_bound=0.185, batch=196\n",
      "17665: loss=0.049, reward_mean=0.470, reward_bound=0.206, batch=175\n",
      "17666: loss=0.049, reward_mean=0.460, reward_bound=0.150, batch=191\n",
      "17667: loss=0.047, reward_mean=0.510, reward_bound=0.167, batch=202\n",
      "17668: loss=0.048, reward_mean=0.520, reward_bound=0.185, batch=205\n",
      "17669: loss=0.039, reward_mean=0.500, reward_bound=0.229, batch=178\n",
      "17670: loss=0.038, reward_mean=0.490, reward_bound=0.169, batch=194\n",
      "17671: loss=0.037, reward_mean=0.410, reward_bound=0.122, batch=205\n",
      "17672: loss=0.038, reward_mean=0.390, reward_bound=0.185, batch=210\n",
      "17673: loss=0.036, reward_mean=0.410, reward_bound=0.206, batch=221\n",
      "17674: loss=0.040, reward_mean=0.340, reward_bound=0.229, batch=219\n",
      "17675: loss=0.038, reward_mean=0.480, reward_bound=0.254, batch=188\n",
      "17676: loss=0.038, reward_mean=0.430, reward_bound=0.282, batch=160\n",
      "17677: loss=0.040, reward_mean=0.380, reward_bound=0.052, batch=180\n",
      "17678: loss=0.035, reward_mean=0.510, reward_bound=0.098, batch=194\n",
      "17679: loss=0.032, reward_mean=0.480, reward_bound=0.135, batch=202\n",
      "17680: loss=0.033, reward_mean=0.430, reward_bound=0.172, batch=211\n",
      "17681: loss=0.033, reward_mean=0.400, reward_bound=0.185, batch=211\n",
      "17682: loss=0.031, reward_mean=0.520, reward_bound=0.206, batch=209\n",
      "17683: loss=0.030, reward_mean=0.320, reward_bound=0.215, batch=216\n",
      "17684: loss=0.031, reward_mean=0.430, reward_bound=0.229, batch=206\n",
      "17685: loss=0.031, reward_mean=0.440, reward_bound=0.241, batch=214\n",
      "17686: loss=0.032, reward_mean=0.500, reward_bound=0.254, batch=210\n",
      "17687: loss=0.032, reward_mean=0.360, reward_bound=0.180, batch=217\n",
      "17688: loss=0.031, reward_mean=0.440, reward_bound=0.254, batch=217\n",
      "17689: loss=0.033, reward_mean=0.460, reward_bound=0.282, batch=209\n",
      "17690: loss=0.025, reward_mean=0.420, reward_bound=0.314, batch=168\n",
      "17691: loss=0.026, reward_mean=0.460, reward_bound=0.138, batch=187\n",
      "17692: loss=0.029, reward_mean=0.540, reward_bound=0.167, batch=198\n",
      "17693: loss=0.030, reward_mean=0.470, reward_bound=0.185, batch=204\n",
      "17694: loss=0.029, reward_mean=0.420, reward_bound=0.206, batch=209\n",
      "17695: loss=0.027, reward_mean=0.480, reward_bound=0.229, batch=214\n",
      "17696: loss=0.026, reward_mean=0.550, reward_bound=0.252, batch=220\n",
      "17697: loss=0.026, reward_mean=0.550, reward_bound=0.254, batch=212\n",
      "17698: loss=0.025, reward_mean=0.340, reward_bound=0.213, batch=218\n",
      "17699: loss=0.025, reward_mean=0.410, reward_bound=0.229, batch=220\n",
      "17700: loss=0.025, reward_mean=0.420, reward_bound=0.206, batch=225\n",
      "17701: loss=0.024, reward_mean=0.350, reward_bound=0.210, batch=227\n",
      "17702: loss=0.029, reward_mean=0.380, reward_bound=0.282, batch=218\n",
      "17703: loss=0.029, reward_mean=0.450, reward_bound=0.169, batch=222\n",
      "17704: loss=0.029, reward_mean=0.420, reward_bound=0.314, batch=209\n",
      "17705: loss=0.030, reward_mean=0.460, reward_bound=0.295, batch=216\n",
      "17706: loss=0.031, reward_mean=0.500, reward_bound=0.298, batch=221\n",
      "17707: loss=0.031, reward_mean=0.390, reward_bound=0.314, batch=223\n",
      "17708: loss=0.032, reward_mean=0.410, reward_bound=0.349, batch=167\n",
      "17709: loss=0.032, reward_mean=0.430, reward_bound=0.072, batch=185\n",
      "17710: loss=0.031, reward_mean=0.430, reward_bound=0.098, batch=198\n",
      "17711: loss=0.036, reward_mean=0.430, reward_bound=0.135, batch=203\n",
      "17712: loss=0.035, reward_mean=0.450, reward_bound=0.150, batch=211\n",
      "17713: loss=0.035, reward_mean=0.420, reward_bound=0.206, batch=213\n",
      "17714: loss=0.036, reward_mean=0.330, reward_bound=0.220, batch=219\n",
      "17715: loss=0.035, reward_mean=0.360, reward_bound=0.203, batch=223\n",
      "17716: loss=0.038, reward_mean=0.520, reward_bound=0.254, batch=221\n",
      "17717: loss=0.036, reward_mean=0.350, reward_bound=0.282, batch=214\n",
      "17718: loss=0.037, reward_mean=0.430, reward_bound=0.311, batch=220\n",
      "17719: loss=0.037, reward_mean=0.390, reward_bound=0.282, batch=223\n",
      "17720: loss=0.033, reward_mean=0.490, reward_bound=0.314, batch=216\n",
      "17721: loss=0.034, reward_mean=0.460, reward_bound=0.268, batch=221\n",
      "17722: loss=0.037, reward_mean=0.370, reward_bound=0.282, batch=222\n",
      "17723: loss=0.039, reward_mean=0.460, reward_bound=0.349, batch=215\n",
      "17724: loss=0.038, reward_mean=0.390, reward_bound=0.254, batch=219\n",
      "17725: loss=0.038, reward_mean=0.450, reward_bound=0.282, batch=222\n",
      "17726: loss=0.039, reward_mean=0.440, reward_bound=0.349, batch=224\n",
      "17727: loss=0.042, reward_mean=0.470, reward_bound=0.387, batch=148\n",
      "17728: loss=0.039, reward_mean=0.480, reward_bound=0.135, batch=172\n",
      "17729: loss=0.040, reward_mean=0.450, reward_bound=0.113, batch=190\n",
      "17730: loss=0.041, reward_mean=0.520, reward_bound=0.122, batch=202\n",
      "17731: loss=0.040, reward_mean=0.390, reward_bound=0.135, batch=207\n",
      "17732: loss=0.037, reward_mean=0.420, reward_bound=0.185, batch=212\n",
      "17733: loss=0.036, reward_mean=0.490, reward_bound=0.229, batch=207\n",
      "17734: loss=0.036, reward_mean=0.490, reward_bound=0.167, batch=214\n",
      "17735: loss=0.036, reward_mean=0.430, reward_bound=0.252, batch=220\n",
      "17736: loss=0.037, reward_mean=0.510, reward_bound=0.254, batch=213\n",
      "17737: loss=0.036, reward_mean=0.520, reward_bound=0.282, batch=211\n",
      "17738: loss=0.037, reward_mean=0.450, reward_bound=0.229, batch=215\n",
      "17739: loss=0.035, reward_mean=0.460, reward_bound=0.282, batch=218\n",
      "17740: loss=0.036, reward_mean=0.550, reward_bound=0.314, batch=206\n",
      "17741: loss=0.035, reward_mean=0.490, reward_bound=0.254, batch=213\n",
      "17742: loss=0.034, reward_mean=0.420, reward_bound=0.282, batch=217\n",
      "17743: loss=0.036, reward_mean=0.400, reward_bound=0.314, batch=218\n",
      "17744: loss=0.035, reward_mean=0.400, reward_bound=0.234, batch=222\n",
      "17745: loss=0.037, reward_mean=0.450, reward_bound=0.349, batch=204\n",
      "17746: loss=0.036, reward_mean=0.490, reward_bound=0.254, batch=211\n",
      "17747: loss=0.034, reward_mean=0.450, reward_bound=0.229, batch=217\n",
      "17748: loss=0.034, reward_mean=0.330, reward_bound=0.229, batch=221\n",
      "17749: loss=0.034, reward_mean=0.360, reward_bound=0.254, batch=224\n",
      "17750: loss=0.036, reward_mean=0.420, reward_bound=0.282, batch=224\n",
      "17751: loss=0.034, reward_mean=0.330, reward_bound=0.314, batch=225\n",
      "17752: loss=0.035, reward_mean=0.460, reward_bound=0.349, batch=220\n",
      "17753: loss=0.034, reward_mean=0.590, reward_bound=0.376, batch=224\n",
      "17754: loss=0.034, reward_mean=0.400, reward_bound=0.311, batch=227\n",
      "17755: loss=0.033, reward_mean=0.480, reward_bound=0.308, batch=229\n",
      "17756: loss=0.038, reward_mean=0.430, reward_bound=0.387, batch=199\n",
      "17757: loss=0.038, reward_mean=0.420, reward_bound=0.185, batch=208\n",
      "17758: loss=0.038, reward_mean=0.400, reward_bound=0.206, batch=211\n",
      "17759: loss=0.037, reward_mean=0.440, reward_bound=0.282, batch=214\n",
      "17760: loss=0.036, reward_mean=0.450, reward_bound=0.252, batch=220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17761: loss=0.034, reward_mean=0.510, reward_bound=0.314, batch=223\n",
      "17762: loss=0.038, reward_mean=0.460, reward_bound=0.349, batch=220\n",
      "17763: loss=0.040, reward_mean=0.560, reward_bound=0.338, batch=224\n",
      "17764: loss=0.038, reward_mean=0.500, reward_bound=0.387, batch=216\n",
      "17765: loss=0.037, reward_mean=0.480, reward_bound=0.331, batch=221\n",
      "17766: loss=0.037, reward_mean=0.450, reward_bound=0.349, batch=222\n",
      "17767: loss=0.036, reward_mean=0.450, reward_bound=0.373, batch=225\n",
      "17768: loss=0.036, reward_mean=0.520, reward_bound=0.387, batch=226\n",
      "17769: loss=0.029, reward_mean=0.480, reward_bound=0.430, batch=138\n",
      "17770: loss=0.028, reward_mean=0.440, reward_bound=0.053, batch=166\n",
      "17771: loss=0.027, reward_mean=0.550, reward_bound=0.089, batch=184\n",
      "17772: loss=0.022, reward_mean=0.520, reward_bound=0.122, batch=196\n",
      "17773: loss=0.030, reward_mean=0.390, reward_bound=0.143, batch=207\n",
      "17774: loss=0.028, reward_mean=0.400, reward_bound=0.150, batch=214\n",
      "17775: loss=0.027, reward_mean=0.460, reward_bound=0.185, batch=214\n",
      "17776: loss=0.028, reward_mean=0.430, reward_bound=0.206, batch=205\n",
      "17777: loss=0.027, reward_mean=0.460, reward_bound=0.229, batch=203\n",
      "17778: loss=0.028, reward_mean=0.440, reward_bound=0.229, batch=211\n",
      "17779: loss=0.029, reward_mean=0.450, reward_bound=0.254, batch=207\n",
      "17780: loss=0.029, reward_mean=0.500, reward_bound=0.163, batch=215\n",
      "17781: loss=0.028, reward_mean=0.490, reward_bound=0.254, batch=217\n",
      "17782: loss=0.027, reward_mean=0.400, reward_bound=0.282, batch=198\n",
      "17783: loss=0.025, reward_mean=0.420, reward_bound=0.185, batch=206\n",
      "17784: loss=0.024, reward_mean=0.400, reward_bound=0.217, batch=214\n",
      "17785: loss=0.026, reward_mean=0.440, reward_bound=0.229, batch=219\n",
      "17786: loss=0.026, reward_mean=0.490, reward_bound=0.282, batch=217\n",
      "17787: loss=0.023, reward_mean=0.570, reward_bound=0.314, batch=209\n",
      "17788: loss=0.023, reward_mean=0.460, reward_bound=0.265, batch=216\n",
      "17789: loss=0.023, reward_mean=0.540, reward_bound=0.282, batch=218\n",
      "17790: loss=0.023, reward_mean=0.460, reward_bound=0.314, batch=217\n",
      "17791: loss=0.026, reward_mean=0.440, reward_bound=0.349, batch=192\n",
      "17792: loss=0.026, reward_mean=0.430, reward_bound=0.172, batch=204\n",
      "17793: loss=0.024, reward_mean=0.350, reward_bound=0.183, batch=213\n",
      "17794: loss=0.027, reward_mean=0.360, reward_bound=0.206, batch=213\n",
      "17795: loss=0.027, reward_mean=0.350, reward_bound=0.229, batch=216\n",
      "17796: loss=0.027, reward_mean=0.360, reward_bound=0.254, batch=216\n",
      "17797: loss=0.027, reward_mean=0.410, reward_bound=0.254, batch=220\n",
      "17798: loss=0.029, reward_mean=0.510, reward_bound=0.282, batch=219\n",
      "17799: loss=0.025, reward_mean=0.430, reward_bound=0.314, batch=220\n",
      "17800: loss=0.023, reward_mean=0.520, reward_bound=0.349, batch=218\n",
      "17801: loss=0.024, reward_mean=0.450, reward_bound=0.387, batch=196\n",
      "17802: loss=0.022, reward_mean=0.430, reward_bound=0.150, batch=206\n",
      "17803: loss=0.024, reward_mean=0.500, reward_bound=0.206, batch=209\n",
      "17804: loss=0.023, reward_mean=0.370, reward_bound=0.229, batch=215\n",
      "17805: loss=0.023, reward_mean=0.470, reward_bound=0.260, batch=220\n",
      "17806: loss=0.024, reward_mean=0.450, reward_bound=0.282, batch=218\n",
      "17807: loss=0.025, reward_mean=0.430, reward_bound=0.257, batch=222\n",
      "17808: loss=0.025, reward_mean=0.340, reward_bound=0.263, batch=225\n",
      "17809: loss=0.023, reward_mean=0.490, reward_bound=0.314, batch=222\n",
      "17810: loss=0.024, reward_mean=0.470, reward_bound=0.349, batch=217\n",
      "17811: loss=0.026, reward_mean=0.410, reward_bound=0.282, batch=221\n",
      "17812: loss=0.025, reward_mean=0.340, reward_bound=0.282, batch=224\n",
      "17813: loss=0.023, reward_mean=0.430, reward_bound=0.345, batch=227\n",
      "17814: loss=0.023, reward_mean=0.480, reward_bound=0.349, batch=225\n",
      "17815: loss=0.023, reward_mean=0.510, reward_bound=0.356, batch=227\n",
      "17816: loss=0.024, reward_mean=0.520, reward_bound=0.387, batch=219\n",
      "17817: loss=0.023, reward_mean=0.380, reward_bound=0.265, batch=223\n",
      "17818: loss=0.026, reward_mean=0.450, reward_bound=0.349, batch=225\n",
      "17819: loss=0.025, reward_mean=0.370, reward_bound=0.329, batch=227\n",
      "17820: loss=0.025, reward_mean=0.450, reward_bound=0.342, batch=229\n",
      "17821: loss=0.025, reward_mean=0.390, reward_bound=0.349, batch=229\n",
      "17822: loss=0.023, reward_mean=0.480, reward_bound=0.405, batch=230\n",
      "17823: loss=0.025, reward_mean=0.440, reward_bound=0.430, batch=190\n",
      "17824: loss=0.023, reward_mean=0.380, reward_bound=0.122, batch=202\n",
      "17825: loss=0.022, reward_mean=0.410, reward_bound=0.167, batch=210\n",
      "17826: loss=0.026, reward_mean=0.450, reward_bound=0.222, batch=217\n",
      "17827: loss=0.026, reward_mean=0.380, reward_bound=0.229, batch=218\n",
      "17828: loss=0.023, reward_mean=0.530, reward_bound=0.254, batch=220\n",
      "17829: loss=0.023, reward_mean=0.420, reward_bound=0.282, batch=222\n",
      "17830: loss=0.023, reward_mean=0.450, reward_bound=0.292, batch=225\n",
      "17831: loss=0.021, reward_mean=0.460, reward_bound=0.314, batch=222\n",
      "17832: loss=0.022, reward_mean=0.420, reward_bound=0.349, batch=219\n",
      "17833: loss=0.022, reward_mean=0.450, reward_bound=0.387, batch=211\n",
      "17834: loss=0.024, reward_mean=0.520, reward_bound=0.282, batch=216\n",
      "17835: loss=0.024, reward_mean=0.480, reward_bound=0.301, batch=221\n",
      "17836: loss=0.023, reward_mean=0.420, reward_bound=0.282, batch=224\n",
      "17837: loss=0.021, reward_mean=0.460, reward_bound=0.349, batch=222\n",
      "17838: loss=0.024, reward_mean=0.480, reward_bound=0.387, batch=222\n",
      "17839: loss=0.024, reward_mean=0.440, reward_bound=0.400, batch=225\n",
      "17840: loss=0.024, reward_mean=0.390, reward_bound=0.387, batch=226\n",
      "17841: loss=0.023, reward_mean=0.490, reward_bound=0.390, batch=228\n",
      "17842: loss=0.023, reward_mean=0.480, reward_bound=0.392, batch=229\n",
      "17843: loss=0.025, reward_mean=0.400, reward_bound=0.430, batch=214\n",
      "17844: loss=0.024, reward_mean=0.560, reward_bound=0.280, batch=220\n",
      "17845: loss=0.024, reward_mean=0.440, reward_bound=0.282, batch=222\n",
      "17846: loss=0.024, reward_mean=0.530, reward_bound=0.314, batch=224\n",
      "17847: loss=0.024, reward_mean=0.480, reward_bound=0.345, batch=227\n",
      "17848: loss=0.024, reward_mean=0.390, reward_bound=0.349, batch=226\n",
      "17849: loss=0.024, reward_mean=0.530, reward_bound=0.387, batch=226\n",
      "17850: loss=0.024, reward_mean=0.370, reward_bound=0.430, batch=222\n",
      "17851: loss=0.024, reward_mean=0.430, reward_bound=0.302, batch=225\n",
      "17852: loss=0.026, reward_mean=0.410, reward_bound=0.396, batch=227\n",
      "17853: loss=0.026, reward_mean=0.370, reward_bound=0.342, batch=229\n",
      "17854: loss=0.024, reward_mean=0.430, reward_bound=0.430, batch=227\n",
      "17855: loss=0.024, reward_mean=0.450, reward_bound=0.335, batch=229\n",
      "17856: loss=0.024, reward_mean=0.400, reward_bound=0.450, batch=230\n",
      "17857: loss=0.023, reward_mean=0.380, reward_bound=0.406, batch=231\n",
      "17858: loss=0.023, reward_mean=0.430, reward_bound=0.349, batch=231\n",
      "17859: loss=0.023, reward_mean=0.480, reward_bound=0.430, batch=231\n",
      "17860: loss=0.031, reward_mean=0.440, reward_bound=0.478, batch=88\n",
      "17861: loss=0.022, reward_mean=0.440, reward_bound=0.000, batch=131\n",
      "17862: loss=0.020, reward_mean=0.500, reward_bound=0.015, batch=161\n",
      "17863: loss=0.016, reward_mean=0.430, reward_bound=0.034, batch=182\n",
      "17864: loss=0.017, reward_mean=0.370, reward_bound=0.052, batch=194\n",
      "17865: loss=0.016, reward_mean=0.440, reward_bound=0.072, batch=203\n",
      "17866: loss=0.016, reward_mean=0.400, reward_bound=0.089, batch=208\n",
      "17867: loss=0.017, reward_mean=0.420, reward_bound=0.135, batch=206\n",
      "17868: loss=0.020, reward_mean=0.430, reward_bound=0.167, batch=203\n",
      "17869: loss=0.019, reward_mean=0.430, reward_bound=0.185, batch=195\n",
      "17870: loss=0.018, reward_mean=0.480, reward_bound=0.206, batch=191\n",
      "17871: loss=0.017, reward_mean=0.350, reward_bound=0.206, batch=200\n",
      "17872: loss=0.016, reward_mean=0.400, reward_bound=0.175, batch=210\n",
      "17873: loss=0.016, reward_mean=0.430, reward_bound=0.222, batch=217\n",
      "17874: loss=0.017, reward_mean=0.420, reward_bound=0.229, batch=206\n",
      "17875: loss=0.017, reward_mean=0.530, reward_bound=0.206, batch=212\n",
      "17876: loss=0.016, reward_mean=0.360, reward_bound=0.229, batch=217\n",
      "17877: loss=0.020, reward_mean=0.460, reward_bound=0.254, batch=207\n",
      "17878: loss=0.019, reward_mean=0.400, reward_bound=0.185, batch=213\n",
      "17879: loss=0.019, reward_mean=0.430, reward_bound=0.282, batch=195\n",
      "17880: loss=0.018, reward_mean=0.450, reward_bound=0.167, batch=205\n",
      "17881: loss=0.018, reward_mean=0.370, reward_bound=0.229, batch=209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17882: loss=0.019, reward_mean=0.500, reward_bound=0.215, batch=216\n",
      "17883: loss=0.019, reward_mean=0.390, reward_bound=0.229, batch=220\n",
      "17884: loss=0.019, reward_mean=0.380, reward_bound=0.229, batch=223\n",
      "17885: loss=0.017, reward_mean=0.500, reward_bound=0.254, batch=221\n",
      "17886: loss=0.017, reward_mean=0.420, reward_bound=0.282, batch=222\n",
      "17887: loss=0.020, reward_mean=0.500, reward_bound=0.314, batch=192\n",
      "17888: loss=0.019, reward_mean=0.430, reward_bound=0.254, batch=202\n",
      "17889: loss=0.020, reward_mean=0.430, reward_bound=0.229, batch=210\n",
      "17890: loss=0.020, reward_mean=0.430, reward_bound=0.229, batch=215\n",
      "17891: loss=0.019, reward_mean=0.490, reward_bound=0.260, batch=220\n",
      "17892: loss=0.019, reward_mean=0.490, reward_bound=0.282, batch=221\n",
      "17893: loss=0.020, reward_mean=0.450, reward_bound=0.314, batch=218\n",
      "17894: loss=0.024, reward_mean=0.570, reward_bound=0.349, batch=185\n",
      "17895: loss=0.021, reward_mean=0.380, reward_bound=0.109, batch=200\n",
      "17896: loss=0.023, reward_mean=0.470, reward_bound=0.200, batch=210\n",
      "17897: loss=0.025, reward_mean=0.400, reward_bound=0.254, batch=215\n",
      "17898: loss=0.025, reward_mean=0.380, reward_bound=0.282, batch=219\n",
      "17899: loss=0.024, reward_mean=0.440, reward_bound=0.278, batch=223\n",
      "17900: loss=0.025, reward_mean=0.450, reward_bound=0.314, batch=221\n",
      "17901: loss=0.026, reward_mean=0.510, reward_bound=0.349, batch=214\n",
      "17902: loss=0.025, reward_mean=0.420, reward_bound=0.204, batch=220\n",
      "17903: loss=0.026, reward_mean=0.430, reward_bound=0.304, batch=224\n",
      "17904: loss=0.029, reward_mean=0.440, reward_bound=0.314, batch=224\n",
      "17905: loss=0.026, reward_mean=0.500, reward_bound=0.384, batch=227\n",
      "17906: loss=0.025, reward_mean=0.440, reward_bound=0.387, batch=181\n",
      "17907: loss=0.023, reward_mean=0.530, reward_bound=0.185, batch=196\n",
      "17908: loss=0.024, reward_mean=0.460, reward_bound=0.158, batch=207\n",
      "17909: loss=0.023, reward_mean=0.460, reward_bound=0.206, batch=214\n",
      "17910: loss=0.024, reward_mean=0.440, reward_bound=0.229, batch=213\n",
      "17911: loss=0.022, reward_mean=0.460, reward_bound=0.282, batch=213\n",
      "17912: loss=0.026, reward_mean=0.410, reward_bound=0.185, batch=218\n",
      "17913: loss=0.025, reward_mean=0.350, reward_bound=0.286, batch=222\n",
      "17914: loss=0.025, reward_mean=0.410, reward_bound=0.213, batch=225\n",
      "17915: loss=0.027, reward_mean=0.470, reward_bound=0.314, batch=225\n",
      "17916: loss=0.028, reward_mean=0.440, reward_bound=0.349, batch=224\n",
      "17917: loss=0.027, reward_mean=0.420, reward_bound=0.384, batch=227\n",
      "17918: loss=0.027, reward_mean=0.450, reward_bound=0.380, batch=229\n",
      "17919: loss=0.027, reward_mean=0.420, reward_bound=0.292, batch=230\n",
      "17920: loss=0.023, reward_mean=0.570, reward_bound=0.387, batch=208\n",
      "17921: loss=0.022, reward_mean=0.390, reward_bound=0.282, batch=213\n",
      "17922: loss=0.021, reward_mean=0.470, reward_bound=0.290, batch=219\n",
      "17923: loss=0.021, reward_mean=0.330, reward_bound=0.265, batch=223\n",
      "17924: loss=0.021, reward_mean=0.420, reward_bound=0.314, batch=224\n",
      "17925: loss=0.021, reward_mean=0.440, reward_bound=0.349, batch=224\n",
      "17926: loss=0.021, reward_mean=0.360, reward_bound=0.342, batch=227\n",
      "17927: loss=0.021, reward_mean=0.430, reward_bound=0.349, batch=227\n",
      "17928: loss=0.021, reward_mean=0.390, reward_bound=0.387, batch=221\n",
      "17929: loss=0.021, reward_mean=0.420, reward_bound=0.387, batch=223\n",
      "17930: loss=0.021, reward_mean=0.470, reward_bound=0.349, batch=225\n",
      "17931: loss=0.027, reward_mean=0.430, reward_bound=0.430, batch=156\n",
      "17932: loss=0.024, reward_mean=0.510, reward_bound=0.089, batch=179\n",
      "17933: loss=0.026, reward_mean=0.400, reward_bound=0.108, batch=195\n",
      "17934: loss=0.021, reward_mean=0.460, reward_bound=0.167, batch=203\n",
      "17935: loss=0.026, reward_mean=0.370, reward_bound=0.185, batch=206\n",
      "17936: loss=0.028, reward_mean=0.380, reward_bound=0.206, batch=209\n",
      "17937: loss=0.024, reward_mean=0.490, reward_bound=0.254, batch=207\n",
      "17938: loss=0.025, reward_mean=0.400, reward_bound=0.282, batch=204\n",
      "17939: loss=0.024, reward_mean=0.470, reward_bound=0.280, batch=213\n",
      "17940: loss=0.023, reward_mean=0.470, reward_bound=0.271, batch=219\n",
      "17941: loss=0.023, reward_mean=0.410, reward_bound=0.239, batch=223\n",
      "17942: loss=0.022, reward_mean=0.460, reward_bound=0.271, batch=226\n",
      "17943: loss=0.022, reward_mean=0.440, reward_bound=0.298, batch=228\n",
      "17944: loss=0.024, reward_mean=0.410, reward_bound=0.314, batch=215\n",
      "17945: loss=0.026, reward_mean=0.480, reward_bound=0.266, batch=220\n",
      "17946: loss=0.025, reward_mean=0.410, reward_bound=0.304, batch=224\n",
      "17947: loss=0.025, reward_mean=0.370, reward_bound=0.254, batch=225\n",
      "17948: loss=0.023, reward_mean=0.500, reward_bound=0.314, batch=224\n",
      "17949: loss=0.023, reward_mean=0.420, reward_bound=0.345, batch=227\n",
      "17950: loss=0.026, reward_mean=0.400, reward_bound=0.349, batch=208\n",
      "17951: loss=0.025, reward_mean=0.360, reward_bound=0.254, batch=213\n",
      "17952: loss=0.024, reward_mean=0.480, reward_bound=0.301, batch=219\n",
      "17953: loss=0.024, reward_mean=0.450, reward_bound=0.314, batch=220\n",
      "17954: loss=0.024, reward_mean=0.490, reward_bound=0.314, batch=223\n",
      "17955: loss=0.024, reward_mean=0.540, reward_bound=0.301, batch=226\n",
      "17956: loss=0.024, reward_mean=0.470, reward_bound=0.349, batch=226\n",
      "17957: loss=0.023, reward_mean=0.510, reward_bound=0.387, batch=209\n",
      "17958: loss=0.022, reward_mean=0.420, reward_bound=0.265, batch=216\n",
      "17959: loss=0.022, reward_mean=0.400, reward_bound=0.268, batch=221\n",
      "17960: loss=0.022, reward_mean=0.370, reward_bound=0.282, batch=224\n",
      "17961: loss=0.024, reward_mean=0.430, reward_bound=0.345, batch=227\n",
      "17962: loss=0.024, reward_mean=0.500, reward_bound=0.349, batch=222\n",
      "17963: loss=0.024, reward_mean=0.480, reward_bound=0.387, batch=223\n",
      "17964: loss=0.024, reward_mean=0.450, reward_bound=0.372, batch=226\n",
      "17965: loss=0.024, reward_mean=0.490, reward_bound=0.351, batch=228\n",
      "17966: loss=0.024, reward_mean=0.420, reward_bound=0.387, batch=228\n",
      "17967: loss=0.025, reward_mean=0.470, reward_bound=0.430, batch=193\n",
      "17968: loss=0.026, reward_mean=0.400, reward_bound=0.178, batch=205\n",
      "17969: loss=0.025, reward_mean=0.400, reward_bound=0.206, batch=210\n",
      "17970: loss=0.027, reward_mean=0.470, reward_bound=0.200, batch=217\n",
      "17971: loss=0.027, reward_mean=0.490, reward_bound=0.254, batch=219\n",
      "17972: loss=0.027, reward_mean=0.470, reward_bound=0.282, batch=221\n",
      "17973: loss=0.026, reward_mean=0.430, reward_bound=0.254, batch=224\n",
      "17974: loss=0.027, reward_mean=0.560, reward_bound=0.314, batch=222\n",
      "17975: loss=0.027, reward_mean=0.530, reward_bound=0.349, batch=220\n",
      "17976: loss=0.027, reward_mean=0.410, reward_bound=0.314, batch=222\n",
      "17977: loss=0.027, reward_mean=0.440, reward_bound=0.349, batch=224\n",
      "17978: loss=0.026, reward_mean=0.450, reward_bound=0.345, batch=227\n",
      "17979: loss=0.026, reward_mean=0.480, reward_bound=0.349, batch=228\n",
      "17980: loss=0.025, reward_mean=0.420, reward_bound=0.387, batch=219\n",
      "17981: loss=0.025, reward_mean=0.460, reward_bound=0.265, batch=223\n",
      "17982: loss=0.029, reward_mean=0.430, reward_bound=0.282, batch=225\n",
      "17983: loss=0.027, reward_mean=0.510, reward_bound=0.349, batch=225\n",
      "17984: loss=0.027, reward_mean=0.410, reward_bound=0.387, batch=225\n",
      "17985: loss=0.026, reward_mean=0.430, reward_bound=0.430, batch=214\n",
      "17986: loss=0.025, reward_mean=0.470, reward_bound=0.384, batch=220\n",
      "17987: loss=0.027, reward_mean=0.420, reward_bound=0.282, batch=222\n",
      "17988: loss=0.025, reward_mean=0.360, reward_bound=0.324, batch=225\n",
      "17989: loss=0.024, reward_mean=0.510, reward_bound=0.349, batch=226\n",
      "17990: loss=0.025, reward_mean=0.390, reward_bound=0.387, batch=222\n",
      "17991: loss=0.025, reward_mean=0.450, reward_bound=0.387, batch=224\n",
      "17992: loss=0.025, reward_mean=0.420, reward_bound=0.314, batch=226\n",
      "17993: loss=0.024, reward_mean=0.440, reward_bound=0.368, batch=228\n",
      "17994: loss=0.025, reward_mean=0.460, reward_bound=0.430, batch=221\n",
      "17995: loss=0.025, reward_mean=0.400, reward_bound=0.387, batch=223\n",
      "17996: loss=0.025, reward_mean=0.530, reward_bound=0.349, batch=225\n",
      "17997: loss=0.025, reward_mean=0.510, reward_bound=0.365, batch=227\n",
      "17998: loss=0.024, reward_mean=0.390, reward_bound=0.422, batch=229\n",
      "17999: loss=0.024, reward_mean=0.430, reward_bound=0.349, batch=229\n",
      "18000: loss=0.025, reward_mean=0.380, reward_bound=0.430, batch=226\n",
      "18001: loss=0.024, reward_mean=0.450, reward_bound=0.478, batch=153\n",
      "18002: loss=0.023, reward_mean=0.500, reward_bound=0.060, batch=177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18003: loss=0.023, reward_mean=0.430, reward_bound=0.087, batch=194\n",
      "18004: loss=0.020, reward_mean=0.510, reward_bound=0.109, batch=204\n",
      "18005: loss=0.020, reward_mean=0.470, reward_bound=0.150, batch=209\n",
      "18006: loss=0.020, reward_mean=0.370, reward_bound=0.185, batch=213\n",
      "18007: loss=0.020, reward_mean=0.560, reward_bound=0.206, batch=218\n",
      "18008: loss=0.019, reward_mean=0.410, reward_bound=0.229, batch=214\n",
      "18009: loss=0.019, reward_mean=0.410, reward_bound=0.254, batch=213\n",
      "18010: loss=0.019, reward_mean=0.370, reward_bound=0.254, batch=218\n",
      "18011: loss=0.017, reward_mean=0.480, reward_bound=0.282, batch=210\n",
      "18012: loss=0.017, reward_mean=0.460, reward_bound=0.282, batch=216\n",
      "18013: loss=0.016, reward_mean=0.460, reward_bound=0.268, batch=221\n",
      "18014: loss=0.018, reward_mean=0.450, reward_bound=0.314, batch=202\n",
      "18015: loss=0.017, reward_mean=0.460, reward_bound=0.245, batch=211\n",
      "18016: loss=0.017, reward_mean=0.390, reward_bound=0.229, batch=216\n",
      "18017: loss=0.017, reward_mean=0.480, reward_bound=0.282, batch=218\n",
      "18018: loss=0.016, reward_mean=0.450, reward_bound=0.254, batch=221\n",
      "18019: loss=0.016, reward_mean=0.530, reward_bound=0.314, batch=224\n",
      "18020: loss=0.018, reward_mean=0.440, reward_bound=0.349, batch=204\n",
      "18021: loss=0.017, reward_mean=0.500, reward_bound=0.282, batch=212\n",
      "18022: loss=0.017, reward_mean=0.550, reward_bound=0.292, batch=218\n",
      "18023: loss=0.017, reward_mean=0.390, reward_bound=0.286, batch=222\n",
      "18024: loss=0.019, reward_mean=0.380, reward_bound=0.314, batch=222\n",
      "18025: loss=0.019, reward_mean=0.390, reward_bound=0.302, batch=225\n",
      "18026: loss=0.019, reward_mean=0.420, reward_bound=0.349, batch=225\n",
      "18027: loss=0.019, reward_mean=0.430, reward_bound=0.289, batch=227\n",
      "18028: loss=0.023, reward_mean=0.470, reward_bound=0.387, batch=198\n",
      "18029: loss=0.021, reward_mean=0.460, reward_bound=0.229, batch=207\n",
      "18030: loss=0.020, reward_mean=0.480, reward_bound=0.229, batch=214\n",
      "18031: loss=0.020, reward_mean=0.490, reward_bound=0.254, batch=217\n",
      "18032: loss=0.019, reward_mean=0.430, reward_bound=0.229, batch=221\n",
      "18033: loss=0.019, reward_mean=0.440, reward_bound=0.282, batch=224\n",
      "18034: loss=0.019, reward_mean=0.400, reward_bound=0.305, batch=227\n",
      "18035: loss=0.019, reward_mean=0.320, reward_bound=0.282, batch=228\n",
      "18036: loss=0.020, reward_mean=0.410, reward_bound=0.349, batch=220\n",
      "18037: loss=0.020, reward_mean=0.510, reward_bound=0.376, batch=224\n",
      "18038: loss=0.019, reward_mean=0.450, reward_bound=0.384, batch=227\n",
      "18039: loss=0.020, reward_mean=0.440, reward_bound=0.387, batch=224\n",
      "18040: loss=0.023, reward_mean=0.490, reward_bound=0.430, batch=195\n",
      "18041: loss=0.021, reward_mean=0.480, reward_bound=0.206, batch=205\n",
      "18042: loss=0.023, reward_mean=0.420, reward_bound=0.210, batch=213\n",
      "18043: loss=0.022, reward_mean=0.440, reward_bound=0.206, batch=218\n",
      "18044: loss=0.022, reward_mean=0.360, reward_bound=0.229, batch=221\n",
      "18045: loss=0.022, reward_mean=0.410, reward_bound=0.254, batch=219\n",
      "18046: loss=0.023, reward_mean=0.500, reward_bound=0.282, batch=218\n",
      "18047: loss=0.022, reward_mean=0.440, reward_bound=0.282, batch=221\n",
      "18048: loss=0.020, reward_mean=0.350, reward_bound=0.314, batch=218\n",
      "18049: loss=0.020, reward_mean=0.390, reward_bound=0.289, batch=222\n",
      "18050: loss=0.020, reward_mean=0.500, reward_bound=0.349, batch=224\n",
      "18051: loss=0.021, reward_mean=0.450, reward_bound=0.387, batch=214\n",
      "18052: loss=0.020, reward_mean=0.470, reward_bound=0.252, batch=220\n",
      "18053: loss=0.020, reward_mean=0.480, reward_bound=0.338, batch=224\n",
      "18054: loss=0.020, reward_mean=0.380, reward_bound=0.387, batch=222\n",
      "18055: loss=0.020, reward_mean=0.430, reward_bound=0.324, batch=225\n",
      "18056: loss=0.024, reward_mean=0.450, reward_bound=0.430, batch=212\n",
      "18057: loss=0.023, reward_mean=0.520, reward_bound=0.349, batch=217\n",
      "18058: loss=0.023, reward_mean=0.410, reward_bound=0.220, batch=222\n",
      "18059: loss=0.022, reward_mean=0.430, reward_bound=0.254, batch=223\n",
      "18060: loss=0.022, reward_mean=0.380, reward_bound=0.349, batch=225\n",
      "18061: loss=0.022, reward_mean=0.500, reward_bound=0.356, batch=227\n",
      "18062: loss=0.022, reward_mean=0.410, reward_bound=0.380, batch=229\n",
      "18063: loss=0.023, reward_mean=0.500, reward_bound=0.387, batch=223\n",
      "18064: loss=0.022, reward_mean=0.430, reward_bound=0.372, batch=226\n",
      "18065: loss=0.022, reward_mean=0.490, reward_bound=0.387, batch=227\n",
      "18066: loss=0.023, reward_mean=0.480, reward_bound=0.430, batch=219\n",
      "18067: loss=0.023, reward_mean=0.370, reward_bound=0.314, batch=222\n",
      "18068: loss=0.023, reward_mean=0.450, reward_bound=0.415, batch=225\n",
      "18069: loss=0.022, reward_mean=0.420, reward_bound=0.314, batch=226\n",
      "18070: loss=0.022, reward_mean=0.480, reward_bound=0.368, batch=228\n",
      "18071: loss=0.022, reward_mean=0.420, reward_bound=0.392, batch=229\n",
      "18072: loss=0.022, reward_mean=0.380, reward_bound=0.430, batch=228\n",
      "18073: loss=0.022, reward_mean=0.430, reward_bound=0.478, batch=230\n",
      "18074: loss=0.022, reward_mean=0.460, reward_bound=0.430, batch=230\n",
      "18075: loss=0.022, reward_mean=0.480, reward_bound=0.451, batch=231\n",
      "18076: loss=0.024, reward_mean=0.480, reward_bound=0.478, batch=188\n",
      "18077: loss=0.022, reward_mean=0.450, reward_bound=0.185, batch=200\n",
      "18078: loss=0.021, reward_mean=0.520, reward_bound=0.254, batch=206\n",
      "18079: loss=0.021, reward_mean=0.490, reward_bound=0.282, batch=211\n",
      "18080: loss=0.020, reward_mean=0.410, reward_bound=0.254, batch=217\n",
      "18081: loss=0.021, reward_mean=0.440, reward_bound=0.314, batch=216\n",
      "18082: loss=0.021, reward_mean=0.500, reward_bound=0.349, batch=217\n",
      "18083: loss=0.020, reward_mean=0.460, reward_bound=0.314, batch=220\n",
      "18084: loss=0.020, reward_mean=0.410, reward_bound=0.329, batch=224\n",
      "18085: loss=0.022, reward_mean=0.480, reward_bound=0.314, batch=226\n",
      "18086: loss=0.022, reward_mean=0.510, reward_bound=0.331, batch=228\n",
      "18087: loss=0.025, reward_mean=0.480, reward_bound=0.349, batch=228\n",
      "18088: loss=0.024, reward_mean=0.440, reward_bound=0.321, batch=229\n",
      "18089: loss=0.024, reward_mean=0.420, reward_bound=0.364, batch=230\n",
      "18090: loss=0.023, reward_mean=0.490, reward_bound=0.387, batch=224\n",
      "18091: loss=0.025, reward_mean=0.470, reward_bound=0.430, batch=204\n",
      "18092: loss=0.024, reward_mean=0.420, reward_bound=0.185, batch=212\n",
      "18093: loss=0.023, reward_mean=0.400, reward_bound=0.229, batch=217\n",
      "18094: loss=0.023, reward_mean=0.510, reward_bound=0.308, batch=222\n",
      "18095: loss=0.022, reward_mean=0.410, reward_bound=0.272, batch=225\n",
      "18096: loss=0.022, reward_mean=0.430, reward_bound=0.282, batch=226\n",
      "18097: loss=0.023, reward_mean=0.550, reward_bound=0.349, batch=222\n",
      "18098: loss=0.025, reward_mean=0.400, reward_bound=0.387, batch=223\n",
      "18099: loss=0.025, reward_mean=0.370, reward_bound=0.387, batch=225\n",
      "18100: loss=0.025, reward_mean=0.400, reward_bound=0.260, batch=227\n",
      "18101: loss=0.023, reward_mean=0.470, reward_bound=0.430, batch=220\n",
      "18102: loss=0.023, reward_mean=0.420, reward_bound=0.376, batch=224\n",
      "18103: loss=0.023, reward_mean=0.440, reward_bound=0.349, batch=225\n",
      "18104: loss=0.025, reward_mean=0.410, reward_bound=0.356, batch=227\n",
      "18105: loss=0.023, reward_mean=0.430, reward_bound=0.387, batch=224\n",
      "18106: loss=0.028, reward_mean=0.490, reward_bound=0.387, batch=226\n",
      "18107: loss=0.028, reward_mean=0.510, reward_bound=0.349, batch=227\n",
      "18108: loss=0.028, reward_mean=0.430, reward_bound=0.387, batch=227\n",
      "18109: loss=0.027, reward_mean=0.450, reward_bound=0.380, batch=229\n",
      "18110: loss=0.025, reward_mean=0.480, reward_bound=0.430, batch=224\n",
      "18111: loss=0.025, reward_mean=0.370, reward_bound=0.380, batch=227\n",
      "18112: loss=0.025, reward_mean=0.360, reward_bound=0.380, batch=229\n",
      "18113: loss=0.025, reward_mean=0.450, reward_bound=0.387, batch=229\n",
      "18114: loss=0.025, reward_mean=0.430, reward_bound=0.430, batch=228\n",
      "18115: loss=0.025, reward_mean=0.380, reward_bound=0.231, batch=229\n",
      "18116: loss=0.025, reward_mean=0.530, reward_bound=0.401, batch=230\n",
      "18117: loss=0.022, reward_mean=0.500, reward_bound=0.478, batch=210\n",
      "18118: loss=0.021, reward_mean=0.480, reward_bound=0.206, batch=218\n",
      "18119: loss=0.023, reward_mean=0.390, reward_bound=0.282, batch=220\n",
      "18120: loss=0.021, reward_mean=0.460, reward_bound=0.314, batch=220\n",
      "18121: loss=0.021, reward_mean=0.520, reward_bound=0.349, batch=216\n",
      "18122: loss=0.023, reward_mean=0.360, reward_bound=0.241, batch=221\n",
      "18123: loss=0.020, reward_mean=0.530, reward_bound=0.314, batch=222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18124: loss=0.023, reward_mean=0.350, reward_bound=0.236, batch=225\n",
      "18125: loss=0.020, reward_mean=0.440, reward_bound=0.349, batch=225\n",
      "18126: loss=0.020, reward_mean=0.540, reward_bound=0.356, batch=227\n",
      "18127: loss=0.020, reward_mean=0.510, reward_bound=0.387, batch=223\n",
      "18128: loss=0.020, reward_mean=0.430, reward_bound=0.372, batch=226\n",
      "18129: loss=0.020, reward_mean=0.490, reward_bound=0.387, batch=227\n",
      "18130: loss=0.021, reward_mean=0.470, reward_bound=0.430, batch=222\n",
      "18131: loss=0.020, reward_mean=0.380, reward_bound=0.387, batch=224\n",
      "18132: loss=0.020, reward_mean=0.420, reward_bound=0.254, batch=226\n",
      "18133: loss=0.020, reward_mean=0.460, reward_bound=0.368, batch=228\n",
      "18134: loss=0.020, reward_mean=0.460, reward_bound=0.387, batch=227\n",
      "18135: loss=0.020, reward_mean=0.520, reward_bound=0.373, batch=229\n",
      "18136: loss=0.020, reward_mean=0.480, reward_bound=0.405, batch=230\n",
      "18137: loss=0.020, reward_mean=0.490, reward_bound=0.430, batch=227\n",
      "18138: loss=0.021, reward_mean=0.550, reward_bound=0.478, batch=214\n",
      "18139: loss=0.023, reward_mean=0.510, reward_bound=0.277, batch=220\n",
      "18140: loss=0.023, reward_mean=0.510, reward_bound=0.314, batch=222\n",
      "18141: loss=0.023, reward_mean=0.400, reward_bound=0.387, batch=221\n",
      "18142: loss=0.023, reward_mean=0.440, reward_bound=0.282, batch=224\n",
      "18143: loss=0.023, reward_mean=0.450, reward_bound=0.280, batch=227\n",
      "18144: loss=0.025, reward_mean=0.550, reward_bound=0.314, batch=227\n",
      "18145: loss=0.025, reward_mean=0.460, reward_bound=0.387, batch=227\n",
      "18146: loss=0.028, reward_mean=0.420, reward_bound=0.414, batch=229\n",
      "18147: loss=0.026, reward_mean=0.470, reward_bound=0.430, batch=224\n",
      "18148: loss=0.025, reward_mean=0.450, reward_bound=0.384, batch=227\n",
      "18149: loss=0.025, reward_mean=0.530, reward_bound=0.387, batch=227\n",
      "18150: loss=0.025, reward_mean=0.490, reward_bound=0.430, batch=228\n",
      "18151: loss=0.025, reward_mean=0.450, reward_bound=0.392, batch=229\n",
      "18152: loss=0.025, reward_mean=0.360, reward_bound=0.478, batch=231\n",
      "18153: loss=0.025, reward_mean=0.330, reward_bound=0.349, batch=231\n",
      "18154: loss=0.025, reward_mean=0.400, reward_bound=0.349, batch=231\n",
      "18155: loss=0.025, reward_mean=0.460, reward_bound=0.430, batch=231\n",
      "18156: loss=0.021, reward_mean=0.440, reward_bound=0.478, batch=220\n",
      "18157: loss=0.021, reward_mean=0.420, reward_bound=0.329, batch=224\n",
      "18158: loss=0.021, reward_mean=0.460, reward_bound=0.349, batch=226\n",
      "18159: loss=0.021, reward_mean=0.420, reward_bound=0.430, batch=224\n",
      "18160: loss=0.020, reward_mean=0.460, reward_bound=0.345, batch=227\n",
      "18161: loss=0.020, reward_mean=0.490, reward_bound=0.469, batch=229\n",
      "18162: loss=0.020, reward_mean=0.440, reward_bound=0.450, batch=230\n",
      "18163: loss=0.020, reward_mean=0.410, reward_bound=0.418, batch=231\n",
      "18164: loss=0.020, reward_mean=0.430, reward_bound=0.430, batch=231\n",
      "18165: loss=0.020, reward_mean=0.510, reward_bound=0.430, batch=231\n",
      "18166: loss=0.023, reward_mean=0.460, reward_bound=0.478, batch=226\n",
      "18167: loss=0.023, reward_mean=0.560, reward_bound=0.454, batch=228\n",
      "18168: loss=0.023, reward_mean=0.420, reward_bound=0.392, batch=229\n",
      "18169: loss=0.023, reward_mean=0.430, reward_bound=0.450, batch=230\n",
      "18170: loss=0.023, reward_mean=0.440, reward_bound=0.387, batch=230\n",
      "18171: loss=0.023, reward_mean=0.370, reward_bound=0.464, batch=231\n",
      "18172: loss=0.023, reward_mean=0.430, reward_bound=0.478, batch=229\n",
      "18173: loss=0.023, reward_mean=0.370, reward_bound=0.478, batch=231\n",
      "18174: loss=0.023, reward_mean=0.490, reward_bound=0.387, batch=231\n",
      "18175: loss=0.023, reward_mean=0.480, reward_bound=0.478, batch=231\n",
      "18176: loss=0.023, reward_mean=0.420, reward_bound=0.430, batch=231\n",
      "18178: loss=0.016, reward_mean=0.390, reward_bound=0.000, batch=39\n",
      "18179: loss=0.017, reward_mean=0.400, reward_bound=0.000, batch=79\n",
      "18180: loss=0.016, reward_mean=0.420, reward_bound=0.000, batch=121\n",
      "18181: loss=0.017, reward_mean=0.410, reward_bound=0.001, batch=154\n",
      "18182: loss=0.023, reward_mean=0.440, reward_bound=0.006, batch=177\n",
      "18183: loss=0.023, reward_mean=0.350, reward_bound=0.018, batch=194\n",
      "18184: loss=0.024, reward_mean=0.490, reward_bound=0.028, batch=204\n",
      "18185: loss=0.026, reward_mean=0.400, reward_bound=0.038, batch=212\n",
      "18186: loss=0.026, reward_mean=0.470, reward_bound=0.058, batch=211\n",
      "18187: loss=0.030, reward_mean=0.460, reward_bound=0.080, batch=214\n",
      "18188: loss=0.031, reward_mean=0.470, reward_bound=0.098, batch=210\n",
      "18189: loss=0.031, reward_mean=0.500, reward_bound=0.118, batch=217\n",
      "18190: loss=0.029, reward_mean=0.480, reward_bound=0.122, batch=218\n",
      "18191: loss=0.030, reward_mean=0.400, reward_bound=0.135, batch=221\n",
      "18192: loss=0.032, reward_mean=0.380, reward_bound=0.150, batch=224\n",
      "18193: loss=0.032, reward_mean=0.420, reward_bound=0.167, batch=215\n",
      "18194: loss=0.033, reward_mean=0.380, reward_bound=0.185, batch=200\n",
      "18195: loss=0.032, reward_mean=0.500, reward_bound=0.206, batch=212\n",
      "18196: loss=0.031, reward_mean=0.440, reward_bound=0.185, batch=217\n",
      "18197: loss=0.029, reward_mean=0.420, reward_bound=0.206, batch=189\n",
      "18198: loss=0.030, reward_mean=0.370, reward_bound=0.150, batch=200\n",
      "18199: loss=0.030, reward_mean=0.390, reward_bound=0.150, batch=208\n",
      "18200: loss=0.032, reward_mean=0.460, reward_bound=0.208, batch=215\n",
      "18201: loss=0.032, reward_mean=0.420, reward_bound=0.229, batch=201\n",
      "18202: loss=0.032, reward_mean=0.430, reward_bound=0.150, batch=210\n",
      "18203: loss=0.033, reward_mean=0.390, reward_bound=0.222, batch=217\n",
      "18204: loss=0.031, reward_mean=0.480, reward_bound=0.254, batch=182\n",
      "18205: loss=0.030, reward_mean=0.420, reward_bound=0.185, batch=196\n",
      "18206: loss=0.032, reward_mean=0.410, reward_bound=0.186, batch=207\n",
      "18207: loss=0.031, reward_mean=0.470, reward_bound=0.206, batch=214\n",
      "18208: loss=0.030, reward_mean=0.500, reward_bound=0.254, batch=218\n",
      "18209: loss=0.036, reward_mean=0.590, reward_bound=0.282, batch=175\n",
      "18210: loss=0.034, reward_mean=0.470, reward_bound=0.153, batch=192\n",
      "18211: loss=0.032, reward_mean=0.420, reward_bound=0.172, batch=204\n",
      "18212: loss=0.031, reward_mean=0.430, reward_bound=0.165, batch=213\n",
      "18213: loss=0.031, reward_mean=0.450, reward_bound=0.198, batch=219\n",
      "18214: loss=0.033, reward_mean=0.460, reward_bound=0.229, batch=219\n",
      "18215: loss=0.031, reward_mean=0.450, reward_bound=0.254, batch=220\n",
      "18216: loss=0.032, reward_mean=0.450, reward_bound=0.282, batch=218\n",
      "18217: loss=0.031, reward_mean=0.420, reward_bound=0.286, batch=222\n",
      "18218: loss=0.032, reward_mean=0.400, reward_bound=0.314, batch=180\n",
      "18219: loss=0.031, reward_mean=0.350, reward_bound=0.118, batch=196\n",
      "18220: loss=0.028, reward_mean=0.430, reward_bound=0.185, batch=205\n",
      "18221: loss=0.028, reward_mean=0.460, reward_bound=0.206, batch=210\n",
      "18222: loss=0.031, reward_mean=0.500, reward_bound=0.229, batch=214\n",
      "18223: loss=0.032, reward_mean=0.440, reward_bound=0.252, batch=220\n",
      "18224: loss=0.033, reward_mean=0.420, reward_bound=0.254, batch=215\n",
      "18225: loss=0.031, reward_mean=0.470, reward_bound=0.282, batch=215\n",
      "18226: loss=0.032, reward_mean=0.500, reward_bound=0.314, batch=213\n",
      "18227: loss=0.031, reward_mean=0.390, reward_bound=0.282, batch=218\n",
      "18228: loss=0.031, reward_mean=0.470, reward_bound=0.317, batch=222\n",
      "18229: loss=0.026, reward_mean=0.470, reward_bound=0.349, batch=169\n",
      "18230: loss=0.026, reward_mean=0.360, reward_bound=0.072, batch=187\n",
      "18231: loss=0.025, reward_mean=0.490, reward_bound=0.135, batch=200\n",
      "18232: loss=0.024, reward_mean=0.500, reward_bound=0.167, batch=208\n",
      "18233: loss=0.027, reward_mean=0.470, reward_bound=0.169, batch=215\n",
      "18234: loss=0.026, reward_mean=0.350, reward_bound=0.185, batch=209\n",
      "18235: loss=0.028, reward_mean=0.410, reward_bound=0.206, batch=211\n",
      "18236: loss=0.027, reward_mean=0.410, reward_bound=0.229, batch=215\n",
      "18237: loss=0.025, reward_mean=0.490, reward_bound=0.254, batch=216\n",
      "18238: loss=0.029, reward_mean=0.420, reward_bound=0.282, batch=217\n",
      "18239: loss=0.027, reward_mean=0.440, reward_bound=0.314, batch=213\n",
      "18240: loss=0.027, reward_mean=0.500, reward_bound=0.254, batch=217\n",
      "18241: loss=0.027, reward_mean=0.380, reward_bound=0.335, batch=222\n",
      "18242: loss=0.026, reward_mean=0.380, reward_bound=0.302, batch=225\n",
      "18243: loss=0.024, reward_mean=0.400, reward_bound=0.349, batch=213\n",
      "18244: loss=0.023, reward_mean=0.270, reward_bound=0.160, batch=219\n",
      "18245: loss=0.023, reward_mean=0.450, reward_bound=0.309, batch=223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18246: loss=0.025, reward_mean=0.440, reward_bound=0.349, batch=222\n",
      "18247: loss=0.025, reward_mean=0.430, reward_bound=0.360, batch=225\n",
      "18248: loss=0.024, reward_mean=0.400, reward_bound=0.387, batch=150\n",
      "18249: loss=0.031, reward_mean=0.380, reward_bound=0.063, batch=175\n",
      "18250: loss=0.033, reward_mean=0.460, reward_bound=0.059, batch=192\n",
      "18251: loss=0.033, reward_mean=0.390, reward_bound=0.089, batch=203\n",
      "18252: loss=0.027, reward_mean=0.440, reward_bound=0.130, batch=212\n",
      "18253: loss=0.026, reward_mean=0.470, reward_bound=0.140, batch=218\n",
      "18254: loss=0.028, reward_mean=0.490, reward_bound=0.150, batch=221\n",
      "18255: loss=0.025, reward_mean=0.460, reward_bound=0.185, batch=214\n",
      "18256: loss=0.023, reward_mean=0.460, reward_bound=0.206, batch=211\n",
      "18257: loss=0.025, reward_mean=0.500, reward_bound=0.229, batch=215\n",
      "18258: loss=0.025, reward_mean=0.460, reward_bound=0.254, batch=217\n",
      "18259: loss=0.024, reward_mean=0.450, reward_bound=0.282, batch=209\n",
      "18260: loss=0.024, reward_mean=0.390, reward_bound=0.239, batch=216\n",
      "18261: loss=0.023, reward_mean=0.400, reward_bound=0.241, batch=221\n",
      "18262: loss=0.023, reward_mean=0.520, reward_bound=0.282, batch=223\n",
      "18263: loss=0.026, reward_mean=0.450, reward_bound=0.314, batch=214\n",
      "18264: loss=0.028, reward_mean=0.510, reward_bound=0.342, batch=220\n",
      "18265: loss=0.028, reward_mean=0.520, reward_bound=0.314, batch=222\n",
      "18266: loss=0.029, reward_mean=0.460, reward_bound=0.324, batch=225\n",
      "18267: loss=0.025, reward_mean=0.410, reward_bound=0.349, batch=208\n",
      "18268: loss=0.027, reward_mean=0.430, reward_bound=0.190, batch=215\n",
      "18269: loss=0.028, reward_mean=0.460, reward_bound=0.229, batch=218\n",
      "18270: loss=0.026, reward_mean=0.450, reward_bound=0.349, batch=220\n",
      "18271: loss=0.026, reward_mean=0.420, reward_bound=0.282, batch=223\n",
      "18272: loss=0.026, reward_mean=0.500, reward_bound=0.335, batch=226\n",
      "18273: loss=0.026, reward_mean=0.500, reward_bound=0.349, batch=226\n",
      "18274: loss=0.029, reward_mean=0.440, reward_bound=0.387, batch=203\n",
      "18275: loss=0.030, reward_mean=0.450, reward_bound=0.229, batch=211\n",
      "18276: loss=0.029, reward_mean=0.400, reward_bound=0.206, batch=216\n",
      "18277: loss=0.028, reward_mean=0.490, reward_bound=0.254, batch=220\n",
      "18278: loss=0.029, reward_mean=0.450, reward_bound=0.314, batch=219\n",
      "18279: loss=0.028, reward_mean=0.390, reward_bound=0.328, batch=223\n",
      "18280: loss=0.028, reward_mean=0.400, reward_bound=0.322, batch=226\n",
      "18281: loss=0.029, reward_mean=0.520, reward_bound=0.349, batch=221\n",
      "18282: loss=0.028, reward_mean=0.380, reward_bound=0.349, batch=223\n",
      "18283: loss=0.028, reward_mean=0.370, reward_bound=0.358, batch=226\n",
      "18284: loss=0.027, reward_mean=0.420, reward_bound=0.387, batch=221\n",
      "18285: loss=0.028, reward_mean=0.520, reward_bound=0.282, batch=224\n",
      "18286: loss=0.028, reward_mean=0.540, reward_bound=0.349, batch=225\n",
      "18287: loss=0.028, reward_mean=0.470, reward_bound=0.356, batch=227\n",
      "18288: loss=0.019, reward_mean=0.490, reward_bound=0.430, batch=117\n",
      "18289: loss=0.020, reward_mean=0.420, reward_bound=0.014, batch=152\n",
      "18290: loss=0.023, reward_mean=0.520, reward_bound=0.039, batch=176\n",
      "18291: loss=0.025, reward_mean=0.470, reward_bound=0.076, batch=193\n",
      "18292: loss=0.025, reward_mean=0.460, reward_bound=0.098, batch=201\n",
      "18293: loss=0.028, reward_mean=0.540, reward_bound=0.135, batch=210\n",
      "18294: loss=0.028, reward_mean=0.430, reward_bound=0.146, batch=217\n",
      "18295: loss=0.021, reward_mean=0.430, reward_bound=0.167, batch=212\n",
      "18296: loss=0.022, reward_mean=0.390, reward_bound=0.185, batch=213\n",
      "18297: loss=0.028, reward_mean=0.480, reward_bound=0.206, batch=203\n",
      "18298: loss=0.027, reward_mean=0.470, reward_bound=0.185, batch=210\n",
      "18299: loss=0.026, reward_mean=0.450, reward_bound=0.229, batch=203\n",
      "18300: loss=0.025, reward_mean=0.590, reward_bound=0.254, batch=198\n",
      "18301: loss=0.024, reward_mean=0.390, reward_bound=0.135, batch=207\n",
      "18302: loss=0.023, reward_mean=0.520, reward_bound=0.206, batch=214\n",
      "18303: loss=0.026, reward_mean=0.370, reward_bound=0.254, batch=214\n",
      "18304: loss=0.024, reward_mean=0.490, reward_bound=0.282, batch=196\n",
      "18305: loss=0.023, reward_mean=0.500, reward_bound=0.230, batch=207\n",
      "18306: loss=0.024, reward_mean=0.470, reward_bound=0.224, batch=215\n",
      "18307: loss=0.024, reward_mean=0.390, reward_bound=0.229, batch=218\n",
      "18308: loss=0.023, reward_mean=0.450, reward_bound=0.254, batch=221\n",
      "18309: loss=0.024, reward_mean=0.430, reward_bound=0.282, batch=218\n",
      "18310: loss=0.031, reward_mean=0.370, reward_bound=0.314, batch=202\n",
      "18311: loss=0.030, reward_mean=0.580, reward_bound=0.282, batch=209\n",
      "18312: loss=0.035, reward_mean=0.490, reward_bound=0.278, batch=216\n",
      "18313: loss=0.034, reward_mean=0.450, reward_bound=0.284, batch=221\n",
      "18314: loss=0.033, reward_mean=0.430, reward_bound=0.282, batch=224\n",
      "18315: loss=0.033, reward_mean=0.400, reward_bound=0.314, batch=223\n",
      "18316: loss=0.033, reward_mean=0.410, reward_bound=0.282, batch=224\n",
      "18317: loss=0.033, reward_mean=0.410, reward_bound=0.345, batch=227\n",
      "18318: loss=0.032, reward_mean=0.390, reward_bound=0.349, batch=194\n",
      "18319: loss=0.035, reward_mean=0.480, reward_bound=0.185, batch=205\n",
      "18320: loss=0.032, reward_mean=0.520, reward_bound=0.229, batch=212\n",
      "18321: loss=0.031, reward_mean=0.430, reward_bound=0.254, batch=215\n",
      "18322: loss=0.031, reward_mean=0.500, reward_bound=0.289, batch=220\n",
      "18323: loss=0.031, reward_mean=0.360, reward_bound=0.314, batch=221\n",
      "18324: loss=0.031, reward_mean=0.400, reward_bound=0.282, batch=224\n",
      "18325: loss=0.030, reward_mean=0.470, reward_bound=0.314, batch=226\n",
      "18326: loss=0.030, reward_mean=0.380, reward_bound=0.331, batch=228\n",
      "18327: loss=0.033, reward_mean=0.480, reward_bound=0.349, batch=222\n",
      "18328: loss=0.032, reward_mean=0.370, reward_bound=0.302, batch=225\n",
      "18329: loss=0.033, reward_mean=0.390, reward_bound=0.387, batch=193\n",
      "18330: loss=0.033, reward_mean=0.450, reward_bound=0.229, batch=203\n",
      "18331: loss=0.035, reward_mean=0.420, reward_bound=0.229, batch=208\n",
      "18332: loss=0.033, reward_mean=0.420, reward_bound=0.208, batch=215\n",
      "18333: loss=0.034, reward_mean=0.470, reward_bound=0.254, batch=212\n",
      "18334: loss=0.033, reward_mean=0.450, reward_bound=0.282, batch=209\n",
      "18335: loss=0.032, reward_mean=0.450, reward_bound=0.239, batch=216\n",
      "18336: loss=0.031, reward_mean=0.420, reward_bound=0.282, batch=220\n",
      "18337: loss=0.032, reward_mean=0.400, reward_bound=0.314, batch=219\n",
      "18338: loss=0.031, reward_mean=0.430, reward_bound=0.254, batch=222\n",
      "18339: loss=0.032, reward_mean=0.450, reward_bound=0.349, batch=222\n",
      "18340: loss=0.033, reward_mean=0.480, reward_bound=0.387, batch=215\n",
      "18341: loss=0.032, reward_mean=0.350, reward_bound=0.260, batch=220\n",
      "18342: loss=0.031, reward_mean=0.400, reward_bound=0.304, batch=224\n",
      "18343: loss=0.031, reward_mean=0.450, reward_bound=0.314, batch=226\n",
      "18344: loss=0.031, reward_mean=0.470, reward_bound=0.368, batch=228\n",
      "18345: loss=0.033, reward_mean=0.420, reward_bound=0.387, batch=227\n",
      "18346: loss=0.033, reward_mean=0.430, reward_bound=0.380, batch=229\n",
      "18347: loss=0.033, reward_mean=0.450, reward_bound=0.387, batch=228\n",
      "18348: loss=0.032, reward_mean=0.400, reward_bound=0.430, batch=171\n",
      "18349: loss=0.038, reward_mean=0.490, reward_bound=0.098, batch=188\n",
      "18350: loss=0.041, reward_mean=0.450, reward_bound=0.135, batch=198\n",
      "18351: loss=0.040, reward_mean=0.470, reward_bound=0.185, batch=206\n",
      "18352: loss=0.037, reward_mean=0.430, reward_bound=0.206, batch=212\n",
      "18353: loss=0.037, reward_mean=0.490, reward_bound=0.229, batch=215\n",
      "18354: loss=0.032, reward_mean=0.370, reward_bound=0.254, batch=212\n",
      "18355: loss=0.035, reward_mean=0.400, reward_bound=0.282, batch=208\n",
      "18356: loss=0.033, reward_mean=0.410, reward_bound=0.190, batch=215\n",
      "18357: loss=0.037, reward_mean=0.510, reward_bound=0.254, batch=218\n",
      "18358: loss=0.038, reward_mean=0.450, reward_bound=0.234, batch=222\n",
      "18359: loss=0.036, reward_mean=0.540, reward_bound=0.314, batch=216\n",
      "18360: loss=0.035, reward_mean=0.420, reward_bound=0.316, batch=221\n",
      "18361: loss=0.035, reward_mean=0.530, reward_bound=0.282, batch=224\n",
      "18362: loss=0.031, reward_mean=0.450, reward_bound=0.349, batch=216\n",
      "18363: loss=0.031, reward_mean=0.420, reward_bound=0.282, batch=220\n",
      "18364: loss=0.032, reward_mean=0.420, reward_bound=0.338, batch=224\n",
      "18365: loss=0.032, reward_mean=0.520, reward_bound=0.349, batch=226\n",
      "18366: loss=0.029, reward_mean=0.470, reward_bound=0.387, batch=212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18367: loss=0.032, reward_mean=0.460, reward_bound=0.263, batch=218\n",
      "18368: loss=0.030, reward_mean=0.400, reward_bound=0.317, batch=222\n",
      "18369: loss=0.031, reward_mean=0.420, reward_bound=0.172, batch=225\n",
      "18370: loss=0.030, reward_mean=0.440, reward_bound=0.349, batch=223\n",
      "18371: loss=0.030, reward_mean=0.420, reward_bound=0.349, batch=225\n",
      "18372: loss=0.030, reward_mean=0.370, reward_bound=0.349, batch=226\n",
      "18373: loss=0.033, reward_mean=0.490, reward_bound=0.387, batch=221\n",
      "18374: loss=0.032, reward_mean=0.460, reward_bound=0.314, batch=223\n",
      "18375: loss=0.034, reward_mean=0.460, reward_bound=0.372, batch=226\n",
      "18376: loss=0.034, reward_mean=0.510, reward_bound=0.331, batch=228\n",
      "18377: loss=0.034, reward_mean=0.430, reward_bound=0.387, batch=227\n",
      "18378: loss=0.033, reward_mean=0.520, reward_bound=0.430, batch=204\n",
      "18379: loss=0.031, reward_mean=0.490, reward_bound=0.280, batch=213\n",
      "18380: loss=0.030, reward_mean=0.390, reward_bound=0.254, batch=218\n",
      "18381: loss=0.031, reward_mean=0.400, reward_bound=0.282, batch=219\n",
      "18382: loss=0.030, reward_mean=0.490, reward_bound=0.328, batch=223\n",
      "18383: loss=0.030, reward_mean=0.450, reward_bound=0.349, batch=224\n",
      "18384: loss=0.030, reward_mean=0.440, reward_bound=0.311, batch=227\n",
      "18385: loss=0.030, reward_mean=0.400, reward_bound=0.349, batch=228\n",
      "18386: loss=0.031, reward_mean=0.470, reward_bound=0.387, batch=223\n",
      "18387: loss=0.030, reward_mean=0.430, reward_bound=0.301, batch=226\n",
      "18388: loss=0.030, reward_mean=0.480, reward_bound=0.351, batch=228\n",
      "18389: loss=0.030, reward_mean=0.430, reward_bound=0.353, batch=229\n",
      "18390: loss=0.030, reward_mean=0.430, reward_bound=0.405, batch=230\n",
      "18391: loss=0.031, reward_mean=0.550, reward_bound=0.430, batch=219\n",
      "18392: loss=0.033, reward_mean=0.470, reward_bound=0.328, batch=223\n",
      "18393: loss=0.032, reward_mean=0.480, reward_bound=0.372, batch=226\n",
      "18394: loss=0.032, reward_mean=0.470, reward_bound=0.387, batch=227\n",
      "18395: loss=0.032, reward_mean=0.460, reward_bound=0.422, batch=229\n",
      "18396: loss=0.032, reward_mean=0.400, reward_bound=0.349, batch=229\n",
      "18397: loss=0.032, reward_mean=0.450, reward_bound=0.430, batch=227\n",
      "18398: loss=0.032, reward_mean=0.380, reward_bound=0.335, batch=229\n",
      "18399: loss=0.032, reward_mean=0.490, reward_bound=0.349, batch=229\n",
      "18400: loss=0.032, reward_mean=0.430, reward_bound=0.381, batch=230\n",
      "18401: loss=0.037, reward_mean=0.420, reward_bound=0.478, batch=87\n",
      "18402: loss=0.025, reward_mean=0.460, reward_bound=0.001, batch=131\n",
      "18403: loss=0.027, reward_mean=0.400, reward_bound=0.009, batch=161\n",
      "18404: loss=0.027, reward_mean=0.440, reward_bound=0.023, batch=182\n",
      "18405: loss=0.029, reward_mean=0.470, reward_bound=0.054, batch=197\n",
      "18406: loss=0.031, reward_mean=0.550, reward_bound=0.080, batch=207\n",
      "18407: loss=0.029, reward_mean=0.350, reward_bound=0.098, batch=213\n",
      "18408: loss=0.031, reward_mean=0.480, reward_bound=0.122, batch=215\n",
      "18409: loss=0.030, reward_mean=0.500, reward_bound=0.150, batch=211\n",
      "18410: loss=0.032, reward_mean=0.510, reward_bound=0.167, batch=209\n",
      "18411: loss=0.037, reward_mean=0.520, reward_bound=0.185, batch=213\n",
      "18412: loss=0.044, reward_mean=0.440, reward_bound=0.206, batch=215\n",
      "18413: loss=0.045, reward_mean=0.450, reward_bound=0.229, batch=208\n",
      "18414: loss=0.044, reward_mean=0.460, reward_bound=0.254, batch=195\n",
      "18415: loss=0.047, reward_mean=0.470, reward_bound=0.229, batch=205\n",
      "18416: loss=0.042, reward_mean=0.430, reward_bound=0.282, batch=198\n",
      "18417: loss=0.042, reward_mean=0.500, reward_bound=0.206, batch=207\n",
      "18418: loss=0.042, reward_mean=0.480, reward_bound=0.249, batch=215\n",
      "18419: loss=0.043, reward_mean=0.460, reward_bound=0.254, batch=218\n",
      "18420: loss=0.044, reward_mean=0.470, reward_bound=0.282, batch=217\n",
      "18421: loss=0.043, reward_mean=0.470, reward_bound=0.282, batch=221\n",
      "18422: loss=0.042, reward_mean=0.510, reward_bound=0.314, batch=198\n",
      "18423: loss=0.040, reward_mean=0.470, reward_bound=0.211, batch=208\n",
      "18424: loss=0.038, reward_mean=0.450, reward_bound=0.349, batch=179\n",
      "18425: loss=0.035, reward_mean=0.520, reward_bound=0.229, batch=194\n",
      "18426: loss=0.033, reward_mean=0.470, reward_bound=0.206, batch=205\n",
      "18427: loss=0.032, reward_mean=0.480, reward_bound=0.229, batch=211\n",
      "18428: loss=0.033, reward_mean=0.410, reward_bound=0.229, batch=217\n",
      "18429: loss=0.034, reward_mean=0.520, reward_bound=0.254, batch=219\n",
      "18430: loss=0.034, reward_mean=0.420, reward_bound=0.282, batch=221\n",
      "18431: loss=0.038, reward_mean=0.540, reward_bound=0.314, batch=217\n",
      "18432: loss=0.037, reward_mean=0.470, reward_bound=0.229, batch=221\n",
      "18433: loss=0.037, reward_mean=0.490, reward_bound=0.314, batch=223\n",
      "18434: loss=0.035, reward_mean=0.450, reward_bound=0.349, batch=211\n",
      "18435: loss=0.034, reward_mean=0.440, reward_bound=0.229, batch=217\n",
      "18436: loss=0.033, reward_mean=0.400, reward_bound=0.277, batch=222\n",
      "18437: loss=0.033, reward_mean=0.510, reward_bound=0.282, batch=224\n",
      "18438: loss=0.033, reward_mean=0.410, reward_bound=0.314, batch=223\n",
      "18439: loss=0.032, reward_mean=0.400, reward_bound=0.271, batch=226\n",
      "18440: loss=0.035, reward_mean=0.410, reward_bound=0.349, batch=222\n",
      "18441: loss=0.031, reward_mean=0.390, reward_bound=0.387, batch=181\n",
      "18442: loss=0.032, reward_mean=0.430, reward_bound=0.089, batch=196\n",
      "18443: loss=0.028, reward_mean=0.450, reward_bound=0.109, batch=205\n",
      "18444: loss=0.032, reward_mean=0.450, reward_bound=0.167, batch=211\n",
      "18445: loss=0.027, reward_mean=0.520, reward_bound=0.206, batch=216\n",
      "18446: loss=0.029, reward_mean=0.380, reward_bound=0.176, batch=221\n",
      "18447: loss=0.031, reward_mean=0.410, reward_bound=0.229, batch=220\n",
      "18448: loss=0.030, reward_mean=0.490, reward_bound=0.247, batch=224\n",
      "18449: loss=0.033, reward_mean=0.450, reward_bound=0.254, batch=222\n",
      "18450: loss=0.032, reward_mean=0.470, reward_bound=0.282, batch=221\n",
      "18451: loss=0.028, reward_mean=0.490, reward_bound=0.314, batch=219\n",
      "18452: loss=0.028, reward_mean=0.410, reward_bound=0.314, batch=222\n",
      "18453: loss=0.027, reward_mean=0.470, reward_bound=0.263, batch=225\n",
      "18454: loss=0.028, reward_mean=0.440, reward_bound=0.349, batch=223\n",
      "18455: loss=0.028, reward_mean=0.440, reward_bound=0.345, batch=226\n",
      "18456: loss=0.029, reward_mean=0.450, reward_bound=0.387, batch=216\n",
      "18457: loss=0.028, reward_mean=0.430, reward_bound=0.282, batch=220\n",
      "18458: loss=0.028, reward_mean=0.490, reward_bound=0.338, batch=224\n",
      "18459: loss=0.028, reward_mean=0.420, reward_bound=0.349, batch=226\n",
      "18460: loss=0.028, reward_mean=0.510, reward_bound=0.387, batch=222\n",
      "18461: loss=0.023, reward_mean=0.580, reward_bound=0.430, batch=156\n",
      "18462: loss=0.020, reward_mean=0.440, reward_bound=0.084, batch=179\n",
      "18463: loss=0.021, reward_mean=0.440, reward_bound=0.098, batch=194\n",
      "18464: loss=0.020, reward_mean=0.420, reward_bound=0.120, batch=206\n",
      "18465: loss=0.021, reward_mean=0.440, reward_bound=0.135, batch=213\n",
      "18466: loss=0.023, reward_mean=0.440, reward_bound=0.178, batch=219\n",
      "18467: loss=0.025, reward_mean=0.440, reward_bound=0.206, batch=215\n",
      "18468: loss=0.025, reward_mean=0.420, reward_bound=0.229, batch=219\n",
      "18469: loss=0.023, reward_mean=0.500, reward_bound=0.254, batch=214\n",
      "18470: loss=0.023, reward_mean=0.530, reward_bound=0.282, batch=217\n",
      "18471: loss=0.023, reward_mean=0.480, reward_bound=0.282, batch=221\n",
      "18472: loss=0.023, reward_mean=0.470, reward_bound=0.282, batch=224\n",
      "18473: loss=0.022, reward_mean=0.440, reward_bound=0.314, batch=213\n",
      "18474: loss=0.021, reward_mean=0.410, reward_bound=0.301, batch=219\n",
      "18475: loss=0.023, reward_mean=0.410, reward_bound=0.203, batch=223\n",
      "18476: loss=0.020, reward_mean=0.310, reward_bound=0.244, batch=226\n",
      "18477: loss=0.020, reward_mean=0.510, reward_bound=0.314, batch=226\n",
      "18478: loss=0.020, reward_mean=0.570, reward_bound=0.349, batch=212\n",
      "18479: loss=0.022, reward_mean=0.450, reward_bound=0.185, batch=217\n",
      "18480: loss=0.022, reward_mean=0.360, reward_bound=0.282, batch=218\n",
      "18481: loss=0.019, reward_mean=0.540, reward_bound=0.314, batch=220\n",
      "18482: loss=0.019, reward_mean=0.430, reward_bound=0.338, batch=224\n",
      "18483: loss=0.019, reward_mean=0.410, reward_bound=0.349, batch=225\n",
      "18484: loss=0.019, reward_mean=0.460, reward_bound=0.349, batch=226\n",
      "18485: loss=0.019, reward_mean=0.440, reward_bound=0.349, batch=227\n",
      "18486: loss=0.018, reward_mean=0.390, reward_bound=0.373, batch=229\n",
      "18487: loss=0.021, reward_mean=0.560, reward_bound=0.387, batch=207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18488: loss=0.022, reward_mean=0.400, reward_bound=0.314, batch=214\n",
      "18489: loss=0.022, reward_mean=0.420, reward_bound=0.282, batch=219\n",
      "18490: loss=0.022, reward_mean=0.450, reward_bound=0.282, batch=222\n",
      "18491: loss=0.022, reward_mean=0.410, reward_bound=0.349, batch=219\n",
      "18492: loss=0.022, reward_mean=0.440, reward_bound=0.364, batch=223\n",
      "18493: loss=0.020, reward_mean=0.490, reward_bound=0.387, batch=220\n",
      "18494: loss=0.019, reward_mean=0.470, reward_bound=0.338, batch=224\n",
      "18495: loss=0.019, reward_mean=0.380, reward_bound=0.349, batch=225\n",
      "18496: loss=0.019, reward_mean=0.450, reward_bound=0.396, batch=227\n",
      "18497: loss=0.019, reward_mean=0.490, reward_bound=0.422, batch=229\n",
      "18498: loss=0.019, reward_mean=0.410, reward_bound=0.430, batch=192\n",
      "18499: loss=0.018, reward_mean=0.370, reward_bound=0.167, batch=203\n",
      "18500: loss=0.020, reward_mean=0.500, reward_bound=0.185, batch=211\n",
      "18501: loss=0.017, reward_mean=0.450, reward_bound=0.206, batch=213\n",
      "18502: loss=0.017, reward_mean=0.400, reward_bound=0.190, batch=219\n",
      "18503: loss=0.017, reward_mean=0.470, reward_bound=0.254, batch=221\n",
      "18504: loss=0.019, reward_mean=0.530, reward_bound=0.282, batch=220\n",
      "18505: loss=0.020, reward_mean=0.460, reward_bound=0.314, batch=217\n",
      "18506: loss=0.019, reward_mean=0.460, reward_bound=0.308, batch=222\n",
      "18507: loss=0.019, reward_mean=0.510, reward_bound=0.314, batch=224\n",
      "18508: loss=0.019, reward_mean=0.390, reward_bound=0.342, batch=227\n",
      "18509: loss=0.019, reward_mean=0.320, reward_bound=0.330, batch=229\n",
      "18510: loss=0.020, reward_mean=0.390, reward_bound=0.349, batch=222\n",
      "18511: loss=0.019, reward_mean=0.410, reward_bound=0.282, batch=224\n",
      "18512: loss=0.022, reward_mean=0.450, reward_bound=0.342, batch=227\n",
      "18513: loss=0.022, reward_mean=0.460, reward_bound=0.342, batch=229\n",
      "18514: loss=0.022, reward_mean=0.430, reward_bound=0.349, batch=229\n",
      "18515: loss=0.023, reward_mean=0.520, reward_bound=0.387, batch=221\n",
      "18516: loss=0.022, reward_mean=0.430, reward_bound=0.282, batch=224\n",
      "18517: loss=0.022, reward_mean=0.590, reward_bound=0.345, batch=227\n",
      "18518: loss=0.022, reward_mean=0.460, reward_bound=0.349, batch=228\n",
      "18519: loss=0.022, reward_mean=0.410, reward_bound=0.387, batch=227\n",
      "18520: loss=0.022, reward_mean=0.360, reward_bound=0.349, batch=228\n",
      "18521: loss=0.023, reward_mean=0.440, reward_bound=0.430, batch=217\n",
      "18522: loss=0.023, reward_mean=0.490, reward_bound=0.254, batch=218\n",
      "18523: loss=0.023, reward_mean=0.430, reward_bound=0.387, batch=220\n",
      "18524: loss=0.025, reward_mean=0.440, reward_bound=0.314, batch=223\n",
      "18525: loss=0.024, reward_mean=0.440, reward_bound=0.311, batch=226\n",
      "18526: loss=0.023, reward_mean=0.530, reward_bound=0.430, batch=221\n",
      "18527: loss=0.022, reward_mean=0.500, reward_bound=0.314, batch=224\n",
      "18528: loss=0.022, reward_mean=0.460, reward_bound=0.384, batch=227\n",
      "18529: loss=0.022, reward_mean=0.440, reward_bound=0.380, batch=229\n",
      "18530: loss=0.022, reward_mean=0.490, reward_bound=0.343, batch=230\n",
      "18531: loss=0.022, reward_mean=0.460, reward_bound=0.387, batch=230\n",
      "18532: loss=0.022, reward_mean=0.500, reward_bound=0.418, batch=231\n",
      "18533: loss=0.022, reward_mean=0.610, reward_bound=0.430, batch=229\n",
      "18534: loss=0.022, reward_mean=0.390, reward_bound=0.424, batch=230\n",
      "18535: loss=0.022, reward_mean=0.450, reward_bound=0.464, batch=231\n",
      "18536: loss=0.029, reward_mean=0.410, reward_bound=0.478, batch=148\n",
      "18537: loss=0.031, reward_mean=0.480, reward_bound=0.082, batch=173\n",
      "18538: loss=0.031, reward_mean=0.380, reward_bound=0.091, batch=191\n",
      "18539: loss=0.028, reward_mean=0.380, reward_bound=0.098, batch=202\n",
      "18540: loss=0.030, reward_mean=0.450, reward_bound=0.135, batch=206\n",
      "18541: loss=0.028, reward_mean=0.380, reward_bound=0.158, batch=214\n",
      "18542: loss=0.024, reward_mean=0.510, reward_bound=0.185, batch=219\n",
      "18543: loss=0.026, reward_mean=0.370, reward_bound=0.206, batch=221\n",
      "18544: loss=0.027, reward_mean=0.490, reward_bound=0.229, batch=214\n",
      "18545: loss=0.028, reward_mean=0.390, reward_bound=0.249, batch=220\n",
      "18546: loss=0.028, reward_mean=0.450, reward_bound=0.254, batch=214\n",
      "18547: loss=0.025, reward_mean=0.420, reward_bound=0.282, batch=207\n",
      "18548: loss=0.026, reward_mean=0.370, reward_bound=0.202, batch=215\n",
      "18549: loss=0.028, reward_mean=0.380, reward_bound=0.314, batch=205\n",
      "18550: loss=0.029, reward_mean=0.440, reward_bound=0.229, batch=212\n",
      "18551: loss=0.029, reward_mean=0.400, reward_bound=0.254, batch=217\n",
      "18552: loss=0.028, reward_mean=0.360, reward_bound=0.282, batch=219\n",
      "18553: loss=0.028, reward_mean=0.410, reward_bound=0.278, batch=223\n",
      "18554: loss=0.027, reward_mean=0.430, reward_bound=0.301, batch=226\n",
      "18555: loss=0.028, reward_mean=0.400, reward_bound=0.314, batch=224\n",
      "18556: loss=0.026, reward_mean=0.440, reward_bound=0.349, batch=203\n",
      "18557: loss=0.025, reward_mean=0.490, reward_bound=0.282, batch=211\n",
      "18558: loss=0.025, reward_mean=0.530, reward_bound=0.282, batch=215\n",
      "18559: loss=0.025, reward_mean=0.460, reward_bound=0.314, batch=217\n",
      "18560: loss=0.024, reward_mean=0.480, reward_bound=0.349, batch=220\n",
      "18561: loss=0.024, reward_mean=0.410, reward_bound=0.376, batch=224\n",
      "18562: loss=0.024, reward_mean=0.450, reward_bound=0.314, batch=226\n",
      "18563: loss=0.024, reward_mean=0.430, reward_bound=0.349, batch=225\n",
      "18564: loss=0.024, reward_mean=0.360, reward_bound=0.314, batch=226\n",
      "18565: loss=0.024, reward_mean=0.450, reward_bound=0.368, batch=228\n",
      "18566: loss=0.025, reward_mean=0.400, reward_bound=0.387, batch=200\n",
      "18567: loss=0.023, reward_mean=0.460, reward_bound=0.247, batch=210\n",
      "18568: loss=0.025, reward_mean=0.440, reward_bound=0.254, batch=215\n",
      "18569: loss=0.025, reward_mean=0.400, reward_bound=0.240, batch=220\n",
      "18570: loss=0.024, reward_mean=0.460, reward_bound=0.254, batch=223\n",
      "18571: loss=0.024, reward_mean=0.450, reward_bound=0.314, batch=224\n",
      "18572: loss=0.022, reward_mean=0.510, reward_bound=0.349, batch=220\n",
      "18573: loss=0.022, reward_mean=0.500, reward_bound=0.282, batch=222\n",
      "18574: loss=0.023, reward_mean=0.510, reward_bound=0.387, batch=218\n",
      "18575: loss=0.022, reward_mean=0.420, reward_bound=0.353, batch=222\n",
      "18576: loss=0.025, reward_mean=0.410, reward_bound=0.400, batch=225\n",
      "18577: loss=0.024, reward_mean=0.380, reward_bound=0.356, batch=227\n",
      "18578: loss=0.024, reward_mean=0.460, reward_bound=0.380, batch=229\n",
      "18579: loss=0.025, reward_mean=0.460, reward_bound=0.430, batch=199\n",
      "18580: loss=0.026, reward_mean=0.430, reward_bound=0.150, batch=208\n",
      "18581: loss=0.026, reward_mean=0.470, reward_bound=0.282, batch=212\n",
      "18582: loss=0.025, reward_mean=0.440, reward_bound=0.198, batch=218\n",
      "18583: loss=0.028, reward_mean=0.440, reward_bound=0.314, batch=216\n",
      "18584: loss=0.027, reward_mean=0.490, reward_bound=0.268, batch=221\n",
      "18585: loss=0.027, reward_mean=0.460, reward_bound=0.282, batch=224\n",
      "18586: loss=0.023, reward_mean=0.500, reward_bound=0.349, batch=219\n",
      "18587: loss=0.023, reward_mean=0.510, reward_bound=0.314, batch=222\n",
      "18588: loss=0.022, reward_mean=0.470, reward_bound=0.360, batch=225\n",
      "18589: loss=0.022, reward_mean=0.400, reward_bound=0.356, batch=227\n",
      "18590: loss=0.023, reward_mean=0.570, reward_bound=0.387, batch=223\n",
      "18591: loss=0.022, reward_mean=0.440, reward_bound=0.413, batch=226\n",
      "18592: loss=0.022, reward_mean=0.470, reward_bound=0.409, batch=228\n",
      "18593: loss=0.024, reward_mean=0.430, reward_bound=0.430, batch=215\n",
      "18594: loss=0.025, reward_mean=0.490, reward_bound=0.234, batch=220\n",
      "18595: loss=0.025, reward_mean=0.400, reward_bound=0.338, batch=224\n",
      "18596: loss=0.025, reward_mean=0.390, reward_bound=0.384, batch=227\n",
      "18597: loss=0.023, reward_mean=0.490, reward_bound=0.387, batch=224\n",
      "18598: loss=0.025, reward_mean=0.490, reward_bound=0.380, batch=227\n",
      "18599: loss=0.025, reward_mean=0.490, reward_bound=0.387, batch=228\n",
      "18600: loss=0.023, reward_mean=0.470, reward_bound=0.430, batch=220\n",
      "18601: loss=0.023, reward_mean=0.440, reward_bound=0.338, batch=224\n",
      "18602: loss=0.022, reward_mean=0.420, reward_bound=0.345, batch=227\n",
      "18603: loss=0.022, reward_mean=0.430, reward_bound=0.349, batch=228\n",
      "18604: loss=0.022, reward_mean=0.440, reward_bound=0.392, batch=229\n",
      "18605: loss=0.022, reward_mean=0.500, reward_bound=0.430, batch=228\n",
      "18606: loss=0.022, reward_mean=0.560, reward_bound=0.478, batch=230\n",
      "18607: loss=0.027, reward_mean=0.480, reward_bound=0.478, batch=181\n",
      "18608: loss=0.029, reward_mean=0.310, reward_bound=0.072, batch=196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18609: loss=0.027, reward_mean=0.460, reward_bound=0.109, batch=206\n",
      "18610: loss=0.032, reward_mean=0.490, reward_bound=0.150, batch=211\n",
      "18611: loss=0.031, reward_mean=0.450, reward_bound=0.206, batch=217\n",
      "18612: loss=0.031, reward_mean=0.450, reward_bound=0.229, batch=219\n",
      "18613: loss=0.031, reward_mean=0.460, reward_bound=0.254, batch=222\n",
      "18614: loss=0.024, reward_mean=0.480, reward_bound=0.282, batch=222\n",
      "18615: loss=0.025, reward_mean=0.490, reward_bound=0.314, batch=219\n",
      "18616: loss=0.026, reward_mean=0.510, reward_bound=0.349, batch=212\n",
      "18617: loss=0.025, reward_mean=0.470, reward_bound=0.314, batch=216\n",
      "18618: loss=0.025, reward_mean=0.420, reward_bound=0.314, batch=220\n",
      "18619: loss=0.029, reward_mean=0.430, reward_bound=0.349, batch=223\n",
      "18620: loss=0.029, reward_mean=0.480, reward_bound=0.335, batch=226\n",
      "18621: loss=0.030, reward_mean=0.420, reward_bound=0.387, batch=217\n",
      "18622: loss=0.030, reward_mean=0.490, reward_bound=0.335, batch=222\n",
      "18623: loss=0.032, reward_mean=0.480, reward_bound=0.360, batch=225\n",
      "18624: loss=0.030, reward_mean=0.500, reward_bound=0.387, batch=222\n",
      "18625: loss=0.029, reward_mean=0.470, reward_bound=0.430, batch=213\n",
      "18626: loss=0.028, reward_mean=0.430, reward_bound=0.254, batch=218\n",
      "18627: loss=0.028, reward_mean=0.450, reward_bound=0.289, batch=222\n",
      "18628: loss=0.030, reward_mean=0.450, reward_bound=0.360, batch=225\n",
      "18629: loss=0.029, reward_mean=0.480, reward_bound=0.356, batch=227\n",
      "18630: loss=0.030, reward_mean=0.460, reward_bound=0.387, batch=227\n",
      "18631: loss=0.029, reward_mean=0.420, reward_bound=0.414, batch=229\n",
      "18632: loss=0.029, reward_mean=0.390, reward_bound=0.342, batch=230\n",
      "18633: loss=0.029, reward_mean=0.450, reward_bound=0.349, batch=230\n",
      "18634: loss=0.029, reward_mean=0.550, reward_bound=0.464, batch=231\n",
      "18635: loss=0.033, reward_mean=0.450, reward_bound=0.478, batch=205\n",
      "18636: loss=0.033, reward_mean=0.350, reward_bound=0.170, batch=213\n",
      "18637: loss=0.032, reward_mean=0.500, reward_bound=0.220, batch=219\n",
      "18638: loss=0.035, reward_mean=0.360, reward_bound=0.254, batch=220\n",
      "18639: loss=0.032, reward_mean=0.390, reward_bound=0.304, batch=224\n",
      "18640: loss=0.032, reward_mean=0.450, reward_bound=0.349, batch=225\n",
      "18641: loss=0.033, reward_mean=0.440, reward_bound=0.387, batch=222\n",
      "18642: loss=0.032, reward_mean=0.420, reward_bound=0.336, batch=225\n",
      "18643: loss=0.032, reward_mean=0.400, reward_bound=0.396, batch=227\n",
      "18644: loss=0.032, reward_mean=0.500, reward_bound=0.373, batch=229\n",
      "18645: loss=0.032, reward_mean=0.430, reward_bound=0.405, batch=230\n",
      "18646: loss=0.032, reward_mean=0.390, reward_bound=0.387, batch=230\n",
      "18647: loss=0.034, reward_mean=0.490, reward_bound=0.338, batch=231\n",
      "18648: loss=0.031, reward_mean=0.610, reward_bound=0.430, batch=223\n",
      "18649: loss=0.030, reward_mean=0.430, reward_bound=0.413, batch=226\n",
      "18650: loss=0.032, reward_mean=0.390, reward_bound=0.430, batch=226\n",
      "18651: loss=0.032, reward_mean=0.390, reward_bound=0.409, batch=228\n",
      "18652: loss=0.032, reward_mean=0.480, reward_bound=0.430, batch=227\n",
      "18653: loss=0.032, reward_mean=0.400, reward_bound=0.407, batch=229\n",
      "18654: loss=0.032, reward_mean=0.400, reward_bound=0.381, batch=230\n",
      "18655: loss=0.032, reward_mean=0.420, reward_bound=0.430, batch=229\n",
      "18656: loss=0.032, reward_mean=0.400, reward_bound=0.450, batch=230\n",
      "18657: loss=0.032, reward_mean=0.390, reward_bound=0.418, batch=231\n",
      "18658: loss=0.031, reward_mean=0.500, reward_bound=0.478, batch=218\n",
      "18659: loss=0.031, reward_mean=0.560, reward_bound=0.353, batch=222\n",
      "18660: loss=0.030, reward_mean=0.420, reward_bound=0.400, batch=225\n",
      "18661: loss=0.032, reward_mean=0.420, reward_bound=0.356, batch=227\n",
      "18662: loss=0.030, reward_mean=0.410, reward_bound=0.430, batch=223\n",
      "18663: loss=0.030, reward_mean=0.530, reward_bound=0.387, batch=225\n",
      "18664: loss=0.030, reward_mean=0.470, reward_bound=0.387, batch=226\n",
      "18665: loss=0.030, reward_mean=0.420, reward_bound=0.387, batch=227\n",
      "18666: loss=0.030, reward_mean=0.550, reward_bound=0.414, batch=229\n",
      "18667: loss=0.030, reward_mean=0.490, reward_bound=0.405, batch=230\n",
      "18668: loss=0.030, reward_mean=0.470, reward_bound=0.430, batch=228\n",
      "18669: loss=0.030, reward_mean=0.490, reward_bound=0.349, batch=228\n",
      "18670: loss=0.030, reward_mean=0.460, reward_bound=0.478, batch=230\n",
      "18671: loss=0.030, reward_mean=0.470, reward_bound=0.464, batch=231\n",
      "18672: loss=0.030, reward_mean=0.400, reward_bound=0.430, batch=231\n",
      "18673: loss=0.030, reward_mean=0.490, reward_bound=0.478, batch=227\n",
      "18674: loss=0.030, reward_mean=0.450, reward_bound=0.387, batch=228\n",
      "18675: loss=0.030, reward_mean=0.460, reward_bound=0.277, batch=229\n",
      "18676: loss=0.030, reward_mean=0.420, reward_bound=0.405, batch=230\n",
      "18677: loss=0.030, reward_mean=0.500, reward_bound=0.430, batch=230\n",
      "18678: loss=0.030, reward_mean=0.470, reward_bound=0.314, batch=230\n",
      "18679: loss=0.032, reward_mean=0.490, reward_bound=0.478, batch=229\n",
      "18680: loss=0.032, reward_mean=0.460, reward_bound=0.445, batch=230\n",
      "18681: loss=0.032, reward_mean=0.400, reward_bound=0.501, batch=231\n",
      "18682: loss=0.032, reward_mean=0.380, reward_bound=0.387, batch=231\n",
      "18683: loss=0.032, reward_mean=0.470, reward_bound=0.478, batch=231\n",
      "18684: loss=0.032, reward_mean=0.490, reward_bound=0.478, batch=231\n",
      "18686: loss=0.030, reward_mean=0.330, reward_bound=0.000, batch=33\n",
      "18687: loss=0.029, reward_mean=0.460, reward_bound=0.000, batch=79\n",
      "18688: loss=0.028, reward_mean=0.440, reward_bound=0.000, batch=123\n",
      "18689: loss=0.032, reward_mean=0.490, reward_bound=0.005, batch=155\n",
      "18690: loss=0.034, reward_mean=0.380, reward_bound=0.008, batch=178\n",
      "18691: loss=0.040, reward_mean=0.510, reward_bound=0.018, batch=192\n",
      "18692: loss=0.039, reward_mean=0.310, reward_bound=0.028, batch=202\n",
      "18693: loss=0.044, reward_mean=0.530, reward_bound=0.052, batch=210\n",
      "18694: loss=0.049, reward_mean=0.380, reward_bound=0.065, batch=210\n",
      "18695: loss=0.050, reward_mean=0.470, reward_bound=0.089, batch=205\n",
      "18696: loss=0.049, reward_mean=0.570, reward_bound=0.098, batch=207\n",
      "18697: loss=0.050, reward_mean=0.300, reward_bound=0.109, batch=221\n",
      "18698: loss=0.056, reward_mean=0.490, reward_bound=0.109, batch=222\n",
      "18699: loss=0.057, reward_mean=0.330, reward_bound=0.122, batch=219\n",
      "18700: loss=0.056, reward_mean=0.510, reward_bound=0.150, batch=201\n",
      "18701: loss=0.057, reward_mean=0.430, reward_bound=0.167, batch=198\n",
      "18702: loss=0.059, reward_mean=0.460, reward_bound=0.185, batch=187\n",
      "18703: loss=0.059, reward_mean=0.410, reward_bound=0.115, batch=201\n",
      "18704: loss=0.060, reward_mean=0.460, reward_bound=0.150, batch=210\n",
      "18705: loss=0.061, reward_mean=0.410, reward_bound=0.206, batch=222\n",
      "18706: loss=0.062, reward_mean=0.460, reward_bound=0.206, batch=237\n",
      "18707: loss=0.064, reward_mean=0.480, reward_bound=0.206, batch=218\n",
      "18708: loss=0.063, reward_mean=0.480, reward_bound=0.229, batch=192\n",
      "18709: loss=0.064, reward_mean=0.460, reward_bound=0.206, batch=205\n",
      "18710: loss=0.064, reward_mean=0.430, reward_bound=0.206, batch=210\n",
      "18711: loss=0.063, reward_mean=0.520, reward_bound=0.200, batch=217\n",
      "18712: loss=0.060, reward_mean=0.470, reward_bound=0.229, batch=220\n",
      "18713: loss=0.060, reward_mean=0.440, reward_bound=0.247, batch=224\n",
      "18714: loss=0.065, reward_mean=0.460, reward_bound=0.254, batch=194\n",
      "18715: loss=0.063, reward_mean=0.430, reward_bound=0.122, batch=205\n",
      "18716: loss=0.063, reward_mean=0.480, reward_bound=0.194, batch=213\n",
      "18717: loss=0.065, reward_mean=0.420, reward_bound=0.254, batch=216\n",
      "18718: loss=0.068, reward_mean=0.420, reward_bound=0.282, batch=182\n",
      "18719: loss=0.071, reward_mean=0.470, reward_bound=0.105, batch=197\n",
      "18720: loss=0.071, reward_mean=0.420, reward_bound=0.135, batch=206\n",
      "18721: loss=0.072, reward_mean=0.480, reward_bound=0.185, batch=211\n",
      "18722: loss=0.068, reward_mean=0.440, reward_bound=0.206, batch=214\n",
      "18723: loss=0.067, reward_mean=0.430, reward_bound=0.229, batch=217\n",
      "18724: loss=0.069, reward_mean=0.550, reward_bound=0.254, batch=216\n",
      "18725: loss=0.070, reward_mean=0.460, reward_bound=0.282, batch=217\n",
      "18726: loss=0.071, reward_mean=0.390, reward_bound=0.302, batch=222\n",
      "18727: loss=0.073, reward_mean=0.420, reward_bound=0.314, batch=178\n",
      "18728: loss=0.066, reward_mean=0.420, reward_bound=0.137, batch=194\n",
      "18729: loss=0.067, reward_mean=0.400, reward_bound=0.167, batch=203\n",
      "18730: loss=0.069, reward_mean=0.440, reward_bound=0.206, batch=209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18731: loss=0.073, reward_mean=0.490, reward_bound=0.229, batch=208\n",
      "18732: loss=0.076, reward_mean=0.540, reward_bound=0.257, batch=215\n",
      "18733: loss=0.076, reward_mean=0.500, reward_bound=0.282, batch=208\n",
      "18734: loss=0.076, reward_mean=0.480, reward_bound=0.257, batch=215\n",
      "18735: loss=0.076, reward_mean=0.470, reward_bound=0.282, batch=215\n",
      "18736: loss=0.075, reward_mean=0.540, reward_bound=0.289, batch=220\n",
      "18737: loss=0.076, reward_mean=0.480, reward_bound=0.314, batch=212\n",
      "18738: loss=0.075, reward_mean=0.390, reward_bound=0.292, batch=218\n",
      "18739: loss=0.075, reward_mean=0.360, reward_bound=0.286, batch=222\n",
      "18740: loss=0.074, reward_mean=0.490, reward_bound=0.292, batch=225\n",
      "18741: loss=0.074, reward_mean=0.540, reward_bound=0.314, batch=225\n",
      "18742: loss=0.072, reward_mean=0.540, reward_bound=0.349, batch=173\n",
      "18743: loss=0.071, reward_mean=0.460, reward_bound=0.171, batch=191\n",
      "18744: loss=0.070, reward_mean=0.410, reward_bound=0.122, batch=203\n",
      "18745: loss=0.074, reward_mean=0.490, reward_bound=0.185, batch=208\n",
      "18746: loss=0.073, reward_mean=0.420, reward_bound=0.206, batch=212\n",
      "18747: loss=0.073, reward_mean=0.460, reward_bound=0.254, batch=215\n",
      "18748: loss=0.073, reward_mean=0.340, reward_bound=0.189, batch=220\n",
      "18749: loss=0.073, reward_mean=0.480, reward_bound=0.274, batch=224\n",
      "18750: loss=0.074, reward_mean=0.320, reward_bound=0.282, batch=218\n",
      "18751: loss=0.074, reward_mean=0.370, reward_bound=0.234, batch=222\n",
      "18752: loss=0.074, reward_mean=0.450, reward_bound=0.314, batch=214\n",
      "18753: loss=0.074, reward_mean=0.470, reward_bound=0.254, batch=219\n",
      "18754: loss=0.072, reward_mean=0.400, reward_bound=0.328, batch=223\n",
      "18755: loss=0.071, reward_mean=0.540, reward_bound=0.335, batch=226\n",
      "18756: loss=0.067, reward_mean=0.420, reward_bound=0.349, batch=209\n",
      "18757: loss=0.070, reward_mean=0.570, reward_bound=0.387, batch=155\n",
      "18758: loss=0.069, reward_mean=0.410, reward_bound=0.042, batch=177\n",
      "18759: loss=0.065, reward_mean=0.420, reward_bound=0.107, batch=194\n",
      "18760: loss=0.068, reward_mean=0.450, reward_bound=0.122, batch=203\n",
      "18761: loss=0.071, reward_mean=0.440, reward_bound=0.150, batch=203\n",
      "18762: loss=0.071, reward_mean=0.400, reward_bound=0.160, batch=212\n",
      "18763: loss=0.069, reward_mean=0.470, reward_bound=0.167, batch=216\n",
      "18764: loss=0.070, reward_mean=0.380, reward_bound=0.206, batch=215\n",
      "18765: loss=0.070, reward_mean=0.450, reward_bound=0.229, batch=213\n",
      "18766: loss=0.068, reward_mean=0.450, reward_bound=0.244, batch=219\n",
      "18767: loss=0.067, reward_mean=0.510, reward_bound=0.254, batch=220\n",
      "18768: loss=0.066, reward_mean=0.360, reward_bound=0.185, batch=223\n",
      "18769: loss=0.065, reward_mean=0.360, reward_bound=0.282, batch=217\n",
      "18770: loss=0.063, reward_mean=0.410, reward_bound=0.314, batch=207\n",
      "18771: loss=0.061, reward_mean=0.500, reward_bound=0.254, batch=214\n",
      "18772: loss=0.062, reward_mean=0.490, reward_bound=0.282, batch=215\n",
      "18773: loss=0.062, reward_mean=0.440, reward_bound=0.254, batch=219\n",
      "18774: loss=0.063, reward_mean=0.470, reward_bound=0.295, batch=223\n",
      "18775: loss=0.064, reward_mean=0.410, reward_bound=0.349, batch=210\n",
      "18776: loss=0.063, reward_mean=0.420, reward_bound=0.200, batch=217\n",
      "18777: loss=0.066, reward_mean=0.450, reward_bound=0.224, batch=222\n",
      "18778: loss=0.064, reward_mean=0.380, reward_bound=0.229, batch=223\n",
      "18779: loss=0.062, reward_mean=0.430, reward_bound=0.271, batch=226\n",
      "18780: loss=0.062, reward_mean=0.400, reward_bound=0.331, batch=228\n",
      "18781: loss=0.062, reward_mean=0.520, reward_bound=0.349, batch=226\n",
      "18782: loss=0.063, reward_mean=0.350, reward_bound=0.368, batch=228\n",
      "18783: loss=0.066, reward_mean=0.400, reward_bound=0.387, batch=194\n",
      "18784: loss=0.065, reward_mean=0.440, reward_bound=0.120, batch=206\n",
      "18785: loss=0.068, reward_mean=0.440, reward_bound=0.217, batch=214\n",
      "18786: loss=0.067, reward_mean=0.450, reward_bound=0.229, batch=216\n",
      "18787: loss=0.068, reward_mean=0.480, reward_bound=0.268, batch=221\n",
      "18788: loss=0.070, reward_mean=0.480, reward_bound=0.314, batch=222\n",
      "18789: loss=0.069, reward_mean=0.470, reward_bound=0.324, batch=225\n",
      "18790: loss=0.066, reward_mean=0.430, reward_bound=0.349, batch=218\n",
      "18791: loss=0.065, reward_mean=0.420, reward_bound=0.317, batch=222\n",
      "18792: loss=0.065, reward_mean=0.470, reward_bound=0.349, batch=223\n",
      "18793: loss=0.068, reward_mean=0.470, reward_bound=0.387, batch=217\n",
      "18794: loss=0.066, reward_mean=0.500, reward_bound=0.282, batch=221\n",
      "18795: loss=0.068, reward_mean=0.490, reward_bound=0.387, batch=222\n",
      "18796: loss=0.069, reward_mean=0.500, reward_bound=0.314, batch=224\n",
      "18797: loss=0.068, reward_mean=0.410, reward_bound=0.349, batch=226\n",
      "18798: loss=0.063, reward_mean=0.470, reward_bound=0.430, batch=131\n",
      "18799: loss=0.060, reward_mean=0.460, reward_bound=0.020, batch=161\n",
      "18800: loss=0.066, reward_mean=0.410, reward_bound=0.047, batch=182\n",
      "18801: loss=0.064, reward_mean=0.380, reward_bound=0.065, batch=196\n",
      "18802: loss=0.062, reward_mean=0.370, reward_bound=0.089, batch=204\n",
      "18803: loss=0.065, reward_mean=0.480, reward_bound=0.122, batch=212\n",
      "18804: loss=0.069, reward_mean=0.490, reward_bound=0.167, batch=209\n",
      "18805: loss=0.068, reward_mean=0.500, reward_bound=0.185, batch=212\n",
      "18806: loss=0.066, reward_mean=0.470, reward_bound=0.206, batch=222\n",
      "18807: loss=0.064, reward_mean=0.450, reward_bound=0.206, batch=237\n",
      "18808: loss=0.062, reward_mean=0.430, reward_bound=0.206, batch=230\n",
      "18809: loss=0.059, reward_mean=0.480, reward_bound=0.229, batch=224\n",
      "18810: loss=0.057, reward_mean=0.450, reward_bound=0.254, batch=213\n",
      "18811: loss=0.056, reward_mean=0.460, reward_bound=0.271, batch=219\n",
      "18812: loss=0.057, reward_mean=0.430, reward_bound=0.282, batch=204\n",
      "18813: loss=0.056, reward_mean=0.490, reward_bound=0.280, batch=213\n",
      "18814: loss=0.060, reward_mean=0.450, reward_bound=0.282, batch=216\n",
      "18815: loss=0.060, reward_mean=0.390, reward_bound=0.298, batch=221\n",
      "18816: loss=0.061, reward_mean=0.400, reward_bound=0.314, batch=202\n",
      "18817: loss=0.062, reward_mean=0.470, reward_bound=0.213, batch=211\n",
      "18818: loss=0.061, reward_mean=0.470, reward_bound=0.206, batch=217\n",
      "18819: loss=0.062, reward_mean=0.460, reward_bound=0.308, batch=222\n",
      "18820: loss=0.061, reward_mean=0.500, reward_bound=0.324, batch=225\n",
      "18821: loss=0.060, reward_mean=0.510, reward_bound=0.349, batch=197\n",
      "18822: loss=0.061, reward_mean=0.500, reward_bound=0.206, batch=206\n",
      "18823: loss=0.062, reward_mean=0.460, reward_bound=0.217, batch=214\n",
      "18824: loss=0.060, reward_mean=0.450, reward_bound=0.254, batch=217\n",
      "18825: loss=0.059, reward_mean=0.460, reward_bound=0.282, batch=217\n",
      "18826: loss=0.058, reward_mean=0.520, reward_bound=0.254, batch=221\n",
      "18827: loss=0.059, reward_mean=0.380, reward_bound=0.282, batch=224\n",
      "18828: loss=0.058, reward_mean=0.410, reward_bound=0.252, batch=227\n",
      "18829: loss=0.062, reward_mean=0.440, reward_bound=0.314, batch=220\n",
      "18830: loss=0.061, reward_mean=0.420, reward_bound=0.349, batch=217\n",
      "18831: loss=0.060, reward_mean=0.470, reward_bound=0.267, batch=222\n",
      "18832: loss=0.061, reward_mean=0.500, reward_bound=0.292, batch=225\n",
      "18833: loss=0.060, reward_mean=0.410, reward_bound=0.349, batch=224\n",
      "18834: loss=0.059, reward_mean=0.420, reward_bound=0.345, batch=227\n",
      "18835: loss=0.056, reward_mean=0.410, reward_bound=0.387, batch=196\n",
      "18836: loss=0.058, reward_mean=0.430, reward_bound=0.135, batch=206\n",
      "18837: loss=0.062, reward_mean=0.420, reward_bound=0.185, batch=212\n",
      "18838: loss=0.056, reward_mean=0.500, reward_bound=0.229, batch=213\n",
      "18839: loss=0.059, reward_mean=0.390, reward_bound=0.271, batch=219\n",
      "18840: loss=0.058, reward_mean=0.450, reward_bound=0.282, batch=218\n",
      "18841: loss=0.060, reward_mean=0.490, reward_bound=0.314, batch=218\n",
      "18842: loss=0.055, reward_mean=0.410, reward_bound=0.349, batch=212\n",
      "18843: loss=0.055, reward_mean=0.440, reward_bound=0.324, batch=218\n",
      "18844: loss=0.056, reward_mean=0.470, reward_bound=0.353, batch=222\n",
      "18845: loss=0.055, reward_mean=0.550, reward_bound=0.324, batch=225\n",
      "18846: loss=0.055, reward_mean=0.410, reward_bound=0.349, batch=226\n",
      "18847: loss=0.056, reward_mean=0.420, reward_bound=0.387, batch=222\n",
      "18848: loss=0.057, reward_mean=0.450, reward_bound=0.324, batch=225\n",
      "18849: loss=0.057, reward_mean=0.450, reward_bound=0.349, batch=225\n",
      "18850: loss=0.057, reward_mean=0.490, reward_bound=0.349, batch=226\n",
      "18851: loss=0.057, reward_mean=0.510, reward_bound=0.409, batch=228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18852: loss=0.057, reward_mean=0.430, reward_bound=0.430, batch=190\n",
      "18853: loss=0.054, reward_mean=0.450, reward_bound=0.167, batch=202\n",
      "18854: loss=0.058, reward_mean=0.400, reward_bound=0.185, batch=208\n",
      "18855: loss=0.057, reward_mean=0.470, reward_bound=0.234, batch=215\n",
      "18856: loss=0.058, reward_mean=0.400, reward_bound=0.282, batch=214\n",
      "18857: loss=0.057, reward_mean=0.430, reward_bound=0.226, batch=220\n",
      "18858: loss=0.058, reward_mean=0.480, reward_bound=0.282, batch=221\n",
      "18859: loss=0.057, reward_mean=0.430, reward_bound=0.282, batch=224\n",
      "18860: loss=0.055, reward_mean=0.470, reward_bound=0.314, batch=224\n",
      "18861: loss=0.055, reward_mean=0.490, reward_bound=0.252, batch=227\n",
      "18862: loss=0.055, reward_mean=0.480, reward_bound=0.349, batch=221\n",
      "18863: loss=0.056, reward_mean=0.450, reward_bound=0.349, batch=223\n",
      "18864: loss=0.057, reward_mean=0.470, reward_bound=0.301, batch=226\n",
      "18865: loss=0.058, reward_mean=0.480, reward_bound=0.368, batch=228\n",
      "18866: loss=0.059, reward_mean=0.450, reward_bound=0.387, batch=215\n",
      "18867: loss=0.061, reward_mean=0.360, reward_bound=0.234, batch=220\n",
      "18868: loss=0.061, reward_mean=0.450, reward_bound=0.274, batch=224\n",
      "18869: loss=0.060, reward_mean=0.480, reward_bound=0.314, batch=223\n",
      "18870: loss=0.061, reward_mean=0.420, reward_bound=0.349, batch=225\n",
      "18871: loss=0.061, reward_mean=0.370, reward_bound=0.387, batch=223\n",
      "18872: loss=0.061, reward_mean=0.390, reward_bound=0.413, batch=226\n",
      "18873: loss=0.058, reward_mean=0.510, reward_bound=0.430, batch=209\n",
      "18874: loss=0.057, reward_mean=0.500, reward_bound=0.282, batch=215\n",
      "18875: loss=0.060, reward_mean=0.440, reward_bound=0.282, batch=219\n",
      "18876: loss=0.059, reward_mean=0.480, reward_bound=0.314, batch=222\n",
      "18877: loss=0.062, reward_mean=0.430, reward_bound=0.324, batch=225\n",
      "18878: loss=0.062, reward_mean=0.480, reward_bound=0.321, batch=227\n",
      "18879: loss=0.061, reward_mean=0.500, reward_bound=0.349, batch=227\n",
      "18880: loss=0.057, reward_mean=0.340, reward_bound=0.387, batch=222\n",
      "18881: loss=0.058, reward_mean=0.430, reward_bound=0.387, batch=224\n",
      "18882: loss=0.058, reward_mean=0.420, reward_bound=0.314, batch=226\n",
      "18883: loss=0.058, reward_mean=0.450, reward_bound=0.314, batch=226\n",
      "18884: loss=0.057, reward_mean=0.430, reward_bound=0.387, batch=227\n",
      "18885: loss=0.056, reward_mean=0.540, reward_bound=0.430, batch=219\n",
      "18886: loss=0.056, reward_mean=0.500, reward_bound=0.364, batch=223\n",
      "18887: loss=0.055, reward_mean=0.450, reward_bound=0.372, batch=226\n",
      "18888: loss=0.055, reward_mean=0.460, reward_bound=0.387, batch=224\n",
      "18889: loss=0.055, reward_mean=0.550, reward_bound=0.387, batch=226\n",
      "18890: loss=0.056, reward_mean=0.470, reward_bound=0.430, batch=224\n",
      "18891: loss=0.055, reward_mean=0.430, reward_bound=0.474, batch=227\n",
      "18892: loss=0.068, reward_mean=0.410, reward_bound=0.478, batch=89\n",
      "18893: loss=0.053, reward_mean=0.410, reward_bound=0.000, batch=130\n",
      "18894: loss=0.055, reward_mean=0.590, reward_bound=0.018, batch=160\n",
      "18895: loss=0.058, reward_mean=0.410, reward_bound=0.025, batch=180\n",
      "18896: loss=0.060, reward_mean=0.480, reward_bound=0.052, batch=191\n",
      "18897: loss=0.065, reward_mean=0.410, reward_bound=0.065, batch=203\n",
      "18898: loss=0.064, reward_mean=0.450, reward_bound=0.080, batch=210\n",
      "18899: loss=0.064, reward_mean=0.400, reward_bound=0.089, batch=214\n",
      "18900: loss=0.065, reward_mean=0.460, reward_bound=0.109, batch=210\n",
      "18901: loss=0.070, reward_mean=0.500, reward_bound=0.135, batch=202\n",
      "18902: loss=0.069, reward_mean=0.360, reward_bound=0.150, batch=195\n",
      "18903: loss=0.066, reward_mean=0.390, reward_bound=0.153, batch=206\n",
      "18904: loss=0.064, reward_mean=0.480, reward_bound=0.167, batch=209\n",
      "18905: loss=0.061, reward_mean=0.470, reward_bound=0.185, batch=208\n",
      "18906: loss=0.064, reward_mean=0.400, reward_bound=0.206, batch=204\n",
      "18907: loss=0.064, reward_mean=0.420, reward_bound=0.224, batch=213\n",
      "18908: loss=0.064, reward_mean=0.430, reward_bound=0.185, batch=218\n",
      "18909: loss=0.066, reward_mean=0.390, reward_bound=0.229, batch=218\n",
      "18910: loss=0.067, reward_mean=0.430, reward_bound=0.254, batch=198\n",
      "18911: loss=0.064, reward_mean=0.530, reward_bound=0.231, batch=208\n",
      "18912: loss=0.067, reward_mean=0.400, reward_bound=0.185, batch=214\n",
      "18913: loss=0.064, reward_mean=0.430, reward_bound=0.229, batch=219\n",
      "18914: loss=0.064, reward_mean=0.440, reward_bound=0.282, batch=202\n",
      "18915: loss=0.062, reward_mean=0.480, reward_bound=0.145, batch=211\n",
      "18916: loss=0.063, reward_mean=0.420, reward_bound=0.206, batch=216\n",
      "18917: loss=0.062, reward_mean=0.480, reward_bound=0.282, batch=215\n",
      "18918: loss=0.063, reward_mean=0.500, reward_bound=0.229, batch=219\n",
      "18919: loss=0.061, reward_mean=0.460, reward_bound=0.282, batch=220\n",
      "18920: loss=0.062, reward_mean=0.460, reward_bound=0.304, batch=224\n",
      "18921: loss=0.066, reward_mean=0.530, reward_bound=0.314, batch=207\n",
      "18922: loss=0.067, reward_mean=0.390, reward_bound=0.185, batch=214\n",
      "18923: loss=0.069, reward_mean=0.420, reward_bound=0.282, batch=219\n",
      "18924: loss=0.070, reward_mean=0.360, reward_bound=0.314, batch=220\n",
      "18925: loss=0.070, reward_mean=0.460, reward_bound=0.304, batch=224\n",
      "18926: loss=0.068, reward_mean=0.390, reward_bound=0.345, batch=227\n",
      "18927: loss=0.068, reward_mean=0.370, reward_bound=0.349, batch=191\n",
      "18928: loss=0.070, reward_mean=0.420, reward_bound=0.122, batch=203\n",
      "18929: loss=0.068, reward_mean=0.420, reward_bound=0.206, batch=210\n",
      "18930: loss=0.069, reward_mean=0.390, reward_bound=0.229, batch=216\n",
      "18931: loss=0.068, reward_mean=0.380, reward_bound=0.241, batch=221\n",
      "18932: loss=0.066, reward_mean=0.390, reward_bound=0.254, batch=216\n",
      "18933: loss=0.067, reward_mean=0.480, reward_bound=0.230, batch=221\n",
      "18934: loss=0.065, reward_mean=0.440, reward_bound=0.254, batch=223\n",
      "18935: loss=0.065, reward_mean=0.490, reward_bound=0.282, batch=220\n",
      "18936: loss=0.064, reward_mean=0.420, reward_bound=0.314, batch=214\n",
      "18937: loss=0.063, reward_mean=0.410, reward_bound=0.349, batch=217\n",
      "18938: loss=0.063, reward_mean=0.430, reward_bound=0.308, batch=222\n",
      "18939: loss=0.063, reward_mean=0.500, reward_bound=0.387, batch=175\n",
      "18940: loss=0.061, reward_mean=0.460, reward_bound=0.122, batch=190\n",
      "18941: loss=0.066, reward_mean=0.430, reward_bound=0.135, batch=199\n",
      "18942: loss=0.063, reward_mean=0.540, reward_bound=0.150, batch=208\n",
      "18943: loss=0.063, reward_mean=0.510, reward_bound=0.206, batch=213\n",
      "18944: loss=0.062, reward_mean=0.360, reward_bound=0.244, batch=219\n",
      "18945: loss=0.061, reward_mean=0.360, reward_bound=0.282, batch=215\n",
      "18946: loss=0.061, reward_mean=0.440, reward_bound=0.289, batch=220\n",
      "18947: loss=0.062, reward_mean=0.420, reward_bound=0.274, batch=224\n",
      "18948: loss=0.063, reward_mean=0.530, reward_bound=0.314, batch=223\n",
      "18949: loss=0.062, reward_mean=0.460, reward_bound=0.290, batch=226\n",
      "18950: loss=0.064, reward_mean=0.440, reward_bound=0.349, batch=217\n",
      "18951: loss=0.063, reward_mean=0.470, reward_bound=0.282, batch=221\n",
      "18952: loss=0.063, reward_mean=0.470, reward_bound=0.387, batch=204\n",
      "18953: loss=0.064, reward_mean=0.420, reward_bound=0.206, batch=212\n",
      "18954: loss=0.063, reward_mean=0.460, reward_bound=0.314, batch=217\n",
      "18955: loss=0.063, reward_mean=0.480, reward_bound=0.335, batch=222\n",
      "18956: loss=0.064, reward_mean=0.530, reward_bound=0.292, batch=225\n",
      "18957: loss=0.063, reward_mean=0.390, reward_bound=0.321, batch=227\n",
      "18958: loss=0.061, reward_mean=0.390, reward_bound=0.349, batch=225\n",
      "18959: loss=0.062, reward_mean=0.460, reward_bound=0.356, batch=227\n",
      "18960: loss=0.063, reward_mean=0.420, reward_bound=0.387, batch=219\n",
      "18961: loss=0.065, reward_mean=0.420, reward_bound=0.364, batch=223\n",
      "18962: loss=0.065, reward_mean=0.510, reward_bound=0.372, batch=226\n",
      "18963: loss=0.064, reward_mean=0.430, reward_bound=0.387, batch=224\n",
      "18964: loss=0.065, reward_mean=0.450, reward_bound=0.387, batch=226\n",
      "18965: loss=0.065, reward_mean=0.420, reward_bound=0.372, batch=228\n",
      "18966: loss=0.065, reward_mean=0.440, reward_bound=0.387, batch=228\n",
      "18967: loss=0.068, reward_mean=0.520, reward_bound=0.430, batch=165\n",
      "18968: loss=0.073, reward_mean=0.490, reward_bound=0.101, batch=185\n",
      "18969: loss=0.064, reward_mean=0.500, reward_bound=0.135, batch=197\n",
      "18970: loss=0.070, reward_mean=0.440, reward_bound=0.206, batch=204\n",
      "18971: loss=0.068, reward_mean=0.400, reward_bound=0.229, batch=206\n",
      "18972: loss=0.070, reward_mean=0.470, reward_bound=0.185, batch=211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18973: loss=0.070, reward_mean=0.380, reward_bound=0.254, batch=213\n",
      "18974: loss=0.071, reward_mean=0.390, reward_bound=0.282, batch=211\n",
      "18975: loss=0.069, reward_mean=0.460, reward_bound=0.314, batch=207\n",
      "18976: loss=0.068, reward_mean=0.450, reward_bound=0.254, batch=213\n",
      "18977: loss=0.067, reward_mean=0.490, reward_bound=0.349, batch=210\n",
      "18978: loss=0.065, reward_mean=0.400, reward_bound=0.247, batch=217\n",
      "18979: loss=0.063, reward_mean=0.500, reward_bound=0.277, batch=222\n",
      "18980: loss=0.065, reward_mean=0.400, reward_bound=0.314, batch=220\n",
      "18981: loss=0.065, reward_mean=0.470, reward_bound=0.349, batch=218\n",
      "18982: loss=0.066, reward_mean=0.540, reward_bound=0.387, batch=203\n",
      "18983: loss=0.065, reward_mean=0.440, reward_bound=0.271, batch=212\n",
      "18984: loss=0.064, reward_mean=0.400, reward_bound=0.263, batch=218\n",
      "18985: loss=0.062, reward_mean=0.440, reward_bound=0.282, batch=221\n",
      "18986: loss=0.063, reward_mean=0.430, reward_bound=0.314, batch=220\n",
      "18987: loss=0.063, reward_mean=0.490, reward_bound=0.349, batch=219\n",
      "18988: loss=0.065, reward_mean=0.470, reward_bound=0.314, batch=222\n",
      "18989: loss=0.064, reward_mean=0.450, reward_bound=0.349, batch=224\n",
      "18990: loss=0.067, reward_mean=0.430, reward_bound=0.387, batch=222\n",
      "18991: loss=0.068, reward_mean=0.410, reward_bound=0.360, batch=225\n",
      "18992: loss=0.066, reward_mean=0.500, reward_bound=0.387, batch=226\n",
      "18993: loss=0.066, reward_mean=0.460, reward_bound=0.387, batch=226\n",
      "18994: loss=0.066, reward_mean=0.430, reward_bound=0.368, batch=228\n",
      "18995: loss=0.069, reward_mean=0.480, reward_bound=0.430, batch=199\n",
      "18996: loss=0.073, reward_mean=0.530, reward_bound=0.239, batch=209\n",
      "18997: loss=0.073, reward_mean=0.510, reward_bound=0.215, batch=216\n",
      "18998: loss=0.073, reward_mean=0.440, reward_bound=0.254, batch=218\n",
      "18999: loss=0.072, reward_mean=0.430, reward_bound=0.286, batch=222\n",
      "19000: loss=0.072, reward_mean=0.500, reward_bound=0.292, batch=225\n",
      "19001: loss=0.072, reward_mean=0.500, reward_bound=0.314, batch=224\n",
      "19002: loss=0.073, reward_mean=0.330, reward_bound=0.345, batch=227\n",
      "19003: loss=0.070, reward_mean=0.500, reward_bound=0.349, batch=220\n",
      "19004: loss=0.070, reward_mean=0.480, reward_bound=0.387, batch=216\n",
      "19005: loss=0.070, reward_mean=0.550, reward_bound=0.298, batch=221\n",
      "19006: loss=0.070, reward_mean=0.500, reward_bound=0.282, batch=223\n",
      "19007: loss=0.070, reward_mean=0.500, reward_bound=0.314, batch=225\n",
      "19008: loss=0.069, reward_mean=0.430, reward_bound=0.349, batch=223\n",
      "19009: loss=0.073, reward_mean=0.510, reward_bound=0.413, batch=226\n",
      "19010: loss=0.072, reward_mean=0.410, reward_bound=0.308, batch=228\n",
      "19011: loss=0.072, reward_mean=0.450, reward_bound=0.387, batch=228\n",
      "19012: loss=0.068, reward_mean=0.490, reward_bound=0.430, batch=216\n",
      "19013: loss=0.068, reward_mean=0.420, reward_bound=0.268, batch=221\n",
      "19014: loss=0.068, reward_mean=0.380, reward_bound=0.229, batch=224\n",
      "19015: loss=0.066, reward_mean=0.420, reward_bound=0.311, batch=227\n",
      "19016: loss=0.068, reward_mean=0.440, reward_bound=0.314, batch=227\n",
      "19017: loss=0.070, reward_mean=0.430, reward_bound=0.380, batch=229\n",
      "19018: loss=0.070, reward_mean=0.420, reward_bound=0.343, batch=230\n",
      "19019: loss=0.069, reward_mean=0.410, reward_bound=0.387, batch=229\n",
      "19020: loss=0.069, reward_mean=0.550, reward_bound=0.360, batch=230\n",
      "19021: loss=0.068, reward_mean=0.390, reward_bound=0.430, batch=228\n",
      "19022: loss=0.068, reward_mean=0.470, reward_bound=0.435, batch=229\n",
      "19023: loss=0.068, reward_mean=0.540, reward_bound=0.478, batch=231\n",
      "19024: loss=0.064, reward_mean=0.500, reward_bound=0.478, batch=147\n",
      "19025: loss=0.062, reward_mean=0.460, reward_bound=0.089, batch=174\n",
      "19026: loss=0.060, reward_mean=0.460, reward_bound=0.080, batch=191\n",
      "19027: loss=0.058, reward_mean=0.350, reward_bound=0.089, batch=199\n",
      "19028: loss=0.057, reward_mean=0.380, reward_bound=0.122, batch=200\n",
      "19029: loss=0.060, reward_mean=0.400, reward_bound=0.135, batch=209\n",
      "19030: loss=0.061, reward_mean=0.410, reward_bound=0.167, batch=212\n",
      "19031: loss=0.064, reward_mean=0.500, reward_bound=0.206, batch=222\n",
      "19032: loss=0.064, reward_mean=0.390, reward_bound=0.206, batch=229\n",
      "19033: loss=0.058, reward_mean=0.470, reward_bound=0.229, batch=217\n",
      "19034: loss=0.057, reward_mean=0.410, reward_bound=0.245, batch=222\n",
      "19035: loss=0.061, reward_mean=0.440, reward_bound=0.254, batch=213\n",
      "19036: loss=0.061, reward_mean=0.380, reward_bound=0.254, batch=218\n",
      "19037: loss=0.062, reward_mean=0.450, reward_bound=0.254, batch=221\n",
      "19038: loss=0.065, reward_mean=0.560, reward_bound=0.282, batch=214\n",
      "19039: loss=0.067, reward_mean=0.450, reward_bound=0.314, batch=204\n",
      "19040: loss=0.064, reward_mean=0.550, reward_bound=0.311, batch=213\n",
      "19041: loss=0.067, reward_mean=0.440, reward_bound=0.220, batch=219\n",
      "19042: loss=0.064, reward_mean=0.530, reward_bound=0.229, batch=222\n",
      "19043: loss=0.065, reward_mean=0.440, reward_bound=0.292, batch=225\n",
      "19044: loss=0.066, reward_mean=0.560, reward_bound=0.314, batch=226\n",
      "19045: loss=0.067, reward_mean=0.340, reward_bound=0.349, batch=201\n",
      "19046: loss=0.069, reward_mean=0.480, reward_bound=0.229, batch=209\n",
      "19047: loss=0.070, reward_mean=0.450, reward_bound=0.239, batch=216\n",
      "19048: loss=0.069, reward_mean=0.490, reward_bound=0.268, batch=221\n",
      "19049: loss=0.065, reward_mean=0.450, reward_bound=0.314, batch=219\n",
      "19050: loss=0.064, reward_mean=0.490, reward_bound=0.295, batch=223\n",
      "19051: loss=0.067, reward_mean=0.460, reward_bound=0.314, batch=223\n",
      "19052: loss=0.066, reward_mean=0.430, reward_bound=0.349, batch=219\n",
      "19053: loss=0.066, reward_mean=0.480, reward_bound=0.295, batch=223\n",
      "19054: loss=0.066, reward_mean=0.420, reward_bound=0.282, batch=225\n",
      "19055: loss=0.065, reward_mean=0.520, reward_bound=0.321, batch=227\n",
      "19056: loss=0.065, reward_mean=0.440, reward_bound=0.349, batch=226\n",
      "19057: loss=0.064, reward_mean=0.520, reward_bound=0.351, batch=228\n",
      "19058: loss=0.065, reward_mean=0.490, reward_bound=0.387, batch=205\n",
      "19059: loss=0.065, reward_mean=0.450, reward_bound=0.199, batch=213\n",
      "19060: loss=0.062, reward_mean=0.480, reward_bound=0.301, batch=219\n",
      "19061: loss=0.063, reward_mean=0.480, reward_bound=0.314, batch=220\n",
      "19062: loss=0.062, reward_mean=0.400, reward_bound=0.314, batch=223\n",
      "19063: loss=0.065, reward_mean=0.410, reward_bound=0.349, batch=220\n",
      "19064: loss=0.064, reward_mean=0.400, reward_bound=0.282, batch=223\n",
      "19065: loss=0.063, reward_mean=0.400, reward_bound=0.282, batch=225\n",
      "19066: loss=0.063, reward_mean=0.480, reward_bound=0.356, batch=227\n",
      "19067: loss=0.065, reward_mean=0.520, reward_bound=0.342, batch=229\n",
      "19068: loss=0.065, reward_mean=0.400, reward_bound=0.349, batch=229\n",
      "19069: loss=0.067, reward_mean=0.460, reward_bound=0.387, batch=229\n",
      "19070: loss=0.060, reward_mean=0.460, reward_bound=0.430, batch=193\n",
      "19071: loss=0.064, reward_mean=0.450, reward_bound=0.101, batch=205\n",
      "19072: loss=0.055, reward_mean=0.500, reward_bound=0.167, batch=211\n",
      "19073: loss=0.061, reward_mean=0.360, reward_bound=0.206, batch=216\n",
      "19074: loss=0.057, reward_mean=0.440, reward_bound=0.268, batch=221\n",
      "19075: loss=0.057, reward_mean=0.410, reward_bound=0.282, batch=222\n",
      "19076: loss=0.058, reward_mean=0.450, reward_bound=0.314, batch=221\n",
      "19077: loss=0.058, reward_mean=0.510, reward_bound=0.349, batch=215\n",
      "19078: loss=0.057, reward_mean=0.370, reward_bound=0.229, batch=219\n",
      "19079: loss=0.056, reward_mean=0.440, reward_bound=0.328, batch=223\n",
      "19080: loss=0.058, reward_mean=0.470, reward_bound=0.349, batch=223\n",
      "19081: loss=0.057, reward_mean=0.410, reward_bound=0.322, batch=226\n",
      "19082: loss=0.058, reward_mean=0.460, reward_bound=0.368, batch=228\n",
      "19083: loss=0.057, reward_mean=0.470, reward_bound=0.387, batch=220\n",
      "19084: loss=0.056, reward_mean=0.540, reward_bound=0.304, batch=224\n",
      "19085: loss=0.056, reward_mean=0.470, reward_bound=0.349, batch=225\n",
      "19086: loss=0.056, reward_mean=0.370, reward_bound=0.387, batch=226\n",
      "19087: loss=0.057, reward_mean=0.480, reward_bound=0.430, batch=213\n",
      "19088: loss=0.058, reward_mean=0.420, reward_bound=0.271, batch=219\n",
      "19089: loss=0.058, reward_mean=0.420, reward_bound=0.265, batch=223\n",
      "19090: loss=0.058, reward_mean=0.440, reward_bound=0.314, batch=225\n",
      "19091: loss=0.059, reward_mean=0.430, reward_bound=0.349, batch=224\n",
      "19092: loss=0.060, reward_mean=0.420, reward_bound=0.380, batch=227\n",
      "19093: loss=0.057, reward_mean=0.410, reward_bound=0.387, batch=223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19094: loss=0.056, reward_mean=0.500, reward_bound=0.372, batch=226\n",
      "19095: loss=0.055, reward_mean=0.460, reward_bound=0.430, batch=224\n",
      "19096: loss=0.055, reward_mean=0.460, reward_bound=0.422, batch=227\n",
      "19097: loss=0.055, reward_mean=0.420, reward_bound=0.430, batch=227\n",
      "19098: loss=0.056, reward_mean=0.500, reward_bound=0.380, batch=229\n",
      "19099: loss=0.054, reward_mean=0.420, reward_bound=0.387, batch=229\n",
      "19100: loss=0.054, reward_mean=0.450, reward_bound=0.430, batch=229\n",
      "19101: loss=0.054, reward_mean=0.510, reward_bound=0.405, batch=230\n",
      "19102: loss=0.054, reward_mean=0.480, reward_bound=0.464, batch=231\n",
      "19103: loss=0.054, reward_mean=0.390, reward_bound=0.282, batch=231\n",
      "19104: loss=0.054, reward_mean=0.430, reward_bound=0.430, batch=231\n",
      "19105: loss=0.061, reward_mean=0.550, reward_bound=0.478, batch=180\n",
      "19106: loss=0.057, reward_mean=0.460, reward_bound=0.118, batch=196\n",
      "19107: loss=0.058, reward_mean=0.410, reward_bound=0.136, batch=207\n",
      "19108: loss=0.061, reward_mean=0.450, reward_bound=0.182, batch=215\n",
      "19109: loss=0.061, reward_mean=0.520, reward_bound=0.194, batch=220\n",
      "19110: loss=0.059, reward_mean=0.440, reward_bound=0.254, batch=221\n",
      "19111: loss=0.059, reward_mean=0.430, reward_bound=0.282, batch=217\n",
      "19112: loss=0.063, reward_mean=0.350, reward_bound=0.314, batch=212\n",
      "19113: loss=0.066, reward_mean=0.410, reward_bound=0.282, batch=216\n",
      "19114: loss=0.066, reward_mean=0.380, reward_bound=0.298, batch=221\n",
      "19115: loss=0.063, reward_mean=0.370, reward_bound=0.349, batch=213\n",
      "19116: loss=0.065, reward_mean=0.500, reward_bound=0.349, batch=218\n",
      "19117: loss=0.064, reward_mean=0.510, reward_bound=0.387, batch=208\n",
      "19118: loss=0.065, reward_mean=0.490, reward_bound=0.254, batch=213\n",
      "19119: loss=0.066, reward_mean=0.370, reward_bound=0.204, batch=219\n",
      "19120: loss=0.065, reward_mean=0.490, reward_bound=0.282, batch=219\n",
      "19121: loss=0.066, reward_mean=0.410, reward_bound=0.295, batch=223\n",
      "19122: loss=0.065, reward_mean=0.500, reward_bound=0.314, batch=225\n",
      "19123: loss=0.065, reward_mean=0.490, reward_bound=0.349, batch=226\n",
      "19124: loss=0.065, reward_mean=0.450, reward_bound=0.387, batch=222\n",
      "19125: loss=0.064, reward_mean=0.420, reward_bound=0.400, batch=225\n",
      "19126: loss=0.063, reward_mean=0.490, reward_bound=0.430, batch=208\n",
      "19127: loss=0.064, reward_mean=0.430, reward_bound=0.317, batch=215\n",
      "19128: loss=0.063, reward_mean=0.490, reward_bound=0.349, batch=218\n",
      "19129: loss=0.062, reward_mean=0.460, reward_bound=0.317, batch=222\n",
      "19130: loss=0.062, reward_mean=0.470, reward_bound=0.349, batch=223\n",
      "19131: loss=0.064, reward_mean=0.480, reward_bound=0.372, batch=226\n",
      "19132: loss=0.065, reward_mean=0.430, reward_bound=0.387, batch=225\n",
      "19133: loss=0.064, reward_mean=0.460, reward_bound=0.396, batch=227\n",
      "19134: loss=0.065, reward_mean=0.470, reward_bound=0.422, batch=229\n",
      "19135: loss=0.062, reward_mean=0.470, reward_bound=0.430, batch=218\n",
      "19136: loss=0.064, reward_mean=0.340, reward_bound=0.231, batch=222\n",
      "19137: loss=0.062, reward_mean=0.380, reward_bound=0.314, batch=224\n",
      "19138: loss=0.062, reward_mean=0.500, reward_bound=0.314, batch=226\n",
      "19139: loss=0.061, reward_mean=0.450, reward_bound=0.368, batch=228\n",
      "19140: loss=0.061, reward_mean=0.470, reward_bound=0.387, batch=228\n",
      "19141: loss=0.065, reward_mean=0.450, reward_bound=0.430, batch=226\n",
      "19142: loss=0.064, reward_mean=0.460, reward_bound=0.478, batch=196\n",
      "19143: loss=0.063, reward_mean=0.430, reward_bound=0.186, batch=207\n",
      "19144: loss=0.060, reward_mean=0.400, reward_bound=0.229, batch=214\n",
      "19145: loss=0.060, reward_mean=0.490, reward_bound=0.254, batch=216\n",
      "19146: loss=0.062, reward_mean=0.490, reward_bound=0.298, batch=221\n",
      "19147: loss=0.061, reward_mean=0.460, reward_bound=0.314, batch=219\n",
      "19148: loss=0.060, reward_mean=0.470, reward_bound=0.309, batch=223\n",
      "19149: loss=0.063, reward_mean=0.480, reward_bound=0.349, batch=217\n",
      "19150: loss=0.063, reward_mean=0.410, reward_bound=0.249, batch=222\n",
      "19151: loss=0.062, reward_mean=0.410, reward_bound=0.292, batch=225\n",
      "19152: loss=0.064, reward_mean=0.550, reward_bound=0.289, batch=227\n",
      "19153: loss=0.064, reward_mean=0.460, reward_bound=0.308, batch=229\n",
      "19154: loss=0.062, reward_mean=0.430, reward_bound=0.349, batch=227\n",
      "19155: loss=0.062, reward_mean=0.390, reward_bound=0.380, batch=229\n",
      "19156: loss=0.063, reward_mean=0.370, reward_bound=0.387, batch=220\n",
      "19157: loss=0.062, reward_mean=0.470, reward_bound=0.365, batch=224\n",
      "19158: loss=0.063, reward_mean=0.400, reward_bound=0.282, batch=226\n",
      "19159: loss=0.064, reward_mean=0.450, reward_bound=0.314, batch=227\n",
      "19160: loss=0.062, reward_mean=0.480, reward_bound=0.387, batch=226\n",
      "19161: loss=0.064, reward_mean=0.430, reward_bound=0.368, batch=228\n",
      "19162: loss=0.063, reward_mean=0.490, reward_bound=0.430, batch=216\n",
      "19163: loss=0.061, reward_mean=0.440, reward_bound=0.331, batch=221\n",
      "19164: loss=0.061, reward_mean=0.560, reward_bound=0.314, batch=224\n",
      "19165: loss=0.062, reward_mean=0.570, reward_bound=0.349, batch=226\n",
      "19166: loss=0.062, reward_mean=0.460, reward_bound=0.387, batch=225\n",
      "19167: loss=0.062, reward_mean=0.610, reward_bound=0.356, batch=227\n",
      "19168: loss=0.062, reward_mean=0.440, reward_bound=0.387, batch=227\n",
      "19169: loss=0.061, reward_mean=0.440, reward_bound=0.430, batch=224\n",
      "19170: loss=0.060, reward_mean=0.470, reward_bound=0.345, batch=227\n",
      "19171: loss=0.060, reward_mean=0.440, reward_bound=0.422, batch=229\n",
      "19172: loss=0.060, reward_mean=0.350, reward_bound=0.450, batch=230\n",
      "19173: loss=0.062, reward_mean=0.500, reward_bound=0.478, batch=213\n",
      "19174: loss=0.064, reward_mean=0.510, reward_bound=0.229, batch=218\n",
      "19175: loss=0.067, reward_mean=0.420, reward_bound=0.317, batch=222\n",
      "19176: loss=0.066, reward_mean=0.470, reward_bound=0.324, batch=225\n",
      "19177: loss=0.067, reward_mean=0.330, reward_bound=0.349, batch=224\n",
      "19178: loss=0.069, reward_mean=0.460, reward_bound=0.387, batch=222\n",
      "19179: loss=0.068, reward_mean=0.320, reward_bound=0.360, batch=225\n",
      "19180: loss=0.068, reward_mean=0.400, reward_bound=0.387, batch=225\n",
      "19181: loss=0.064, reward_mean=0.420, reward_bound=0.430, batch=221\n",
      "19182: loss=0.064, reward_mean=0.510, reward_bound=0.314, batch=224\n",
      "19183: loss=0.065, reward_mean=0.490, reward_bound=0.311, batch=227\n",
      "19184: loss=0.067, reward_mean=0.380, reward_bound=0.314, batch=228\n",
      "19185: loss=0.065, reward_mean=0.490, reward_bound=0.387, batch=227\n",
      "19186: loss=0.064, reward_mean=0.430, reward_bound=0.414, batch=229\n",
      "19187: loss=0.064, reward_mean=0.380, reward_bound=0.430, batch=225\n",
      "19188: loss=0.064, reward_mean=0.450, reward_bound=0.430, batch=226\n",
      "19189: loss=0.063, reward_mean=0.430, reward_bound=0.349, batch=227\n",
      "19190: loss=0.064, reward_mean=0.490, reward_bound=0.277, batch=229\n",
      "19191: loss=0.064, reward_mean=0.430, reward_bound=0.349, batch=229\n",
      "19192: loss=0.065, reward_mean=0.480, reward_bound=0.405, batch=230\n",
      "19193: loss=0.065, reward_mean=0.420, reward_bound=0.387, batch=230\n",
      "19194: loss=0.063, reward_mean=0.540, reward_bound=0.430, batch=230\n",
      "19195: loss=0.064, reward_mean=0.490, reward_bound=0.464, batch=231\n",
      "19196: loss=0.064, reward_mean=0.440, reward_bound=0.430, batch=231\n",
      "19197: loss=0.064, reward_mean=0.400, reward_bound=0.430, batch=231\n",
      "19198: loss=0.062, reward_mean=0.420, reward_bound=0.478, batch=222\n",
      "19199: loss=0.063, reward_mean=0.500, reward_bound=0.363, batch=225\n",
      "19200: loss=0.062, reward_mean=0.380, reward_bound=0.430, batch=226\n",
      "19201: loss=0.062, reward_mean=0.460, reward_bound=0.409, batch=228\n",
      "19202: loss=0.063, reward_mean=0.450, reward_bound=0.357, batch=229\n",
      "19203: loss=0.062, reward_mean=0.480, reward_bound=0.450, batch=230\n",
      "19204: loss=0.063, reward_mean=0.420, reward_bound=0.464, batch=231\n",
      "19205: loss=0.062, reward_mean=0.460, reward_bound=0.478, batch=226\n",
      "19206: loss=0.062, reward_mean=0.500, reward_bound=0.430, batch=226\n",
      "19207: loss=0.062, reward_mean=0.510, reward_bound=0.433, batch=228\n",
      "19208: loss=0.062, reward_mean=0.440, reward_bound=0.478, batch=230\n",
      "19209: loss=0.062, reward_mean=0.470, reward_bound=0.365, batch=231\n",
      "19210: loss=0.061, reward_mean=0.420, reward_bound=0.387, batch=231\n",
      "19211: loss=0.062, reward_mean=0.400, reward_bound=0.478, batch=228\n",
      "19212: loss=0.062, reward_mean=0.380, reward_bound=0.430, batch=228\n",
      "19213: loss=0.063, reward_mean=0.500, reward_bound=0.435, batch=229\n",
      "19214: loss=0.065, reward_mean=0.450, reward_bound=0.450, batch=230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19215: loss=0.063, reward_mean=0.490, reward_bound=0.515, batch=231\n",
      "19216: loss=0.063, reward_mean=0.470, reward_bound=0.430, batch=231\n",
      "19217: loss=0.063, reward_mean=0.460, reward_bound=0.478, batch=231\n",
      "19219: loss=0.061, reward_mean=0.510, reward_bound=0.000, batch=51\n",
      "19220: loss=0.067, reward_mean=0.500, reward_bound=0.000, batch=101\n",
      "19221: loss=0.067, reward_mean=0.490, reward_bound=0.002, batch=140\n",
      "19222: loss=0.066, reward_mean=0.500, reward_bound=0.008, batch=168\n",
      "19223: loss=0.069, reward_mean=0.430, reward_bound=0.017, batch=187\n",
      "19224: loss=0.074, reward_mean=0.430, reward_bound=0.028, batch=196\n",
      "19225: loss=0.077, reward_mean=0.420, reward_bound=0.038, batch=206\n",
      "19226: loss=0.071, reward_mean=0.390, reward_bound=0.047, batch=212\n",
      "19227: loss=0.069, reward_mean=0.470, reward_bound=0.058, batch=215\n",
      "19228: loss=0.070, reward_mean=0.440, reward_bound=0.073, batch=220\n",
      "19229: loss=0.072, reward_mean=0.390, reward_bound=0.089, batch=216\n",
      "19230: loss=0.076, reward_mean=0.480, reward_bound=0.109, batch=217\n",
      "19231: loss=0.082, reward_mean=0.410, reward_bound=0.122, batch=215\n",
      "19232: loss=0.083, reward_mean=0.440, reward_bound=0.135, batch=218\n",
      "19233: loss=0.080, reward_mean=0.430, reward_bound=0.150, batch=213\n",
      "19234: loss=0.079, reward_mean=0.420, reward_bound=0.167, batch=205\n",
      "19235: loss=0.083, reward_mean=0.410, reward_bound=0.185, batch=191\n",
      "19236: loss=0.083, reward_mean=0.450, reward_bound=0.206, batch=179\n",
      "19237: loss=0.084, reward_mean=0.350, reward_bound=0.089, batch=194\n",
      "19238: loss=0.084, reward_mean=0.360, reward_bound=0.164, batch=206\n",
      "19239: loss=0.086, reward_mean=0.500, reward_bound=0.206, batch=208\n",
      "19240: loss=0.081, reward_mean=0.480, reward_bound=0.229, batch=185\n",
      "19241: loss=0.079, reward_mean=0.410, reward_bound=0.153, batch=199\n",
      "19242: loss=0.077, reward_mean=0.500, reward_bound=0.185, batch=208\n",
      "19243: loss=0.077, reward_mean=0.400, reward_bound=0.231, batch=215\n",
      "19244: loss=0.083, reward_mean=0.490, reward_bound=0.254, batch=179\n",
      "19245: loss=0.082, reward_mean=0.450, reward_bound=0.157, batch=195\n",
      "19246: loss=0.080, reward_mean=0.470, reward_bound=0.124, batch=206\n",
      "19247: loss=0.082, reward_mean=0.510, reward_bound=0.185, batch=210\n",
      "19248: loss=0.085, reward_mean=0.440, reward_bound=0.180, batch=217\n",
      "19249: loss=0.084, reward_mean=0.380, reward_bound=0.206, batch=217\n",
      "19250: loss=0.083, reward_mean=0.470, reward_bound=0.229, batch=216\n",
      "19251: loss=0.083, reward_mean=0.470, reward_bound=0.254, batch=213\n",
      "19252: loss=0.081, reward_mean=0.470, reward_bound=0.282, batch=185\n",
      "19253: loss=0.082, reward_mean=0.470, reward_bound=0.229, batch=198\n",
      "19254: loss=0.082, reward_mean=0.450, reward_bound=0.229, batch=206\n",
      "19255: loss=0.082, reward_mean=0.400, reward_bound=0.206, batch=211\n",
      "19256: loss=0.079, reward_mean=0.460, reward_bound=0.254, batch=216\n",
      "19257: loss=0.081, reward_mean=0.370, reward_bound=0.268, batch=221\n",
      "19258: loss=0.082, reward_mean=0.420, reward_bound=0.282, batch=223\n",
      "19259: loss=0.079, reward_mean=0.400, reward_bound=0.314, batch=163\n",
      "19260: loss=0.079, reward_mean=0.440, reward_bound=0.109, batch=183\n",
      "19261: loss=0.080, reward_mean=0.410, reward_bound=0.130, batch=198\n",
      "19262: loss=0.077, reward_mean=0.540, reward_bound=0.150, batch=207\n",
      "19263: loss=0.075, reward_mean=0.450, reward_bound=0.185, batch=211\n",
      "19264: loss=0.076, reward_mean=0.470, reward_bound=0.229, batch=211\n",
      "19265: loss=0.076, reward_mean=0.500, reward_bound=0.254, batch=206\n",
      "19266: loss=0.077, reward_mean=0.420, reward_bound=0.254, batch=213\n",
      "19267: loss=0.077, reward_mean=0.430, reward_bound=0.244, batch=219\n",
      "19268: loss=0.076, reward_mean=0.500, reward_bound=0.254, batch=222\n",
      "19269: loss=0.077, reward_mean=0.410, reward_bound=0.282, batch=213\n",
      "19270: loss=0.076, reward_mean=0.390, reward_bound=0.254, batch=218\n",
      "19271: loss=0.074, reward_mean=0.420, reward_bound=0.314, batch=214\n",
      "19272: loss=0.075, reward_mean=0.440, reward_bound=0.280, batch=220\n",
      "19273: loss=0.074, reward_mean=0.500, reward_bound=0.304, batch=224\n",
      "19274: loss=0.074, reward_mean=0.420, reward_bound=0.314, batch=222\n",
      "19275: loss=0.075, reward_mean=0.490, reward_bound=0.324, batch=225\n",
      "19276: loss=0.076, reward_mean=0.380, reward_bound=0.349, batch=168\n",
      "19277: loss=0.073, reward_mean=0.440, reward_bound=0.112, batch=187\n",
      "19278: loss=0.072, reward_mean=0.470, reward_bound=0.147, batch=201\n",
      "19279: loss=0.071, reward_mean=0.500, reward_bound=0.167, batch=210\n",
      "19280: loss=0.068, reward_mean=0.400, reward_bound=0.185, batch=216\n",
      "19281: loss=0.068, reward_mean=0.450, reward_bound=0.206, batch=216\n",
      "19282: loss=0.071, reward_mean=0.470, reward_bound=0.229, batch=216\n",
      "19283: loss=0.070, reward_mean=0.440, reward_bound=0.282, batch=209\n",
      "19284: loss=0.070, reward_mean=0.350, reward_bound=0.295, batch=216\n",
      "19285: loss=0.070, reward_mean=0.560, reward_bound=0.314, batch=213\n",
      "19286: loss=0.070, reward_mean=0.500, reward_bound=0.335, batch=219\n",
      "19287: loss=0.072, reward_mean=0.510, reward_bound=0.349, batch=210\n",
      "19288: loss=0.071, reward_mean=0.400, reward_bound=0.349, batch=215\n",
      "19289: loss=0.072, reward_mean=0.390, reward_bound=0.314, batch=219\n",
      "19290: loss=0.073, reward_mean=0.440, reward_bound=0.328, batch=223\n",
      "19291: loss=0.072, reward_mean=0.370, reward_bound=0.322, batch=226\n",
      "19292: loss=0.071, reward_mean=0.450, reward_bound=0.387, batch=146\n",
      "19293: loss=0.066, reward_mean=0.440, reward_bound=0.084, batch=172\n",
      "19294: loss=0.070, reward_mean=0.500, reward_bound=0.098, batch=184\n",
      "19295: loss=0.076, reward_mean=0.540, reward_bound=0.150, batch=198\n",
      "19296: loss=0.071, reward_mean=0.500, reward_bound=0.167, batch=206\n",
      "19297: loss=0.073, reward_mean=0.420, reward_bound=0.206, batch=209\n",
      "19298: loss=0.071, reward_mean=0.380, reward_bound=0.229, batch=207\n",
      "19299: loss=0.072, reward_mean=0.520, reward_bound=0.254, batch=202\n",
      "19300: loss=0.070, reward_mean=0.520, reward_bound=0.263, batch=211\n",
      "19301: loss=0.071, reward_mean=0.380, reward_bound=0.254, batch=217\n",
      "19302: loss=0.074, reward_mean=0.490, reward_bound=0.282, batch=206\n",
      "19303: loss=0.077, reward_mean=0.410, reward_bound=0.217, batch=214\n",
      "19304: loss=0.075, reward_mean=0.430, reward_bound=0.252, batch=220\n",
      "19305: loss=0.080, reward_mean=0.460, reward_bound=0.314, batch=215\n",
      "19306: loss=0.080, reward_mean=0.410, reward_bound=0.314, batch=218\n",
      "19307: loss=0.077, reward_mean=0.460, reward_bound=0.349, batch=197\n",
      "19308: loss=0.076, reward_mean=0.400, reward_bound=0.150, batch=207\n",
      "19309: loss=0.076, reward_mean=0.390, reward_bound=0.206, batch=213\n",
      "19310: loss=0.076, reward_mean=0.450, reward_bound=0.198, batch=219\n",
      "19311: loss=0.077, reward_mean=0.410, reward_bound=0.239, batch=223\n",
      "19312: loss=0.076, reward_mean=0.450, reward_bound=0.282, batch=220\n",
      "19313: loss=0.076, reward_mean=0.400, reward_bound=0.314, batch=217\n",
      "19314: loss=0.077, reward_mean=0.360, reward_bound=0.277, batch=222\n",
      "19315: loss=0.076, reward_mean=0.460, reward_bound=0.220, batch=225\n",
      "19316: loss=0.075, reward_mean=0.410, reward_bound=0.289, batch=227\n",
      "19317: loss=0.076, reward_mean=0.410, reward_bound=0.349, batch=219\n",
      "19318: loss=0.078, reward_mean=0.340, reward_bound=0.239, batch=223\n",
      "19319: loss=0.077, reward_mean=0.500, reward_bound=0.314, batch=225\n",
      "19320: loss=0.075, reward_mean=0.510, reward_bound=0.349, batch=226\n",
      "19321: loss=0.075, reward_mean=0.480, reward_bound=0.316, batch=228\n",
      "19322: loss=0.074, reward_mean=0.460, reward_bound=0.317, batch=229\n",
      "19323: loss=0.076, reward_mean=0.410, reward_bound=0.387, batch=205\n",
      "19324: loss=0.077, reward_mean=0.470, reward_bound=0.210, batch=213\n",
      "19325: loss=0.079, reward_mean=0.320, reward_bound=0.178, batch=219\n",
      "19326: loss=0.078, reward_mean=0.450, reward_bound=0.282, batch=222\n",
      "19327: loss=0.078, reward_mean=0.470, reward_bound=0.245, batch=225\n",
      "19328: loss=0.077, reward_mean=0.570, reward_bound=0.314, batch=220\n",
      "19329: loss=0.077, reward_mean=0.480, reward_bound=0.349, batch=222\n",
      "19330: loss=0.078, reward_mean=0.390, reward_bound=0.387, batch=217\n",
      "19331: loss=0.078, reward_mean=0.410, reward_bound=0.308, batch=222\n",
      "19332: loss=0.078, reward_mean=0.490, reward_bound=0.387, batch=224\n",
      "19333: loss=0.067, reward_mean=0.520, reward_bound=0.430, batch=122\n",
      "19334: loss=0.060, reward_mean=0.410, reward_bound=0.008, batch=155\n",
      "19335: loss=0.068, reward_mean=0.490, reward_bound=0.038, batch=176\n",
      "19336: loss=0.058, reward_mean=0.530, reward_bound=0.076, batch=193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19337: loss=0.058, reward_mean=0.470, reward_bound=0.095, batch=205\n",
      "19338: loss=0.063, reward_mean=0.480, reward_bound=0.122, batch=209\n",
      "19339: loss=0.062, reward_mean=0.430, reward_bound=0.135, batch=211\n",
      "19340: loss=0.065, reward_mean=0.440, reward_bound=0.150, batch=210\n",
      "19341: loss=0.067, reward_mean=0.500, reward_bound=0.185, batch=204\n",
      "19342: loss=0.065, reward_mean=0.460, reward_bound=0.185, batch=211\n",
      "19343: loss=0.059, reward_mean=0.470, reward_bound=0.206, batch=208\n",
      "19344: loss=0.054, reward_mean=0.400, reward_bound=0.229, batch=208\n",
      "19345: loss=0.057, reward_mean=0.420, reward_bound=0.254, batch=206\n",
      "19346: loss=0.057, reward_mean=0.420, reward_bound=0.254, batch=213\n",
      "19347: loss=0.056, reward_mean=0.510, reward_bound=0.254, batch=218\n",
      "19348: loss=0.056, reward_mean=0.480, reward_bound=0.282, batch=208\n",
      "19349: loss=0.055, reward_mean=0.410, reward_bound=0.229, batch=211\n",
      "19350: loss=0.059, reward_mean=0.550, reward_bound=0.314, batch=199\n",
      "19351: loss=0.059, reward_mean=0.410, reward_bound=0.174, batch=209\n",
      "19352: loss=0.058, reward_mean=0.480, reward_bound=0.229, batch=215\n",
      "19353: loss=0.056, reward_mean=0.370, reward_bound=0.254, batch=215\n",
      "19354: loss=0.056, reward_mean=0.400, reward_bound=0.282, batch=216\n",
      "19355: loss=0.056, reward_mean=0.430, reward_bound=0.206, batch=220\n",
      "19356: loss=0.060, reward_mean=0.540, reward_bound=0.282, batch=223\n",
      "19357: loss=0.059, reward_mean=0.380, reward_bound=0.314, batch=221\n",
      "19358: loss=0.060, reward_mean=0.440, reward_bound=0.282, batch=223\n",
      "19359: loss=0.059, reward_mean=0.460, reward_bound=0.335, batch=226\n",
      "19360: loss=0.064, reward_mean=0.450, reward_bound=0.349, batch=201\n",
      "19361: loss=0.063, reward_mean=0.420, reward_bound=0.254, batch=210\n",
      "19362: loss=0.064, reward_mean=0.410, reward_bound=0.274, batch=217\n",
      "19363: loss=0.064, reward_mean=0.480, reward_bound=0.282, batch=219\n",
      "19364: loss=0.065, reward_mean=0.500, reward_bound=0.295, batch=223\n",
      "19365: loss=0.064, reward_mean=0.460, reward_bound=0.301, batch=226\n",
      "19366: loss=0.062, reward_mean=0.440, reward_bound=0.314, batch=221\n",
      "19367: loss=0.064, reward_mean=0.420, reward_bound=0.314, batch=224\n",
      "19368: loss=0.065, reward_mean=0.360, reward_bound=0.282, batch=226\n",
      "19369: loss=0.067, reward_mean=0.510, reward_bound=0.349, batch=224\n",
      "19370: loss=0.066, reward_mean=0.390, reward_bound=0.387, batch=187\n",
      "19371: loss=0.062, reward_mean=0.430, reward_bound=0.144, batch=201\n",
      "19372: loss=0.060, reward_mean=0.420, reward_bound=0.185, batch=209\n",
      "19373: loss=0.060, reward_mean=0.510, reward_bound=0.206, batch=215\n",
      "19374: loss=0.060, reward_mean=0.410, reward_bound=0.254, batch=215\n",
      "19375: loss=0.061, reward_mean=0.400, reward_bound=0.282, batch=217\n",
      "19376: loss=0.062, reward_mean=0.480, reward_bound=0.314, batch=218\n",
      "19377: loss=0.063, reward_mean=0.540, reward_bound=0.286, batch=222\n",
      "19378: loss=0.062, reward_mean=0.470, reward_bound=0.324, batch=225\n",
      "19379: loss=0.061, reward_mean=0.450, reward_bound=0.349, batch=218\n",
      "19380: loss=0.061, reward_mean=0.420, reward_bound=0.282, batch=221\n",
      "19381: loss=0.060, reward_mean=0.440, reward_bound=0.314, batch=224\n",
      "19382: loss=0.060, reward_mean=0.430, reward_bound=0.349, batch=226\n",
      "19383: loss=0.062, reward_mean=0.470, reward_bound=0.331, batch=228\n",
      "19384: loss=0.061, reward_mean=0.380, reward_bound=0.349, batch=227\n",
      "19385: loss=0.065, reward_mean=0.470, reward_bound=0.387, batch=208\n",
      "19386: loss=0.064, reward_mean=0.470, reward_bound=0.231, batch=215\n",
      "19387: loss=0.062, reward_mean=0.410, reward_bound=0.254, batch=218\n",
      "19388: loss=0.061, reward_mean=0.390, reward_bound=0.282, batch=221\n",
      "19389: loss=0.062, reward_mean=0.400, reward_bound=0.314, batch=219\n",
      "19390: loss=0.062, reward_mean=0.500, reward_bound=0.309, batch=223\n",
      "19391: loss=0.064, reward_mean=0.410, reward_bound=0.349, batch=221\n",
      "19392: loss=0.064, reward_mean=0.420, reward_bound=0.314, batch=224\n",
      "19393: loss=0.063, reward_mean=0.460, reward_bound=0.349, batch=226\n",
      "19394: loss=0.062, reward_mean=0.460, reward_bound=0.387, batch=221\n",
      "19395: loss=0.062, reward_mean=0.430, reward_bound=0.314, batch=224\n",
      "19396: loss=0.064, reward_mean=0.470, reward_bound=0.349, batch=224\n",
      "19397: loss=0.064, reward_mean=0.410, reward_bound=0.345, batch=227\n",
      "19398: loss=0.065, reward_mean=0.460, reward_bound=0.349, batch=226\n",
      "19399: loss=0.064, reward_mean=0.480, reward_bound=0.387, batch=225\n",
      "19400: loss=0.063, reward_mean=0.390, reward_bound=0.337, batch=227\n",
      "19401: loss=0.064, reward_mean=0.410, reward_bound=0.430, batch=178\n",
      "19402: loss=0.059, reward_mean=0.480, reward_bound=0.100, batch=194\n",
      "19403: loss=0.062, reward_mean=0.470, reward_bound=0.149, batch=206\n",
      "19404: loss=0.061, reward_mean=0.400, reward_bound=0.135, batch=213\n",
      "19405: loss=0.063, reward_mean=0.450, reward_bound=0.167, batch=216\n",
      "19406: loss=0.064, reward_mean=0.470, reward_bound=0.196, batch=221\n",
      "19407: loss=0.064, reward_mean=0.470, reward_bound=0.254, batch=218\n",
      "19408: loss=0.064, reward_mean=0.500, reward_bound=0.282, batch=217\n",
      "19409: loss=0.064, reward_mean=0.420, reward_bound=0.277, batch=222\n",
      "19410: loss=0.062, reward_mean=0.410, reward_bound=0.314, batch=213\n",
      "19411: loss=0.063, reward_mean=0.470, reward_bound=0.301, batch=219\n",
      "19412: loss=0.062, reward_mean=0.380, reward_bound=0.328, batch=223\n",
      "19413: loss=0.065, reward_mean=0.430, reward_bound=0.349, batch=213\n",
      "19414: loss=0.067, reward_mean=0.490, reward_bound=0.314, batch=218\n",
      "19415: loss=0.067, reward_mean=0.450, reward_bound=0.314, batch=221\n",
      "19416: loss=0.067, reward_mean=0.440, reward_bound=0.349, batch=221\n",
      "19417: loss=0.063, reward_mean=0.450, reward_bound=0.387, batch=208\n",
      "19418: loss=0.065, reward_mean=0.430, reward_bound=0.137, batch=215\n",
      "19419: loss=0.060, reward_mean=0.490, reward_bound=0.254, batch=218\n",
      "19420: loss=0.062, reward_mean=0.520, reward_bound=0.286, batch=222\n",
      "19421: loss=0.063, reward_mean=0.510, reward_bound=0.324, batch=225\n",
      "19422: loss=0.065, reward_mean=0.430, reward_bound=0.349, batch=222\n",
      "19423: loss=0.067, reward_mean=0.490, reward_bound=0.387, batch=221\n",
      "19424: loss=0.068, reward_mean=0.460, reward_bound=0.349, batch=224\n",
      "19425: loss=0.068, reward_mean=0.440, reward_bound=0.254, batch=226\n",
      "19426: loss=0.069, reward_mean=0.380, reward_bound=0.349, batch=226\n",
      "19427: loss=0.070, reward_mean=0.400, reward_bound=0.314, batch=227\n",
      "19428: loss=0.070, reward_mean=0.520, reward_bound=0.308, batch=229\n",
      "19429: loss=0.068, reward_mean=0.440, reward_bound=0.430, batch=204\n",
      "19430: loss=0.066, reward_mean=0.390, reward_bound=0.134, batch=213\n",
      "19431: loss=0.068, reward_mean=0.360, reward_bound=0.150, batch=218\n",
      "19432: loss=0.070, reward_mean=0.440, reward_bound=0.169, batch=222\n",
      "19433: loss=0.067, reward_mean=0.380, reward_bound=0.229, batch=222\n",
      "19434: loss=0.066, reward_mean=0.460, reward_bound=0.282, batch=224\n",
      "19435: loss=0.067, reward_mean=0.530, reward_bound=0.314, batch=223\n",
      "19436: loss=0.066, reward_mean=0.500, reward_bound=0.349, batch=220\n",
      "19437: loss=0.065, reward_mean=0.500, reward_bound=0.376, batch=224\n",
      "19438: loss=0.067, reward_mean=0.470, reward_bound=0.387, batch=219\n",
      "19439: loss=0.066, reward_mean=0.420, reward_bound=0.314, batch=222\n",
      "19440: loss=0.065, reward_mean=0.500, reward_bound=0.302, batch=225\n",
      "19441: loss=0.068, reward_mean=0.440, reward_bound=0.349, batch=224\n",
      "19442: loss=0.068, reward_mean=0.420, reward_bound=0.384, batch=227\n",
      "19443: loss=0.067, reward_mean=0.430, reward_bound=0.387, batch=228\n",
      "19444: loss=0.067, reward_mean=0.460, reward_bound=0.392, batch=229\n",
      "19445: loss=0.070, reward_mean=0.470, reward_bound=0.430, batch=218\n",
      "19446: loss=0.069, reward_mean=0.430, reward_bound=0.289, batch=222\n",
      "19447: loss=0.068, reward_mean=0.470, reward_bound=0.324, batch=225\n",
      "19448: loss=0.069, reward_mean=0.430, reward_bound=0.349, batch=223\n",
      "19449: loss=0.071, reward_mean=0.490, reward_bound=0.387, batch=224\n",
      "19450: loss=0.072, reward_mean=0.360, reward_bound=0.345, batch=227\n",
      "19451: loss=0.070, reward_mean=0.460, reward_bound=0.387, batch=228\n",
      "19452: loss=0.070, reward_mean=0.450, reward_bound=0.357, batch=229\n",
      "19453: loss=0.069, reward_mean=0.390, reward_bound=0.430, batch=224\n",
      "19454: loss=0.069, reward_mean=0.520, reward_bound=0.426, batch=227\n",
      "19455: loss=0.070, reward_mean=0.440, reward_bound=0.422, batch=229\n",
      "19456: loss=0.069, reward_mean=0.440, reward_bound=0.430, batch=227\n",
      "19457: loss=0.061, reward_mean=0.430, reward_bound=0.478, batch=102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19458: loss=0.055, reward_mean=0.470, reward_bound=0.024, batch=141\n",
      "19459: loss=0.061, reward_mean=0.420, reward_bound=0.031, batch=168\n",
      "19460: loss=0.060, reward_mean=0.470, reward_bound=0.052, batch=186\n",
      "19461: loss=0.064, reward_mean=0.410, reward_bound=0.065, batch=198\n",
      "19462: loss=0.063, reward_mean=0.450, reward_bound=0.089, batch=207\n",
      "19463: loss=0.065, reward_mean=0.410, reward_bound=0.098, batch=214\n",
      "19464: loss=0.067, reward_mean=0.430, reward_bound=0.122, batch=215\n",
      "19465: loss=0.060, reward_mean=0.420, reward_bound=0.135, batch=218\n",
      "19466: loss=0.056, reward_mean=0.420, reward_bound=0.150, batch=216\n",
      "19467: loss=0.054, reward_mean=0.500, reward_bound=0.167, batch=220\n",
      "19468: loss=0.053, reward_mean=0.530, reward_bound=0.185, batch=221\n",
      "19469: loss=0.053, reward_mean=0.440, reward_bound=0.206, batch=208\n",
      "19470: loss=0.052, reward_mean=0.460, reward_bound=0.229, batch=200\n",
      "19471: loss=0.052, reward_mean=0.570, reward_bound=0.254, batch=200\n",
      "19472: loss=0.055, reward_mean=0.350, reward_bound=0.175, batch=210\n",
      "19473: loss=0.055, reward_mean=0.440, reward_bound=0.185, batch=216\n",
      "19474: loss=0.054, reward_mean=0.430, reward_bound=0.229, batch=220\n",
      "19475: loss=0.053, reward_mean=0.440, reward_bound=0.282, batch=206\n",
      "19476: loss=0.055, reward_mean=0.410, reward_bound=0.284, batch=214\n",
      "19477: loss=0.056, reward_mean=0.440, reward_bound=0.229, batch=219\n",
      "19478: loss=0.055, reward_mean=0.490, reward_bound=0.265, batch=223\n",
      "19479: loss=0.059, reward_mean=0.520, reward_bound=0.314, batch=189\n",
      "19480: loss=0.059, reward_mean=0.400, reward_bound=0.114, batch=202\n",
      "19481: loss=0.056, reward_mean=0.400, reward_bound=0.145, batch=211\n",
      "19482: loss=0.057, reward_mean=0.430, reward_bound=0.206, batch=216\n",
      "19483: loss=0.056, reward_mean=0.440, reward_bound=0.229, batch=218\n",
      "19484: loss=0.057, reward_mean=0.480, reward_bound=0.282, batch=217\n",
      "19485: loss=0.058, reward_mean=0.470, reward_bound=0.249, batch=222\n",
      "19486: loss=0.057, reward_mean=0.420, reward_bound=0.314, batch=223\n",
      "19487: loss=0.059, reward_mean=0.520, reward_bound=0.349, batch=194\n",
      "19488: loss=0.057, reward_mean=0.490, reward_bound=0.252, batch=206\n",
      "19489: loss=0.056, reward_mean=0.500, reward_bound=0.217, batch=214\n",
      "19490: loss=0.055, reward_mean=0.440, reward_bound=0.254, batch=217\n",
      "19491: loss=0.054, reward_mean=0.450, reward_bound=0.308, batch=222\n",
      "19492: loss=0.057, reward_mean=0.460, reward_bound=0.314, batch=221\n",
      "19493: loss=0.058, reward_mean=0.440, reward_bound=0.254, batch=223\n",
      "19494: loss=0.058, reward_mean=0.400, reward_bound=0.314, batch=225\n",
      "19495: loss=0.058, reward_mean=0.440, reward_bound=0.349, batch=218\n",
      "19496: loss=0.062, reward_mean=0.480, reward_bound=0.387, batch=179\n",
      "19497: loss=0.068, reward_mean=0.490, reward_bound=0.174, batch=195\n",
      "19498: loss=0.062, reward_mean=0.500, reward_bound=0.206, batch=205\n",
      "19499: loss=0.061, reward_mean=0.440, reward_bound=0.210, batch=213\n",
      "19500: loss=0.060, reward_mean=0.520, reward_bound=0.254, batch=213\n",
      "19501: loss=0.062, reward_mean=0.500, reward_bound=0.271, batch=219\n",
      "19502: loss=0.062, reward_mean=0.470, reward_bound=0.265, batch=223\n",
      "19503: loss=0.062, reward_mean=0.520, reward_bound=0.282, batch=221\n",
      "19504: loss=0.061, reward_mean=0.460, reward_bound=0.314, batch=220\n",
      "19505: loss=0.061, reward_mean=0.450, reward_bound=0.349, batch=217\n",
      "19506: loss=0.063, reward_mean=0.480, reward_bound=0.308, batch=222\n",
      "19507: loss=0.062, reward_mean=0.590, reward_bound=0.324, batch=225\n",
      "19508: loss=0.062, reward_mean=0.380, reward_bound=0.349, batch=223\n",
      "19509: loss=0.063, reward_mean=0.460, reward_bound=0.301, batch=226\n",
      "19510: loss=0.063, reward_mean=0.510, reward_bound=0.331, batch=228\n",
      "19511: loss=0.063, reward_mean=0.420, reward_bound=0.349, batch=228\n",
      "19512: loss=0.061, reward_mean=0.400, reward_bound=0.387, batch=212\n",
      "19513: loss=0.060, reward_mean=0.400, reward_bound=0.324, batch=218\n",
      "19514: loss=0.059, reward_mean=0.420, reward_bound=0.282, batch=221\n",
      "19515: loss=0.059, reward_mean=0.330, reward_bound=0.254, batch=224\n",
      "19516: loss=0.058, reward_mean=0.480, reward_bound=0.311, batch=227\n",
      "19517: loss=0.059, reward_mean=0.520, reward_bound=0.349, batch=228\n",
      "19518: loss=0.059, reward_mean=0.400, reward_bound=0.321, batch=229\n",
      "19519: loss=0.060, reward_mean=0.390, reward_bound=0.387, batch=225\n",
      "19520: loss=0.064, reward_mean=0.510, reward_bound=0.430, batch=167\n",
      "19521: loss=0.060, reward_mean=0.360, reward_bound=0.109, batch=188\n",
      "19522: loss=0.058, reward_mean=0.480, reward_bound=0.150, batch=200\n",
      "19523: loss=0.060, reward_mean=0.400, reward_bound=0.167, batch=202\n",
      "19524: loss=0.060, reward_mean=0.370, reward_bound=0.172, batch=211\n",
      "19525: loss=0.058, reward_mean=0.390, reward_bound=0.229, batch=208\n",
      "19526: loss=0.056, reward_mean=0.480, reward_bound=0.185, batch=214\n",
      "19527: loss=0.056, reward_mean=0.440, reward_bound=0.229, batch=219\n",
      "19528: loss=0.059, reward_mean=0.440, reward_bound=0.254, batch=212\n",
      "19529: loss=0.057, reward_mean=0.460, reward_bound=0.254, batch=216\n",
      "19530: loss=0.062, reward_mean=0.400, reward_bound=0.282, batch=210\n",
      "19531: loss=0.065, reward_mean=0.460, reward_bound=0.222, batch=217\n",
      "19532: loss=0.063, reward_mean=0.520, reward_bound=0.308, batch=222\n",
      "19533: loss=0.062, reward_mean=0.430, reward_bound=0.314, batch=217\n",
      "19534: loss=0.061, reward_mean=0.520, reward_bound=0.254, batch=221\n",
      "19535: loss=0.061, reward_mean=0.500, reward_bound=0.314, batch=223\n",
      "19536: loss=0.062, reward_mean=0.410, reward_bound=0.349, batch=208\n",
      "19537: loss=0.060, reward_mean=0.410, reward_bound=0.208, batch=215\n",
      "19538: loss=0.062, reward_mean=0.460, reward_bound=0.321, batch=220\n",
      "19539: loss=0.061, reward_mean=0.370, reward_bound=0.320, batch=224\n",
      "19540: loss=0.061, reward_mean=0.560, reward_bound=0.349, batch=223\n",
      "19541: loss=0.060, reward_mean=0.450, reward_bound=0.335, batch=226\n",
      "19542: loss=0.060, reward_mean=0.420, reward_bound=0.349, batch=227\n",
      "19543: loss=0.065, reward_mean=0.490, reward_bound=0.387, batch=198\n",
      "19544: loss=0.067, reward_mean=0.450, reward_bound=0.206, batch=207\n",
      "19545: loss=0.067, reward_mean=0.360, reward_bound=0.249, batch=215\n",
      "19546: loss=0.066, reward_mean=0.460, reward_bound=0.254, batch=217\n",
      "19547: loss=0.072, reward_mean=0.480, reward_bound=0.282, batch=220\n",
      "19548: loss=0.070, reward_mean=0.500, reward_bound=0.338, batch=224\n",
      "19549: loss=0.068, reward_mean=0.460, reward_bound=0.349, batch=224\n",
      "19550: loss=0.068, reward_mean=0.460, reward_bound=0.387, batch=220\n",
      "19551: loss=0.069, reward_mean=0.390, reward_bound=0.418, batch=224\n",
      "19552: loss=0.070, reward_mean=0.490, reward_bound=0.275, batch=227\n",
      "19553: loss=0.071, reward_mean=0.540, reward_bound=0.387, batch=228\n",
      "19554: loss=0.067, reward_mean=0.440, reward_bound=0.430, batch=201\n",
      "19555: loss=0.064, reward_mean=0.490, reward_bound=0.229, batch=210\n",
      "19556: loss=0.065, reward_mean=0.550, reward_bound=0.282, batch=211\n",
      "19557: loss=0.065, reward_mean=0.390, reward_bound=0.282, batch=215\n",
      "19558: loss=0.063, reward_mean=0.380, reward_bound=0.314, batch=216\n",
      "19559: loss=0.062, reward_mean=0.420, reward_bound=0.298, batch=221\n",
      "19560: loss=0.062, reward_mean=0.390, reward_bound=0.314, batch=222\n",
      "19561: loss=0.062, reward_mean=0.420, reward_bound=0.349, batch=223\n",
      "19562: loss=0.062, reward_mean=0.460, reward_bound=0.314, batch=225\n",
      "19563: loss=0.061, reward_mean=0.410, reward_bound=0.356, batch=227\n",
      "19564: loss=0.064, reward_mean=0.380, reward_bound=0.387, batch=223\n",
      "19565: loss=0.063, reward_mean=0.460, reward_bound=0.372, batch=226\n",
      "19566: loss=0.063, reward_mean=0.500, reward_bound=0.331, batch=228\n",
      "19567: loss=0.063, reward_mean=0.480, reward_bound=0.387, batch=225\n",
      "19568: loss=0.066, reward_mean=0.430, reward_bound=0.430, batch=215\n",
      "19569: loss=0.064, reward_mean=0.390, reward_bound=0.321, batch=220\n",
      "19570: loss=0.063, reward_mean=0.380, reward_bound=0.304, batch=224\n",
      "19571: loss=0.067, reward_mean=0.480, reward_bound=0.349, batch=223\n",
      "19572: loss=0.066, reward_mean=0.470, reward_bound=0.372, batch=226\n",
      "19573: loss=0.070, reward_mean=0.430, reward_bound=0.387, batch=227\n",
      "19574: loss=0.070, reward_mean=0.490, reward_bound=0.380, batch=229\n",
      "19575: loss=0.069, reward_mean=0.400, reward_bound=0.405, batch=230\n",
      "19576: loss=0.067, reward_mean=0.450, reward_bound=0.430, batch=224\n",
      "19577: loss=0.066, reward_mean=0.370, reward_bound=0.422, batch=227\n",
      "19578: loss=0.066, reward_mean=0.440, reward_bound=0.422, batch=229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19579: loss=0.066, reward_mean=0.450, reward_bound=0.430, batch=228\n",
      "19580: loss=0.066, reward_mean=0.490, reward_bound=0.435, batch=229\n",
      "19581: loss=0.067, reward_mean=0.450, reward_bound=0.401, batch=230\n",
      "19582: loss=0.062, reward_mean=0.500, reward_bound=0.478, batch=157\n",
      "19583: loss=0.052, reward_mean=0.460, reward_bound=0.072, batch=179\n",
      "19584: loss=0.057, reward_mean=0.440, reward_bound=0.089, batch=194\n",
      "19585: loss=0.063, reward_mean=0.440, reward_bound=0.122, batch=205\n",
      "19586: loss=0.066, reward_mean=0.400, reward_bound=0.150, batch=211\n",
      "19587: loss=0.063, reward_mean=0.480, reward_bound=0.167, batch=216\n",
      "19588: loss=0.061, reward_mean=0.510, reward_bound=0.196, batch=221\n",
      "19589: loss=0.068, reward_mean=0.570, reward_bound=0.229, batch=218\n",
      "19590: loss=0.064, reward_mean=0.440, reward_bound=0.254, batch=213\n",
      "19591: loss=0.068, reward_mean=0.460, reward_bound=0.282, batch=210\n",
      "19592: loss=0.072, reward_mean=0.410, reward_bound=0.247, batch=217\n",
      "19593: loss=0.070, reward_mean=0.370, reward_bound=0.302, batch=222\n",
      "19594: loss=0.066, reward_mean=0.450, reward_bound=0.314, batch=213\n",
      "19595: loss=0.066, reward_mean=0.420, reward_bound=0.349, batch=203\n",
      "19596: loss=0.067, reward_mean=0.440, reward_bound=0.271, batch=212\n",
      "19597: loss=0.066, reward_mean=0.400, reward_bound=0.282, batch=217\n",
      "19598: loss=0.064, reward_mean=0.470, reward_bound=0.277, batch=222\n",
      "19599: loss=0.065, reward_mean=0.370, reward_bound=0.292, batch=225\n",
      "19600: loss=0.068, reward_mean=0.440, reward_bound=0.314, batch=221\n",
      "19601: loss=0.065, reward_mean=0.380, reward_bound=0.349, batch=217\n",
      "19602: loss=0.064, reward_mean=0.500, reward_bound=0.373, batch=222\n",
      "19603: loss=0.063, reward_mean=0.450, reward_bound=0.349, batch=224\n",
      "19604: loss=0.064, reward_mean=0.480, reward_bound=0.280, batch=227\n",
      "19605: loss=0.065, reward_mean=0.500, reward_bound=0.387, batch=199\n",
      "19606: loss=0.065, reward_mean=0.420, reward_bound=0.229, batch=205\n",
      "19607: loss=0.062, reward_mean=0.440, reward_bound=0.194, batch=213\n",
      "19608: loss=0.063, reward_mean=0.410, reward_bound=0.244, batch=219\n",
      "19609: loss=0.064, reward_mean=0.390, reward_bound=0.254, batch=221\n",
      "19610: loss=0.065, reward_mean=0.350, reward_bound=0.282, batch=223\n",
      "19611: loss=0.065, reward_mean=0.440, reward_bound=0.290, batch=226\n",
      "19612: loss=0.064, reward_mean=0.440, reward_bound=0.314, batch=221\n",
      "19613: loss=0.064, reward_mean=0.530, reward_bound=0.349, batch=217\n",
      "19614: loss=0.064, reward_mean=0.390, reward_bound=0.195, batch=222\n",
      "19615: loss=0.068, reward_mean=0.450, reward_bound=0.254, batch=224\n",
      "19616: loss=0.066, reward_mean=0.460, reward_bound=0.314, batch=224\n",
      "19617: loss=0.066, reward_mean=0.490, reward_bound=0.282, batch=225\n",
      "19618: loss=0.066, reward_mean=0.490, reward_bound=0.349, batch=226\n",
      "19619: loss=0.066, reward_mean=0.380, reward_bound=0.349, batch=227\n",
      "19620: loss=0.066, reward_mean=0.450, reward_bound=0.387, batch=218\n",
      "19621: loss=0.069, reward_mean=0.400, reward_bound=0.317, batch=222\n",
      "19622: loss=0.067, reward_mean=0.480, reward_bound=0.400, batch=225\n",
      "19623: loss=0.068, reward_mean=0.470, reward_bound=0.349, batch=226\n",
      "19624: loss=0.067, reward_mean=0.520, reward_bound=0.409, batch=228\n",
      "19625: loss=0.065, reward_mean=0.400, reward_bound=0.430, batch=197\n",
      "19626: loss=0.066, reward_mean=0.420, reward_bound=0.158, batch=208\n",
      "19627: loss=0.066, reward_mean=0.440, reward_bound=0.124, batch=215\n",
      "19628: loss=0.066, reward_mean=0.430, reward_bound=0.189, batch=220\n",
      "19629: loss=0.063, reward_mean=0.420, reward_bound=0.229, batch=223\n",
      "19630: loss=0.063, reward_mean=0.390, reward_bound=0.229, batch=224\n",
      "19631: loss=0.066, reward_mean=0.470, reward_bound=0.311, batch=227\n",
      "19632: loss=0.066, reward_mean=0.470, reward_bound=0.314, batch=225\n",
      "19633: loss=0.063, reward_mean=0.370, reward_bound=0.349, batch=223\n",
      "19634: loss=0.062, reward_mean=0.410, reward_bound=0.314, batch=225\n",
      "19635: loss=0.063, reward_mean=0.470, reward_bound=0.356, batch=227\n",
      "19636: loss=0.063, reward_mean=0.430, reward_bound=0.308, batch=229\n",
      "19637: loss=0.062, reward_mean=0.380, reward_bound=0.295, batch=230\n",
      "19638: loss=0.064, reward_mean=0.500, reward_bound=0.387, batch=220\n",
      "19639: loss=0.066, reward_mean=0.410, reward_bound=0.254, batch=223\n",
      "19640: loss=0.065, reward_mean=0.380, reward_bound=0.206, batch=225\n",
      "19641: loss=0.065, reward_mean=0.430, reward_bound=0.314, batch=225\n",
      "19642: loss=0.066, reward_mean=0.430, reward_bound=0.321, batch=227\n",
      "19643: loss=0.066, reward_mean=0.590, reward_bound=0.387, batch=226\n",
      "19644: loss=0.066, reward_mean=0.370, reward_bound=0.387, batch=227\n",
      "19645: loss=0.067, reward_mean=0.520, reward_bound=0.430, batch=218\n",
      "19646: loss=0.067, reward_mean=0.550, reward_bound=0.353, batch=222\n",
      "19647: loss=0.067, reward_mean=0.460, reward_bound=0.324, batch=225\n",
      "19648: loss=0.070, reward_mean=0.450, reward_bound=0.387, batch=226\n",
      "19649: loss=0.069, reward_mean=0.430, reward_bound=0.409, batch=228\n",
      "19650: loss=0.066, reward_mean=0.450, reward_bound=0.430, batch=223\n",
      "19651: loss=0.066, reward_mean=0.390, reward_bound=0.430, batch=224\n",
      "19652: loss=0.067, reward_mean=0.510, reward_bound=0.384, batch=227\n",
      "19653: loss=0.067, reward_mean=0.450, reward_bound=0.349, batch=228\n",
      "19654: loss=0.066, reward_mean=0.430, reward_bound=0.321, batch=229\n",
      "19655: loss=0.066, reward_mean=0.430, reward_bound=0.430, batch=226\n",
      "19656: loss=0.065, reward_mean=0.500, reward_bound=0.409, batch=228\n",
      "19657: loss=0.066, reward_mean=0.500, reward_bound=0.430, batch=226\n",
      "19658: loss=0.065, reward_mean=0.460, reward_bound=0.390, batch=228\n",
      "19659: loss=0.065, reward_mean=0.520, reward_bound=0.435, batch=229\n",
      "19660: loss=0.065, reward_mean=0.460, reward_bound=0.405, batch=230\n",
      "19661: loss=0.066, reward_mean=0.470, reward_bound=0.376, batch=231\n",
      "19662: loss=0.065, reward_mean=0.450, reward_bound=0.430, batch=231\n",
      "19663: loss=0.065, reward_mean=0.460, reward_bound=0.478, batch=182\n",
      "19664: loss=0.067, reward_mean=0.450, reward_bound=0.167, batch=194\n",
      "19665: loss=0.064, reward_mean=0.500, reward_bound=0.122, batch=204\n",
      "19666: loss=0.062, reward_mean=0.470, reward_bound=0.150, batch=210\n",
      "19667: loss=0.066, reward_mean=0.510, reward_bound=0.200, batch=217\n",
      "19668: loss=0.068, reward_mean=0.460, reward_bound=0.206, batch=221\n",
      "19669: loss=0.065, reward_mean=0.480, reward_bound=0.254, batch=220\n",
      "19670: loss=0.065, reward_mean=0.430, reward_bound=0.282, batch=223\n",
      "19671: loss=0.066, reward_mean=0.410, reward_bound=0.301, batch=226\n",
      "19672: loss=0.065, reward_mean=0.470, reward_bound=0.314, batch=223\n",
      "19673: loss=0.065, reward_mean=0.640, reward_bound=0.349, batch=221\n",
      "19674: loss=0.065, reward_mean=0.510, reward_bound=0.314, batch=224\n",
      "19675: loss=0.064, reward_mean=0.460, reward_bound=0.280, batch=227\n",
      "19676: loss=0.065, reward_mean=0.480, reward_bound=0.349, batch=228\n",
      "19677: loss=0.063, reward_mean=0.390, reward_bound=0.387, batch=217\n",
      "19678: loss=0.062, reward_mean=0.350, reward_bound=0.282, batch=221\n",
      "19679: loss=0.062, reward_mean=0.500, reward_bound=0.314, batch=222\n",
      "19680: loss=0.063, reward_mean=0.530, reward_bound=0.387, batch=224\n",
      "19681: loss=0.066, reward_mean=0.480, reward_bound=0.430, batch=209\n",
      "19682: loss=0.069, reward_mean=0.450, reward_bound=0.167, batch=215\n",
      "19683: loss=0.071, reward_mean=0.390, reward_bound=0.206, batch=219\n",
      "19684: loss=0.067, reward_mean=0.370, reward_bound=0.229, batch=222\n",
      "19685: loss=0.065, reward_mean=0.420, reward_bound=0.292, batch=225\n",
      "19686: loss=0.069, reward_mean=0.450, reward_bound=0.349, batch=222\n",
      "19687: loss=0.070, reward_mean=0.440, reward_bound=0.302, batch=225\n",
      "19688: loss=0.066, reward_mean=0.420, reward_bound=0.387, batch=224\n",
      "19689: loss=0.067, reward_mean=0.510, reward_bound=0.387, batch=226\n",
      "19690: loss=0.067, reward_mean=0.500, reward_bound=0.387, batch=227\n",
      "19691: loss=0.068, reward_mean=0.420, reward_bound=0.422, batch=229\n",
      "19692: loss=0.067, reward_mean=0.450, reward_bound=0.405, batch=230\n",
      "19693: loss=0.067, reward_mean=0.380, reward_bound=0.418, batch=231\n",
      "19694: loss=0.067, reward_mean=0.500, reward_bound=0.430, batch=219\n",
      "19695: loss=0.066, reward_mean=0.450, reward_bound=0.282, batch=221\n",
      "19696: loss=0.065, reward_mean=0.440, reward_bound=0.349, batch=223\n",
      "19697: loss=0.066, reward_mean=0.490, reward_bound=0.372, batch=226\n",
      "19698: loss=0.068, reward_mean=0.470, reward_bound=0.387, batch=225\n",
      "19699: loss=0.068, reward_mean=0.430, reward_bound=0.396, batch=227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19700: loss=0.067, reward_mean=0.470, reward_bound=0.422, batch=229\n",
      "19701: loss=0.067, reward_mean=0.340, reward_bound=0.430, batch=228\n",
      "19702: loss=0.067, reward_mean=0.430, reward_bound=0.435, batch=229\n",
      "19703: loss=0.067, reward_mean=0.420, reward_bound=0.424, batch=230\n",
      "19704: loss=0.067, reward_mean=0.430, reward_bound=0.406, batch=231\n",
      "19705: loss=0.067, reward_mean=0.470, reward_bound=0.430, batch=230\n",
      "19706: loss=0.067, reward_mean=0.360, reward_bound=0.451, batch=231\n",
      "19707: loss=0.067, reward_mean=0.530, reward_bound=0.430, batch=231\n",
      "19708: loss=0.067, reward_mean=0.360, reward_bound=0.478, batch=202\n",
      "19709: loss=0.069, reward_mean=0.540, reward_bound=0.206, batch=213\n",
      "19710: loss=0.068, reward_mean=0.490, reward_bound=0.244, batch=219\n",
      "19711: loss=0.067, reward_mean=0.430, reward_bound=0.254, batch=222\n",
      "19712: loss=0.067, reward_mean=0.450, reward_bound=0.314, batch=222\n",
      "19713: loss=0.067, reward_mean=0.430, reward_bound=0.314, batch=224\n",
      "19714: loss=0.067, reward_mean=0.470, reward_bound=0.349, batch=223\n",
      "19715: loss=0.068, reward_mean=0.460, reward_bound=0.387, batch=216\n",
      "19716: loss=0.069, reward_mean=0.530, reward_bound=0.268, batch=221\n",
      "19717: loss=0.068, reward_mean=0.340, reward_bound=0.349, batch=223\n",
      "19718: loss=0.068, reward_mean=0.380, reward_bound=0.387, batch=224\n",
      "19719: loss=0.070, reward_mean=0.520, reward_bound=0.345, batch=227\n",
      "19720: loss=0.068, reward_mean=0.500, reward_bound=0.380, batch=229\n",
      "19721: loss=0.068, reward_mean=0.390, reward_bound=0.387, batch=228\n",
      "19722: loss=0.068, reward_mean=0.420, reward_bound=0.387, batch=228\n",
      "19723: loss=0.068, reward_mean=0.440, reward_bound=0.392, batch=229\n",
      "19724: loss=0.070, reward_mean=0.410, reward_bound=0.430, batch=220\n",
      "19725: loss=0.073, reward_mean=0.450, reward_bound=0.338, batch=224\n",
      "19726: loss=0.073, reward_mean=0.500, reward_bound=0.314, batch=226\n",
      "19727: loss=0.072, reward_mean=0.440, reward_bound=0.349, batch=226\n",
      "19728: loss=0.070, reward_mean=0.550, reward_bound=0.387, batch=227\n",
      "19729: loss=0.070, reward_mean=0.430, reward_bound=0.349, batch=228\n",
      "19730: loss=0.070, reward_mean=0.530, reward_bound=0.430, batch=223\n",
      "19731: loss=0.069, reward_mean=0.430, reward_bound=0.459, batch=226\n",
      "19732: loss=0.069, reward_mean=0.500, reward_bound=0.454, batch=228\n",
      "19733: loss=0.068, reward_mean=0.420, reward_bound=0.397, batch=229\n",
      "19734: loss=0.068, reward_mean=0.370, reward_bound=0.450, batch=230\n",
      "19735: loss=0.068, reward_mean=0.440, reward_bound=0.418, batch=231\n",
      "19736: loss=0.068, reward_mean=0.470, reward_bound=0.430, batch=231\n",
      "19737: loss=0.066, reward_mean=0.440, reward_bound=0.478, batch=220\n",
      "19738: loss=0.065, reward_mean=0.360, reward_bound=0.274, batch=224\n",
      "19739: loss=0.067, reward_mean=0.460, reward_bound=0.384, batch=227\n",
      "19740: loss=0.067, reward_mean=0.370, reward_bound=0.342, batch=229\n",
      "19741: loss=0.067, reward_mean=0.560, reward_bound=0.364, batch=230\n",
      "19742: loss=0.068, reward_mean=0.440, reward_bound=0.387, batch=227\n",
      "19743: loss=0.068, reward_mean=0.510, reward_bound=0.430, batch=228\n",
      "19744: loss=0.067, reward_mean=0.400, reward_bound=0.357, batch=229\n",
      "19745: loss=0.068, reward_mean=0.450, reward_bound=0.450, batch=230\n",
      "19746: loss=0.068, reward_mean=0.410, reward_bound=0.464, batch=231\n",
      "19747: loss=0.068, reward_mean=0.380, reward_bound=0.430, batch=231\n",
      "19748: loss=0.068, reward_mean=0.430, reward_bound=0.430, batch=231\n",
      "19749: loss=0.068, reward_mean=0.510, reward_bound=0.387, batch=231\n",
      "19750: loss=0.067, reward_mean=0.390, reward_bound=0.478, batch=225\n",
      "19751: loss=0.066, reward_mean=0.440, reward_bound=0.396, batch=227\n",
      "19752: loss=0.066, reward_mean=0.470, reward_bound=0.422, batch=229\n",
      "19753: loss=0.066, reward_mean=0.450, reward_bound=0.430, batch=227\n",
      "19754: loss=0.067, reward_mean=0.430, reward_bound=0.469, batch=229\n",
      "19755: loss=0.067, reward_mean=0.450, reward_bound=0.478, batch=231\n",
      "19756: loss=0.067, reward_mean=0.440, reward_bound=0.478, batch=229\n",
      "19757: loss=0.067, reward_mean=0.420, reward_bound=0.405, batch=230\n",
      "19758: loss=0.067, reward_mean=0.480, reward_bound=0.430, batch=230\n",
      "19759: loss=0.068, reward_mean=0.370, reward_bound=0.464, batch=231\n",
      "19760: loss=0.068, reward_mean=0.540, reward_bound=0.430, batch=231\n",
      "19761: loss=0.068, reward_mean=0.410, reward_bound=0.349, batch=231\n",
      "19762: loss=0.067, reward_mean=0.490, reward_bound=0.478, batch=230\n",
      "19763: loss=0.067, reward_mean=0.460, reward_bound=0.478, batch=230\n",
      "19764: loss=0.067, reward_mean=0.490, reward_bound=0.418, batch=231\n",
      "19765: loss=0.067, reward_mean=0.390, reward_bound=0.478, batch=231\n",
      "19766: loss=0.067, reward_mean=0.460, reward_bound=0.478, batch=231\n",
      "19768: loss=0.058, reward_mean=0.410, reward_bound=0.000, batch=41\n",
      "19769: loss=0.050, reward_mean=0.470, reward_bound=0.000, batch=88\n",
      "19770: loss=0.050, reward_mean=0.420, reward_bound=0.000, batch=130\n",
      "19771: loss=0.058, reward_mean=0.440, reward_bound=0.002, batch=160\n",
      "19772: loss=0.065, reward_mean=0.470, reward_bound=0.008, batch=181\n",
      "19773: loss=0.063, reward_mean=0.450, reward_bound=0.020, batch=192\n",
      "19774: loss=0.062, reward_mean=0.440, reward_bound=0.038, batch=201\n",
      "19775: loss=0.071, reward_mean=0.480, reward_bound=0.052, batch=210\n",
      "19776: loss=0.069, reward_mean=0.430, reward_bound=0.065, batch=214\n",
      "19777: loss=0.068, reward_mean=0.330, reward_bound=0.080, batch=214\n",
      "19778: loss=0.072, reward_mean=0.510, reward_bound=0.098, batch=210\n",
      "19779: loss=0.074, reward_mean=0.390, reward_bound=0.122, batch=207\n",
      "19780: loss=0.073, reward_mean=0.330, reward_bound=0.135, batch=214\n",
      "19781: loss=0.071, reward_mean=0.420, reward_bound=0.150, batch=209\n",
      "19782: loss=0.069, reward_mean=0.450, reward_bound=0.167, batch=199\n",
      "19783: loss=0.065, reward_mean=0.470, reward_bound=0.185, batch=187\n",
      "19784: loss=0.064, reward_mean=0.400, reward_bound=0.098, batch=200\n",
      "19785: loss=0.066, reward_mean=0.360, reward_bound=0.167, batch=207\n",
      "19786: loss=0.066, reward_mean=0.410, reward_bound=0.167, batch=214\n",
      "19787: loss=0.067, reward_mean=0.420, reward_bound=0.206, batch=202\n",
      "19788: loss=0.064, reward_mean=0.410, reward_bound=0.229, batch=184\n",
      "19789: loss=0.064, reward_mean=0.390, reward_bound=0.134, batch=199\n",
      "19790: loss=0.062, reward_mean=0.460, reward_bound=0.150, batch=205\n",
      "19791: loss=0.062, reward_mean=0.440, reward_bound=0.167, batch=212\n",
      "19792: loss=0.061, reward_mean=0.460, reward_bound=0.206, batch=219\n",
      "19793: loss=0.060, reward_mean=0.430, reward_bound=0.229, batch=219\n",
      "19794: loss=0.063, reward_mean=0.420, reward_bound=0.254, batch=187\n",
      "19795: loss=0.059, reward_mean=0.450, reward_bound=0.132, batch=201\n",
      "19796: loss=0.062, reward_mean=0.470, reward_bound=0.150, batch=209\n",
      "19797: loss=0.061, reward_mean=0.500, reward_bound=0.206, batch=213\n",
      "19798: loss=0.062, reward_mean=0.410, reward_bound=0.229, batch=218\n",
      "19799: loss=0.062, reward_mean=0.390, reward_bound=0.254, batch=219\n",
      "19800: loss=0.064, reward_mean=0.430, reward_bound=0.282, batch=178\n",
      "19801: loss=0.064, reward_mean=0.370, reward_bound=0.089, batch=193\n",
      "19802: loss=0.065, reward_mean=0.410, reward_bound=0.150, batch=202\n",
      "19803: loss=0.061, reward_mean=0.410, reward_bound=0.185, batch=209\n",
      "19804: loss=0.063, reward_mean=0.430, reward_bound=0.206, batch=214\n",
      "19805: loss=0.059, reward_mean=0.540, reward_bound=0.229, batch=218\n",
      "19806: loss=0.060, reward_mean=0.430, reward_bound=0.254, batch=218\n",
      "19807: loss=0.061, reward_mean=0.440, reward_bound=0.282, batch=217\n",
      "19808: loss=0.062, reward_mean=0.310, reward_bound=0.182, batch=222\n",
      "19809: loss=0.061, reward_mean=0.410, reward_bound=0.282, batch=224\n",
      "19810: loss=0.060, reward_mean=0.400, reward_bound=0.314, batch=176\n",
      "19811: loss=0.056, reward_mean=0.440, reward_bound=0.109, batch=192\n",
      "19812: loss=0.057, reward_mean=0.540, reward_bound=0.167, batch=202\n",
      "19813: loss=0.057, reward_mean=0.460, reward_bound=0.206, batch=213\n",
      "19814: loss=0.057, reward_mean=0.430, reward_bound=0.229, batch=212\n",
      "19815: loss=0.058, reward_mean=0.540, reward_bound=0.254, batch=217\n",
      "19816: loss=0.059, reward_mean=0.490, reward_bound=0.282, batch=214\n",
      "19817: loss=0.058, reward_mean=0.420, reward_bound=0.280, batch=220\n",
      "19818: loss=0.058, reward_mean=0.480, reward_bound=0.282, batch=221\n",
      "19819: loss=0.059, reward_mean=0.430, reward_bound=0.282, batch=224\n",
      "19820: loss=0.060, reward_mean=0.420, reward_bound=0.314, batch=221\n",
      "19821: loss=0.054, reward_mean=0.520, reward_bound=0.349, batch=159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19822: loss=0.047, reward_mean=0.390, reward_bound=0.036, batch=181\n",
      "19823: loss=0.055, reward_mean=0.380, reward_bound=0.098, batch=193\n",
      "19824: loss=0.053, reward_mean=0.520, reward_bound=0.185, batch=201\n",
      "19825: loss=0.055, reward_mean=0.360, reward_bound=0.206, batch=201\n",
      "19826: loss=0.054, reward_mean=0.510, reward_bound=0.206, batch=210\n",
      "19827: loss=0.053, reward_mean=0.470, reward_bound=0.229, batch=210\n",
      "19828: loss=0.055, reward_mean=0.490, reward_bound=0.254, batch=207\n",
      "19829: loss=0.052, reward_mean=0.440, reward_bound=0.282, batch=209\n",
      "19830: loss=0.051, reward_mean=0.420, reward_bound=0.157, batch=216\n",
      "19831: loss=0.052, reward_mean=0.410, reward_bound=0.254, batch=219\n",
      "19832: loss=0.052, reward_mean=0.460, reward_bound=0.229, batch=222\n",
      "19833: loss=0.052, reward_mean=0.410, reward_bound=0.254, batch=223\n",
      "19834: loss=0.052, reward_mean=0.450, reward_bound=0.282, batch=225\n",
      "19835: loss=0.055, reward_mean=0.410, reward_bound=0.314, batch=218\n",
      "19836: loss=0.055, reward_mean=0.410, reward_bound=0.260, batch=222\n",
      "19837: loss=0.054, reward_mean=0.350, reward_bound=0.324, batch=225\n",
      "19838: loss=0.053, reward_mean=0.370, reward_bound=0.349, batch=208\n",
      "19839: loss=0.051, reward_mean=0.460, reward_bound=0.206, batch=214\n",
      "19840: loss=0.051, reward_mean=0.420, reward_bound=0.282, batch=219\n",
      "19841: loss=0.050, reward_mean=0.330, reward_bound=0.343, batch=223\n",
      "19842: loss=0.043, reward_mean=0.420, reward_bound=0.387, batch=144\n",
      "19843: loss=0.046, reward_mean=0.420, reward_bound=0.107, batch=171\n",
      "19844: loss=0.044, reward_mean=0.430, reward_bound=0.122, batch=188\n",
      "19845: loss=0.047, reward_mean=0.430, reward_bound=0.150, batch=196\n",
      "19846: loss=0.048, reward_mean=0.480, reward_bound=0.167, batch=205\n",
      "19847: loss=0.051, reward_mean=0.360, reward_bound=0.185, batch=212\n",
      "19848: loss=0.045, reward_mean=0.440, reward_bound=0.229, batch=204\n",
      "19849: loss=0.043, reward_mean=0.500, reward_bound=0.206, batch=212\n",
      "19850: loss=0.043, reward_mean=0.330, reward_bound=0.213, batch=218\n",
      "19851: loss=0.043, reward_mean=0.400, reward_bound=0.254, batch=208\n",
      "19852: loss=0.043, reward_mean=0.470, reward_bound=0.282, batch=209\n",
      "19853: loss=0.042, reward_mean=0.390, reward_bound=0.132, batch=216\n",
      "19854: loss=0.043, reward_mean=0.470, reward_bound=0.206, batch=220\n",
      "19855: loss=0.043, reward_mean=0.500, reward_bound=0.282, batch=222\n",
      "19856: loss=0.042, reward_mean=0.460, reward_bound=0.314, batch=204\n",
      "19857: loss=0.044, reward_mean=0.420, reward_bound=0.206, batch=212\n",
      "19858: loss=0.045, reward_mean=0.470, reward_bound=0.254, batch=217\n",
      "19859: loss=0.043, reward_mean=0.430, reward_bound=0.282, batch=220\n",
      "19860: loss=0.045, reward_mean=0.450, reward_bound=0.243, batch=224\n",
      "19861: loss=0.047, reward_mean=0.480, reward_bound=0.314, batch=222\n",
      "19862: loss=0.050, reward_mean=0.460, reward_bound=0.349, batch=205\n",
      "19863: loss=0.048, reward_mean=0.410, reward_bound=0.289, batch=213\n",
      "19864: loss=0.047, reward_mean=0.460, reward_bound=0.290, batch=219\n",
      "19865: loss=0.047, reward_mean=0.460, reward_bound=0.328, batch=223\n",
      "19866: loss=0.048, reward_mean=0.440, reward_bound=0.314, batch=225\n",
      "19867: loss=0.047, reward_mean=0.450, reward_bound=0.349, batch=223\n",
      "19868: loss=0.046, reward_mean=0.450, reward_bound=0.335, batch=226\n",
      "19869: loss=0.048, reward_mean=0.440, reward_bound=0.331, batch=228\n",
      "19870: loss=0.048, reward_mean=0.400, reward_bound=0.349, batch=227\n",
      "19871: loss=0.048, reward_mean=0.430, reward_bound=0.349, batch=228\n",
      "19872: loss=0.045, reward_mean=0.340, reward_bound=0.387, batch=200\n",
      "19873: loss=0.044, reward_mean=0.460, reward_bound=0.240, batch=210\n",
      "19874: loss=0.042, reward_mean=0.490, reward_bound=0.282, batch=213\n",
      "19875: loss=0.043, reward_mean=0.480, reward_bound=0.282, batch=218\n",
      "19876: loss=0.044, reward_mean=0.440, reward_bound=0.206, batch=221\n",
      "19877: loss=0.042, reward_mean=0.420, reward_bound=0.314, batch=218\n",
      "19878: loss=0.041, reward_mean=0.550, reward_bound=0.314, batch=221\n",
      "19879: loss=0.041, reward_mean=0.390, reward_bound=0.282, batch=224\n",
      "19880: loss=0.042, reward_mean=0.490, reward_bound=0.349, batch=221\n",
      "19881: loss=0.043, reward_mean=0.400, reward_bound=0.349, batch=224\n",
      "19882: loss=0.046, reward_mean=0.430, reward_bound=0.387, batch=219\n",
      "19883: loss=0.045, reward_mean=0.520, reward_bound=0.314, batch=222\n",
      "19884: loss=0.045, reward_mean=0.430, reward_bound=0.387, batch=223\n",
      "19885: loss=0.045, reward_mean=0.410, reward_bound=0.387, batch=225\n",
      "19886: loss=0.046, reward_mean=0.480, reward_bound=0.329, batch=227\n",
      "19887: loss=0.046, reward_mean=0.460, reward_bound=0.422, batch=229\n",
      "19888: loss=0.039, reward_mean=0.470, reward_bound=0.430, batch=118\n",
      "19889: loss=0.035, reward_mean=0.380, reward_bound=0.001, batch=152\n",
      "19890: loss=0.042, reward_mean=0.470, reward_bound=0.029, batch=176\n",
      "19891: loss=0.045, reward_mean=0.420, reward_bound=0.052, batch=191\n",
      "19892: loss=0.051, reward_mean=0.390, reward_bound=0.065, batch=202\n",
      "19893: loss=0.050, reward_mean=0.370, reward_bound=0.080, batch=210\n",
      "19894: loss=0.044, reward_mean=0.440, reward_bound=0.109, batch=215\n",
      "19895: loss=0.044, reward_mean=0.380, reward_bound=0.135, batch=210\n",
      "19896: loss=0.045, reward_mean=0.440, reward_bound=0.167, batch=213\n",
      "19897: loss=0.044, reward_mean=0.380, reward_bound=0.185, batch=212\n",
      "19898: loss=0.044, reward_mean=0.480, reward_bound=0.206, batch=226\n",
      "19899: loss=0.041, reward_mean=0.410, reward_bound=0.206, batch=223\n",
      "19900: loss=0.047, reward_mean=0.420, reward_bound=0.229, batch=217\n",
      "19901: loss=0.048, reward_mean=0.440, reward_bound=0.245, batch=222\n",
      "19902: loss=0.045, reward_mean=0.390, reward_bound=0.254, batch=209\n",
      "19903: loss=0.044, reward_mean=0.380, reward_bound=0.215, batch=216\n",
      "19904: loss=0.043, reward_mean=0.530, reward_bound=0.282, batch=201\n",
      "19905: loss=0.042, reward_mean=0.420, reward_bound=0.229, batch=208\n",
      "19906: loss=0.040, reward_mean=0.380, reward_bound=0.231, batch=215\n",
      "19907: loss=0.043, reward_mean=0.440, reward_bound=0.254, batch=219\n",
      "19908: loss=0.045, reward_mean=0.420, reward_bound=0.282, batch=219\n",
      "19909: loss=0.046, reward_mean=0.430, reward_bound=0.278, batch=223\n",
      "19910: loss=0.049, reward_mean=0.550, reward_bound=0.314, batch=203\n",
      "19911: loss=0.052, reward_mean=0.490, reward_bound=0.244, batch=212\n",
      "19912: loss=0.053, reward_mean=0.380, reward_bound=0.254, batch=216\n",
      "19913: loss=0.051, reward_mean=0.460, reward_bound=0.282, batch=218\n",
      "19914: loss=0.050, reward_mean=0.450, reward_bound=0.314, batch=219\n",
      "19915: loss=0.051, reward_mean=0.370, reward_bound=0.278, batch=223\n",
      "19916: loss=0.049, reward_mean=0.490, reward_bound=0.349, batch=197\n",
      "19917: loss=0.050, reward_mean=0.470, reward_bound=0.185, batch=207\n",
      "19918: loss=0.048, reward_mean=0.450, reward_bound=0.206, batch=213\n",
      "19919: loss=0.045, reward_mean=0.430, reward_bound=0.254, batch=217\n",
      "19920: loss=0.044, reward_mean=0.410, reward_bound=0.277, batch=222\n",
      "19921: loss=0.044, reward_mean=0.470, reward_bound=0.263, batch=225\n",
      "19922: loss=0.045, reward_mean=0.340, reward_bound=0.289, batch=227\n",
      "19923: loss=0.046, reward_mean=0.400, reward_bound=0.314, batch=224\n",
      "19924: loss=0.045, reward_mean=0.390, reward_bound=0.314, batch=226\n",
      "19925: loss=0.050, reward_mean=0.450, reward_bound=0.349, batch=221\n",
      "19926: loss=0.050, reward_mean=0.480, reward_bound=0.387, batch=192\n",
      "19927: loss=0.054, reward_mean=0.390, reward_bound=0.117, batch=204\n",
      "19928: loss=0.053, reward_mean=0.440, reward_bound=0.167, batch=212\n",
      "19929: loss=0.054, reward_mean=0.370, reward_bound=0.191, batch=218\n",
      "19930: loss=0.049, reward_mean=0.510, reward_bound=0.282, batch=216\n",
      "19931: loss=0.048, reward_mean=0.440, reward_bound=0.241, batch=221\n",
      "19932: loss=0.049, reward_mean=0.450, reward_bound=0.314, batch=218\n",
      "19933: loss=0.050, reward_mean=0.320, reward_bound=0.231, batch=222\n",
      "19934: loss=0.049, reward_mean=0.410, reward_bound=0.254, batch=224\n",
      "19935: loss=0.049, reward_mean=0.390, reward_bound=0.314, batch=226\n",
      "19936: loss=0.049, reward_mean=0.410, reward_bound=0.268, batch=228\n",
      "19937: loss=0.050, reward_mean=0.430, reward_bound=0.349, batch=216\n",
      "19938: loss=0.051, reward_mean=0.440, reward_bound=0.349, batch=220\n",
      "19939: loss=0.050, reward_mean=0.420, reward_bound=0.376, batch=224\n",
      "19940: loss=0.050, reward_mean=0.430, reward_bound=0.314, batch=226\n",
      "19941: loss=0.049, reward_mean=0.400, reward_bound=0.331, batch=228\n",
      "19942: loss=0.051, reward_mean=0.420, reward_bound=0.387, batch=213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19943: loss=0.050, reward_mean=0.520, reward_bound=0.282, batch=218\n",
      "19944: loss=0.051, reward_mean=0.480, reward_bound=0.349, batch=220\n",
      "19945: loss=0.051, reward_mean=0.540, reward_bound=0.338, batch=224\n",
      "19946: loss=0.051, reward_mean=0.460, reward_bound=0.387, batch=224\n",
      "19947: loss=0.047, reward_mean=0.550, reward_bound=0.430, batch=171\n",
      "19948: loss=0.043, reward_mean=0.500, reward_bound=0.098, batch=189\n",
      "19949: loss=0.041, reward_mean=0.490, reward_bound=0.157, batch=202\n",
      "19950: loss=0.041, reward_mean=0.450, reward_bound=0.185, batch=208\n",
      "19951: loss=0.046, reward_mean=0.420, reward_bound=0.229, batch=212\n",
      "19952: loss=0.046, reward_mean=0.450, reward_bound=0.191, batch=218\n",
      "19953: loss=0.045, reward_mean=0.410, reward_bound=0.254, batch=212\n",
      "19954: loss=0.044, reward_mean=0.490, reward_bound=0.254, batch=214\n",
      "19955: loss=0.043, reward_mean=0.300, reward_bound=0.280, batch=220\n",
      "19956: loss=0.046, reward_mean=0.450, reward_bound=0.282, batch=222\n",
      "19957: loss=0.050, reward_mean=0.470, reward_bound=0.314, batch=211\n",
      "19958: loss=0.044, reward_mean=0.460, reward_bound=0.349, batch=203\n",
      "19959: loss=0.042, reward_mean=0.470, reward_bound=0.261, batch=212\n",
      "19960: loss=0.041, reward_mean=0.400, reward_bound=0.236, batch=218\n",
      "19961: loss=0.041, reward_mean=0.590, reward_bound=0.314, batch=220\n",
      "19962: loss=0.042, reward_mean=0.420, reward_bound=0.349, batch=217\n",
      "19963: loss=0.043, reward_mean=0.510, reward_bound=0.342, batch=222\n",
      "19964: loss=0.042, reward_mean=0.420, reward_bound=0.229, batch=224\n",
      "19965: loss=0.044, reward_mean=0.450, reward_bound=0.303, batch=227\n",
      "19966: loss=0.044, reward_mean=0.490, reward_bound=0.349, batch=226\n",
      "19967: loss=0.043, reward_mean=0.450, reward_bound=0.387, batch=215\n",
      "19968: loss=0.044, reward_mean=0.470, reward_bound=0.396, batch=220\n",
      "19969: loss=0.043, reward_mean=0.430, reward_bound=0.376, batch=224\n",
      "19970: loss=0.044, reward_mean=0.470, reward_bound=0.311, batch=227\n",
      "19971: loss=0.046, reward_mean=0.460, reward_bound=0.308, batch=229\n",
      "19972: loss=0.044, reward_mean=0.360, reward_bound=0.314, batch=228\n",
      "19973: loss=0.045, reward_mean=0.380, reward_bound=0.387, batch=225\n",
      "19974: loss=0.045, reward_mean=0.450, reward_bound=0.365, batch=227\n",
      "19975: loss=0.044, reward_mean=0.480, reward_bound=0.422, batch=229\n",
      "19976: loss=0.046, reward_mean=0.400, reward_bound=0.430, batch=200\n",
      "19977: loss=0.047, reward_mean=0.450, reward_bound=0.222, batch=210\n",
      "19978: loss=0.046, reward_mean=0.450, reward_bound=0.247, batch=217\n",
      "19979: loss=0.044, reward_mean=0.390, reward_bound=0.254, batch=218\n",
      "19980: loss=0.047, reward_mean=0.440, reward_bound=0.314, batch=214\n",
      "19981: loss=0.049, reward_mean=0.490, reward_bound=0.349, batch=219\n",
      "19982: loss=0.049, reward_mean=0.510, reward_bound=0.328, batch=223\n",
      "19983: loss=0.049, reward_mean=0.480, reward_bound=0.387, batch=221\n",
      "19984: loss=0.049, reward_mean=0.340, reward_bound=0.314, batch=224\n",
      "19985: loss=0.050, reward_mean=0.560, reward_bound=0.349, batch=224\n",
      "19986: loss=0.050, reward_mean=0.450, reward_bound=0.311, batch=227\n",
      "19987: loss=0.051, reward_mean=0.460, reward_bound=0.342, batch=229\n",
      "19988: loss=0.050, reward_mean=0.460, reward_bound=0.349, batch=228\n",
      "19989: loss=0.051, reward_mean=0.500, reward_bound=0.353, batch=229\n",
      "19990: loss=0.050, reward_mean=0.330, reward_bound=0.387, batch=228\n",
      "19991: loss=0.050, reward_mean=0.450, reward_bound=0.392, batch=229\n",
      "19992: loss=0.051, reward_mean=0.390, reward_bound=0.405, batch=230\n",
      "19993: loss=0.051, reward_mean=0.480, reward_bound=0.395, batch=231\n",
      "19994: loss=0.047, reward_mean=0.520, reward_bound=0.430, batch=215\n",
      "19995: loss=0.050, reward_mean=0.380, reward_bound=0.234, batch=220\n",
      "19996: loss=0.050, reward_mean=0.390, reward_bound=0.274, batch=224\n",
      "19997: loss=0.050, reward_mean=0.510, reward_bound=0.345, batch=227\n",
      "19998: loss=0.047, reward_mean=0.540, reward_bound=0.349, batch=226\n",
      "19999: loss=0.048, reward_mean=0.440, reward_bound=0.430, batch=223\n",
      "20000: loss=0.049, reward_mean=0.440, reward_bound=0.335, batch=226\n",
      "20001: loss=0.047, reward_mean=0.380, reward_bound=0.387, batch=227\n",
      "20002: loss=0.047, reward_mean=0.520, reward_bound=0.380, batch=229\n",
      "20003: loss=0.048, reward_mean=0.410, reward_bound=0.405, batch=230\n",
      "20004: loss=0.047, reward_mean=0.470, reward_bound=0.430, batch=226\n",
      "20005: loss=0.047, reward_mean=0.430, reward_bound=0.409, batch=228\n",
      "20006: loss=0.047, reward_mean=0.470, reward_bound=0.392, batch=229\n",
      "20007: loss=0.047, reward_mean=0.460, reward_bound=0.430, batch=228\n",
      "20008: loss=0.047, reward_mean=0.470, reward_bound=0.397, batch=229\n",
      "20009: loss=0.048, reward_mean=0.450, reward_bound=0.405, batch=230\n",
      "20010: loss=0.048, reward_mean=0.400, reward_bound=0.464, batch=231\n",
      "20011: loss=0.043, reward_mean=0.530, reward_bound=0.478, batch=97\n",
      "20012: loss=0.041, reward_mean=0.420, reward_bound=0.001, batch=138\n",
      "20013: loss=0.045, reward_mean=0.410, reward_bound=0.009, batch=166\n",
      "20014: loss=0.049, reward_mean=0.480, reward_bound=0.031, batch=184\n",
      "20015: loss=0.047, reward_mean=0.500, reward_bound=0.052, batch=198\n",
      "20016: loss=0.049, reward_mean=0.410, reward_bound=0.073, batch=208\n",
      "20017: loss=0.054, reward_mean=0.480, reward_bound=0.098, batch=213\n",
      "20018: loss=0.053, reward_mean=0.440, reward_bound=0.122, batch=211\n",
      "20019: loss=0.055, reward_mean=0.380, reward_bound=0.135, batch=216\n",
      "20020: loss=0.060, reward_mean=0.440, reward_bound=0.150, batch=218\n",
      "20021: loss=0.054, reward_mean=0.410, reward_bound=0.167, batch=219\n",
      "20022: loss=0.058, reward_mean=0.480, reward_bound=0.185, batch=221\n",
      "20023: loss=0.056, reward_mean=0.430, reward_bound=0.206, batch=216\n",
      "20024: loss=0.057, reward_mean=0.400, reward_bound=0.229, batch=209\n",
      "20025: loss=0.058, reward_mean=0.450, reward_bound=0.254, batch=195\n",
      "20026: loss=0.058, reward_mean=0.530, reward_bound=0.170, batch=206\n",
      "20027: loss=0.060, reward_mean=0.430, reward_bound=0.217, batch=214\n",
      "20028: loss=0.061, reward_mean=0.440, reward_bound=0.254, batch=215\n",
      "20029: loss=0.057, reward_mean=0.480, reward_bound=0.282, batch=198\n",
      "20030: loss=0.054, reward_mean=0.390, reward_bound=0.112, batch=208\n",
      "20031: loss=0.055, reward_mean=0.420, reward_bound=0.185, batch=214\n",
      "20032: loss=0.057, reward_mean=0.400, reward_bound=0.254, batch=218\n",
      "20033: loss=0.049, reward_mean=0.410, reward_bound=0.314, batch=197\n",
      "20034: loss=0.046, reward_mean=0.460, reward_bound=0.167, batch=206\n",
      "20035: loss=0.048, reward_mean=0.400, reward_bound=0.229, batch=210\n",
      "20036: loss=0.048, reward_mean=0.460, reward_bound=0.247, batch=217\n",
      "20037: loss=0.048, reward_mean=0.530, reward_bound=0.254, batch=220\n",
      "20038: loss=0.050, reward_mean=0.490, reward_bound=0.282, batch=220\n",
      "20039: loss=0.050, reward_mean=0.360, reward_bound=0.314, batch=221\n",
      "20040: loss=0.049, reward_mean=0.410, reward_bound=0.349, batch=187\n",
      "20041: loss=0.048, reward_mean=0.400, reward_bound=0.155, batch=201\n",
      "20042: loss=0.044, reward_mean=0.440, reward_bound=0.206, batch=210\n",
      "20043: loss=0.044, reward_mean=0.440, reward_bound=0.229, batch=212\n",
      "20044: loss=0.046, reward_mean=0.450, reward_bound=0.220, batch=218\n",
      "20045: loss=0.047, reward_mean=0.360, reward_bound=0.254, batch=218\n",
      "20046: loss=0.046, reward_mean=0.500, reward_bound=0.257, batch=222\n",
      "20047: loss=0.048, reward_mean=0.380, reward_bound=0.282, batch=221\n",
      "20048: loss=0.048, reward_mean=0.450, reward_bound=0.282, batch=224\n",
      "20049: loss=0.047, reward_mean=0.450, reward_bound=0.314, batch=221\n",
      "20050: loss=0.048, reward_mean=0.450, reward_bound=0.349, batch=218\n",
      "20051: loss=0.038, reward_mean=0.510, reward_bound=0.387, batch=174\n",
      "20052: loss=0.042, reward_mean=0.430, reward_bound=0.120, batch=192\n",
      "20053: loss=0.041, reward_mean=0.450, reward_bound=0.135, batch=202\n",
      "20054: loss=0.037, reward_mean=0.510, reward_bound=0.185, batch=207\n",
      "20055: loss=0.039, reward_mean=0.440, reward_bound=0.206, batch=208\n",
      "20056: loss=0.038, reward_mean=0.470, reward_bound=0.229, batch=211\n",
      "20057: loss=0.036, reward_mean=0.410, reward_bound=0.254, batch=211\n",
      "20058: loss=0.035, reward_mean=0.370, reward_bound=0.185, batch=217\n",
      "20059: loss=0.037, reward_mean=0.440, reward_bound=0.282, batch=210\n",
      "20060: loss=0.035, reward_mean=0.430, reward_bound=0.314, batch=213\n",
      "20061: loss=0.034, reward_mean=0.490, reward_bound=0.314, batch=216\n",
      "20062: loss=0.035, reward_mean=0.510, reward_bound=0.349, batch=201\n",
      "20063: loss=0.034, reward_mean=0.490, reward_bound=0.254, batch=210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20064: loss=0.032, reward_mean=0.520, reward_bound=0.229, batch=216\n",
      "20065: loss=0.034, reward_mean=0.370, reward_bound=0.254, batch=219\n",
      "20066: loss=0.034, reward_mean=0.470, reward_bound=0.282, batch=221\n",
      "20067: loss=0.033, reward_mean=0.300, reward_bound=0.282, batch=224\n",
      "20068: loss=0.034, reward_mean=0.430, reward_bound=0.314, batch=224\n",
      "20069: loss=0.035, reward_mean=0.390, reward_bound=0.342, batch=227\n",
      "20070: loss=0.037, reward_mean=0.420, reward_bound=0.349, batch=219\n",
      "20071: loss=0.036, reward_mean=0.560, reward_bound=0.282, batch=222\n",
      "20072: loss=0.036, reward_mean=0.340, reward_bound=0.324, batch=225\n",
      "20073: loss=0.037, reward_mean=0.430, reward_bound=0.349, batch=226\n",
      "20074: loss=0.037, reward_mean=0.480, reward_bound=0.368, batch=228\n",
      "20075: loss=0.035, reward_mean=0.490, reward_bound=0.387, batch=214\n",
      "20076: loss=0.037, reward_mean=0.360, reward_bound=0.229, batch=219\n",
      "20077: loss=0.035, reward_mean=0.520, reward_bound=0.349, batch=220\n",
      "20078: loss=0.034, reward_mean=0.430, reward_bound=0.376, batch=224\n",
      "20079: loss=0.034, reward_mean=0.490, reward_bound=0.426, batch=227\n",
      "20080: loss=0.034, reward_mean=0.480, reward_bound=0.414, batch=229\n",
      "20081: loss=0.041, reward_mean=0.440, reward_bound=0.430, batch=174\n",
      "20082: loss=0.042, reward_mean=0.380, reward_bound=0.108, batch=192\n",
      "20083: loss=0.036, reward_mean=0.440, reward_bound=0.150, batch=203\n",
      "20084: loss=0.036, reward_mean=0.410, reward_bound=0.167, batch=209\n",
      "20085: loss=0.039, reward_mean=0.400, reward_bound=0.206, batch=214\n",
      "20086: loss=0.039, reward_mean=0.570, reward_bound=0.254, batch=210\n",
      "20087: loss=0.040, reward_mean=0.470, reward_bound=0.254, batch=215\n",
      "20088: loss=0.041, reward_mean=0.450, reward_bound=0.282, batch=214\n",
      "20089: loss=0.036, reward_mean=0.470, reward_bound=0.314, batch=209\n",
      "20090: loss=0.037, reward_mean=0.470, reward_bound=0.239, batch=216\n",
      "20091: loss=0.036, reward_mean=0.440, reward_bound=0.206, batch=220\n",
      "20092: loss=0.036, reward_mean=0.420, reward_bound=0.282, batch=221\n",
      "20093: loss=0.034, reward_mean=0.480, reward_bound=0.314, batch=224\n",
      "20094: loss=0.035, reward_mean=0.410, reward_bound=0.249, batch=227\n",
      "20095: loss=0.035, reward_mean=0.390, reward_bound=0.349, batch=206\n",
      "20096: loss=0.035, reward_mean=0.440, reward_bound=0.217, batch=214\n",
      "20097: loss=0.035, reward_mean=0.400, reward_bound=0.282, batch=217\n",
      "20098: loss=0.035, reward_mean=0.400, reward_bound=0.308, batch=222\n",
      "20099: loss=0.035, reward_mean=0.480, reward_bound=0.349, batch=221\n",
      "20100: loss=0.037, reward_mean=0.380, reward_bound=0.387, batch=210\n",
      "20101: loss=0.036, reward_mean=0.430, reward_bound=0.247, batch=217\n",
      "20102: loss=0.037, reward_mean=0.470, reward_bound=0.277, batch=222\n",
      "20103: loss=0.037, reward_mean=0.400, reward_bound=0.282, batch=224\n",
      "20104: loss=0.036, reward_mean=0.430, reward_bound=0.311, batch=227\n",
      "20105: loss=0.038, reward_mean=0.560, reward_bound=0.314, batch=228\n",
      "20106: loss=0.039, reward_mean=0.450, reward_bound=0.349, batch=225\n",
      "20107: loss=0.039, reward_mean=0.460, reward_bound=0.356, batch=227\n",
      "20108: loss=0.038, reward_mean=0.400, reward_bound=0.349, batch=228\n",
      "20109: loss=0.037, reward_mean=0.500, reward_bound=0.387, batch=223\n",
      "20110: loss=0.039, reward_mean=0.450, reward_bound=0.349, batch=225\n",
      "20111: loss=0.038, reward_mean=0.440, reward_bound=0.321, batch=227\n",
      "20112: loss=0.038, reward_mean=0.530, reward_bound=0.380, batch=229\n",
      "20113: loss=0.038, reward_mean=0.510, reward_bound=0.324, batch=230\n",
      "20114: loss=0.038, reward_mean=0.450, reward_bound=0.387, batch=229\n",
      "20115: loss=0.037, reward_mean=0.510, reward_bound=0.430, batch=213\n",
      "20116: loss=0.036, reward_mean=0.470, reward_bound=0.271, batch=219\n",
      "20117: loss=0.037, reward_mean=0.460, reward_bound=0.282, batch=222\n",
      "20118: loss=0.039, reward_mean=0.450, reward_bound=0.292, batch=225\n",
      "20119: loss=0.037, reward_mean=0.460, reward_bound=0.349, batch=226\n",
      "20120: loss=0.037, reward_mean=0.490, reward_bound=0.387, batch=224\n",
      "20121: loss=0.039, reward_mean=0.520, reward_bound=0.387, batch=226\n",
      "20122: loss=0.036, reward_mean=0.450, reward_bound=0.430, batch=223\n",
      "20123: loss=0.037, reward_mean=0.450, reward_bound=0.349, batch=225\n",
      "20124: loss=0.037, reward_mean=0.490, reward_bound=0.356, batch=227\n",
      "20125: loss=0.037, reward_mean=0.470, reward_bound=0.387, batch=228\n",
      "20126: loss=0.037, reward_mean=0.400, reward_bound=0.357, batch=229\n",
      "20127: loss=0.037, reward_mean=0.500, reward_bound=0.430, batch=228\n",
      "20128: loss=0.037, reward_mean=0.520, reward_bound=0.397, batch=229\n",
      "20129: loss=0.037, reward_mean=0.420, reward_bound=0.424, batch=230\n",
      "20130: loss=0.037, reward_mean=0.470, reward_bound=0.430, batch=230\n",
      "20131: loss=0.037, reward_mean=0.490, reward_bound=0.282, batch=230\n",
      "20132: loss=0.037, reward_mean=0.420, reward_bound=0.464, batch=231\n",
      "20133: loss=0.037, reward_mean=0.450, reward_bound=0.430, batch=231\n",
      "20134: loss=0.045, reward_mean=0.500, reward_bound=0.478, batch=145\n",
      "20135: loss=0.047, reward_mean=0.500, reward_bound=0.066, batch=171\n",
      "20136: loss=0.046, reward_mean=0.540, reward_bound=0.072, batch=189\n",
      "20137: loss=0.043, reward_mean=0.460, reward_bound=0.122, batch=197\n",
      "20138: loss=0.041, reward_mean=0.490, reward_bound=0.150, batch=206\n",
      "20139: loss=0.037, reward_mean=0.440, reward_bound=0.176, batch=214\n",
      "20140: loss=0.039, reward_mean=0.330, reward_bound=0.185, batch=217\n",
      "20141: loss=0.038, reward_mean=0.570, reward_bound=0.206, batch=221\n",
      "20142: loss=0.037, reward_mean=0.400, reward_bound=0.229, batch=216\n",
      "20143: loss=0.038, reward_mean=0.520, reward_bound=0.254, batch=213\n",
      "20144: loss=0.038, reward_mean=0.440, reward_bound=0.282, batch=206\n",
      "20145: loss=0.036, reward_mean=0.390, reward_bound=0.284, batch=214\n",
      "20146: loss=0.037, reward_mean=0.430, reward_bound=0.280, batch=220\n",
      "20147: loss=0.038, reward_mean=0.460, reward_bound=0.314, batch=205\n",
      "20148: loss=0.041, reward_mean=0.410, reward_bound=0.240, batch=213\n",
      "20149: loss=0.042, reward_mean=0.430, reward_bound=0.282, batch=216\n",
      "20150: loss=0.037, reward_mean=0.490, reward_bound=0.314, batch=215\n",
      "20151: loss=0.040, reward_mean=0.440, reward_bound=0.314, batch=219\n",
      "20152: loss=0.039, reward_mean=0.400, reward_bound=0.295, batch=223\n",
      "20153: loss=0.041, reward_mean=0.400, reward_bound=0.314, batch=224\n",
      "20154: loss=0.041, reward_mean=0.450, reward_bound=0.342, batch=227\n",
      "20155: loss=0.040, reward_mean=0.400, reward_bound=0.335, batch=229\n",
      "20156: loss=0.040, reward_mean=0.430, reward_bound=0.349, batch=204\n",
      "20157: loss=0.038, reward_mean=0.430, reward_bound=0.206, batch=211\n",
      "20158: loss=0.037, reward_mean=0.470, reward_bound=0.254, batch=216\n",
      "20159: loss=0.037, reward_mean=0.400, reward_bound=0.314, batch=220\n",
      "20160: loss=0.036, reward_mean=0.410, reward_bound=0.329, batch=224\n",
      "20161: loss=0.036, reward_mean=0.360, reward_bound=0.254, batch=226\n",
      "20162: loss=0.036, reward_mean=0.610, reward_bound=0.349, batch=224\n",
      "20163: loss=0.036, reward_mean=0.430, reward_bound=0.349, batch=226\n",
      "20164: loss=0.036, reward_mean=0.470, reward_bound=0.349, batch=227\n",
      "20165: loss=0.038, reward_mean=0.500, reward_bound=0.387, batch=206\n",
      "20166: loss=0.036, reward_mean=0.540, reward_bound=0.241, batch=214\n",
      "20167: loss=0.035, reward_mean=0.480, reward_bound=0.280, batch=220\n",
      "20168: loss=0.040, reward_mean=0.460, reward_bound=0.314, batch=220\n",
      "20169: loss=0.041, reward_mean=0.470, reward_bound=0.314, batch=222\n",
      "20170: loss=0.041, reward_mean=0.380, reward_bound=0.283, batch=225\n",
      "20171: loss=0.039, reward_mean=0.530, reward_bound=0.349, batch=226\n",
      "20172: loss=0.040, reward_mean=0.420, reward_bound=0.387, batch=222\n",
      "20173: loss=0.041, reward_mean=0.440, reward_bound=0.349, batch=224\n",
      "20174: loss=0.041, reward_mean=0.410, reward_bound=0.377, batch=227\n",
      "20175: loss=0.040, reward_mean=0.490, reward_bound=0.380, batch=229\n",
      "20176: loss=0.040, reward_mean=0.410, reward_bound=0.364, batch=230\n",
      "20177: loss=0.040, reward_mean=0.490, reward_bound=0.376, batch=231\n",
      "20178: loss=0.039, reward_mean=0.370, reward_bound=0.387, batch=229\n",
      "20179: loss=0.038, reward_mean=0.330, reward_bound=0.328, batch=230\n",
      "20180: loss=0.039, reward_mean=0.490, reward_bound=0.349, batch=229\n",
      "20181: loss=0.041, reward_mean=0.460, reward_bound=0.430, batch=190\n",
      "20182: loss=0.039, reward_mean=0.440, reward_bound=0.180, batch=203\n",
      "20183: loss=0.039, reward_mean=0.440, reward_bound=0.206, batch=210\n",
      "20184: loss=0.042, reward_mean=0.460, reward_bound=0.247, batch=217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20185: loss=0.039, reward_mean=0.490, reward_bound=0.277, batch=222\n",
      "20186: loss=0.037, reward_mean=0.390, reward_bound=0.282, batch=219\n",
      "20187: loss=0.038, reward_mean=0.400, reward_bound=0.265, batch=223\n",
      "20188: loss=0.037, reward_mean=0.410, reward_bound=0.220, batch=226\n",
      "20189: loss=0.038, reward_mean=0.490, reward_bound=0.282, batch=225\n",
      "20190: loss=0.039, reward_mean=0.530, reward_bound=0.314, batch=213\n",
      "20191: loss=0.037, reward_mean=0.400, reward_bound=0.178, batch=219\n",
      "20192: loss=0.037, reward_mean=0.440, reward_bound=0.265, batch=223\n",
      "20193: loss=0.040, reward_mean=0.430, reward_bound=0.301, batch=226\n",
      "20194: loss=0.041, reward_mean=0.500, reward_bound=0.349, batch=215\n",
      "20195: loss=0.039, reward_mean=0.480, reward_bound=0.260, batch=220\n",
      "20196: loss=0.041, reward_mean=0.440, reward_bound=0.304, batch=224\n",
      "20197: loss=0.039, reward_mean=0.450, reward_bound=0.314, batch=225\n",
      "20198: loss=0.038, reward_mean=0.550, reward_bound=0.321, batch=227\n",
      "20199: loss=0.038, reward_mean=0.370, reward_bound=0.349, batch=228\n",
      "20200: loss=0.040, reward_mean=0.510, reward_bound=0.387, batch=221\n",
      "20201: loss=0.040, reward_mean=0.420, reward_bound=0.387, batch=223\n",
      "20202: loss=0.041, reward_mean=0.410, reward_bound=0.314, batch=225\n",
      "20203: loss=0.039, reward_mean=0.470, reward_bound=0.396, batch=227\n",
      "20204: loss=0.039, reward_mean=0.380, reward_bound=0.387, batch=228\n",
      "20205: loss=0.040, reward_mean=0.450, reward_bound=0.430, batch=210\n",
      "20206: loss=0.038, reward_mean=0.430, reward_bound=0.216, batch=217\n",
      "20207: loss=0.039, reward_mean=0.480, reward_bound=0.202, batch=222\n",
      "20208: loss=0.038, reward_mean=0.500, reward_bound=0.282, batch=222\n",
      "20209: loss=0.038, reward_mean=0.400, reward_bound=0.314, batch=223\n",
      "20210: loss=0.037, reward_mean=0.580, reward_bound=0.349, batch=225\n",
      "20211: loss=0.038, reward_mean=0.430, reward_bound=0.387, batch=219\n",
      "20212: loss=0.038, reward_mean=0.510, reward_bound=0.349, batch=220\n",
      "20213: loss=0.039, reward_mean=0.540, reward_bound=0.288, batch=224\n",
      "20214: loss=0.037, reward_mean=0.450, reward_bound=0.349, batch=225\n",
      "20215: loss=0.037, reward_mean=0.500, reward_bound=0.329, batch=227\n",
      "20216: loss=0.037, reward_mean=0.390, reward_bound=0.342, batch=229\n",
      "20217: loss=0.037, reward_mean=0.500, reward_bound=0.349, batch=228\n",
      "20218: loss=0.038, reward_mean=0.430, reward_bound=0.387, batch=225\n",
      "20219: loss=0.037, reward_mean=0.410, reward_bound=0.337, batch=227\n",
      "20220: loss=0.037, reward_mean=0.460, reward_bound=0.422, batch=229\n",
      "20221: loss=0.039, reward_mean=0.480, reward_bound=0.430, batch=220\n",
      "20222: loss=0.038, reward_mean=0.400, reward_bound=0.274, batch=224\n",
      "20223: loss=0.037, reward_mean=0.420, reward_bound=0.314, batch=226\n",
      "20224: loss=0.040, reward_mean=0.530, reward_bound=0.349, batch=226\n",
      "20225: loss=0.038, reward_mean=0.390, reward_bound=0.387, batch=225\n",
      "20226: loss=0.038, reward_mean=0.320, reward_bound=0.365, batch=227\n",
      "20227: loss=0.039, reward_mean=0.360, reward_bound=0.422, batch=229\n",
      "20228: loss=0.039, reward_mean=0.550, reward_bound=0.430, batch=229\n",
      "20229: loss=0.039, reward_mean=0.380, reward_bound=0.424, batch=230\n",
      "20230: loss=0.039, reward_mean=0.380, reward_bound=0.464, batch=231\n",
      "20231: loss=0.041, reward_mean=0.450, reward_bound=0.478, batch=178\n",
      "20232: loss=0.038, reward_mean=0.410, reward_bound=0.167, batch=192\n",
      "20233: loss=0.039, reward_mean=0.410, reward_bound=0.191, batch=204\n",
      "20234: loss=0.041, reward_mean=0.480, reward_bound=0.229, batch=209\n",
      "20235: loss=0.041, reward_mean=0.410, reward_bound=0.254, batch=211\n",
      "20236: loss=0.041, reward_mean=0.480, reward_bound=0.282, batch=214\n",
      "20237: loss=0.039, reward_mean=0.340, reward_bound=0.183, batch=220\n",
      "20238: loss=0.043, reward_mean=0.490, reward_bound=0.254, batch=223\n",
      "20239: loss=0.044, reward_mean=0.450, reward_bound=0.282, batch=224\n",
      "20240: loss=0.043, reward_mean=0.430, reward_bound=0.314, batch=223\n",
      "20241: loss=0.044, reward_mean=0.400, reward_bound=0.322, batch=226\n",
      "20242: loss=0.045, reward_mean=0.380, reward_bound=0.349, batch=222\n",
      "20243: loss=0.043, reward_mean=0.520, reward_bound=0.387, batch=215\n",
      "20244: loss=0.044, reward_mean=0.470, reward_bound=0.289, batch=220\n",
      "20245: loss=0.045, reward_mean=0.440, reward_bound=0.229, batch=223\n",
      "20246: loss=0.043, reward_mean=0.470, reward_bound=0.301, batch=226\n",
      "20247: loss=0.043, reward_mean=0.430, reward_bound=0.314, batch=225\n",
      "20248: loss=0.043, reward_mean=0.470, reward_bound=0.349, batch=226\n",
      "20249: loss=0.045, reward_mean=0.470, reward_bound=0.387, batch=227\n",
      "20250: loss=0.045, reward_mean=0.520, reward_bound=0.349, batch=228\n",
      "20251: loss=0.043, reward_mean=0.310, reward_bound=0.430, batch=207\n",
      "20252: loss=0.043, reward_mean=0.520, reward_bound=0.277, batch=215\n",
      "20253: loss=0.043, reward_mean=0.420, reward_bound=0.282, batch=218\n",
      "20254: loss=0.049, reward_mean=0.450, reward_bound=0.349, batch=218\n",
      "20255: loss=0.048, reward_mean=0.420, reward_bound=0.353, batch=222\n",
      "20256: loss=0.045, reward_mean=0.430, reward_bound=0.387, batch=219\n",
      "20257: loss=0.046, reward_mean=0.390, reward_bound=0.364, batch=223\n",
      "20258: loss=0.045, reward_mean=0.370, reward_bound=0.372, batch=226\n",
      "20259: loss=0.046, reward_mean=0.440, reward_bound=0.387, batch=223\n",
      "20260: loss=0.045, reward_mean=0.550, reward_bound=0.322, batch=226\n",
      "20261: loss=0.047, reward_mean=0.520, reward_bound=0.368, batch=228\n",
      "20262: loss=0.043, reward_mean=0.430, reward_bound=0.430, batch=221\n",
      "20263: loss=0.041, reward_mean=0.550, reward_bound=0.478, batch=196\n",
      "20264: loss=0.042, reward_mean=0.360, reward_bound=0.206, batch=206\n",
      "20265: loss=0.046, reward_mean=0.410, reward_bound=0.196, batch=214\n",
      "20266: loss=0.047, reward_mean=0.440, reward_bound=0.229, batch=216\n",
      "20267: loss=0.046, reward_mean=0.470, reward_bound=0.268, batch=221\n",
      "20268: loss=0.046, reward_mean=0.440, reward_bound=0.282, batch=219\n",
      "20269: loss=0.045, reward_mean=0.400, reward_bound=0.295, batch=223\n",
      "20270: loss=0.044, reward_mean=0.480, reward_bound=0.314, batch=221\n",
      "20271: loss=0.042, reward_mean=0.500, reward_bound=0.349, batch=214\n",
      "20272: loss=0.041, reward_mean=0.420, reward_bound=0.314, batch=217\n",
      "20273: loss=0.040, reward_mean=0.500, reward_bound=0.342, batch=222\n",
      "20274: loss=0.041, reward_mean=0.510, reward_bound=0.349, batch=219\n",
      "20275: loss=0.039, reward_mean=0.480, reward_bound=0.387, batch=218\n",
      "20276: loss=0.039, reward_mean=0.470, reward_bound=0.314, batch=221\n",
      "20277: loss=0.039, reward_mean=0.440, reward_bound=0.387, batch=223\n",
      "20278: loss=0.038, reward_mean=0.440, reward_bound=0.387, batch=224\n",
      "20279: loss=0.038, reward_mean=0.540, reward_bound=0.422, batch=227\n",
      "20280: loss=0.038, reward_mean=0.460, reward_bound=0.342, batch=229\n",
      "20281: loss=0.038, reward_mean=0.390, reward_bound=0.430, batch=216\n",
      "20282: loss=0.037, reward_mean=0.470, reward_bound=0.314, batch=218\n",
      "20283: loss=0.037, reward_mean=0.420, reward_bound=0.286, batch=222\n",
      "20284: loss=0.037, reward_mean=0.370, reward_bound=0.349, batch=222\n",
      "20285: loss=0.036, reward_mean=0.430, reward_bound=0.360, batch=225\n",
      "20286: loss=0.036, reward_mean=0.380, reward_bound=0.356, batch=227\n",
      "20287: loss=0.037, reward_mean=0.400, reward_bound=0.387, batch=224\n",
      "20288: loss=0.040, reward_mean=0.320, reward_bound=0.247, batch=227\n",
      "20289: loss=0.036, reward_mean=0.410, reward_bound=0.349, batch=228\n",
      "20290: loss=0.036, reward_mean=0.470, reward_bound=0.353, batch=229\n",
      "20291: loss=0.036, reward_mean=0.350, reward_bound=0.387, batch=229\n",
      "20292: loss=0.036, reward_mean=0.380, reward_bound=0.381, batch=230\n",
      "20293: loss=0.038, reward_mean=0.440, reward_bound=0.430, batch=227\n",
      "20294: loss=0.038, reward_mean=0.460, reward_bound=0.342, batch=229\n",
      "20295: loss=0.038, reward_mean=0.430, reward_bound=0.364, batch=230\n",
      "20296: loss=0.038, reward_mean=0.440, reward_bound=0.387, batch=230\n",
      "20297: loss=0.040, reward_mean=0.470, reward_bound=0.430, batch=229\n",
      "20298: loss=0.040, reward_mean=0.490, reward_bound=0.478, batch=232\n",
      "20299: loss=0.040, reward_mean=0.440, reward_bound=0.478, batch=213\n",
      "20300: loss=0.041, reward_mean=0.370, reward_bound=0.244, batch=219\n",
      "20301: loss=0.042, reward_mean=0.470, reward_bound=0.265, batch=223\n",
      "20302: loss=0.042, reward_mean=0.410, reward_bound=0.282, batch=225\n",
      "20303: loss=0.040, reward_mean=0.540, reward_bound=0.314, batch=226\n",
      "20304: loss=0.042, reward_mean=0.440, reward_bound=0.368, batch=228\n",
      "20305: loss=0.042, reward_mean=0.530, reward_bound=0.387, batch=225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20306: loss=0.039, reward_mean=0.360, reward_bound=0.430, batch=221\n",
      "20307: loss=0.039, reward_mean=0.420, reward_bound=0.387, batch=224\n",
      "20308: loss=0.038, reward_mean=0.600, reward_bound=0.426, batch=227\n",
      "20309: loss=0.038, reward_mean=0.340, reward_bound=0.422, batch=229\n",
      "20310: loss=0.040, reward_mean=0.380, reward_bound=0.328, batch=230\n",
      "20311: loss=0.038, reward_mean=0.550, reward_bound=0.349, batch=229\n",
      "20312: loss=0.038, reward_mean=0.420, reward_bound=0.430, batch=229\n",
      "20313: loss=0.038, reward_mean=0.490, reward_bound=0.401, batch=230\n",
      "20314: loss=0.038, reward_mean=0.510, reward_bound=0.464, batch=231\n",
      "20315: loss=0.038, reward_mean=0.450, reward_bound=0.430, batch=231\n",
      "20316: loss=0.039, reward_mean=0.510, reward_bound=0.478, batch=223\n",
      "20317: loss=0.039, reward_mean=0.500, reward_bound=0.459, batch=226\n",
      "20318: loss=0.038, reward_mean=0.460, reward_bound=0.454, batch=228\n",
      "20319: loss=0.038, reward_mean=0.450, reward_bound=0.392, batch=229\n",
      "20320: loss=0.038, reward_mean=0.430, reward_bound=0.381, batch=230\n",
      "20321: loss=0.038, reward_mean=0.390, reward_bound=0.365, batch=231\n",
      "20322: loss=0.038, reward_mean=0.400, reward_bound=0.430, batch=230\n",
      "20323: loss=0.039, reward_mean=0.500, reward_bound=0.478, batch=226\n",
      "20324: loss=0.039, reward_mean=0.470, reward_bound=0.349, batch=227\n",
      "20325: loss=0.038, reward_mean=0.460, reward_bound=0.422, batch=229\n",
      "20326: loss=0.040, reward_mean=0.430, reward_bound=0.450, batch=230\n",
      "20327: loss=0.042, reward_mean=0.390, reward_bound=0.464, batch=231\n",
      "20328: loss=0.040, reward_mean=0.440, reward_bound=0.478, batch=229\n",
      "20329: loss=0.040, reward_mean=0.520, reward_bound=0.424, batch=230\n",
      "20330: loss=0.040, reward_mean=0.450, reward_bound=0.387, batch=230\n",
      "20331: loss=0.042, reward_mean=0.480, reward_bound=0.406, batch=231\n",
      "20332: loss=0.042, reward_mean=0.380, reward_bound=0.430, batch=231\n",
      "20333: loss=0.042, reward_mean=0.470, reward_bound=0.387, batch=231\n",
      "20334: loss=0.042, reward_mean=0.460, reward_bound=0.349, batch=231\n",
      "20335: loss=0.042, reward_mean=0.530, reward_bound=0.430, batch=231\n",
      "20336: loss=0.040, reward_mean=0.480, reward_bound=0.478, batch=230\n",
      "20337: loss=0.040, reward_mean=0.470, reward_bound=0.464, batch=231\n",
      "20338: loss=0.040, reward_mean=0.520, reward_bound=0.478, batch=230\n",
      "20339: loss=0.040, reward_mean=0.440, reward_bound=0.376, batch=231\n",
      "20340: loss=0.040, reward_mean=0.440, reward_bound=0.478, batch=230\n",
      "20341: loss=0.040, reward_mean=0.440, reward_bound=0.430, batch=230\n",
      "20342: loss=0.042, reward_mean=0.410, reward_bound=0.418, batch=231\n",
      "20344: loss=0.032, reward_mean=0.400, reward_bound=0.000, batch=40\n",
      "20345: loss=0.032, reward_mean=0.400, reward_bound=0.000, batch=80\n",
      "20346: loss=0.029, reward_mean=0.480, reward_bound=0.000, batch=126\n",
      "20347: loss=0.031, reward_mean=0.390, reward_bound=0.001, batch=158\n",
      "20348: loss=0.032, reward_mean=0.390, reward_bound=0.007, batch=180\n",
      "20349: loss=0.034, reward_mean=0.430, reward_bound=0.015, batch=197\n",
      "20350: loss=0.033, reward_mean=0.430, reward_bound=0.027, batch=208\n",
      "20351: loss=0.032, reward_mean=0.470, reward_bound=0.047, batch=216\n",
      "20352: loss=0.035, reward_mean=0.440, reward_bound=0.058, batch=216\n",
      "20353: loss=0.038, reward_mean=0.470, reward_bound=0.072, batch=219\n",
      "20354: loss=0.041, reward_mean=0.420, reward_bound=0.089, batch=219\n",
      "20355: loss=0.040, reward_mean=0.530, reward_bound=0.109, batch=221\n",
      "20356: loss=0.039, reward_mean=0.420, reward_bound=0.122, batch=221\n",
      "20357: loss=0.036, reward_mean=0.410, reward_bound=0.135, batch=219\n",
      "20358: loss=0.035, reward_mean=0.500, reward_bound=0.150, batch=216\n",
      "20359: loss=0.032, reward_mean=0.410, reward_bound=0.167, batch=208\n",
      "20360: loss=0.033, reward_mean=0.390, reward_bound=0.185, batch=189\n",
      "20361: loss=0.032, reward_mean=0.500, reward_bound=0.167, batch=201\n",
      "20362: loss=0.024, reward_mean=0.550, reward_bound=0.206, batch=179\n",
      "20363: loss=0.022, reward_mean=0.440, reward_bound=0.135, batch=193\n",
      "20364: loss=0.022, reward_mean=0.410, reward_bound=0.198, batch=205\n",
      "20365: loss=0.022, reward_mean=0.470, reward_bound=0.206, batch=210\n",
      "20366: loss=0.024, reward_mean=0.400, reward_bound=0.229, batch=185\n",
      "20367: loss=0.023, reward_mean=0.450, reward_bound=0.124, batch=199\n",
      "20368: loss=0.023, reward_mean=0.470, reward_bound=0.135, batch=204\n",
      "20369: loss=0.022, reward_mean=0.420, reward_bound=0.185, batch=210\n",
      "20370: loss=0.021, reward_mean=0.350, reward_bound=0.206, batch=221\n",
      "20371: loss=0.021, reward_mean=0.420, reward_bound=0.206, batch=224\n",
      "20372: loss=0.022, reward_mean=0.470, reward_bound=0.254, batch=193\n",
      "20373: loss=0.020, reward_mean=0.420, reward_bound=0.117, batch=205\n",
      "20374: loss=0.020, reward_mean=0.510, reward_bound=0.185, batch=211\n",
      "20375: loss=0.020, reward_mean=0.520, reward_bound=0.254, batch=216\n",
      "20376: loss=0.023, reward_mean=0.440, reward_bound=0.282, batch=176\n",
      "20377: loss=0.021, reward_mean=0.460, reward_bound=0.122, batch=192\n",
      "20378: loss=0.022, reward_mean=0.520, reward_bound=0.172, batch=204\n",
      "20379: loss=0.024, reward_mean=0.550, reward_bound=0.229, batch=209\n",
      "20380: loss=0.023, reward_mean=0.460, reward_bound=0.215, batch=216\n",
      "20381: loss=0.021, reward_mean=0.400, reward_bound=0.254, batch=216\n",
      "20382: loss=0.022, reward_mean=0.500, reward_bound=0.282, batch=212\n",
      "20383: loss=0.023, reward_mean=0.480, reward_bound=0.292, batch=218\n",
      "20384: loss=0.023, reward_mean=0.490, reward_bound=0.229, batch=221\n",
      "20385: loss=0.028, reward_mean=0.400, reward_bound=0.314, batch=179\n",
      "20386: loss=0.028, reward_mean=0.480, reward_bound=0.150, batch=193\n",
      "20387: loss=0.028, reward_mean=0.440, reward_bound=0.178, batch=205\n",
      "20388: loss=0.030, reward_mean=0.540, reward_bound=0.206, batch=208\n",
      "20389: loss=0.029, reward_mean=0.580, reward_bound=0.254, batch=212\n",
      "20390: loss=0.028, reward_mean=0.480, reward_bound=0.282, batch=213\n",
      "20391: loss=0.027, reward_mean=0.360, reward_bound=0.244, batch=219\n",
      "20392: loss=0.028, reward_mean=0.430, reward_bound=0.254, batch=222\n",
      "20393: loss=0.030, reward_mean=0.330, reward_bound=0.245, batch=225\n",
      "20394: loss=0.028, reward_mean=0.470, reward_bound=0.289, batch=227\n",
      "20395: loss=0.029, reward_mean=0.430, reward_bound=0.314, batch=223\n",
      "20396: loss=0.028, reward_mean=0.500, reward_bound=0.349, batch=155\n",
      "20397: loss=0.031, reward_mean=0.430, reward_bound=0.059, batch=178\n",
      "20398: loss=0.029, reward_mean=0.440, reward_bound=0.080, batch=192\n",
      "20399: loss=0.026, reward_mean=0.420, reward_bound=0.109, batch=202\n",
      "20400: loss=0.025, reward_mean=0.450, reward_bound=0.150, batch=206\n",
      "20401: loss=0.023, reward_mean=0.460, reward_bound=0.185, batch=206\n",
      "20402: loss=0.025, reward_mean=0.540, reward_bound=0.206, batch=209\n",
      "20403: loss=0.025, reward_mean=0.380, reward_bound=0.229, batch=212\n",
      "20404: loss=0.025, reward_mean=0.480, reward_bound=0.254, batch=215\n",
      "20405: loss=0.028, reward_mean=0.480, reward_bound=0.282, batch=205\n",
      "20406: loss=0.027, reward_mean=0.470, reward_bound=0.282, batch=212\n",
      "20407: loss=0.026, reward_mean=0.500, reward_bound=0.314, batch=205\n",
      "20408: loss=0.027, reward_mean=0.470, reward_bound=0.210, batch=213\n",
      "20409: loss=0.026, reward_mean=0.390, reward_bound=0.229, batch=218\n",
      "20410: loss=0.026, reward_mean=0.500, reward_bound=0.257, batch=222\n",
      "20411: loss=0.024, reward_mean=0.360, reward_bound=0.282, batch=224\n",
      "20412: loss=0.024, reward_mean=0.410, reward_bound=0.314, batch=224\n",
      "20413: loss=0.025, reward_mean=0.440, reward_bound=0.349, batch=200\n",
      "20414: loss=0.023, reward_mean=0.470, reward_bound=0.206, batch=211\n",
      "20415: loss=0.024, reward_mean=0.410, reward_bound=0.229, batch=213\n",
      "20416: loss=0.023, reward_mean=0.470, reward_bound=0.271, batch=219\n",
      "20417: loss=0.023, reward_mean=0.510, reward_bound=0.282, batch=221\n",
      "20418: loss=0.023, reward_mean=0.480, reward_bound=0.314, batch=221\n",
      "20419: loss=0.023, reward_mean=0.420, reward_bound=0.282, batch=224\n",
      "20420: loss=0.023, reward_mean=0.420, reward_bound=0.314, batch=225\n",
      "20421: loss=0.023, reward_mean=0.500, reward_bound=0.321, batch=227\n",
      "20422: loss=0.022, reward_mean=0.510, reward_bound=0.342, batch=229\n",
      "20423: loss=0.023, reward_mean=0.430, reward_bound=0.349, batch=220\n",
      "20424: loss=0.023, reward_mean=0.490, reward_bound=0.304, batch=224\n",
      "20425: loss=0.018, reward_mean=0.450, reward_bound=0.387, batch=143\n",
      "20426: loss=0.022, reward_mean=0.500, reward_bound=0.074, batch=170\n",
      "20427: loss=0.022, reward_mean=0.410, reward_bound=0.089, batch=185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20428: loss=0.018, reward_mean=0.380, reward_bound=0.109, batch=201\n",
      "20429: loss=0.019, reward_mean=0.400, reward_bound=0.109, batch=208\n",
      "20430: loss=0.017, reward_mean=0.380, reward_bound=0.122, batch=212\n",
      "20431: loss=0.019, reward_mean=0.520, reward_bound=0.135, batch=213\n",
      "20432: loss=0.018, reward_mean=0.460, reward_bound=0.167, batch=218\n",
      "20433: loss=0.018, reward_mean=0.400, reward_bound=0.185, batch=212\n",
      "20434: loss=0.018, reward_mean=0.360, reward_bound=0.206, batch=219\n",
      "20435: loss=0.018, reward_mean=0.470, reward_bound=0.206, batch=219\n",
      "20436: loss=0.018, reward_mean=0.430, reward_bound=0.203, batch=223\n",
      "20437: loss=0.021, reward_mean=0.450, reward_bound=0.229, batch=221\n",
      "20438: loss=0.023, reward_mean=0.460, reward_bound=0.254, batch=218\n",
      "20439: loss=0.022, reward_mean=0.420, reward_bound=0.282, batch=214\n",
      "20440: loss=0.021, reward_mean=0.440, reward_bound=0.311, batch=220\n",
      "20441: loss=0.021, reward_mean=0.400, reward_bound=0.314, batch=207\n",
      "20442: loss=0.020, reward_mean=0.520, reward_bound=0.224, batch=215\n",
      "20443: loss=0.020, reward_mean=0.480, reward_bound=0.254, batch=217\n",
      "20444: loss=0.020, reward_mean=0.540, reward_bound=0.314, batch=219\n",
      "20445: loss=0.019, reward_mean=0.490, reward_bound=0.328, batch=223\n",
      "20446: loss=0.017, reward_mean=0.430, reward_bound=0.349, batch=198\n",
      "20447: loss=0.016, reward_mean=0.480, reward_bound=0.171, batch=208\n",
      "20448: loss=0.016, reward_mean=0.580, reward_bound=0.229, batch=211\n",
      "20449: loss=0.016, reward_mean=0.480, reward_bound=0.254, batch=213\n",
      "20450: loss=0.015, reward_mean=0.430, reward_bound=0.282, batch=217\n",
      "20451: loss=0.016, reward_mean=0.510, reward_bound=0.314, batch=217\n",
      "20452: loss=0.015, reward_mean=0.470, reward_bound=0.302, batch=222\n",
      "20453: loss=0.015, reward_mean=0.400, reward_bound=0.314, batch=222\n",
      "20454: loss=0.016, reward_mean=0.470, reward_bound=0.349, batch=217\n",
      "20455: loss=0.018, reward_mean=0.480, reward_bound=0.308, batch=222\n",
      "20456: loss=0.018, reward_mean=0.500, reward_bound=0.314, batch=223\n",
      "20457: loss=0.017, reward_mean=0.390, reward_bound=0.229, batch=225\n",
      "20458: loss=0.017, reward_mean=0.480, reward_bound=0.349, batch=226\n",
      "20459: loss=0.017, reward_mean=0.470, reward_bound=0.349, batch=226\n",
      "20460: loss=0.017, reward_mean=0.420, reward_bound=0.298, batch=228\n",
      "20461: loss=0.017, reward_mean=0.450, reward_bound=0.353, batch=229\n",
      "20462: loss=0.019, reward_mean=0.420, reward_bound=0.387, batch=207\n",
      "20463: loss=0.018, reward_mean=0.390, reward_bound=0.254, batch=214\n",
      "20464: loss=0.018, reward_mean=0.440, reward_bound=0.282, batch=217\n",
      "20465: loss=0.018, reward_mean=0.440, reward_bound=0.314, batch=218\n",
      "20466: loss=0.018, reward_mean=0.520, reward_bound=0.260, batch=222\n",
      "20467: loss=0.018, reward_mean=0.380, reward_bound=0.314, batch=221\n",
      "20468: loss=0.018, reward_mean=0.500, reward_bound=0.349, batch=220\n",
      "20469: loss=0.018, reward_mean=0.410, reward_bound=0.314, batch=221\n",
      "20470: loss=0.018, reward_mean=0.480, reward_bound=0.387, batch=217\n",
      "20471: loss=0.018, reward_mean=0.460, reward_bound=0.277, batch=222\n",
      "20472: loss=0.018, reward_mean=0.470, reward_bound=0.360, batch=225\n",
      "20473: loss=0.018, reward_mean=0.380, reward_bound=0.234, batch=227\n",
      "20474: loss=0.018, reward_mean=0.400, reward_bound=0.349, batch=228\n",
      "20475: loss=0.022, reward_mean=0.420, reward_bound=0.392, batch=229\n",
      "20476: loss=0.018, reward_mean=0.470, reward_bound=0.430, batch=120\n",
      "20477: loss=0.012, reward_mean=0.470, reward_bound=0.046, batch=154\n",
      "20478: loss=0.011, reward_mean=0.520, reward_bound=0.097, batch=178\n",
      "20479: loss=0.010, reward_mean=0.430, reward_bound=0.098, batch=193\n",
      "20480: loss=0.012, reward_mean=0.510, reward_bound=0.122, batch=204\n",
      "20481: loss=0.014, reward_mean=0.450, reward_bound=0.150, batch=212\n",
      "20482: loss=0.016, reward_mean=0.480, reward_bound=0.167, batch=214\n",
      "20483: loss=0.016, reward_mean=0.460, reward_bound=0.185, batch=217\n",
      "20484: loss=0.017, reward_mean=0.470, reward_bound=0.206, batch=213\n",
      "20485: loss=0.019, reward_mean=0.490, reward_bound=0.229, batch=216\n",
      "20486: loss=0.018, reward_mean=0.480, reward_bound=0.206, batch=220\n",
      "20487: loss=0.022, reward_mean=0.470, reward_bound=0.254, batch=212\n",
      "20488: loss=0.017, reward_mean=0.480, reward_bound=0.282, batch=196\n",
      "20489: loss=0.020, reward_mean=0.460, reward_bound=0.160, batch=207\n",
      "20490: loss=0.020, reward_mean=0.370, reward_bound=0.150, batch=214\n",
      "20491: loss=0.019, reward_mean=0.390, reward_bound=0.185, batch=218\n",
      "20492: loss=0.017, reward_mean=0.460, reward_bound=0.208, batch=222\n",
      "20493: loss=0.017, reward_mean=0.370, reward_bound=0.236, batch=225\n",
      "20494: loss=0.017, reward_mean=0.490, reward_bound=0.282, batch=218\n",
      "20495: loss=0.016, reward_mean=0.380, reward_bound=0.314, batch=209\n",
      "20496: loss=0.016, reward_mean=0.510, reward_bound=0.254, batch=215\n",
      "20497: loss=0.016, reward_mean=0.530, reward_bound=0.314, batch=217\n",
      "20498: loss=0.015, reward_mean=0.470, reward_bound=0.308, batch=222\n",
      "20499: loss=0.015, reward_mean=0.460, reward_bound=0.349, batch=188\n",
      "20500: loss=0.020, reward_mean=0.460, reward_bound=0.208, batch=201\n",
      "20501: loss=0.016, reward_mean=0.450, reward_bound=0.229, batch=210\n",
      "20502: loss=0.016, reward_mean=0.490, reward_bound=0.254, batch=215\n",
      "20503: loss=0.015, reward_mean=0.490, reward_bound=0.260, batch=220\n",
      "20504: loss=0.016, reward_mean=0.550, reward_bound=0.282, batch=220\n",
      "20505: loss=0.015, reward_mean=0.400, reward_bound=0.254, batch=223\n",
      "20506: loss=0.016, reward_mean=0.500, reward_bound=0.314, batch=214\n",
      "20507: loss=0.018, reward_mean=0.410, reward_bound=0.342, batch=220\n",
      "20508: loss=0.018, reward_mean=0.480, reward_bound=0.338, batch=224\n",
      "20509: loss=0.018, reward_mean=0.450, reward_bound=0.345, batch=227\n",
      "20510: loss=0.018, reward_mean=0.440, reward_bound=0.349, batch=222\n",
      "20511: loss=0.018, reward_mean=0.420, reward_bound=0.336, batch=225\n",
      "20512: loss=0.018, reward_mean=0.430, reward_bound=0.356, batch=227\n",
      "20513: loss=0.018, reward_mean=0.440, reward_bound=0.277, batch=229\n",
      "20514: loss=0.018, reward_mean=0.480, reward_bound=0.349, batch=229\n",
      "20515: loss=0.015, reward_mean=0.490, reward_bound=0.387, batch=190\n",
      "20516: loss=0.017, reward_mean=0.480, reward_bound=0.135, batch=203\n",
      "20517: loss=0.016, reward_mean=0.520, reward_bound=0.185, batch=211\n",
      "20518: loss=0.013, reward_mean=0.430, reward_bound=0.206, batch=217\n",
      "20519: loss=0.013, reward_mean=0.440, reward_bound=0.229, batch=221\n",
      "20520: loss=0.013, reward_mean=0.460, reward_bound=0.254, batch=218\n",
      "20521: loss=0.014, reward_mean=0.400, reward_bound=0.282, batch=217\n",
      "20522: loss=0.013, reward_mean=0.450, reward_bound=0.314, batch=219\n",
      "20523: loss=0.014, reward_mean=0.530, reward_bound=0.349, batch=216\n",
      "20524: loss=0.013, reward_mean=0.450, reward_bound=0.241, batch=221\n",
      "20525: loss=0.013, reward_mean=0.420, reward_bound=0.314, batch=223\n",
      "20526: loss=0.013, reward_mean=0.450, reward_bound=0.349, batch=224\n",
      "20527: loss=0.013, reward_mean=0.480, reward_bound=0.311, batch=227\n",
      "20528: loss=0.013, reward_mean=0.490, reward_bound=0.314, batch=225\n",
      "20529: loss=0.014, reward_mean=0.440, reward_bound=0.387, batch=221\n",
      "20530: loss=0.018, reward_mean=0.500, reward_bound=0.430, batch=170\n",
      "20531: loss=0.014, reward_mean=0.430, reward_bound=0.075, batch=189\n",
      "20532: loss=0.022, reward_mean=0.520, reward_bound=0.122, batch=201\n",
      "20533: loss=0.021, reward_mean=0.380, reward_bound=0.122, batch=207\n",
      "20534: loss=0.020, reward_mean=0.470, reward_bound=0.150, batch=212\n",
      "20535: loss=0.021, reward_mean=0.460, reward_bound=0.185, batch=210\n",
      "20536: loss=0.020, reward_mean=0.380, reward_bound=0.200, batch=217\n",
      "20537: loss=0.018, reward_mean=0.420, reward_bound=0.229, batch=216\n",
      "20538: loss=0.016, reward_mean=0.490, reward_bound=0.254, batch=213\n",
      "20539: loss=0.016, reward_mean=0.500, reward_bound=0.220, batch=219\n",
      "20540: loss=0.016, reward_mean=0.440, reward_bound=0.282, batch=215\n",
      "20541: loss=0.017, reward_mean=0.450, reward_bound=0.314, batch=209\n",
      "20542: loss=0.016, reward_mean=0.420, reward_bound=0.239, batch=216\n",
      "20543: loss=0.016, reward_mean=0.450, reward_bound=0.254, batch=217\n",
      "20544: loss=0.016, reward_mean=0.480, reward_bound=0.314, batch=219\n",
      "20545: loss=0.016, reward_mean=0.450, reward_bound=0.328, batch=223\n",
      "20546: loss=0.014, reward_mean=0.470, reward_bound=0.349, batch=210\n",
      "20547: loss=0.014, reward_mean=0.440, reward_bound=0.254, batch=216\n",
      "20548: loss=0.014, reward_mean=0.460, reward_bound=0.298, batch=221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20549: loss=0.014, reward_mean=0.510, reward_bound=0.349, batch=223\n",
      "20550: loss=0.014, reward_mean=0.490, reward_bound=0.349, batch=225\n",
      "20551: loss=0.015, reward_mean=0.410, reward_bound=0.387, batch=209\n",
      "20552: loss=0.014, reward_mean=0.360, reward_bound=0.194, batch=216\n",
      "20553: loss=0.014, reward_mean=0.380, reward_bound=0.254, batch=220\n",
      "20554: loss=0.014, reward_mean=0.490, reward_bound=0.314, batch=223\n",
      "20555: loss=0.014, reward_mean=0.450, reward_bound=0.229, batch=225\n",
      "20556: loss=0.014, reward_mean=0.440, reward_bound=0.349, batch=225\n",
      "20557: loss=0.014, reward_mean=0.430, reward_bound=0.349, batch=226\n",
      "20558: loss=0.013, reward_mean=0.420, reward_bound=0.368, batch=228\n",
      "20559: loss=0.014, reward_mean=0.440, reward_bound=0.387, batch=223\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-268c6198e298>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfull_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0miter_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterate_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mreward_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mfull_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_batch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPERCENTILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-8636f4a7df1b>\u001b[0m in \u001b[0;36miterate_batches\u001b[0;34m(env, net, batch_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mobs_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mact_probs_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mact_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mact_probs_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random.seed(12345)\n",
    "env = DiscreteOneHotWrapper(gym.make(\"FrozenLake-v0\"))\n",
    "# env = gym.wrappers.Monitor(env, directory=\"mon\", force=True)\n",
    "obs_size = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "net = Net(obs_size, HIDDEN_SIZE, n_actions)\n",
    "objective = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=net.parameters(), lr=0.001)\n",
    "writer = SummaryWriter(comment=\"-frozenlake-tweaked\")\n",
    "\n",
    "full_batch = []\n",
    "for iter_no, batch in enumerate(iterate_batches(env, net, BATCH_SIZE)):\n",
    "    reward_mean = float(np.mean(list(map(lambda s: s.reward, batch))))\n",
    "    full_batch, obs, acts, reward_bound = filter_batch(full_batch + batch, PERCENTILE)\n",
    "    if not full_batch:\n",
    "        continue\n",
    "    obs_v = torch.FloatTensor(obs)\n",
    "    acts_v = torch.LongTensor(acts)\n",
    "    full_batch = full_batch[-500:]\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    action_scores_v = net(obs_v)\n",
    "    loss_v = objective(action_scores_v, acts_v)\n",
    "    loss_v.backward()\n",
    "    optimizer.step()\n",
    "    print(\"%d: loss=%.3f, reward_mean=%.3f, reward_bound=%.3f, batch=%d\" % (iter_no, loss_v.item(), reward_mean, reward_bound, len(full_batch)))\n",
    "    writer.add_scalar(\"loss\", loss_v.item(), iter_no)\n",
    "    writer.add_scalar(\"reward_mean\", reward_mean, iter_no)\n",
    "    writer.add_scalar(\"reward_bound\", reward_bound, iter_no)\n",
    "    if reward_mean > 0.8:\n",
    "        print(\"Solved!\")\n",
    "        break\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 frozenlake_nonslippery.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym.wrappers\n",
    "import gym.envs.toy_text.frozen_lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'max_episode_steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-aea7ccb759bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12345\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoy_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrozen_lake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFrozenLakeEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_slippery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeLimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_episode_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiscreteOneHotWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# env = gym.wrappers.Monitor(env, directory=\"mon\", force=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env, max_episode_steps)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax_episode_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mmax_episode_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_episode_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_episode_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_episode_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_episode_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'max_episode_steps'"
     ]
    }
   ],
   "source": [
    "random.seed(12345)\n",
    "env = gym.envs.toy_text.frozen_lake.FrozenLakeEnv(is_slippery=False)\n",
    "env = gym.wrappers.TimeLimit(env, max_episode_steps=100)\n",
    "env = DiscreteOneHotWrapper(env)\n",
    "# env = gym.wrappers.Monitor(env, directory=\"mon\", force=True)\n",
    "obs_size = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "net = Net(obs_size, HIDDEN_SIZE, n_actions)\n",
    "objective = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=net.parameters(), lr=0.001)\n",
    "writer = SummaryWriter(comment=\"-frozenlake-nonslippery\")\n",
    "\n",
    "full_batch = []\n",
    "for iter_no, batch in enumerate(iterate_batches(env, net, BATCH_SIZE)):\n",
    "    reward_mean = float(np.mean(list(map(lambda s: s.reward, batch))))\n",
    "    full_batch, obs, acts, reward_bound = filter_batch(full_batch + batch, PERCENTILE)\n",
    "    if not full_batch:\n",
    "        continue\n",
    "    obs_v = torch.FloatTensor(obs)\n",
    "    acts_v = torch.LongTensor(acts)\n",
    "    full_batch = full_batch[-500:]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    action_scores_v = net(obs_v)\n",
    "    loss_v = objective(action_scores_v, acts_v)\n",
    "    loss_v.backward()\n",
    "    optimizer.step()\n",
    "    print(\"%d: loss=%.3f, reward_mean=%.3f, reward_bound=%.3f, batch=%d\" % (\n",
    "        iter_no, loss_v.item(), reward_mean, reward_bound, len(full_batch)))\n",
    "    writer.add_scalar(\"loss\", loss_v.item(), iter_no)\n",
    "    writer.add_scalar(\"reward_mean\", reward_mean, iter_no)\n",
    "    writer.add_scalar(\"reward_bound\", reward_bound, iter_no)\n",
    "    if reward_mean > 0.8:\n",
    "        print(\"Solved!\")\n",
    "        break\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
