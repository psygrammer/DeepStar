{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter 3. Deep Learning with PyTorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBXNSATc5XHH",
        "colab_type": "text"
      },
      "source": [
        "# Chapter 3. Deep Learning with PyTorch\n",
        "## Creation of tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l0YNYENjg_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVwyjR2wqnhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = torch.FloatTensor(3,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URufMweUqsO2",
        "colab_type": "code",
        "outputId": "2776c5f0-f819-4ca5-8799-205716ebaf9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "a"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.6741e-36, 0.0000e+00],\n",
              "        [3.7835e-44, 0.0000e+00],\n",
              "        [       nan, 0.0000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLs1tEQc5wG7",
        "colab_type": "text"
      },
      "source": [
        "Pytorch에서 3*2 사이즈의 tensor를 만들었지만 초기화 하지 않았기 때문에 tensor를 clear하기 위해서 아래의 코드를 작성한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrNtPNzuAVEZ",
        "colab_type": "text"
      },
      "source": [
        "### 첫번째 방법 : Inplace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OOAy5ymqs_P",
        "colab_type": "code",
        "outputId": "c78ffc9d-bd2f-4ec8-9f79-b51a730ee964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "a.zero_()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUYxQK8W7O09",
        "colab_type": "text"
      },
      "source": [
        "constructor로 tensor를 만드는 또 다른 방법은 Python iterable (list, tuple과 같은) 를 넣는 것이다. 이것은 새롭게 만들어지는 tensor의 내용으로 사용된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_UwIQ2ksAe3",
        "colab_type": "code",
        "outputId": "3eb1a812-0b59-4db9-ee56-c124cd3a2b87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "torch.FloatTensor([[1,2,3],[3,2,1]])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [3., 2., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE3ojbOfAaPD",
        "colab_type": "text"
      },
      "source": [
        "### 두번째 방법 : Functional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kKxJt7v7hi3",
        "colab_type": "text"
      },
      "source": [
        "Numpy를 이용하여 똑같은 zero object를 만들어 본다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIxihIEW7Xda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = np.zeros(shape=(3,2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9DcYSE97qtz",
        "colab_type": "code",
        "outputId": "5d3713b2-a03b-4896-db82-6dd68b3bea3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZT2cgXS7rxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b = torch.tensor(n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAF35HWI7v_M",
        "colab_type": "code",
        "outputId": "aef285b3-97f7-4f74-af41-f289951e407c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "b"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpU7JUuh9UER",
        "colab_type": "text"
      },
      "source": [
        "이전 코드 예시에서는 numpy로 default인 zero initialize한 a double (64-bit float) array를 만들었다.\n",
        "\n",
        "그래서 the DoubleTensor type을 가지게 되었다.\n",
        "\n",
        "하지만 보통 DL에서는 double precision이 요구되지 않고 이것은 extra memory와 performance overhead를 추가한다.\n",
        "\n",
        "보통 32-bit float type 또는 16-bit float type를 사용한다.\n",
        "\n",
        "이러한 tensor들을 만들기 위해 dtype으로 세부사항을 명시해준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9M3jYvG7wuy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = np.zeros(shape=(3,2), dtype=np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEs2FSlp9c1r",
        "colab_type": "code",
        "outputId": "d014d255-62ef-463a-b9ea-af2c0c6e725c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "torch.tensor(n)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDu4WXL89ujS",
        "colab_type": "text"
      },
      "source": [
        "또 다른 방법으로는 torch.tensor에도 dtype argument가 있기 때문에 이를 선택해도 된다.\n",
        "\n",
        "하지만, 여기서 주의 사항은 이 dtype은 PyTorch type의 명시조건을 써줘야 한다. \n",
        "\n",
        "앞선 예제에서는 np.float32였지만 여기에서는 torch.float32이다.\n",
        "\n",
        "PyTorch type들에 대한 것은 torch package에 있으며 예로는 torch.float32, torch.unit8 등이 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I8TzKW59guW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = np.zeros(shape=(3,2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIy-GaoG90Hb",
        "colab_type": "code",
        "outputId": "a72daf0b-4186-4c26-d2d9-4485c20cc5ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "torch.tensor(n, dtype=torch.float32)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqqsDNC3-ARJ",
        "colab_type": "text"
      },
      "source": [
        "(version 참고) 이전 버전에서는 torch.from_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0VULsp0-eaM",
        "colab_type": "text"
      },
      "source": [
        "# Scalar tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp4SgQx795qW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = torch.tensor([1,2,3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfeqksF0-pui",
        "colab_type": "code",
        "outputId": "dfe69b3c-dc20-4eb8-f602-482ed854e93e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ3pQOPf-qRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s = a.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXaKuxil-smL",
        "colab_type": "code",
        "outputId": "21956667-48b9-4979-d48f-87d643afa139",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "s"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFMh11n9-tHO",
        "colab_type": "code",
        "outputId": "1b1c8ef1-c5bb-44d8-e643-fa3399a3c30c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "s.item()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ovt-vjf1-wHh",
        "colab_type": "code",
        "outputId": "d40c4938-62ef-4811-b396-e0e44b1f3e3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.tensor(1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFiHnKA0QEdv",
        "colab_type": "text"
      },
      "source": [
        "# GPU tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9t21a2oSLQa",
        "colab_type": "text"
      },
      "source": [
        "CPU tensor를 만든다음에 GPU memory에 복사하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MECicVlQQHxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = torch.FloatTensor([2,3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X5DrqwfRrwK",
        "colab_type": "code",
        "outputId": "236985b8-34f7-49c7-c2fb-829cb25e9b5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXdANE2uRsdX",
        "colab_type": "code",
        "outputId": "b2bcf366-de79-40cc-8f26-b70eabd8d07c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ca = a.cuda();ca"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 3.], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozk-dOFYuHsV",
        "colab_type": "text"
      },
      "source": [
        "a와 ca 둘다 연산에 쓰이고 모든 GPU-specific machinery는 사용자에게 보여진다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPGutVRSR6IR",
        "colab_type": "code",
        "outputId": "e50111b3-cafe-404a-affa-8972378c8835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a+1"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6aH0KycTIHG",
        "colab_type": "code",
        "outputId": "97ff9831-a6bd-40ce-ec85-bb7c3c4860d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ca+1"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 4.], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeDPXT_dTJih",
        "colab_type": "code",
        "outputId": "7baa8190-0a8b-4f84-a804-115c93be040a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ca.device"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bDr-HHt-7Wb",
        "colab_type": "text"
      },
      "source": [
        "# Tensor and gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJOlBFac--2E",
        "colab_type": "text"
      },
      "source": [
        "gradient-leaf machinery를 잘 이해하기 위한 코드 실습이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoCd6jwCTLZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v1 = torch.tensor([1.0, 1.0], requires_grad=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGmj7Aib_Xm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v2 = torch.tensor([2.0, 2.0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sAODup9_c9G",
        "colab_type": "text"
      },
      "source": [
        "2개의 tensor를 생성했다.\n",
        "\n",
        "v1은 연산을 위한 gradients를 require했고 v2는 그러지 않았다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx2g_vXs_bkp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v_sum = v1 + v2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0zF837O_sHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v_res = (v_sum*2).sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1NU9pPK_wXL",
        "colab_type": "code",
        "outputId": "4a00f57d-3b2d-4956-d6c3-b975f671e253",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "v_res"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(12., grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9zuH7Oo_6d_",
        "colab_type": "text"
      },
      "source": [
        "두 개의 vetor를 element-wise로 더했고([3, 3]), 더한 값을 2배로 곱해서([6, 6]) 요소들을 더했다.\n",
        "\n",
        "그 결과 zero-dimension tensor의 값은 12가 되었다. \n",
        "\n",
        "tensor들의 attributes를 확인해보면 v1과 v2들이 leaf node들인지 그리고 v2를 제외한 모든 변수들이 gradients들을 require하고 있음을 알 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMbWWuXD_xi8",
        "colab_type": "code",
        "outputId": "884a0996-1049-4397-c038-c0684ee66f7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "v1.is_leaf, v2.is_leaf"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGByLA1_A1y5",
        "colab_type": "code",
        "outputId": "127bf735-adb0-43e4-f519-8d11417d9063",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "v_sum.is_leaf, v_res.is_leaf"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False, False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPZY73ZjA6XB",
        "colab_type": "code",
        "outputId": "06921d2c-ee21-408a-b8b9-d49203cbb17f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "v1.requires_grad"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmK0P2kvA-Hn",
        "colab_type": "code",
        "outputId": "28065d70-e85e-4241-bcfc-c2b57af15cc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "v2.requires_grad"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XCzGsDJBBK5",
        "colab_type": "code",
        "outputId": "b6947c3c-6e0d-4933-bd95-352a48b94f4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "v_sum.requires_grad"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBgMenvlBEho",
        "colab_type": "code",
        "outputId": "50e6d736-c99f-42c1-d0ff-edd3b61da4a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "v_res.requires_grad"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OpmarYHBJB0",
        "colab_type": "text"
      },
      "source": [
        "이제 Pytorch에게 그래프의 gradients들을 계산 시켜본다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXRINK1_BH3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v_res.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDIsw6okBSfv",
        "colab_type": "code",
        "outputId": "9d81404b-6d24-4853-b0e3-f657d5536aa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "v1.grad"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHRXoW2R4qQy",
        "colab_type": "text"
      },
      "source": [
        "the backward function으로 그래프에 있는 다른 변수들도 고려하여 v_res variable에 대한 미분을 할 수 있었다.\n",
        "\n",
        "다시 말해, 그래프의 다른 요소들로 인해 the v_res variable는 어떻게 변화하는가?\n",
        "\n",
        "예제에서 보듯이,  v1의 gradient 값인 2는 v1이 1증가할 때마다 v_res는 2씩 증가한다는 것을 알 수 있다.\n",
        "\n",
        "이전에 말했듯이 PyTorch는 requires_grad=True인 leaf tenor들에 대해서만 gradient를 계산할 수 있다. 그래서 v2의 gradient를 확인해보면 아무것도 나오지 않는다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKmkbLgh4x-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v2.grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2sA8MbH49el",
        "colab_type": "text"
      },
      "source": [
        "compution과 memory의 효율성 때문에 이렇게 따로 requires_grad=True로 한 변수들에 대해서만 계산해주는 것이다.\n",
        "\n",
        "gradient descent optimization을 할 때, 모든 매트릭스 중간 연산들에 대해서 gradient를 알고 싶은 것이 아니다. 우리는 오직 모델의parameter(weights)의 loss gradient만 원한다.\n",
        "\n",
        "물론 input data에 대해 gradient를 구하고 싶다면 requires_grad=True를 하면 된다. (it could be useful if you want to generate some adversarial examples to fool the existing NN or adjust pretrained word embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ0_PWxbMcaq",
        "colab_type": "text"
      },
      "source": [
        "# NN building blocks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QwwUw-PD-TC",
        "colab_type": "text"
      },
      "source": [
        "For example, the Linear class implements a feed-forward layer with optional bias:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQtzOKaTBUHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj97u0TJMigO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = nn.Linear(2, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIvzB2SQMlN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v = torch.FloatTensor([1, 2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSKn-8AWMpw3",
        "colab_type": "code",
        "outputId": "123e4a66-754f-4c83-dca4-26f882003762",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "l(v)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.3427, -0.2845, -2.2182,  0.0536, -0.0588], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFBgu7nZM-2e",
        "colab_type": "text"
      },
      "source": [
        "Here, we created a randomly initialized feed-forward layer, with two inputs and five outputs, and applied it to our float tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fiwv2XUgOu98",
        "colab_type": "text"
      },
      "source": [
        "## Sequential Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVMkLfzoGGPJ",
        "colab_type": "text"
      },
      "source": [
        "The best way to demonstrate Sequential is through an example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4fwH126Mqq2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s = nn.Sequential(\n",
        "nn.Linear(2, 5),\n",
        "nn.ReLU(),\n",
        "nn.Linear(5, 20),\n",
        "nn.ReLU(),\n",
        "nn.Linear(20, 10),\n",
        "nn.Dropout(p=0.3),\n",
        "nn.Softmax(dim=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlJDNqYrPNxN",
        "colab_type": "code",
        "outputId": "40d97acd-04f8-4900-88c1-78d70a80c530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "s"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=2, out_features=5, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=5, out_features=20, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=20, out_features=10, bias=True)\n",
              "  (5): Dropout(p=0.3)\n",
              "  (6): Softmax()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6WsjmupPQWs",
        "colab_type": "text"
      },
      "source": [
        "Here, we defined a three-layer NN with softmax on output, \n",
        "applied along dimension 1 (dimension 0 is batch samples), ReLU nonlinearities and dropout.\n",
        "\n",
        "Let's push something through it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agJTBxoyPOaL",
        "colab_type": "code",
        "outputId": "574dc8f8-39cf-44bd-9e0b-23830cbbb730",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "s(torch.FloatTensor([[1,2]]))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0741, 0.0741, 0.1361, 0.0741, 0.1844, 0.0741, 0.0741, 0.0741, 0.1607,\n",
              "         0.0741]], grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYz8Okc1PxME",
        "colab_type": "text"
      },
      "source": [
        "So, our minibatch is one example successfully traversed through the network!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rcy82Ra_WaT-",
        "colab_type": "text"
      },
      "source": [
        "# Custom Layers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaX3zaYGWfPT",
        "colab_type": "text"
      },
      "source": [
        "Let's look at how this can be done for our Sequential example from the previous section, but in a more generic and reusable way (full sample is Chaper03/01modules.py):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNZroXdKXyPj",
        "colab_type": "text"
      },
      "source": [
        "This is our module class that inherits nn.Module. In the constructor, we pass three parameters : \n",
        "\n",
        "\n",
        "*   the size of input\n",
        "*   size of output\n",
        "*   optional dropout probability\n",
        "\n",
        "\n",
        "\n",
        "1.   call the parent's constructor to let it initializw itself.\n",
        "2.   create an already familiar nn.Sequential with a bunch of layers and assign it to our class field named pip. \n",
        "3.   By assigning a Sequential instance to our field, we automatically resigter this module (nn.Sequential inherits from nn.Module as does everything in the nn package)\n",
        "4.   To register, we don't need to call anything, we just assign our submodules to fields.\n",
        "\n",
        "After the constructor finishes, all those fields will be registered automatically ( if you really want to , there is a function in nn.Module to register submodules):\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJvK9wI_Pq38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OurModule(nn.Module):\n",
        "    def __init__(self, num_inputs, num_classes, dropout_prob=0.3):\n",
        "      super(OurModule, self).__init__()\n",
        "      self.pipe = nn.Sequential(\n",
        "      nn.Linear(num_inputs, 5),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(5, 20),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(20, num_classes),\n",
        "      nn.Dropout(p=dropout_prob),\n",
        "      nn.Softmax()\n",
        "      )\n",
        "    def forward(self, x):\n",
        "      return self.pipe(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UTf0E7ZZ0eT",
        "colab_type": "text"
      },
      "source": [
        "Here, we override the forward function with our implementaion of data transformation. \n",
        "\n",
        "As our module is a very simple wrapper around other layers, we just need to ask them to transform the data.\n",
        "\n",
        "Note that to apply a module to the data, you need to call the module as callable (that is, pretend that the module instance is a function and call it with the arguments) and not use the forward() function of the nn.Module class. \n",
        "\n",
        "This is because nn.Module overrides the __call__() method, which is being used when we treat an instance as callable.\n",
        "\n",
        "This method does some nn.Module magic stuff and calls your forward() method.\n",
        "\n",
        "If you call forward() directly, you'll intervene with the nn.Module duty, which can give you wrong results.\n",
        "\n",
        "\n",
        "So, that's what we need to do define our own module.\n",
        "\n",
        "Now, let's use it:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAhfOo9AZzaT",
        "colab_type": "code",
        "outputId": "acb7c204-3bb4-424b-97ef-735e0b5bb744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  net = OurModule(num_inputs=2, num_classes=3)\n",
        "  v = torch.FloatTensor([[2,3]])\n",
        "  out = net(v)\n",
        "  print(net)\n",
        "  print(out)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OurModule(\n",
            "  (pipe): Sequential(\n",
            "    (0): Linear(in_features=2, out_features=5, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=5, out_features=20, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
            "    (5): Dropout(p=0.3)\n",
            "    (6): Softmax()\n",
            "  )\n",
            ")\n",
            "tensor([[0.3283, 0.3869, 0.2849]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syvWpcP6Lvmo",
        "colab_type": "text"
      },
      "source": [
        "We create our module, providing it with the desired number of inputs and outputs, then we create a tensor, wrapped into the Variable and ask our module to transform it, following the same convention of using it as callable. \n",
        "\n",
        "Then we print our network's structure (nn.Module overrides __str__() and __repr__()) to represent the inner structure in a nice way. \n",
        "\n",
        "The last thing we show is the result of the network's transformation.\n",
        "\n",
        "The output of our code should look like this:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy5EiQaEaFmL",
        "colab_type": "text"
      },
      "source": [
        "# Optimizers\n",
        "Now, let's discuss the common blueprint of a training loop:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X02YCW8-dDJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for batch_samples, batch_labels in iterate_batches(data, batch_size=32):\n",
        "  #1\n",
        "  batch_samples_t = torch.tensor(batch_samples)\n",
        "  #2\n",
        "  batch_labels_t = torch.tensor(batch_labels)\n",
        "  #3\n",
        "  out_t = net(batch_samples_t)\n",
        "  #4\n",
        "  loss_t = loss_function(out_t, batch_labels_t)\n",
        "  #5\n",
        "  loss_t.backward()\n",
        "  #6\n",
        "  optimizer.step()\n",
        "  #7\n",
        "  optimizer.sero_grad()\n",
        "  #8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKPsvsCNHBYq",
        "colab_type": "text"
      },
      "source": [
        "# *Plotting stuff\n",
        "the full example code is in Chapter03/02_tensorboard.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twctVM8KHOnK",
        "colab_type": "code",
        "outputId": "63e6f686-2315-49a7-ae9d-7d04832716ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "pip install tensorboardX"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/57/2f0a46538295b8e7f09625da6dd24c23f9d0d7ef119ca1c33528660130d5/tensorboardX-1.7-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.16.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX) (41.0.1)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-1.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAwzU7nLHEet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "from tensorboardX import SummaryWriter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeFFeOrtHLOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  writer = SummaryWriter()\n",
        "  \n",
        "  funcs = {\"sin\":math.sin, \"cos\":math.cos, \"tan\":math.tan}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wm1Nzl1kH0T4",
        "colab_type": "text"
      },
      "source": [
        "We import the required packages, create a writer of data, and define functions that we're going to visualize.\n",
        "\n",
        "By default, SummaryWriter will create a unique directory under the runs directory for every launch, to be able to compare different launches of training.\n",
        "\n",
        "Names of the new directory include the current date and time, and hostname.\n",
        "\n",
        "To override this, you can pass the log_dir argument to SummaryWriter.\n",
        "\n",
        "you also can add a suffix to the name of the directory by passing a comment option, for example to capture different experiments' semanrics, such as dropout=0.3 or strong_regularisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDGja362Hk3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for angle in range(-360, 360):\n",
        "  angle_rad = angle * math.pi / 180\n",
        "  for name, fun in funcs.items():\n",
        "    val = fun(angle_rad)\n",
        "    writer.add_scalar(name, val, angle)\n",
        "    writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcMdX8usNV2e",
        "colab_type": "text"
      },
      "source": [
        "Here, we loop over angle ranges in degrees, convert them into radians, and calculate our functions' values.\n",
        "\n",
        "Every values is being added to the writer using the add_scalar function, which takes three argumetns : the name of the parameter, its valus, and the current iteration( which has to be an integer).\n",
        "\n",
        "The last thing we need to do after the loop is to close the writer. \n",
        "\n",
        "Note that the writer does a periodical flush ( by default, every two minutes), so even in the case of a lengthy optimization process, you still will see your valus.\n",
        "\n",
        "The result of running this will be zero output on the console, but you will see a new directory created inside the runs directory with a single file.\n",
        "\n",
        "To look at the result, we need to start TensorBoard:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_THDxUA_P_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    writer = SummaryWriter()\n",
        "\n",
        "    funcs = {\"sin\": math.sin, \"cos\": math.cos, \"tan\": math.tan}\n",
        "\n",
        "    for angle in range(-360, 360):\n",
        "        angle_rad = angle * math.pi / 180\n",
        "        for name, fun in funcs.items():\n",
        "            val = fun(angle_rad)\n",
        "            writer.add_scalar(name, val, angle)\n",
        "\n",
        "    writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOgGz5IxPNyW",
        "colab_type": "code",
        "outputId": "9234bea0-71c3-4b48-a2d8-b8a4ac0188c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!tensorboard --logdir runs --host 9df31622c663"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorBoard 1.13.1 at http://9df31622c663:6006 (Press CTRL+C to quit)\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe5rUrfmCUOO",
        "colab_type": "text"
      },
      "source": [
        "[텐서보드 참고](https://zzsza.github.io/data/2018/08/30/google-colab/#tensorboard-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tT51W62B3d_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "880ed904-4ed0-479b-f069-99cae790291c"
      },
      "source": [
        "LOG_DIR = 'drive/data/tb_logs'\n",
        "\t\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\t\n",
        "import os\n",
        "if not os.path.exists(LOG_DIR):\n",
        "  os.makedirs(LOG_DIR)\n",
        "\t  \n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR))\n",
        "\t\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\t\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-27 02:04:19--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 34.195.49.195, 54.236.200.27, 52.73.94.166, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|34.195.49.195|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16648024 (16M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab  80%[===============>    ]  12.72M  63.3MB/s               \rngrok-stable-linux- 100%[===================>]  15.88M  68.9MB/s    in 0.2s    \n",
            "\n",
            "2019-05-27 02:04:20 (68.9 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [16648024/16648024]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n",
            "https://027fafa8.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_x9i3odCH_r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1075
        },
        "outputId": "23739cfb-7e16-4066-8718-6d5a88901c6e"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "### input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "### the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "### convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "tbCallBack = TensorBoard(log_dir=LOG_DIR, \n",
        "                         histogram_freq=1,\n",
        "                         write_graph=True,\n",
        "                         write_grads=True,\n",
        "                         batch_size=batch_size,\n",
        "                         write_images=True)\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[tbCallBack])\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/12\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.2714 - acc: 0.9169 - val_loss: 0.0589 - val_acc: 0.9814\n",
            "Epoch 2/12\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.0916 - acc: 0.9723 - val_loss: 0.0425 - val_acc: 0.9858\n",
            "Epoch 3/12\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0681 - acc: 0.9792 - val_loss: 0.0360 - val_acc: 0.9878\n",
            "Epoch 4/12\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0576 - acc: 0.9827 - val_loss: 0.0339 - val_acc: 0.9886\n",
            "Epoch 5/12\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0496 - acc: 0.9849 - val_loss: 0.0317 - val_acc: 0.9904\n",
            "Epoch 6/12\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0415 - acc: 0.9874 - val_loss: 0.0294 - val_acc: 0.9898\n",
            "Epoch 7/12\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0383 - acc: 0.9880 - val_loss: 0.0326 - val_acc: 0.9890\n",
            "Epoch 8/12\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0343 - acc: 0.9891 - val_loss: 0.0286 - val_acc: 0.9905\n",
            "Epoch 9/12\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0321 - acc: 0.9903 - val_loss: 0.0327 - val_acc: 0.9900\n",
            "Epoch 10/12\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.0296 - acc: 0.9906 - val_loss: 0.0276 - val_acc: 0.9914\n",
            "Epoch 11/12\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0267 - acc: 0.9918 - val_loss: 0.0265 - val_acc: 0.9912\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-eb7024dea384>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m           callbacks=[tbCallBack])\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    215\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                             \u001b[0mepoch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    939\u001b[0m                     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m                     \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m                     \u001b[0msummary_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEdDeq5-0Var",
        "colab_type": "text"
      },
      "source": [
        "# Example - Gan on Atari images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNQvzcvT0bH_",
        "colab_type": "text"
      },
      "source": [
        "So, let's get started.\n",
        "\n",
        "The whole example code is in the file Chapter03/03_atari_gan.py\n",
        "\n",
        "Here we'// look at only significant pieces of code, without the import section and constant declaration:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEeDMM9CKVvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import gym.spaces\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlHP_lhhP6fk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InputWrapper(gym.ObservationWrapper):\n",
        "    \"\"\"\n",
        "    Preprocessing of input numpy array:\n",
        "    1. resize image into predefined size\n",
        "    2. move color channel axis to a first place\n",
        "    \"\"\"\n",
        "    def __init__(self, *args):\n",
        "        super(InputWrapper, self).__init__(*args)\n",
        "        assert isinstance(self.observation_space, gym.spaces.Box)\n",
        "        old_space = self.observation_space\n",
        "        self.observation_space = gym.spaces.Box(self.observation(old_space.low), self.observation(old_space.high),\n",
        "                                                dtype=np.float32)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        # resize image\n",
        "        new_obs = cv2.resize(observation, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "        # transform (210, 160, 3) -> (3, 210, 160)\n",
        "        new_obs = np.moveaxis(new_obs, 2, 0)\n",
        "        return new_obs.astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1JXxCrGKaY0",
        "colab_type": "text"
      },
      "source": [
        "This class is wrapper around a Gym game, which includes several transformations:\n",
        " *   Resize input image from 210 * 160 (standard Atari resolution) to a square size 64 * 64\n",
        " *   Move color plane of the image from the last position to first, to meet the PyTorch convention of convolution layers that input a tensor with the shape of channels, height, and width\n",
        " *   Cast the image from bytes to float and rescale its values to a 0..1 range\n",
        " \n",
        " \n",
        " Then we define nn.Module classes:\n",
        " *   Discriminator\n",
        " *   Generator\n",
        " \n",
        " \n",
        " The first takes our scaled color image as input and, by applying five layers of convolutions, converts it into a single number, passed through a sigmoid nonlinearity.\n",
        " \n",
        " The output from Sigmoid is interpreted as the probability that Discriminator thinks our input image is from the real dataset.\n",
        " \n",
        " Generator takes as inout a vector of random numbers (latent vector) and using the \"transposed convolution\" operation (it is also known as deconvolution), converts this vector into a color image of the original resolution.\n",
        " \n",
        "We will not look at those classses here as they are lengthy and not very relevant to our example.\n",
        "\n",
        "You can find them in the complete example file.\n",
        "\n",
        "As input, we'll use screenshots from several Atari games played simultaneously by a random agent.\n",
        "\n",
        "Figure 6 is an example of what the input data looks like and it is generated by the following function:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIe7CGDfKN-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def iterate_batches(envs, batch_size=BATCH_SIZE):\n",
        "    batch = [e.reset() for e in envs]\n",
        "    env_gen = iter(lambda: random.choice(envs), None)\n",
        "\n",
        "    while True:\n",
        "        e = next(env_gen)\n",
        "        obs, reward, is_done, _ = e.step(e.action_space.sample())\n",
        "        if np.mean(obs) > 0.01:\n",
        "            batch.append(obs)\n",
        "        if len(batch) == batch_size:\n",
        "            # Normalising input between -1 to 1\n",
        "            batch_np = np.array(batch, dtype=np.float32) * 2.0 / 255.0 - 1.0\n",
        "            yield torch.tensor(batch_np)\n",
        "            batch.clear()\n",
        "        if is_done:\n",
        "            e.reset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CFjU499vwhK",
        "colab_type": "text"
      },
      "source": [
        "This infinitely samples the environment from the provided array, random actions and remembers observations in the batch list. \n",
        "\n",
        "When the batch becomes of the required size, we covert it to a tensor and yield from the generatoe.\n",
        "\n",
        "The check for the nonzero mean observation is required due to a bug in on e of the games to prevent the filckering of an image.\n",
        "\n",
        "Now let's look at our main function, which prepares models and runs the training loop:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se6hhpKo7_lG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--cuda\", default=False, action='store_true', help=\"Enable cuda computation\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "    envs = [InputWrapper(gym.make(name)) for name in ('Breakout-v0', 'AirRaid-v0', 'Pong-v0')]\n",
        "    input_shape = envs[0].observation_space.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpArgtWf8S4S",
        "colab_type": "text"
      },
      "source": [
        "Here, we process the command-line arguments (which could be only one optional arguments, --cuda, enabling GPU computation mode) and create our environment pool with a wrapper applied.\n",
        "\n",
        "This environment array will be passed to the iterate_batches function to generate training data:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEYKwozR8uAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    writer = SummaryWriter()\n",
        "    net_discr = Discriminator(input_shape=input_shape).to(device)\n",
        "    net_gener = Generator(output_shape=input_shape).to(device)\n",
        "\n",
        "    objective = nn.BCELoss()\n",
        "    gen_optimizer = optim.Adam(params=net_gener.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
        "    dis_optimizer = optim.Adam(params=net_discr.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeP-HsKh9NCA",
        "colab_type": "text"
      },
      "source": [
        "In this piece, we create our classes:\n",
        "*   a summary writer\n",
        "*   both networks\n",
        "*   a loss function\n",
        "*   two optimizers\n",
        "\n",
        "Why two?\n",
        "\n",
        "It's because that's the way that GANs get trained: to train the discriminator, we need to show it both real and fake data samples with appropriate labels (1 for real, 0 for fake).\n",
        "\n",
        "During this pass, we update only the discriminator's parameters.\n",
        "\n",
        "After that, we pass both real and fake samples through the discriminator again, but this time the labels are 1s for all samples, and now we update only the generator's weights.\n",
        "\n",
        "The second pass teaches the generator how to fool the discriminator and confuse real samples with the generated ones:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwwd6lJn-cWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    gen_losses = []\n",
        "    dis_losses = []\n",
        "    iter_no = 0\n",
        "\n",
        "    true_labels_v = torch.ones(BATCH_SIZE, dtype=torch.float32, device=device)\n",
        "    fake_labels_v = torch.zeros(BATCH_SIZE, dtype=torch.float32, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfD8ogiY-iud",
        "colab_type": "text"
      },
      "source": [
        "Here, we define arrays, which will be used to accumulate losses, iterator counters, and variables with the True and Fake labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vkEm3_c-vFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    for batch_v in iterate_batches(envs):\n",
        "        # generate extra fake samples, input is 4D: batch, filters, x, y\n",
        "        gen_input_v = torch.FloatTensor(BATCH_SIZE, LATENT_VECTOR_SIZE, 1, 1).normal_(0, 1).to(device)\n",
        "        batch_v = batch_v.to(device)\n",
        "        gen_output_v = net_gener(gen_input_v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOMtbaeE-0hm",
        "colab_type": "text"
      },
      "source": [
        "At the beginning of the training loop, we generate a random vector and pass it to the Generator network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp3IVWfi_AiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        # train discriminator\n",
        "        dis_optimizer.zero_grad()\n",
        "        dis_output_true_v = net_discr(batch_v)\n",
        "        dis_output_fake_v = net_discr(gen_output_v.detach())\n",
        "        dis_loss = objective(dis_output_true_v, true_labels_v) + objective(dis_output_fake_v, fake_labels_v)\n",
        "        dis_loss.backward()\n",
        "        dis_optimizer.step()\n",
        "        dis_losses.append(dis_loss.item())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOqjWsMc_H10",
        "colab_type": "text"
      },
      "source": [
        "At first, we train the discriminator by applying it two times: to the true data samples in our batch and to the generated ones.\n",
        "\n",
        "We need to call the *detach()* function on the generator's output to prevent gradients of this training pass from flowing into the generator (*detach()* is a method of tensor, which makes a copy of it without connection to the parent's operation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlTsHmkW_uso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        # train generator\n",
        "        gen_optimizer.zero_grad()\n",
        "        dis_output_v = net_discr(gen_output_v)\n",
        "        gen_loss_v = objective(dis_output_v, true_labels_v)\n",
        "        gen_loss_v.backward()\n",
        "        gen_optimizer.step()\n",
        "        gen_losses.append(gen_loss_v.item())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfarBQW4_0Xo",
        "colab_type": "text"
      },
      "source": [
        "Now it's the generator's training time.\n",
        "\n",
        "We pass the generator's output to the discriminator, but now we don't stop the gradients.\n",
        "\n",
        "Instead, we apply the objective function with True labels.\n",
        "\n",
        "It will push our generator in the direction where the samples that it generates make the discriminator confuse them with the real data.\n",
        "\n",
        "That's all real training, and the next couple of lines report losses and feed image samples to TensorBoard:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nVUlUSlAczv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        iter_no += 1\n",
        "        if iter_no % REPORT_EVERY_ITER == 0:\n",
        "            log.info(\"Iter %d: gen_loss=%.3e, dis_loss=%.3e\", iter_no, np.mean(gen_losses), np.mean(dis_losses))\n",
        "            writer.add_scalar(\"gen_loss\", np.mean(gen_losses), iter_no)\n",
        "            writer.add_scalar(\"dis_loss\", np.mean(dis_losses), iter_no)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b37JiZDAlHi",
        "colab_type": "text"
      },
      "source": [
        "The training of this example is quite a lengthy process.\n",
        "\n",
        "On a GTX 1080 GPU, 100 iterations take about 40 seconds. \n",
        "\n",
        "At the beginning, the generated images are completely random noise, but after 10k-20k iterations, the generator becomes more and more proficient at its job and the generated images become more and more simliar to the real game screenshots.\n",
        "\n",
        "My experiments gave the following images after 40k-50k of training iterations (several hours on a GPU):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ8A3Y65Uwt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}